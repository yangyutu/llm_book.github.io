{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Lab: LLM Pretraining\n",
    "\n",
    "Here we directly leverage the decoder architecture we made from previous sections. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from llm_lab.model.rotary_decoder import RotaryDecoderModel\n",
    "from llm_lab.utils.collate_utils import default_data_collator\n",
    "from llm_lab.utils.common_utils import move_to_device\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name =  \"wikitext\"\n",
    "data_config = \"wikitext-2-raw-v1\"\n",
    "text_column_name = \"text\"\n",
    "\n",
    "# model parameters\n",
    "model_name_or_path=\"openai-community/gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(dataset_name, data_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples[text_column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_chunk(tokenized_examples, chunk_size=1024, chunk_key='input_ids'):\n",
    "    keys = list(tokenized_examples.keys())\n",
    "    # use chain to flatten list\n",
    "    concat_examples = {k: list(chain(*tokenized_examples[k])) for k in keys}\n",
    "    total_length = len(concat_examples[chunk_key])\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    \n",
    "    result_dict = {\n",
    "        k: [v[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, v in concat_examples.items()\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = raw_datasets.map(\n",
    "                    tokenize, \n",
    "                    batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data = tokenized_dataset.map(\n",
    "                                    partial(group_and_chunk, \n",
    "                                            chunk_size=256),\n",
    "                                        #chunk_size=tokenizer.model_max_length),\n",
    "                                    batched=True,\n",
    "                                    remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1104\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9327\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 964\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderCausalLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.decoder = RotaryDecoderModel(config)\n",
    "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        hidden_states = self.decoder(input_ids=batch['input_ids'])\n",
    "        logits = self.lm_head(hidden_states)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_loss(batch, model, device):\n",
    "    assert model.training\n",
    "    move_to_device(batch, device)\n",
    "    model_input = {'input_ids':batch['input_ids'],'attention_mask': batch['attention_mask']}\n",
    "    logits = model(model_input)[:,:-1,:].contiguous()\n",
    "    labels = batch['input_ids'][:,1:].contiguous()\n",
    "    flat_labels = labels.view(-1)\n",
    "    flat_logits = logits.view(-1, logits.shape[-1])\n",
    "    loss = F.cross_entropy(flat_logits, flat_labels)\n",
    "    return loss\n",
    "\n",
    "def compute_eval_loss(eval_dataloader, model, device):\n",
    "    assert not model.training\n",
    "    all_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            move_to_device(batch, device)\n",
    "            model_input = {'input_ids':batch['input_ids'],'attention_mask': batch['attention_mask']}\n",
    "            logits = model(model_input)[:,:-1,:].contiguous()\n",
    "            labels = batch['input_ids'][:,1:].contiguous()\n",
    "            flat_labels = labels.view(-1)\n",
    "            flat_logits = logits.view(-1, logits.shape[-1])\n",
    "            losses = F.cross_entropy(flat_logits, flat_labels, reduction='none').tolist()\n",
    "            all_losses.extend(losses)\n",
    "    \n",
    "    mean_loss = np.mean(all_losses)\n",
    "    return mean_loss\n",
    "\n",
    "def train_model_epoch(model, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                optimizer,\n",
    "                device,\n",
    "                train_config):\n",
    "    \n",
    "    global_steps = 0\n",
    "    record_list = []\n",
    "    model = model.to(device)\n",
    "    for epoch in range(train_config.num_epochs):\n",
    "        \n",
    "        \n",
    "        for batch in train_loader:\n",
    "            model.train()\n",
    "            loss = compute_batch_loss(batch, model, device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_steps += 1\n",
    "            if global_steps % train_config.log_freq == 0:\n",
    "                model.eval()\n",
    "                val_loss = compute_eval_loss(val_loader, model, device)\n",
    "                record = {\"epoch\": epoch,\n",
    "                          \"step\": global_steps,\n",
    "                          \"train_loss\": loss.detach().item(),\n",
    "                          \"val_loss\": val_loss}\n",
    "                print(record)\n",
    "                record_list.append(record)\n",
    "        \n",
    "    return record_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(model, train_settings, chunk_data):\n",
    "    \n",
    "    torch.manual_seed(train_settings.seed)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "            \n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                  lr=train_settings.learning_rate,\n",
    "                                  weight_decay=train_settings.weight_decay)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(chunk_data['train'],\n",
    "                                      batch_size=train_settings.batch_size,\n",
    "                                      shuffle=True,\n",
    "                                        num_workers=0,\n",
    "                                        collate_fn=default_data_collator\n",
    "    )\n",
    "    \n",
    "    val_loader =  DataLoader(chunk_data['validation'],\n",
    "                                      batch_size=train_settings.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                        num_workers=0,\n",
    "                                        collate_fn=default_data_collator\n",
    "    )\n",
    "    \n",
    "    train_model_epoch(model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                optimizer=optimizer,\n",
    "                train_config=train_settings,\n",
    "                device=device)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'step': 50, 'train_loss': 6.443654537200928, 'val_loss': 6.222963180783427}\n",
      "{'epoch': 0, 'step': 100, 'train_loss': 4.750997543334961, 'val_loss': 4.789597112796632}\n",
      "{'epoch': 0, 'step': 150, 'train_loss': 3.582821846008301, 'val_loss': 3.7710027126769075}\n",
      "{'epoch': 0, 'step': 200, 'train_loss': 3.2809979915618896, 'val_loss': 2.950766039287138}\n",
      "{'epoch': 0, 'step': 250, 'train_loss': 2.340188980102539, 'val_loss': 2.3664528295247216}\n",
      "{'epoch': 0, 'step': 300, 'train_loss': 1.801066517829895, 'val_loss': 1.941244657337387}\n",
      "{'epoch': 0, 'step': 350, 'train_loss': 1.3811639547348022, 'val_loss': 1.6324611990018612}\n",
      "{'epoch': 0, 'step': 400, 'train_loss': 1.3440756797790527, 'val_loss': 1.4200505426395214}\n",
      "{'epoch': 0, 'step': 450, 'train_loss': 1.0726163387298584, 'val_loss': 1.2206830867753753}\n",
      "{'epoch': 0, 'step': 500, 'train_loss': 1.0867966413497925, 'val_loss': 1.0942917932776743}\n",
      "{'epoch': 0, 'step': 550, 'train_loss': 0.8598262071609497, 'val_loss': 0.9846969384686359}\n",
      "{'epoch': 0, 'step': 600, 'train_loss': 0.9549437165260315, 'val_loss': 0.8801799913123036}\n",
      "{'epoch': 0, 'step': 650, 'train_loss': 0.9031557440757751, 'val_loss': 0.8039013421655691}\n",
      "{'epoch': 0, 'step': 700, 'train_loss': 0.8120495676994324, 'val_loss': 0.7417791814936555}\n",
      "{'epoch': 0, 'step': 750, 'train_loss': 0.7510650157928467, 'val_loss': 0.6847008255091278}\n",
      "{'epoch': 0, 'step': 800, 'train_loss': 0.33809590339660645, 'val_loss': 0.6356757690936935}\n",
      "{'epoch': 0, 'step': 850, 'train_loss': 0.6464892029762268, 'val_loss': 0.5926566254299581}\n",
      "{'epoch': 0, 'step': 900, 'train_loss': 0.31882891058921814, 'val_loss': 0.553176465954383}\n",
      "{'epoch': 0, 'step': 950, 'train_loss': 0.32380014657974243, 'val_loss': 0.5186385689112097}\n",
      "{'epoch': 0, 'step': 1000, 'train_loss': 0.33788901567459106, 'val_loss': 0.48636644519118244}\n",
      "{'epoch': 0, 'step': 1050, 'train_loss': 0.6999263763427734, 'val_loss': 0.459089873116955}\n",
      "{'epoch': 0, 'step': 1100, 'train_loss': 0.4620920717716217, 'val_loss': 0.43452664378135836}\n",
      "{'epoch': 0, 'step': 1150, 'train_loss': 0.5703980922698975, 'val_loss': 0.4170907893260998}\n",
      "{'epoch': 0, 'step': 1200, 'train_loss': 0.5466711521148682, 'val_loss': 0.39752792490171385}\n",
      "{'epoch': 0, 'step': 1250, 'train_loss': 0.23809491097927094, 'val_loss': 0.3886507183687435}\n",
      "{'epoch': 0, 'step': 1300, 'train_loss': 0.17122578620910645, 'val_loss': 0.3612214343547479}\n",
      "{'epoch': 0, 'step': 1350, 'train_loss': 0.1409422904253006, 'val_loss': 0.34083427321280213}\n",
      "{'epoch': 0, 'step': 1400, 'train_loss': 6.661154747009277, 'val_loss': 6.123573954786629}\n",
      "{'epoch': 0, 'step': 1450, 'train_loss': 6.838023662567139, 'val_loss': 7.107352736063789}\n",
      "{'epoch': 0, 'step': 1500, 'train_loss': 5.402196884155273, 'val_loss': 5.7780526316379905}\n",
      "{'epoch': 0, 'step': 1550, 'train_loss': 5.795349597930908, 'val_loss': 5.197745674303094}\n",
      "{'epoch': 0, 'step': 1600, 'train_loss': 4.0115485191345215, 'val_loss': 3.8669445791473813}\n",
      "{'epoch': 0, 'step': 1650, 'train_loss': 2.7894034385681152, 'val_loss': 3.12959947493059}\n",
      "{'epoch': 0, 'step': 1700, 'train_loss': 2.0540661811828613, 'val_loss': 2.229717187384429}\n",
      "{'epoch': 0, 'step': 1750, 'train_loss': 1.038453221321106, 'val_loss': 0.8255412506691135}\n",
      "{'epoch': 0, 'step': 1800, 'train_loss': 0.4203126132488251, 'val_loss': 0.4903801768560084}\n",
      "{'epoch': 0, 'step': 1850, 'train_loss': 0.5012596845626831, 'val_loss': 0.48142140447567916}\n",
      "{'epoch': 0, 'step': 1900, 'train_loss': 0.22600102424621582, 'val_loss': 0.3803527708124587}\n",
      "{'epoch': 0, 'step': 1950, 'train_loss': 0.5007568597793579, 'val_loss': 0.3485625588653546}\n",
      "{'epoch': 0, 'step': 2000, 'train_loss': 0.21041475236415863, 'val_loss': 0.32181632701462176}\n",
      "{'epoch': 0, 'step': 2050, 'train_loss': 0.3176763653755188, 'val_loss': 0.3046751322628398}\n",
      "{'epoch': 0, 'step': 2100, 'train_loss': 0.09846565872430801, 'val_loss': 0.29371931388523326}\n",
      "{'epoch': 0, 'step': 2150, 'train_loss': 0.20252478122711182, 'val_loss': 0.2771111111363161}\n",
      "{'epoch': 0, 'step': 2200, 'train_loss': 0.16214261949062347, 'val_loss': 0.2664235215644374}\n",
      "{'epoch': 0, 'step': 2250, 'train_loss': 0.14119701087474823, 'val_loss': 0.25505348973423997}\n",
      "{'epoch': 0, 'step': 2300, 'train_loss': 0.2737562954425812, 'val_loss': 0.23661862704544848}\n",
      "{'epoch': 0, 'step': 2350, 'train_loss': 0.3493458032608032, 'val_loss': 0.22827393377719477}\n",
      "{'epoch': 0, 'step': 2400, 'train_loss': 0.23240895569324493, 'val_loss': 0.22066428711606323}\n",
      "{'epoch': 0, 'step': 2450, 'train_loss': 0.15140801668167114, 'val_loss': 0.21372671583573447}\n",
      "{'epoch': 0, 'step': 2500, 'train_loss': 0.18866665661334991, 'val_loss': 0.20593902700711922}\n",
      "{'epoch': 0, 'step': 2550, 'train_loss': 0.0978085920214653, 'val_loss': 0.19847146367217583}\n",
      "{'epoch': 0, 'step': 2600, 'train_loss': 0.09970742464065552, 'val_loss': 0.19472972133768132}\n",
      "{'epoch': 0, 'step': 2650, 'train_loss': 0.13327841460704803, 'val_loss': 0.18756598992034113}\n",
      "{'epoch': 0, 'step': 2700, 'train_loss': 0.0951777771115303, 'val_loss': 0.18229276818889928}\n",
      "{'epoch': 0, 'step': 2750, 'train_loss': 0.042835865169763565, 'val_loss': 0.17783366617429647}\n",
      "{'epoch': 0, 'step': 2800, 'train_loss': 0.12496960908174515, 'val_loss': 0.17223779158541208}\n",
      "{'epoch': 0, 'step': 2850, 'train_loss': 0.13227467238903046, 'val_loss': 0.16804416083002502}\n",
      "{'epoch': 0, 'step': 2900, 'train_loss': 0.11419998109340668, 'val_loss': 0.16558397279405168}\n",
      "{'epoch': 0, 'step': 2950, 'train_loss': 0.07860798388719559, 'val_loss': 0.1626234652470901}\n",
      "{'epoch': 0, 'step': 3000, 'train_loss': 0.028167860582470894, 'val_loss': 0.15936224774573568}\n",
      "{'epoch': 0, 'step': 3050, 'train_loss': 0.2391510307788849, 'val_loss': 0.15681146832444437}\n",
      "{'epoch': 0, 'step': 3100, 'train_loss': 0.08087973296642303, 'val_loss': 0.1915173450127617}\n",
      "{'epoch': 0, 'step': 3150, 'train_loss': 0.01749119721353054, 'val_loss': 0.16021164146267777}\n",
      "{'epoch': 0, 'step': 3200, 'train_loss': 0.08943475037813187, 'val_loss': 0.14926765159547992}\n",
      "{'epoch': 0, 'step': 3250, 'train_loss': 0.13431835174560547, 'val_loss': 0.144858111757363}\n",
      "{'epoch': 0, 'step': 3300, 'train_loss': 0.044864557683467865, 'val_loss': 0.14043828817649318}\n",
      "{'epoch': 0, 'step': 3350, 'train_loss': 0.09199745208024979, 'val_loss': 0.1372048725387087}\n",
      "{'epoch': 0, 'step': 3400, 'train_loss': 0.06369533389806747, 'val_loss': 0.13546580498663374}\n",
      "{'epoch': 0, 'step': 3450, 'train_loss': 0.07315263897180557, 'val_loss': 0.1339990134175203}\n",
      "{'epoch': 0, 'step': 3500, 'train_loss': 0.11597861349582672, 'val_loss': 0.13519489584667266}\n",
      "{'epoch': 0, 'step': 3550, 'train_loss': 0.04917261376976967, 'val_loss': 0.14754994504456728}\n",
      "{'epoch': 0, 'step': 3600, 'train_loss': 0.129360169172287, 'val_loss': 0.1323277017665738}\n",
      "{'epoch': 0, 'step': 3650, 'train_loss': 0.0049327886663377285, 'val_loss': 0.1254068982033933}\n",
      "{'epoch': 0, 'step': 3700, 'train_loss': 0.09100469946861267, 'val_loss': 0.11835431482270431}\n",
      "{'epoch': 0, 'step': 3750, 'train_loss': 0.06171591579914093, 'val_loss': 0.11631832277057659}\n",
      "{'epoch': 0, 'step': 3800, 'train_loss': 0.08852477371692657, 'val_loss': 0.1157995785856468}\n",
      "{'epoch': 0, 'step': 3850, 'train_loss': 0.12755721807479858, 'val_loss': 0.11090309825137172}\n",
      "{'epoch': 0, 'step': 3900, 'train_loss': 0.05371549353003502, 'val_loss': 0.10879962742782757}\n",
      "{'epoch': 0, 'step': 3950, 'train_loss': 0.05349564552307129, 'val_loss': 0.10747613034433395}\n",
      "{'epoch': 0, 'step': 4000, 'train_loss': 0.012558519840240479, 'val_loss': 0.10541309954729426}\n",
      "{'epoch': 0, 'step': 4050, 'train_loss': 0.09193770587444305, 'val_loss': 0.10214402911569342}\n",
      "{'epoch': 0, 'step': 4100, 'train_loss': 0.0913868397474289, 'val_loss': 0.1037580309057891}\n",
      "{'epoch': 0, 'step': 4150, 'train_loss': 0.02239757589995861, 'val_loss': 0.10046021437010047}\n",
      "{'epoch': 0, 'step': 4200, 'train_loss': 0.005583634600043297, 'val_loss': 0.09936721491361006}\n",
      "{'epoch': 0, 'step': 4250, 'train_loss': 0.05004185065627098, 'val_loss': 0.09795382973945699}\n",
      "{'epoch': 0, 'step': 4300, 'train_loss': 0.04048806056380272, 'val_loss': 0.09542155728238375}\n",
      "{'epoch': 0, 'step': 4350, 'train_loss': 0.009602132253348827, 'val_loss': 0.0940444548894769}\n",
      "{'epoch': 0, 'step': 4400, 'train_loss': 0.0307700764387846, 'val_loss': 0.09432680868820614}\n",
      "{'epoch': 0, 'step': 4450, 'train_loss': 0.004550542216747999, 'val_loss': 0.09300336774102817}\n",
      "{'epoch': 0, 'step': 4500, 'train_loss': 0.08975072205066681, 'val_loss': 0.08691104051705038}\n",
      "{'epoch': 0, 'step': 4550, 'train_loss': 5.105496883392334, 'val_loss': 4.866138740711402}\n",
      "{'epoch': 0, 'step': 4600, 'train_loss': 2.2473268508911133, 'val_loss': 2.0137510591185417}\n",
      "{'epoch': 0, 'step': 4650, 'train_loss': 0.20804107189178467, 'val_loss': 0.2932451358992718}\n"
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"max_position_embeddings\": 1024,\n",
    "    \"hidden_size\": 768,         # model dimension\n",
    "    \"intermediate_size\": 768*4,\n",
    "    \"num_key_value_heads\": 2,\n",
    "    \"num_heads\": 4,          # Number of attention heads\n",
    "    \"num_layers\": 6,         # Number of layers\n",
    "    \"attention_dropout\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False,       # Query-key-value bias\n",
    "    \"o_bias\": True,\n",
    "    \"mlp_bias\": True,\n",
    "    \"rms_norm_eps\": 1e-6,\n",
    "    \"dropout\": 0.1,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"causal_attention\": True\n",
    "}\n",
    "\n",
    "model_config = OmegaConf.create(model_config)\n",
    "train_settings = {\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"num_epochs\": 1,\n",
    "    \"batch_size\": 2,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"seed\": 1,\n",
    "    \"log_freq\": 50\n",
    "}\n",
    "\n",
    "train_settings = OmegaConf.create(train_settings)\n",
    "\n",
    "\n",
    "model = DecoderCausalLM(config=model_config)\n",
    "# train model\n",
    "train_main(model, train_settings=train_settings, chunk_data=chunk_data)\n",
    "    \n",
    "\n",
    "# save model\n",
    "#torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# training process\n",
    "# {'epoch': 0, 'step': 950, 'train_loss': 0.3691011965274811, 'val_loss': 0.4959029606489849}\n",
    "# {'epoch': 0, 'step': 1000, 'train_loss': 0.4940517842769623, 'val_loss': 0.4663128215367203}\n",
    "# {'epoch': 0, 'step': 1050, 'train_loss': 0.8797768950462341, 'val_loss': 0.4402653791785611}\n",
    "# {'epoch': 0, 'step': 1100, 'train_loss': 0.34599336981773376, 'val_loss': 0.41212919295760314}\n",
    "# {'epoch': 0, 'step': 1150, 'train_loss': 0.3531911373138428, 'val_loss': 0.4092062050130844}\n",
    "# {'epoch': 0, 'step': 1200, 'train_loss': 0.4641529619693756, 'val_loss': 0.38234950190919664}\n",
    "# {'epoch': 0, 'step': 1250, 'train_loss': 0.22967249155044556, 'val_loss': 0.3607293127420803}\n",
    "# {'epoch': 0, 'step': 1300, 'train_loss': 0.3634558618068695, 'val_loss': 0.3436481123064947}\n",
    "# {'epoch': 0, 'step': 1350, 'train_loss': 0.35325485467910767, 'val_loss': 0.3274566013152589}\n",
    "# {'epoch': 0, 'step': 1400, 'train_loss': 0.09018289297819138, 'val_loss': 0.3139857236895701}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
