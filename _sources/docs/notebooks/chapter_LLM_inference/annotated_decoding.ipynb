{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Lab: Decoding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import os, urllib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from omegaconf import OmegaConf\n",
    "import tiktoken\n",
    "import json\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GreedySampler:\n",
    "    def __call__(self, prompt, max_new_tokens=10):\n",
    "        predictions = []\n",
    "        result = prompt\n",
    "        \n",
    "        for i in range(max_new_tokens):\n",
    "            input_ids = self.encode(result)\n",
    "            next_token_probs = self.get_next_token_prob(input_ids=input_ids)\n",
    "            \n",
    "            # choose the token with the highest probability\n",
    "            id = torch.argmax(next_token_probs, dim=-1).item()\n",
    "            \n",
    "            result += self.decode(id)\n",
    "            predictions.append(next_token_probs[id].item())\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Decoding"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
