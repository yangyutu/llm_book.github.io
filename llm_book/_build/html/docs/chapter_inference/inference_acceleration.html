
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Inference acceleration: Quantization &#8212; LLM Foundations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/chapter_inference/inference_acceleration';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Basic prompt" href="../chapter_prompt/basic_prompt.html" />
    <link rel="prev" title="LLM Inference" href="inference_fundamentals.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/qe-logo-large.png" class="logo__image only-light" alt="LLM Foundations - Home"/>
    <script>document.write(`<img src="../../_static/qe-logo-large.png" class="logo__image only-dark" alt="LLM Foundations - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/language_models.html">Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/neural_language_models.html">Early Neural Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/word_embeddings.html">Word Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/transformers_and_bert.html">Transformers and BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/t5.html">T5</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_dense_architectures.html">LLM Dense Architectures Fundamentals</a></li>

<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_moe_sparse_architectures.html">MOE sparse models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Training</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/training_fundamentals.html">LLM training fundamentals</a></li>

<li class="toctree-l1"><a class="reference internal" href="../chapter_training/finetuning.html">LLM finetuning</a></li>


<li class="toctree-l1"><a class="reference internal" href="../chapter_training/alignment.html">LLM alignement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/accelerated_training.html">LLM Training Acceleration</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Inference</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="inference_fundamentals.html">LLM Inference</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Inference acceleration: Quantization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prompting</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/basic_prompt.html">Basic prompt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/advanced_prompt.html">Advanced prompt techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Retrieval-Augmented Generation (RAG)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/basic_rag.html">Basic RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/advanced_rag.html">Advanced rag techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vision LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/multimodality_fundamentals.html">Multimodality fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/vision_transformers.html">Vision transformers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Application in Information Retrieval</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/information_retrieval_fundamentals.html">Information Retrieval Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/application_LLM_in_IR.html">Application of LLM in IR</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/chapter_inference/inference_acceleration.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Inference acceleration: Quantization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">Basic Concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rtn-quantization">RTN quantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-quantization-performance-trade-off-in-language-models">Basic Quantization-performance trade-off in language models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-quantization-techniques">Advanced quantization techniques</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-int8">LLM.int8()</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smooth-quant">Smooth Quant</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#awq">AWQ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gptq">GPTQ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fp8">FP8</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-software">References and software</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="inference-acceleration-quantization">
<h1>Inference acceleration: Quantization<a class="headerlink" href="#inference-acceleration-quantization" title="Link to this heading">#</a></h1>
<section id="basic-concepts">
<h2>Basic Concepts<a class="headerlink" href="#basic-concepts" title="Link to this heading">#</a></h2>
<p><strong>Quantization</strong> is the process of using a finite number of low-precision values (usually int8) to approximate high-precision (usually float32) numbers with relatively low loss in inference precision.</p>
<p>The objective of quantization is to <strong>reduce memory usage</strong> and improve inference speed without significantly compromising performance.</p>
<p>In the development of different quantization methods, there are</p>
<ul class="simple">
<li><p>QAT (Quantization-Aware-Training), which involves retraining or fine-tuning by approximating the differential rounding operation. While QAT is popular for small neural models, it is rarely used for LLMs.</p></li>
<li><p>PTQ (Post-Training Quantization), which directly quantizes pre-trained LLM models. It requires a small amount of data for determining quantization parameters. This is the mainstream quantization method for LLMs.</p></li>
</ul>
<p>Quantization can be applied to different parts of model, including</p>
<ul class="simple">
<li><p>weights</p></li>
<li><p>activations</p></li>
<li><p>KV Cache</p></li>
</ul>
<p>with different levels of <strong>quantization granularities</strong>, including:</p>
<ul class="simple">
<li><p>per-tensor</p></li>
<li><p>per-token/per-channel</p></li>
<li><p>group-wise</p></li>
</ul>
</section>
<section id="rtn-quantization">
<h2>RTN quantization<a class="headerlink" href="#rtn-quantization" title="Link to this heading">#</a></h2>
<p>The <strong>Round-to-Nearest (RTN) quantization</strong> is a basic method used in the process of quantizing neural networks.</p>
<p>For a given numerical value <span class="math notranslate nohighlight">\(r\)</span>, RTN applies the following quantization formula</p>
<div class="math notranslate nohighlight">
\[q = \operatorname{Clip}(\operatorname{Round}(\frac{r}{s}) + z, q_{min}, q_max)\]</div>
<p>where <span class="math notranslate nohighlight">\(s\)</span> is scaling parameter, <span class="math notranslate nohighlight">\(z\)</span> is the shifting parameter, and <span class="math notranslate nohighlight">\(q_{min}, q_{max}\)</span> are the clipping range.</p>
</section>
<section id="basic-quantization-performance-trade-off-in-language-models">
<h2>Basic Quantization-performance trade-off in language models<a class="headerlink" href="#basic-quantization-performance-trade-off-in-language-models" title="Link to this heading">#</a></h2>
<p>Early research [<span id="id1">[<a class="reference internal" href="../chapter_prompt/advanced_prompt.html#id1493" title="Yelysei Bondarenko, Markus Nagel, and Tijmen Blankevoort. Understanding and overcoming the challenges of efficient transformer quantization. 2021. URL: https://arxiv.org/abs/2109.12948, arXiv:2109.12948.">BNB21</a>]</span>] during the BERT era revealed significant challenges in quantizing large language models. <span id="id2">[<a class="reference internal" href="../chapter_prompt/advanced_prompt.html#id1493" title="Yelysei Bondarenko, Markus Nagel, and Tijmen Blankevoort. Understanding and overcoming the challenges of efficient transformer quantization. 2021. URL: https://arxiv.org/abs/2109.12948, arXiv:2109.12948.">BNB21</a>]</span> demonstrated that applying round-to-nearest (RTN) quantization to both weights and activations of BERT models, reducing them to 8-bit precision, resulted in substantial performance deterioration on language understanding benchmarks.</p>
<p>Further ablation shows that quantization on activation is major cause of the performance drop and quantization on the model weights have minimal impact. The reason is that activation values from FFN’s input and output can have strong outliers, which can directly cause notable error in the quantization process.</p>
<p>As summary in the following table [<span id="id3">[<a class="reference internal" href="../chapter_prompt/advanced_prompt.html#id1493" title="Yelysei Bondarenko, Markus Nagel, and Tijmen Blankevoort. Understanding and overcoming the challenges of efficient transformer quantization. 2021. URL: https://arxiv.org/abs/2109.12948, arXiv:2109.12948.">BNB21</a>]</span>], a strategy of quantizing only the model weights to 8-bit precision while maintaining 32-bit precision for activations (referred to as ‘W8A32’) achieved performance comparable to full-precision models. This finding highlights the importance of selective quantization strategies that preserve critical information in activations while still benefiting from the efficiency gains of weight quantization.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Configuration</p></th>
<th class="head text-center"><p>CoLA</p></th>
<th class="head text-center"><p>SST-2</p></th>
<th class="head text-center"><p>MRPC</p></th>
<th class="head text-center"><p>STS-B</p></th>
<th class="head text-center"><p>QQP</p></th>
<th class="head text-center"><p>MNLI</p></th>
<th class="head text-center"><p>QNLI</p></th>
<th class="head text-center"><p>RTE</p></th>
<th class="head text-center"><p>GLUE</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>FP32</p></td>
<td class="text-center"><p>57.27</p></td>
<td class="text-center"><p>93.12</p></td>
<td class="text-center"><p>88.36</p></td>
<td class="text-center"><p>89.09</p></td>
<td class="text-center"><p>89.72</p></td>
<td class="text-center"><p>84.91</p></td>
<td class="text-center"><p>91.58</p></td>
<td class="text-center"><p>70.40</p></td>
<td class="text-center"><p>83.06</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>W8A8</p></td>
<td class="text-center"><p>54.74</p></td>
<td class="text-center"><p>92.55</p></td>
<td class="text-center"><p>88.53</p></td>
<td class="text-center"><p>81.02</p></td>
<td class="text-center"><p>83.81</p></td>
<td class="text-center"><p>50.31</p></td>
<td class="text-center"><p>52.32</p></td>
<td class="text-center"><p>64.98</p></td>
<td class="text-center"><p>71.03</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>W32A8</p></td>
<td class="text-center"><p>56.70</p></td>
<td class="text-center"><p>92.43</p></td>
<td class="text-center"><p>86.98</p></td>
<td class="text-center"><p>82.87</p></td>
<td class="text-center"><p>84.70</p></td>
<td class="text-center"><p>52.80</p></td>
<td class="text-center"><p>52.44</p></td>
<td class="text-center"><p>53.07</p></td>
<td class="text-center"><p>70.25</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>W8A32</p></td>
<td class="text-center"><p>58.63</p></td>
<td class="text-center"><p>92.55</p></td>
<td class="text-center"><p>88.74</p></td>
<td class="text-center"><p>89.05</p></td>
<td class="text-center"><p>89.72</p></td>
<td class="text-center"><p>84.58</p></td>
<td class="text-center"><p>91.43</p></td>
<td class="text-center"><p>71.12</p></td>
<td class="text-center"><p>83.23</p></td>
</tr>
</tbody>
</table>
</div>
<p>As the model size continues to grow to billions of parameters, outlier features of high magnitude start to emerge in all transformer layers, causing failure of simple low-bit quantization. Dettmers et al. (2022) observed such a phenomenon for OPT models larger than 6.7B parameters. Larger models have more layers with extreme outliers and these outlier features have a significant impact on the model performance. The scale of activation outliers in a few dimensions can be <span class="math notranslate nohighlight">\(\sim 100 \times\)</span> larger than most of the other values.</p>
<p>As language models grow to encompass billions of parameters, a significant challenge emerges: the appearance of high-magnitude outlier features across all transformer layers. This phenomenon compromises the effectiveness of simple low-bit quantization techniques. <span id="id4">[<a class="reference internal" href="../chapter_prompt/advanced_prompt.html#id1494" title="Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. Llm.int8(): 8-bit matrix multiplication for transformers at scale. 2022. URL: https://arxiv.org/abs/2208.07339, arXiv:2208.07339.">DLBZ22</a>]</span> identified this issue in OPT models exceeding 6.7 billion parameters.</p>
<p>The problem intensifies with model size; larger models exhibit more layers with extreme outliers. These outlier features disproportionately influence model performance. In some dimensions, the scale of activation outliers can be approximately 100 times larger than the majority of other values.</p>
<p>This disparity poses a significant challenge for quantization, as traditional methods struggle to accurately represent both the outliers and the more typical values within the same low-bit format. Consequently, addressing these outliers has become a critical focus in the development of quantization techniques for large language models.</p>
</section>
<section id="advanced-quantization-techniques">
<h2>Advanced quantization techniques<a class="headerlink" href="#advanced-quantization-techniques" title="Link to this heading">#</a></h2>
<section id="llm-int8">
<h3>LLM.int8()<a class="headerlink" href="#llm-int8" title="Link to this heading">#</a></h3>
</section>
<section id="smooth-quant">
<h3>Smooth Quant<a class="headerlink" href="#smooth-quant" title="Link to this heading">#</a></h3>
</section>
<section id="awq">
<h3>AWQ<a class="headerlink" href="#awq" title="Link to this heading">#</a></h3>
</section>
<section id="gptq">
<h3>GPTQ<a class="headerlink" href="#gptq" title="Link to this heading">#</a></h3>
</section>
<section id="fp8">
<h3>FP8<a class="headerlink" href="#fp8" title="Link to this heading">#</a></h3>
</section>
</section>
<section id="references-and-software">
<h2>References and software<a class="headerlink" href="#references-and-software" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">https://lilianweng.github.io/posts/2023-01-10-inference-optimization/</a></p>
<p>:bibliography:<code class="docutils literal notranslate"><span class="pre">../llm_book.bib</span></code></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/chapter_inference"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="inference_fundamentals.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">LLM Inference</p>
      </div>
    </a>
    <a class="right-next"
       href="../chapter_prompt/basic_prompt.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Basic prompt</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">Basic Concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rtn-quantization">RTN quantization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-quantization-performance-trade-off-in-language-models">Basic Quantization-performance trade-off in language models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-quantization-techniques">Advanced quantization techniques</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-int8">LLM.int8()</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#smooth-quant">Smooth Quant</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#awq">AWQ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gptq">GPTQ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fp8">FP8</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-software">References and software</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yuguang Yang
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>