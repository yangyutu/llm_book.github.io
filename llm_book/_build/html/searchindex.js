Search.setIndex({"alltitles": {"": [[1, "example-0"], [1, "example-2"], [1, "remark-4"], [1, "example-5"], [6, "remark-2"], [7, "example-0"], [7, "example-1"], [9, "example-0"], [10, "example-0"], [11, "example-0"], [11, "example-1"], [12, "example-0"], [12, "example-2"], [17, "example-3"], [20, "example-0"]], " (Adam stochastic gradient descent algorithm with weight decay)": [[24, "Adam_stochastic_gradient_descent_algorithm_with_weight_decay"]], " (Adam stochastic gradient descent algorithm)": [[24, "Adam_stochastic_gradient_descent_algorithm"]], " (BPE)": [[1, "BPE-algorithm"]], " (Caveats)": [[7, "remark-3"]], " (Comparision of base LLM and instructed LLM in response to a prompt)": [[22, "example-0"]], " (Encoder layer)": [[6, "definition-0"], [10, "chapter_foundation_def_pretrained_LM_transformer_encoder_layer"]], " (Expansion of G_k)": [[24, "remark-2"]], " (FLOPs estimation)": [[1, "remark-6"]], " (How DPO loss work)": [[21, "remark-1"]], " (Is feedforward layer necessary for Transformer?)": [[10, "remark-2"]], " (KV-cache pre-fill for prompts)": [[12, "remark-1"]], " (LoRA low rank matrices initialization)": [[22, "remark-1"]], " (Minibatch stochastic gradient descent algorithm)": [[24, "Minibatch_stochastic_gradient_descent_algorithm"]], " (OBS Neural Network Pruning Algorithm)": [[12, "OBS_network_pruning_algorithm"]], " (Per-channel quantization)": [[12, "example-4"]], " (Per-tensor quantization)": [[12, "example-3"]], " (Practical simple back-off)": [[7, "remark-2"]], " (Relationship to Cross Entropy)": [[7, "remark-4"]], " (Relationship to logistic regression)": [[21, "remark-0"]], " (Skip-gram and CBOW optimization problem)": [[11, "chapter_foundation_word_embedding_def_skipGramOptimization"]], " (Translation pairs can appear naturally in pretraining text corpus)": [[5, "example-0"]], " (What does Byte-level mean?)": [[1, "remark-3"]], " (Zero shot prompt for movie review sentiment classification)": [[17, "example-0"]], " (Zero shot prompt for programming task)": [[17, "example-2"]], " (Zero shot prompt for text extracting)": [[17, "example-1"]], " (choice of minibatch size)": [[24, "remark-1"]], " (computation in decoder module)": [[10, "definition-4"]], " (computation in encoder module)": [[6, "chapter_foundation_def_pretrained_LM_transformer_bert_encoder_computation"], [10, "chapter_foundation_def_pretrained_LM_transformer_encoder_computation"]], "*Reinforcement Learning Essentials": [[23, null]], "A minimal RAG example": [[19, "a-minimal-rag-example"]], "ALBERT": [[6, "albert"]], "ALiBi": [[1, "alibi"]], "AWQ": [[12, "awq"]], "About This Book": [[0, "about-this-book"]], "Absolute Position Encoding": [[1, "absolute-position-encoding"]], "Activation Checkpointing Techniques": [[20, "activation-checkpointing-techniques"]], "Activations": [[20, "activations"]], "Adam": [[24, "adam"]], "Adapter Tuning": [[22, "adapter-tuning"]], "Adaptive Gradient (AdaGrad)": [[24, "adaptive-gradient-adagrad"]], "Adaptive Gradient Method": [[24, "adaptive-gradient-method"]], "Add \\alpha Smoothing And Discounting": [[7, "add-alpha-smoothing-and-discounting"]], "Additional remark RL vs SFT vs DPO": [[21, "additional-remark-rl-vs-sft-vs-dpo"]], "Advanced prompt techniques": [[16, null]], "Advanced quantization techniques": [[12, "advanced-quantization-techniques"]], "Advanced rag techniques": [[18, null]], "Analysis": [[22, "analysis"]], "Appendix": [[20, "appendix"]], "Application in Information Retrieval": [[26, null]], "Application of LLM in IR": [[3, null]], "Arithmetic tasks": [[5, "arithmetic-tasks"]], "BART": [[9, "bart"]], "BERT": [[6, null]], "BERT Architecture": [[6, "bert-architecture"]], "BERT Architecture Componenents": [[6, "bert-architecture-componenents"]], "BERT model parameters": [[6, "id1549"]], "BPE Tokenization": [[1, "bpe-tokenization"]], "Base LLM vs instructed LLM": [[17, "base-llm-vs-instructed-llm"]], "Basic Concepts": [[12, "basic-concepts"]], "Basic prompt": [[17, null]], "Basics": [[12, "basics"], [13, "basics"], [22, "basics"]], "Beam search decoding": [[13, "beam-search-decoding"]], "Benchmarking": [[7, "benchmarking"]], "Bibliography": [[1, "bibliography"], [5, "bibliography"], [6, "bibliography"], [7, "bibliography"], [8, "bibliography"], [9, "bibliography"], [10, "bibliography"], [11, "bibliography"], [12, "bibliography"], [13, "bibliography"], [16, "bibliography"], [17, "bibliography"], [20, "bibliography"], [21, "bibliography"], [22, "bibliography"], [24, "bibliography"]], "Blocked KV Caching via Paged Attention": [[12, "blocked-kv-caching-via-paged-attention"]], "Chain-of-Thought (CoT) Prompting": [[17, "chain-of-thought-cot-prompting"]], "Choice Shuffling Ensembling": [[16, "choice-shuffling-ensembling"]], "Choices Of n And Bias-variance Trade-off": [[7, "choices-of-n-and-bias-variance-trade-off"]], "Closed-book question answering": [[5, "closed-book-question-answering"]], "Combined Together: Adam and AdamW": [[24, "combined-together-adam-and-adamw"]], "Combined with GQA": [[12, "combined-with-gqa"]], "Combining Together: the Med prompt": [[16, "combining-together-the-med-prompt"]], "Common Sense Reasoning": [[5, "common-sense-reasoning"]], "Communication volumne summary for different operations. Let \\Phi be the total data size in one device and N be the total number of devices.": [[20, "id1527"]], "Compared With ELMO": [[6, "compared-with-elmo"]], "Comparison With Recurrent Layer In Sequence Modeling": [[10, "comparison-with-recurrent-layer-in-sequence-modeling"]], "Comparison with other approaches": [[22, "comparison-with-other-approaches"]], "Computation breakdown": [[1, "id1547"], [12, "id1532"]], "Computational Breakdown Analysis": [[10, "computational-breakdown-analysis"]], "Computational complexity": [[13, "computational-complexity"]], "Computational cost with KV Cache": [[12, "computational-cost-with-kv-cache"]], "Continued Pretraining": [[24, "continued-pretraining"]], "Controling beam search behavior": [[13, "controling-beam-search-behavior"]], "DPO": [[21, "dpo"]], "DPO variants": [[21, "dpo-variants"]], "Data mixture and schedule": [[24, "data-mixture-and-schedule"]], "Data sources and cleaning": [[24, "data-sources-and-cleaning"]], "Datasets": [[7, "datasets"]], "Decoder Anatomy": [[10, "decoder-anatomy"]], "Decoding": [[13, null]], "Decoding Fundamentals": [[13, "decoding-fundamentals"]], "Dense Architecture Examples": [[1, "dense-architecture-examples"]], "Different Branches Of Developments": [[10, "different-branches-of-developments"]], "DistillBERT": [[6, "distillbert"]], "Distributed Parallel Training": [[20, "distributed-parallel-training"]], "Driving the DPO": [[21, "driving-the-dpo"]], "Dynamic in-context learning": [[16, "dynamic-in-context-learning"]], "Early Neural Language Models": [[8, null]], "Efficient BERT Models": [[6, "efficient-bert-models"]], "Encoder Computation Summary": [[10, "encoder-computation-summary"]], "Evaluation Metrics": [[7, "evaluation-metrics"]], "Examples of five types of semantic relationships.": [[11, "id1525"]], "Examples of nine types of syntactic relationships.": [[11, "id1526"]], "FP8": [[12, "fp8"]], "Feed-forward Neural Language Model": [[8, "feed-forward-neural-language-model"]], "Few-shot and in-context learning": [[17, "few-shot-and-in-context-learning"]], "Fine-tuning And Evaluation": [[6, "fine-tuning-and-evaluation"]], "Flash Attention": [[20, "flash-attention"]], "Floating Data Types": [[20, "floating-data-types"]], "Forward Pass Computation Breadown": [[1, "forward-pass-computation-breadown"]], "From BPE to BBPE": [[1, "from-bpe-to-bbpe"]], "From Online Softmax To Flash Attention": [[20, "from-online-softmax-to-flash-attention"]], "Fundamentals": [[24, "fundamentals"]], "GPT Series": [[5, null]], "GPT-1": [[5, "gpt-1"]], "GPT-1 Fine Tuning": [[5, "gpt-1-fine-tuning"]], "GPT-2": [[5, "gpt-2"]], "GPT-3": [[5, "gpt-3"]], "GPTQ": [[12, "gptq"]], "GPU Memory Allocation": [[20, "gpu-memory-allocation"]], "GPU Parallel Operations": [[20, "gpu-parallel-operations"]], "General Case": [[12, "general-case"]], "GloVe": [[11, "glove"]], "Greedy decoding": [[13, "greedy-decoding"]], "Grouped Query Attention (GQA)": [[1, "grouped-query-attention-gqa"]], "Groupwise quantization": [[12, "groupwise-quantization"]], "How labeler evaluates the response quality": [[21, "id1531"]], "Human accuracy in identifying whether short (around 200 word) news articles are model generated.": [[5, "id1526"]], "Inference": [[22, "inference"]], "Inference Acceleration": [[12, null]], "Inference Memory Requirement with KV Cache": [[12, "inference-memory-requirement-with-kv-cache"]], "Information Retrieval Fundamentals": [[4, null]], "Input Embeddings": [[6, "input-embeddings"]], "Input Output Conventions": [[10, "input-output-conventions"]], "Instruction Finetuning": [[22, "instruction-finetuning"]], "Introduction": [[5, "introduction"], [5, "id4"], [6, "introduction"], [6, "id19"], [19, "introduction"], [26, null]], "Introduction: LLM in the Age of AI": [[0, null]], "KV Cache": [[12, "kv-cache"]], "Katz\u2019s Back-off": [[7, "katz-s-back-off"]], "LLM Alignement and Preference learning": [[21, null]], "LLM Architectures": [[26, null]], "LLM Architectures Fundamentals": [[1, null]], "LLM Finetuning": [[22, null]], "LLM Foundations": [[26, null]], "LLM Inference": [[26, null]], "LLM Training": [[26, null]], "LLM Training Acceleration": [[20, null]], "LLM Training Fundamentals": [[24, null]], "LLM.int8()": [[12, "llm-int8"]], "L_2 Weight Decay and AdamW": [[24, "l-2-weight-decay-and-adamw"]], "Language Models": [[7, null]], "Language modeling": [[5, "language-modeling"]], "Layer normalization": [[1, "layer-normalization"]], "Layer normalization basics": [[1, "layer-normalization-basics"]], "Layer normalization example choices": [[1, "layer-normalization-example-choices"]], "Layer normalization position": [[1, "layer-normalization-position"]], "LoRA (Low-Rank Adaptation)": [[22, "lora-low-rank-adaptation"]], "MOE LLM in practice": [[2, "moe-llm-in-practice"]], "MOE Sparse Architectures (WIP)": [[2, null]], "MOE architecture fundamentals": [[2, "moe-architecture-fundamentals"]], "Machine Translation": [[5, "machine-translation"]], "Masked Language Modeling (Masked LM)": [[6, "masked-language-modeling-masked-lm"]], "Memory Requirement Breakdown": [[12, "memory-requirement-breakdown"]], "Memory requirement breakdown": [[12, "id1531"]], "MiniLM": [[6, "minilm"]], "Minibatch Stochastic Gradient Descent": [[24, "minibatch-stochastic-gradient-descent"]], "Mistral MOE": [[2, "mistral-moe"]], "Mixed Precision Training": [[20, "mixed-precision-training"]], "MobileBERT": [[6, "mobilebert"]], "Model Distillation": [[6, "model-distillation"]], "Model Evaluation": [[7, "model-evaluation"]], "Model Parameter Estimation": [[7, "model-parameter-estimation"]], "Model and Optimizer States": [[20, "model-and-optimizer-states"]], "Model configuration of Qwen2 and Mistral, which uses GQA (# KV heads is number of groups )": [[1, "id1545"]], "Model parallelism (tensor parallelism)": [[20, "model-parallelism-tensor-parallelism"]], "Momentum Method": [[24, "momentum-method"]], "More On Perplexity": [[7, "more-on-perplexity"]], "Motivation": [[7, "motivation"], [8, "motivation"], [19, "motivation"], [22, "motivation"]], "Motivation and Overview": [[21, "motivation-and-overview"], [22, "motivation-and-overview"]], "Multi Query Attention (MQA)": [[1, "multi-query-attention-mqa"]], "Multi-Head Attention (MHA)": [[1, "multi-head-attention-mha"]], "Multihead Attention With Masks": [[10, "multihead-attention-with-masks"]], "Multilingual Models": [[6, "multilingual-models"]], "Multilingual-BERT (mBERT)": [[6, "multilingual-bert-mbert"]], "Multimodality fundamentals": [[14, null]], "News article generation": [[5, "news-article-generation"]], "Next Sentence Prediction (NSP)": [[6, "next-sentence-prediction-nsp"]], "Noise Contrastive Estimation}": [[11, "noise-contrastive-estimation"]], "Nonlinearity in FFN": [[1, "nonlinearity-in-ffn"]], "Online Softmax Algorithm": [[20, "online-softmax-algorithm"]], "Online Softmax Motivation": [[20, "online-softmax-motivation"]], "Optimization Algorithms": [[24, "optimization-algorithms"]], "Optimization I: negative sampling": [[11, "optimization-i-negative-sampling"]], "Optimization II: down-sampling of frequent words": [[11, "optimization-ii-down-sampling-of-frequent-words"]], "Out Of Vocabulary (OOV) Words And Rare Words": [[7, "out-of-vocabulary-oov-words-and-rare-words"]], "Overall Architecture": [[10, "overall-architecture"]], "Overall methodology": [[21, "overall-methodology"]], "Overview": [[1, "overview"], [9, "overview"], [9, "id3"], [10, "overview"], [11, "overview"], [12, "overview"], [20, "overview"]], "Overview of parallel training techniques": [[20, "overview-of-parallel-training-techniques"]], "Parameter composition in Transformer models": [[1, "parameter-composition-in-transformer-models"]], "Parameter-Efficient Fine Tuning (PEFT)": [[22, "parameter-efficient-fine-tuning-peft"]], "Parameters in a Transformer": [[1, "id1546"]], "Performance Overview": [[5, "performance-overview"]], "Performance comparison among  supervised SOTA neural machine translation models, unsupervised multi-lingual pretrained language models, and GPT-3.": [[5, "id1527"]], "Pointwise FeedForward Layer": [[10, "pointwise-feedforward-layer"]], "Position Encoding and Long Context": [[1, "position-encoding-and-long-context"]], "Position Encodings": [[10, "position-encodings"]], "Pre-training": [[9, "pre-training"]], "Pre-training Tasks": [[6, "pre-training-tasks"]], "Preference data collection": [[21, "preference-data-collection"]], "Preliminary: MDP": [[21, "preliminary-mdp"]], "Preliminary: Preference modeling": [[21, "preliminary-preference-modeling"]], "Pretrained Language Models": [[10, "pretrained-language-models"]], "Pretraining": [[5, "pretraining"], [9, "pretraining"], [24, "pretraining"]], "Pretraining performance analysis": [[9, "pretraining-performance-analysis"]], "Prompting and RAG": [[26, null]], "Properties of RoPE": [[1, "properties-of-rope"]], "Put It Together": [[6, "put-it-together"]], "Quantization Fundamentals": [[12, "quantization-fundamentals"]], "Quantization granularities": [[12, "quantization-granularities"]], "Quantization-performance trade-off in language models": [[12, "quantization-performance-trade-off-in-language-models"]], "Quantized matrix multiplication": [[12, "quantized-matrix-multiplication"]], "RAG": [[19, null]], "RAG Advantages": [[19, "rag-advantages"]], "RAG paradigam overview": [[19, "rag-paradigam-overview"]], "RLHF via PPO": [[21, "rlhf-via-ppo"]], "RMS Norm (Root Mean Square Norm)": [[1, "rms-norm-root-mean-square-norm"]], "RMSProp": [[24, "rmsprop"]], "Recurrent Neural Language Model": [[8, "recurrent-neural-language-model"]], "Reinforcement learning": [[21, "reinforcement-learning"]], "Reward modeling": [[21, "reward-modeling"]], "Rotary Postion Embedding": [[1, "rotary-postion-embedding"]], "SFT": [[21, "sft"]], "SFT Vs RLHF": [[21, "sft-vs-rlhf"]], "SVD based word embeddings": [[11, "svd-based-word-embeddings"]], "Sample Efficient: ELECTRA": [[6, "sample-efficient-electra"]], "Scaling Instruction Finetuning": [[22, "scaling-instruction-finetuning"]], "Self-attention Variants": [[1, "self-attention-variants"]], "Self-generated chain of thought": [[16, "self-generated-chain-of-thought"]], "Seq2Seq: T5 and BART": [[9, null]], "Simple DPO": [[21, "simple-dpo"]], "Sliding Window Attention": [[1, "sliding-window-attention"]], "Smooth Quant": [[12, "smooth-quant"]], "Smoothing And Discounting Techniques": [[7, "smoothing-and-discounting-techniques"]], "Smoothing preference label": [[21, "smoothing-preference-label"]], "Speed-Up Hessian Computation": [[12, "speed-up-hessian-computation"]], "Speical Case: Diagonal Hessian Assumption": [[12, "speical-case-diagonal-hessian-assumption"]], "Standard quantization techniques": [[12, "standard-quantization-techniques"]], "Statistical Language Models": [[7, "statistical-language-models"]], "Storage requirement for different components during LLM training using Adam.": [[20, "id1526"]], "Subword model": [[11, "subword-model"]], "SuperGLUE": [[5, "superglue"]], "T5": [[9, "t5"]], "Table of Contents": [[26, null]], "Temperature-controlled sampling": [[13, "temperature-controlled-sampling"]], "Text Generation Tasks": [[9, "text-generation-tasks"]], "The Decoder Branch": [[10, "the-decoder-branch"]], "The EXTREME Benchmark": [[6, "the-extreme-benchmark"]], "The Encoder Anatomy": [[6, "the-encoder-anatomy"]], "The Encoder Branch": [[10, "the-encoder-branch"]], "The Encoder-decoder Branch": [[10, "the-encoder-decoder-branch"]], "The Error Minimization Framework": [[12, "the-error-minimization-framework"]], "The Memory Requirement For Training LLM": [[20, "the-memory-requirement-for-training-llm"]], "The PPO algorithm": [[21, "the-ppo-algorithm"]], "The Rise of Large Language Models": [[0, "the-rise-of-large-language-models"]], "The basics": [[13, "the-basics"]], "The fundamental challenge of LLM inference": [[12, "the-fundamental-challenge-of-llm-inference"]], "The hyperparameter settings of various pretrained BERT configurations.  BERTBase and BERTLarge are the two most commonly used configurations today;": [[6, "id1548"]], "The hypothesis and method": [[22, "the-hypothesis-and-method"]], "The mechanism": [[1, "the-mechanism"]], "The model": [[11, "the-model"]], "TinyBERT": [[6, "tinybert"]], "Tokenziation, vocabulary, and weight tying": [[1, "tokenziation-vocabulary-and-weight-tying"]], "Top-k and top-p sampling": [[13, "top-k-and-top-p-sampling"]], "Total Memory Requirement": [[20, "total-memory-requirement"]], "Training": [[22, "training"]], "Training Overview": [[24, "training-overview"]], "Training Process": [[20, "training-process"]], "Transformers": [[10, null]], "Transformers Anatomy": [[10, "transformers-anatomy"]], "Understanding RoPE with Visualization": [[1, "understanding-rope-with-visualization"]], "Vision transformers": [[15, null]], "Visualization": [[11, "visualization"]], "What is RAG": [[19, "what-is-rag"]], "Where quantization and dequant happen? What is the trade off": [[12, "where-quantization-and-dequant-happen-what-is-the-trade-off"]], "Word Embeddings": [[11, null]], "Word2Vec": [[11, "word2vec"]], "XLM, XLM-R, And XLM-E": [[6, "xlm-xlm-r-and-xlm-e"]], "ZeRO Via DeepSpeed": [[20, "zero-via-deepspeed"]], "ZeRO-Stage-One": [[20, "zero-stage-one"]], "Zero-shot prompt": [[17, "zero-shot-prompt"]], "\\star Deriving The MLE": [[7, "star-deriving-the-mle"]], "ensemble CoT with self-consistency": [[16, "ensemble-cot-with-self-consistency"]], "n-gram Language Model": [[7, "n-gram-language-model"]]}, "docnames": ["docs/Introduction", "docs/chapter_LLM_arch/LLM_dense_architectures", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures", "docs/chapter_application_IR/application_LLM_in_IR", "docs/chapter_application_IR/information_retrieval_fundamentals", "docs/chapter_foundation/GPT_series", "docs/chapter_foundation/bert", "docs/chapter_foundation/language_models", "docs/chapter_foundation/neural_language_models", "docs/chapter_foundation/t5", "docs/chapter_foundation/transformers", "docs/chapter_foundation/word_embeddings", "docs/chapter_inference/inference_acceleration", "docs/chapter_inference/inference_fundamentals", "docs/chapter_multimodality/multimodality_fundamentals", "docs/chapter_multimodality/vision_transformers", "docs/chapter_prompt/advanced_prompt", "docs/chapter_prompt/basic_prompt", "docs/chapter_rag/advanced_rag", "docs/chapter_rag/basic_rag", "docs/chapter_training/accelerated_training", "docs/chapter_training/alignment", "docs/chapter_training/finetuning", "docs/chapter_training/reinforcement_learning", "docs/chapter_training/training_fundamentals", "docs/chapter_training/training_lab", "docs/index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["docs/Introduction.md", "docs/chapter_LLM_arch/LLM_dense_architectures.md", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures.md", "docs/chapter_application_IR/application_LLM_in_IR.md", "docs/chapter_application_IR/information_retrieval_fundamentals.md", "docs/chapter_foundation/GPT_series.md", "docs/chapter_foundation/bert.md", "docs/chapter_foundation/language_models.md", "docs/chapter_foundation/neural_language_models.md", "docs/chapter_foundation/t5.md", "docs/chapter_foundation/transformers.md", "docs/chapter_foundation/word_embeddings.md", "docs/chapter_inference/inference_acceleration.md", "docs/chapter_inference/inference_fundamentals.md", "docs/chapter_multimodality/multimodality_fundamentals.md", "docs/chapter_multimodality/vision_transformers.md", "docs/chapter_prompt/advanced_prompt.md", "docs/chapter_prompt/basic_prompt.md", "docs/chapter_rag/advanced_rag.md", "docs/chapter_rag/basic_rag.md", "docs/chapter_training/accelerated_training.md", "docs/chapter_training/alignment.md", "docs/chapter_training/finetuning.md", "docs/chapter_training/reinforcement_learning.md", "docs/chapter_training/training_fundamentals.md", "docs/chapter_training/training_lab.md", "docs/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 5, 6, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "0": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "00": 9, "000": [1, 6, 7, 11, 22], "001": 24, "002": 16, "0041": 1, "00510": 12, "00751": 22, "00854": 10, "01": [12, 22], "01000001": 1, "01108": 6, "01652": 22, "01759": 11, "02": 12, "02054": 20, "021": 7, "02116": 6, "02150": 1, "02155": 21, "025": 17, "02531": 6, "02677": 24, "02984": 6, "03": 12, "03167": 1, "03740": 20, "038": 5, "04": 7, "04341": 6, "044715x": [], "04805": [6, 10], "05": [7, 9, 12], "05101": 24, "05202": 1, "05365": 6, "05941": 1, "06": 12, "06174": 20, "06825": 1, "07": [7, 12], "07278": 6, "07291": 6, "07339": 12, "07467": 1, "08": 9, "08144": 6, "08361": 24, "08510": 6, "08730": 9, "08747": 22, "088": 7, "09": [12, 21], "09685": 22, "09864": 1, "0b": 1, "1": [1, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "10": [5, 6, 7, 8, 9, 10, 11, 12, 17, 20, 24], "100": [5, 10, 12, 24], "10000": [1, 10], "100000": [], "10000010": 1, "10001010": 1, "10011000": 1, "10011111": 1, "100m": 20, "10101100": 1, "10183": 10, "1024": [1, 6, 12], "103": [1, 7], "10351": 6, "104": 6, "1045": 8, "1048": 8, "10524": [1, 10], "10533": [1, 10], "10555": 6, "1058346884778766336": [], "10671": [1, 20], "108": 6, "108m": 6, "109": [], "10997": 19, "10b": 1, "10k": [7, 20], "11": [1, 5, 6, 7, 9, 10, 20, 24], "110": [6, 7], "110k": 6, "110m": 6, "111": [], "11100010": 1, "11110000": 1, "11171": 16, "112": 20, "1120": 20, "1137": 8, "1139": 24, "11416": 22, "1147": 24, "1155": 8, "11692": [6, 10], "118": [], "11903": 17, "11916": 17, "11929": 10, "11942": [6, 10], "11b": 20, "12": [1, 5, 6, 9, 10, 12, 17, 20, 22, 24], "120": [7, 20], "1212": [], "12288": 1, "1234": [], "12409": 1, "125m": 5, "127": [12, 20], "128": [1, 6, 20], "12948": 12, "13": [1, 11, 12, 21], "1301": 11, "131k": 1, "13245": 1, "13461": 9, "135": 11, "137": [], "137b": 16, "13b": [1, 5], "14": [1, 5, 9, 20], "140": 9, "1412": 24, "1441": 10, "1450": 10, "146": 11, "14734": 21, "149": [], "15": [1, 6, 9, 11, 17], "1502": 1, "1503": 6, "1536": [], "156": [], "16": [5, 6, 9, 12, 20], "1604": 20, "1607": 11, "1609": 6, "16138": 6, "16384": [], "16452": 16, "16_": [], "16x16": 10, "17": [9, 10, 16, 17, 20, 24], "1706": 24, "1710": [1, 20], "1711": 24, "1723701178611920896": [], "175": [0, 1, 5, 22], "17576": 11, "175b": [1, 5, 21, 22], "176": [], "179b": 1, "17bsdp": 20, "18": [5, 6, 10, 16, 24], "1802": 6, "1806": 9, "1809": 6, "1810": [6, 10], "18223": [1, 24], "18290": 21, "1877": [1, 5, 7, 10], "19": [5, 6, 7, 9, 10, 20, 22], "1901": [1, 5, 6, 7, 10], "1902": 22, "1906": 6, "1907": [6, 10], "1909": [6, 10], "1910": [1, 6, 9, 20], "1911": [1, 6], "192": 1, "1952": 21, "196": [], "19680801": [], "1986": [], "1989": 12, "1993": 12, "1994": 7, "1999": 7, "1b": 22, "1d": 6, "1e": 24, "1f60a": 1, "1g": [5, 12], "1i": 5, "1j": 10, "1m": 10, "1mb": 12, "2": [1, 6, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22, 24], "20": [1, 5, 6, 7, 9, 10, 11, 21, 24], "200": 7, "2001": 24, "2002": 1, "2003": [6, 8], "2004": 6, "2007": 10, "2010": [8, 10], "2011": 24, "2012": 24, "2013": [11, 24], "2014": 24, "2015": [1, 6], "2016": [6, 11, 20, 21], "2017": [1, 6, 9, 10, 11, 20, 21, 24], "2018": [5, 6, 7, 9, 10], "2019": [1, 5, 6, 7, 9, 10, 21, 22], "2020": [1, 5, 6, 7, 9, 10, 20, 21, 24], "2021": [6, 12, 16, 21, 22], "2022": [1, 12, 16, 17, 21, 22], "2023": [1, 12, 16, 21, 24], "2024": [1, 20, 21, 22], "2048": [6, 10, 12], "207b": [], "20ac": 1, "20b": 16, "21": [1, 5, 6, 9, 10, 22], "2104": 1, "2106": [6, 22], "2108": 1, "2109": [12, 22], "2121": 24, "215": 5, "2159": 24, "217": 7, "21783": 1, "22": [1, 7, 10, 16, 17, 21, 22], "2201": 17, "2203": [16, 21], "2205": 17, "2208": 12, "2210": 22, "227": 7, "23": [1, 12, 16, 20, 24], "2303": [1, 24], "2305": [1, 21], "2308": 22, "2310": 1, "2311": 16, "2312": 19, "2334029": 21, "235": [], "24": [1, 5, 6, 9, 12, 20, 21, 22], "2405": 21, "2407": [1, 20], "245": 7, "2454": [], "2455": [], "2456": [], "2458": [], "2459": [], "2460": [], "2461": [], "25": [5, 7, 9, 11, 12], "2500": 24, "255": [12, 20], "256": [1, 6, 10], "2560": [], "257": 1, "26": [5, 9, 11], "267": 7, "269": 17, "27": [5, 12, 16], "278": 7, "28": [1, 5, 7, 20], "288": [5, 22], "28th": 10, "29": [5, 6], "293": 12, "299": 12, "29th": 12, "2_": 10, "2b": 20, "2bsd": 20, "2bsdp": 20, "2bypt": 20, "2d": [1, 11], "2d_": 10, "2gd_": 1, "2h": 20, "2hp": 20, "2j": 10, "2m": 10, "2pas\u00b2b": [], "2psbh": [], "3": [0, 1, 6, 7, 8, 9, 10, 11, 12, 16, 20, 21, 22, 25], "30": [5, 6, 10], "3072": 1, "31": [5, 12, 20], "3111": 11, "3119": 11, "32": [1, 5, 12, 20], "324": 21, "33": [1, 5, 6, 7, 10, 17], "334": 6, "34": 5, "340": 6, "340m": 6, "345": 21, "34bsd": 20, "35": [5, 22], "350": 22, "350m": [], "3584": 20, "36": [11, 12], "3609": [], "3610": [], "3611": [], "3612": [], "3628": [], "3629": [], "3630": [], "3632": [], "3633": [], "37": 5, "3781": 11, "38": 5, "39": [5, 21], "390": 7, "3b": 20, "3bsdp": 20, "3d": 1, "3psbh": [], "3rd": 7, "4": [0, 1, 5, 6, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22], "40": [1, 5, 6, 9, 12, 16, 17], "405b": 1, "4096": [1, 12, 20], "41": [5, 9], "410": 5, "42": 6, "43": 12, "44": [7, 12], "4411": 6, "4421": 6, "45": 5, "46": 9, "475": 7, "48": [7, 17, 20], "49": 5, "4bsbdp": [], "4bsdp": 20, "4d": 10, "4d_": [], "4h": 20, "4n_": [], "4psbh": [], "4sbhp": [], "4x": 12, "5": [5, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22, 24], "50": [1, 6, 12, 17], "500": [1, 6, 11, 22], "500k": 24, "504": [], "50b": 24, "50th": 17, "51": [5, 9, 17], "512": [1, 6, 10], "5140": 1, "52": [5, 12], "521": 7, "53": [5, 9, 12], "536": 1, "54": [5, 12], "540": 0, "540b": 16, "55": [5, 12], "56": [5, 9, 12], "569": 7, "57": [5, 12], "5701": [], "5776": 6, "5788": 6, "58": [5, 12], "584": 1, "586": 17, "59": 9, "5998": 10, "5b": [1, 20], "5bsdp": 20, "5d_": [], "5psbh": [], "5x": 16, "5x2": [], "6": [1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 24], "60": [5, 7], "600": 7, "6008": 10, "61": 9, "611": 12, "62": [5, 9], "626": 12, "628": 7, "63": [5, 12], "64": [1, 12, 20], "643969218": [], "646": 7, "64k": 20, "65": 5, "66": [], "669": 7, "67": [7, 9], "674874586": [], "68": [5, 12], "68g": 12, "69": 9, "6980": 24, "6b": 21, "6t": 1, "7": [5, 7, 9, 11, 12, 16, 17, 20, 21, 22, 24], "70": [5, 7, 12], "700": 24, "70b": 20, "71": [5, 12, 20], "72": [5, 12], "72b": [1, 20, 22], "73": 9, "735": 7, "74": [7, 12], "74m": 5, "75": [9, 13], "76": [5, 9], "760m": [], "768": [5, 6, 12], "77": 9, "78": [5, 7, 17], "79": 5, "79gb": 20, "7b": [1, 5, 12, 20, 21, 24], "8": [1, 5, 6, 7, 9, 10, 11, 12, 17, 20, 24], "80": [1, 5, 6, 9, 12, 19], "800": 6, "81": [9, 12], "8192": 20, "82": [5, 12], "83": [5, 9, 12], "836": 22, "84": [9, 12], "85": 9, "86": [5, 12], "87": [5, 9, 12], "88": [9, 12], "887": 7, "8888": [], "89": [9, 12], "896": [1, 20], "8d_": [], "9": [1, 5, 6, 7, 9, 10, 11, 12, 20, 24, 25], "90": [5, 9, 16], "91": 12, "92": [5, 12, 17], "929": 7, "93": [5, 9, 12, 17], "94": [], "95": 5, "96": [1, 5, 11], "97": 6, "98": 12, "99": 12, "999": 24, "9bsdp": 20, "9gb": 20, "9psbh": [], "A": [0, 1, 6, 7, 8, 9, 11, 12, 17, 20, 21, 22, 24], "AT": 6, "And": [12, 20], "As": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21, 22, 24], "At": [5, 10, 12, 13, 16, 20, 21, 22], "Be": 19, "Being": 11, "But": [7, 11, 17, 20, 22], "By": [0, 1, 5, 6, 7, 10, 11, 12, 13, 16, 19, 21, 24], "FOR": 22, "For": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 21, 22, 24], "IT": 12, "If": [1, 5, 6, 7, 10, 12, 13, 16, 19, 20], "In": [0, 1, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 20, 21, 22, 24], "It": [0, 1, 5, 7, 8, 10, 11, 12, 16, 17, 20, 21, 22, 24], "Its": [], "No": [7, 12, 17, 22], "Not": [11, 20, 24], "OR": 10, "Of": [], "On": [1, 5, 6, 10, 11, 17, 20, 22, 24], "One": [1, 5, 6, 7, 8, 10, 11, 12, 13, 19, 22, 24], "Such": [1, 11, 21], "That": [1, 5, 6, 9, 11, 12, 21, 24], "The": [5, 8, 9, 16, 17, 19, 24], "Their": [1, 6], "Then": [1, 6, 7, 12, 24], "There": [5, 6, 7, 9, 10, 11, 12, 13, 21, 24], "These": [0, 1, 6, 7, 8, 9, 10, 11, 12, 16, 19, 20, 22, 24], "To": [1, 5, 6, 7, 8, 9, 10, 12, 16, 19, 21, 22, 24], "With": [1, 9, 11, 12, 16, 20, 21, 24], "_": [1, 5, 6, 10, 11, 12, 13, 17, 20, 21, 22, 24], "_0": 21, "_1": [1, 10], "_2": 10, "__init__": [], "__version__": [], "_h": 1, "_i": [1, 7, 10, 11], "_j": [1, 10], "_k": [11, 24], "_len": [], "_length": [], "_m": 10, "_n": 13, "_q": 12, "_show_matplotlib_backend": [], "_stack_depth": [], "_t": [11, 13], "_w": 12, "_x": 12, "a_": [1, 5, 6, 21], "a_0": 21, "a_i": 20, "a_j": 20, "a_t": 21, "aakanksha": [16, 22], "aapo": 24, "ab": [1, 6, 10, 12, 17, 20, 21, 22], "abcd": 9, "abdelrahman": 9, "abhimanyu": 1, "abhinav": 1, "abil": [0, 1, 5, 6, 11, 19, 21, 22, 24], "abl": [5, 6, 7, 10, 11, 20], "ablat": [6, 12, 16], "abolut": 1, "about": [1, 5, 6, 12, 22], "abov": [1, 6, 7, 8, 9, 10, 11, 12, 17, 20, 21, 22], "abs_x": [], "absent": 10, "absmax": 12, "absolut": [7, 12, 20], "absorb": 5, "abstract": 9, "acc": 9, "acceler": [0, 1, 10, 26], "accelerated_train": [], "accept": 9, "access": [0, 10, 12, 22], "accommod": 12, "accomplish": [5, 10, 17, 20, 21], "accord": [12, 13, 20, 22], "accordingli": 5, "account": [1, 6], "accum": 12, "accumul": [12, 20, 24], "accur": [6, 7, 9, 12, 16, 17, 19, 22, 24], "accuraci": [0, 7, 12, 16, 19, 20, 21], "achiev": [1, 5, 6, 7, 9, 10, 11, 12, 16, 21, 22], "achin": [1, 9, 10], "acm": 10, "acquir": [1, 5, 6, 24], "across": [0, 1, 5, 6, 9, 10, 11, 12, 16, 17, 19, 20, 22, 24], "act": [1, 10, 17, 22], "action": [17, 21], "actit": 20, "activ": [1, 5, 6, 10, 12], "activations_memori": [], "actor": 21, "actual": [6, 7, 11, 12, 22], "ad": [1, 5, 6, 7, 10, 12, 13, 22, 24], "ada": 16, "adam": [9, 22], "adapt": [1, 5, 6, 10, 13, 16, 17, 21], "adaptor": 22, "add": [1, 6, 9, 10, 12, 13, 20, 21, 22, 24], "addit": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 22, 24], "addition": 20, "address": [1, 10, 11, 12, 17, 19, 20, 22, 24], "adept": 22, "aditya": 6, "adject": [7, 11], "adjust": [6, 11, 12, 24], "admit": 16, "adopt": [1, 5, 6, 9, 10, 20, 21, 22], "advanc": [0, 1, 5, 6, 7, 10, 11, 22, 26], "advanced_prompt": [], "advanced_rag": [], "advantag": [1, 6, 7, 8, 9, 10, 11, 12, 20, 24], "advent": [0, 6], "adventur": 5, "adverb": 11, "adversari": 6, "ae": 10, "aer": 7, "affect": [1, 7, 24], "affin": 12, "afflin": 12, "afford": 20, "aforement": [], "after": [1, 6, 7, 10, 11, 12, 20, 21, 22, 24], "ag": [1, 26], "again": 12, "against": [6, 19, 21], "agarw": 21, "aggreg": [11, 20], "aggress": [1, 12, 22, 24], "aghajanyan": 6, "aghajanyan2018toward": [], "agi": 0, "agnost": [5, 6, 9], "agreement": 7, "ahm": 1, "ai": [1, 7, 11, 19, 21, 22, 26], "aidan": 10, "aim": [0, 1, 5, 6, 7, 8, 10, 13, 16, 19, 20, 22, 24], "ain": 11, "ainsli": 1, "aka": 1, "al": [1, 5, 7, 9, 10, 12, 16, 20, 21], "alben": 20, "albert": [1, 10, 22], "alec": [5, 7, 9, 10, 24], "alex": [21, 22], "alexand": 10, "alexandr": 1, "alexei": 10, "alexi": 6, "alg": [], "algebra": 21, "algorithm": [1, 11, 16], "align": [0, 1, 5, 6, 8, 9, 10, 11, 12, 17, 20, 22, 24, 26], "all": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 19, 20, 21, 22], "allan": 21, "alleg": 7, "allen": 22, "aller": 5, "allevi": [1, 7, 8, 10], "allgath": 20, "alloc": 12, "allow": [0, 1, 6, 8, 9, 10, 11, 12, 17, 19, 20, 22, 24], "allreduc": 20, "almeida": 21, "almost": [], "alon": [5, 6, 10], "along": [1, 5, 19], "aloud": 17, "alpha": [6, 11, 13, 22, 24], "alpha_0": 24, "alpha_k": 24, "alreadi": [], "also": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "altdj": 1, "altern": [6, 7, 11, 13], "although": [1, 6, 8, 10, 11, 20, 22, 24], "alwai": [5, 7, 9, 17, 20], "am": 6, "amanda": [1, 5, 7, 10, 21], "amaz": 17, "amazonaw": [5, 7, 10], "ambigu": 5, "amen": [9, 10], "america": 11, "amodei": [5, 7, 9, 10, 24], "among": [1, 7, 8, 10, 11], "amount": [0, 1, 5, 6, 7, 10, 12, 13, 20, 24], "amper": 20, "an": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "anaconda3": [], "analysi": [6, 11, 12, 21], "analyt": 10, "analyz": [10, 12], "anatomi": 5, "andrea": 22, "andrei": 22, "andrew": [22, 24], "angl": 1, "angola": 11, "ani": [5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 20], "anim": [], "animos": 9, "anli": [], "ann": [1, 7], "annot": [7, 16, 21], "anoth": [1, 6, 7, 8, 10, 11, 21, 22, 24], "answer": [1, 6, 9, 10, 11, 16, 17, 19, 22, 24], "anymor": [], "anyth": [], "apart": 1, "api": [], "appar": 11, "appeal": 1, "appear": [7, 8, 11, 12, 13], "append": [16, 21], "appendix": [], "appl": [6, 11], "appli": [1, 5, 6, 8, 9, 10, 11, 12, 16, 20, 21, 22, 24], "applic": [0, 1, 6, 7, 8, 9, 10, 11, 13, 19, 22, 24], "applicationnlp": [], "applicationrecommendersi": [], "applicationsnlp": [], "applicationsnlp_llm": [], "apporach": 13, "approach": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 21, 24], "appropri": 7, "approx": [7, 10, 11, 12, 20, 22, 24], "approx1": 11, "approxim": [1, 7, 11, 12, 22], "ar": [0, 1, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "arab": 1, "arbitrari": 6, "arbitrarili": [5, 7], "arc": 5, "archit": 21, "architectur": [0, 5, 8, 9, 11, 12, 20, 22], "architecturecombin": [], "architur": 22, "area": 16, "area_estim": [], "arg": [], "argmax": [11, 13], "argmax_": [], "argmin": 11, "argmin_": [], "arguabl": 10, "argument": 1, "aris": [0, 6, 9], "arithemat": 5, "arithemetic_task_gpt3": [], "arithemetictaskgpt3": [], "arithmet": [1, 16, 20], "armand": 11, "armen": 6, "arora2016lat": 11, "around": [7, 11], "arrai": [1, 6, 10, 11, 22], "arriv": [11, 16, 20, 21], "art": [0, 5, 7, 9, 10], "arthur": 1, "articl": [6, 7, 10, 12], "artifici": [0, 1, 7], "artperform": 10, "arvind": [1, 5, 7, 10], "arxiv": [1, 6, 9, 10, 11, 12, 16, 17, 19, 20, 21, 22, 24], "ascii": 1, "ashish": 10, "ask": [5, 9, 17], "askel": [1, 5, 7, 10, 21], "aspect": [8, 10, 21, 22, 24], "assembl": 11, "assess": [5, 19], "asset": [5, 7, 10], "assign": [7, 21], "assist": [0, 19, 21, 22], "associ": [6, 10, 11, 13, 16, 20, 22, 24], "assum": [6, 7, 10, 11, 12, 20, 24], "assumpt": [6, 8, 10, 16], "ast18": 6, "astana": 11, "astronomi": [], "asymmetr": 12, "as\u00b2b": [], "athen": 11, "atom": 11, "att": 10, "attach": 9, "attariyan": 22, "attempt": [5, 17], "attend": [1, 6, 10, 12], "attent": [5, 6, 7, 9, 22], "attentionweight": 1, "attn": 6, "attnet": 1, "attract": [6, 7], "attribut": [], "au": 5, "audio": 7, "aug": 5, "augment": [0, 6, 19], "author": [6, 16], "auto": [5, 9, 10, 24], "autom": 21, "automat": [5, 6, 8, 12], "autonom": [], "autoref": [], "autoregress": [9, 12, 24], "autr": 5, "auxiliari": [5, 6, 16], "auxillari": 21, "auxilliari": [], "avail": [0, 6, 21, 24], "averag": [11, 16, 24], "avil": 24, "avoid": [6, 13, 16, 17, 20, 21, 24], "awai": [5, 10, 11], "awar": 12, "awesom": [], "ax": [], "axi": [], "b": [1, 6, 8, 9, 11, 12, 13, 17, 20, 22, 24], "b_": [1, 10, 11], "b_0": [], "b_1": [1, 6, 10], "b_2": [1, 6, 10], "b_t": [], "b_x": 8, "b_y": 8, "ba": 24, "babak": 12, "babi": 6, "back": [5, 6, 22], "backend": [], "backend_agg": [], "backend_inlin": [], "backends_list": [], "backoff": 7, "backpropag": 20, "backpropg": 5, "backpropog": 20, "backtick": 19, "backward": [6, 10, 20, 22], "bad": [5, 17, 21, 24], "bag": 11, "bai": [], "baichuan": [], "baidu": 20, "bajaj": 6, "balanc": [0, 1, 6, 12, 24], "ball": 24, "bamford": 1, "bandwidth": [1, 12, 20], "bank": [5, 7, 11], "banknot": 7, "bao": 6, "baosong": [1, 10, 20], "bar": [], "barret": [1, 22], "bart": [10, 26], "bart_fine_tun": [], "bart_fine_tuning_classif": 9, "bartcorrupt": [], "base": [1, 5, 6, 7, 8, 9, 10, 12, 13, 16, 19, 20, 24], "baselin": [1, 7, 12, 21], "basi": 11, "basic": [0, 6, 7, 11, 24, 26], "basic_prompt": [], "basic_rag": [], "batch": [1, 6, 10, 12, 20, 21], "batch_siz": [], "batchsiz": [], "bce": [5, 21], "bdvj03": 8, "beam": 12, "beauti": [], "becam": 0, "becaus": [5, 6, 7, 9, 10, 11, 12, 20, 21, 22], "becom": [1, 8, 9, 10, 11, 12, 19, 20, 22, 24], "bedrock": 24, "bedroom": 8, "been": [0, 5, 6, 7, 10, 19, 21, 22], "befor": [1, 5, 6, 9, 10, 12, 13, 16, 17, 20, 24], "began": 0, "begin": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 24], "beginn": [], "behav": 21, "behavior": [1, 5, 6, 9, 21, 22], "behind": [7, 13, 17, 20, 24], "beichen": [1, 24], "beij": 11, "being": [0, 1, 5, 6, 7, 10, 11, 12, 13, 17], "beings": 7, "believ": 7, "belkada": 12, "below": [1, 7, 11, 12], "benchmark": [5, 9, 10, 12, 16, 24], "benefici": 1, "benefit": [1, 6, 12, 16, 17, 20, 24], "bengio": 8, "bengio2003neur": [], "benjamin": [1, 5, 7, 10, 24], "berlin": 11, "berlitz": 7, "bert": [1, 5, 9, 10, 11, 12, 26], "bert4rec": 10, "bert_albert": [], "bert_input": [], "bert_model_distil": [], "bert_pretrainedlanguagemodel": [], "bert_task": [], "bertbas": [], "bertdownstreamtask": [], "bertencoderlay": [], "bertinput": [], "bertlarg": [], "bertpretrain": [], "bertpretrainfinetun": [], "berttask": [], "besid": [9, 10, 17, 24], "best": [5, 16, 21, 24], "beta": [1, 7, 21], "beta_": 7, "beta_i": 21, "beta_j": 21, "better": [1, 5, 6, 7, 8, 11, 17, 22, 24], "between": [0, 1, 5, 6, 7, 9, 10, 11, 12, 17, 20, 21, 22, 24], "beyer": 10, "beyond": [1, 6, 16, 20, 21], "bf16": 20, "bfloat16": [12, 20], "bgjm17": 11, "bia": [1, 11, 12, 16, 22, 24], "biao": 1, "bias": [1, 8, 21, 22, 24], "bib": [], "bibliographi": [], "bidirect": [6, 9, 10], "bidirection": [], "big": [6, 7, 11], "bigger": [0, 5], "biggest": [6, 12], "bigram": 7, "bilingu": 6, "billion": [0, 1, 5, 10, 12, 20, 22, 24], "binari": [5, 6, 10, 11, 21], "bind": [], "bing": 20, "binom": 21, "binyuan": [1, 20], "biologi": [], "biometrika": 21, "bird": 6, "bit": [1, 5, 12, 20], "bitlion": 24, "bivari": [], "blank": [], "blankevoort": 12, "blend": 5, "bleu": 5, "blindli": 22, "blink": [], "block": [1, 5, 10, 11, 19, 20, 21], "blog": [1, 5, 7, 9, 10], "bloom": [], "bloomberggpt": 24, "blue": 16, "blunsom": 6, "bm": [], "bmatrix": [1, 10], "bmr": [1, 5, 7, 10], "bnb21": 12, "bo": [1, 20], "board": 7, "bodi": 17, "bojanowski": 11, "bojanowski2017enrich": [], "bokeh": [], "bold": 7, "boldsymbol": [1, 6, 12, 21], "bondarenko": 12, "book": [10, 11, 24], "bookcorpu": [5, 10, 24], "books1": 5, "books2": 5, "bookscorpu": [5, 6], "boolean": [], "boost": [1, 5, 6], "border": [], "bore": [13, 17], "bori": 20, "borrow": 7, "bosma": [17, 22], "both": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 19, 20, 22, 24], "bottl": 10, "bottleneck": [6, 10, 22], "bottom": [1, 6], "bought": 6, "bound": [1, 10, 11, 12, 20], "boundari": [0, 1, 11], "bowen": [], "box": 5, "bpe": [], "bracket": [], "bradlei": 21, "brahma": 22, "brain": 12, "branch": [], "breadown": 12, "break": [1, 11, 12, 17], "breakthrough": 0, "bressand": 1, "brevet": 5, "breviti": 13, "brian": 22, "bridg": [6, 22, 24], "brief": 22, "bring": [1, 5, 8], "british": 7, "broad": [5, 13, 17, 22, 24], "broadcast": 20, "broader": 21, "broadli": [6, 16, 24], "brockman": 21, "brother": 11, "brought": 0, "brown": [1, 5, 7, 10, 21, 24], "brown2020languag": [], "browser": [], "bruna": 22, "brute": 13, "bryan": 9, "bsbdp": [], "bsd": 20, "bsdp": 20, "bt": 21, "bt52": 21, "btml": 17, "bucket": 11, "budget": [0, 6], "buffer": 20, "bug": [], "build": [1, 6, 7, 10, 11], "built": 19, "builtin_trap": [], "burden": 1, "burget": 8, "burr": 5, "button": [], "byond": [], "byte": [12, 20], "c": [1, 5, 6, 7, 10, 11, 12, 13], "c4": [10, 24], "c_": 1, "c_0": 7, "c_1": 7, "c_2": 7, "c_3": 7, "c_4": 7, "c_5": 7, "c_6": 7, "c_i": 7, "cach": [1, 8], "caim": 9, "calcuat": 12, "calcul": [1, 6, 10, 11, 12, 17, 20, 22], "california": 11, "call": [5, 6, 7, 10, 11, 20, 24], "callowai": 7, "cambodia": 11, "cambodian": 11, "cambridg": [], "came": [], "can": [0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "canada": 11, "cancel": 21, "candid": [5, 7, 12, 13, 16], "cannot": [0, 1, 5, 9, 11, 12, 13, 16, 20], "cao": 6, "cap": 11, "capabl": [0, 1, 5, 6, 9, 10, 12, 16, 17, 19, 22, 24], "capac": [1, 5, 6, 10, 21], "capit": 11, "caption": 7, "captur": [1, 5, 6, 7, 8, 10, 11], "car": 22, "carbon": 22, "cardin": 13, "care": [], "carefulli": [1, 5, 13, 21, 22], "carignan": 16, "carlo": 20, "carri": [7, 16], "carrol": 21, "casa": 1, "case": [1, 5, 6, 7, 9, 10, 11, 13, 16, 20, 24], "caslon": 6, "cast": 9, "castro": 22, "casual": 7, "cat": 8, "catastroph": [22, 24], "categor": 10, "categori": [5, 10], "caus": [1, 6, 7, 12, 13, 22], "causal": 10, "cbow": [], "cc": [1, 11], "ccc": [], "cccc": 11, "ccccc": [], "ccccccc": 1, "ccnl": 21, "cd": 9, "cdot": [1, 6, 7, 8, 10, 11, 12, 13, 21, 24], "cdpo": 21, "ce": 7, "ceil": 20, "cell": [], "center": [1, 11, 24], "central": [10, 11], "centrust": 7, "cernock\u00fd": 8, "certain": [1, 6, 7, 11, 12, 20, 22, 24], "certainli": 17, "cgi": [], "ch": [], "chain": [7, 13, 20], "chain_of_thought": [], "chain_of_thought_prompt_demo": [], "chainofthoughtpromptdemo": [], "chairman": 7, "challeng": [0, 1, 5, 6, 7, 8, 10, 13, 16, 17, 19, 20, 22, 24], "chanc": 12, "chang": [1, 5, 6, 7, 10, 11, 12, 22], "changer": 0, "changhua": 10, "channel": [], "chap_llm_architectur": [], "chap_llm_found": [], "chap_llm_infer": [], "chap_llm_prompt_engin": [], "chap_llm_rag": [], "chap_llm_train": [], "chap_multimod": [], "chaplot": 1, "chapter": [1, 10, 24], "chapter_found": 9, "chapter_foundation_def_pretrained_lm_transformer_bert_encoder_lay": 6, "chapter_foundation_def_pretrained_lm_transformer_encoder_comput": [], "chapter_foundation_def_pretrained_lm_transformer_encoder_lay": [], "chapter_foundation_fig_language_model_feedforward_model": 8, "chapter_foundation_fig_seq2seq_bart_finetun": [], "chapter_foundation_fig_seq2seq_bart_finetuning_classif": 9, "chapter_foundation_fig_word_embedding_word2vec_visu": 11, "chapter_foundation_sec_word_embed": [], "chapter_foundation_word_embedding_def_skipgramoptim": 11, "chapter_foundation_word_embedding_subwordwordembeddingmodel": [], "chapter_inference_eq_inference_acceleration_gptq_error_minimization_objective_matrix_form": 12, "chapter_inference_inference_fundamentals_beam_decoding_demo": [], "chapter_inference_inference_fundamentals_greedy_decoding_demo": [], "chapter_llm_arch_eq_ffn_swiglu": 1, "chapter_llm_arch_fig_fundamentals_position_encoding_alibi_comparison": 1, "chapter_llm_arch_layer_nomalization_formula": [], "chapter_prompt_fig_advanced_prompt_cot_self_consist": [], "chapter_prompt_fig_advanced_prompt_cot_self_consistency_exampl": [], "chapter_prompt_fig_advanced_prompt_cot_self_consistency_num_path": [], "chapter_prompt_fig_advanced_prompt_self_cot": [], "chapter_training_fig_fundamentals_pretrain_data_distribut": [], "charact": [1, 6, 7, 11, 17], "characterist": [1, 7], "chart": [], "chatglm": [], "chatglm2": [], "chatgpt": [], "chaudhari": 6, "chaumond": 6, "chd": 6, "cheaper": [6, 12], "check": 19, "checkmark": [], "checkpoint": [1, 21], "chelsea": 21, "chemistri": [], "chen": [1, 6, 10, 11, 20, 21, 22, 24], "chen1999empir": 7, "chengpeng": [], "chengyuan": [], "chess": 24, "chi": [6, 16, 17, 22], "chi2021xlm": [], "chicago": 11, "child": [5, 7, 9, 10, 24], "china": 11, "chines": [1, 6, 24], "chiyuan": 20, "chl": 22, "choic": [6, 11, 13], "chois": 16, "chong": 21, "choos": [6, 7, 13, 21, 24], "chose": 5, "chosen": [11, 13], "chowdheri": [16, 22], "chri": 1, "christian": [1, 8], "christiano": 21, "christoph": [6, 7, 21], "chu": [], "chuck": 20, "chung": 22, "chung2022scal": [], "chunk": [12, 19], "cinema": 17, "cin\u00e9ma": 5, "circl": [], "circumst": 12, "citat": 19, "cite": [7, 9, 11, 13, 20], "citi": [6, 11], "ckg": 6, "cklm19": 6, "cl": [6, 9], "cl_": [], "clarifi": [], "clark": 6, "clark2019do": [], "clark2020electra": [], "class": [5, 6, 9, 11], "classic": [6, 7, 11, 17, 21, 24], "classif": [5, 6, 9, 10, 11, 20, 21], "classifi": [6, 9, 11, 17], "classroom": 6, "claus": [], "clean": [], "clear": [1, 5, 10, 22], "clearli": [1, 5, 11, 24], "clearn": 24, "cleverest": 5, "click": [], "clip": 12, "cllm20": 6, "clm": 10, "clone": [21, 25], "close": [1, 6, 7, 11, 20], "closer": [0, 11], "cloth": 11, "cluett": 7, "cluster": 8, "clutter": [], "cm": [], "cn": [], "cnn": [9, 10], "co": [1, 6, 7, 8, 10, 11, 21], "cobb": 16, "code": [6, 10, 17, 24], "codex": 24, "codi": 12, "coeffici": [21, 24], "coexist": 11, "cognit": [], "coher": [1, 5, 6, 7, 10, 19], "cohes": [11, 13], "coin": [], "cola": 12, "colin": 9, "colleagu": [], "collect": [5, 7, 16, 20], "collison": 11, "collobert2008unifi": 11, "colon": [], "color": 1, "coloss": 24, "column": [11, 12], "columnwidth": [], "com": [5, 7, 10, 20], "combat": 1, "combin": [6, 8, 9, 10, 11, 19, 20, 22], "come": [1, 6, 7, 10, 16, 21], "command": [], "comment": 5, "commnic": 20, "common": [1, 6, 10, 11, 13, 16, 17, 24], "commoncrawl": [6, 24], "commonli": [1, 10, 11, 13], "commonsens": [5, 16], "commun": [0, 7, 17, 24], "compact": [6, 8], "compani": [1, 11], "compar": [1, 7, 8, 10, 11, 12, 16, 17, 19, 20, 21, 22], "comparis": [1, 12], "comparison": [1, 6, 7, 9, 16, 17, 20, 21, 24], "comparisonbertvsalbert": [], "compat": 1, "compens": 11, "compet": 11, "competit": 22, "compil": [], "complet": [5, 6, 7, 9, 10, 11, 17, 20, 21], "complex": [0, 1, 10, 11, 12, 16, 17, 20, 24], "compon": [1, 5, 6, 7, 10, 11, 12, 16, 19, 22], "componentwis": 1, "compos": 7, "composit": [12, 24], "composition": 11, "comprehens": [0, 5, 6, 9, 22], "compress": [6, 10], "compris": [], "compromis": [1, 6, 12, 22], "comput": [0, 5, 7, 8, 11, 16, 17, 20, 22, 24], "computatio": 12, "computation": [12, 21, 24], "con": [12, 22], "concat": [1, 8, 10], "concaten": [5, 6, 8, 11], "conceiv": [], "concept": [0, 7, 11, 17, 24], "concern": 22, "concis": [19, 22], "conclus": 1, "conda": 25, "condit": [5, 6, 7, 8, 9, 10, 11, 12, 13, 22], "conduct": [6, 12], "conf": 8, "confer": [6, 10, 12, 24], "confid": [5, 13, 19, 21], "config": [], "configur": [5, 12, 24], "configure_inline_support": [], "conglomer": 7, "conjectur": [], "conjunct": [], "conneau": 6, "conneau2019unsupervis": [], "connect": [1, 6, 7, 8, 10], "consecut": [1, 6, 7], "consensu": 16, "consequ": [6, 12], "conserv": 21, "consid": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 22, 24], "consider": [1, 6, 7, 9, 16, 22], "consist": [0, 1, 5, 6, 7, 9, 10, 11, 13, 17, 20, 21, 22], "consol": 22, "consolid": 7, "constant": [1, 6, 10, 12, 21, 24], "constantli": 0, "constitu": [7, 11], "constrain": 1, "constraint": [0, 7, 12, 13, 20, 21, 22, 24], "construct": [1, 7, 8, 10, 11, 17, 21, 22, 24], "consum": [12, 20, 22], "consumpt": [20, 22], "contain": [1, 5, 6, 7, 8, 12, 20, 21], "contamin": 22, "content": [19, 20, 21, 22], "context": [5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21, 24], "contextu": [5, 6, 10, 12], "contextualencod": 6, "contextualizedembed": [], "contexu": 10, "contigu": [12, 20], "continu": [0, 5, 10, 11, 12, 19, 21, 22], "contour": [], "contract": 11, "contradict": [6, 9], "contrari": 24, "contrast": [5, 6, 20, 21], "contribut": [5, 9, 10, 11, 12, 16, 22, 24], "control": [5, 6, 7, 10, 21, 24], "convai2": 9, "conveni": 10, "convens": 12, "convent": [], "converg": [1, 5, 6, 12, 20, 24], "convers": [5, 6, 24], "convert": [5, 7, 9, 10, 11, 12, 13, 21], "convex": 24, "convolut": [6, 12], "coordin": [], "copi": 20, "copyl_clm": [], "copyright": [], "core": [1, 8, 10, 12, 21, 22, 24], "cornerston": [1, 24], "corpora": [6, 7, 11, 24], "corpu": [6, 7, 9, 10, 11, 24], "corrado": 11, "correct": [6, 16, 17, 21, 24], "correctli": 24, "correl": [], "correspond": [1, 5, 6, 7, 9, 10, 11, 16, 20, 21, 22, 24], "corrupt": [6, 9, 10], "cosin": [6, 10], "cossimilar": 6, "cost": [1, 11, 13, 16, 17, 20, 22, 24], "costli": 11, "cot": 22, "cot\u00e9": 5, "could": [1, 6, 8, 10, 11, 12, 22, 24], "count": [5, 7, 8, 9], "counter": 8, "counterpart": 20, "cours": [], "covari": 1, "cover": [0, 1, 6, 7, 11, 22, 24], "coverag": 22, "coverg": 1, "craft": [16, 22], "crash": 7, "crawl": [5, 10, 24], "creat": [1, 7, 10, 16, 19, 20, 21, 22, 25], "creativ": [0, 13], "criteria": [12, 24], "criterion": [12, 16], "critic": [1, 5, 10, 12, 13, 22], "cross": [5, 6, 9, 11, 12, 24], "crossentropi": 6, "crowd": 6, "crucial": [0, 1, 6, 10, 12, 22, 24], "cs324": [], "ctrl": [], "cui": [], "cumul": [], "cup": [1, 11], "curat": 24, "currenc": 11, "current": [1, 5, 6, 10, 12, 19, 20, 21, 24], "curriculum": 24, "curs": [7, 8], "cursor": [], "curv": [], "cusp": 0, "custom": 21, "cut": [1, 13], "cv": 11, "cvi": 24, "cxzg16": 20, "d": [1, 5, 6, 7, 8, 10, 11, 12, 20, 21, 22], "d2l_book": [], "d_": [1, 5, 6, 7, 10, 12, 20, 21, 22], "d_0": 10, "d_1": 10, "d_2": 10, "d_h": 12, "d_i": [7, 20], "d_k": [1, 10], "d_model": [1, 5], "d_n": [10, 20], "d_v": 10, "d_x": 12, "da": 9, "dahl": 24, "dai": 22, "daj24": 1, "dale": [16, 17], "damag": [12, 22], "danc": 11, "dang": [], "danqi": [6, 10, 21], "dario": [5, 7, 9, 10, 24], "dasha": 22, "dashboard": [], "data": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 22], "databas": 19, "datafram": [], "datapoint": 21, "dataset": [0, 1, 5, 9, 10, 16, 21, 22, 24], "date": [10, 19], "date_rang": [], "david": [5, 7, 9, 10, 12, 20], "dayiheng": [], "db": 8, "dbk": 10, "dblp": 8, "dclt18": [6, 10], "dded": 11, "ddot": [1, 10], "de": [1, 5, 8, 11, 12, 22], "deal": 1, "dean": [6, 11, 16, 22], "debat": [], "deberta": [], "debut": 6, "decad": 7, "decai": 1, "decathlon": 9, "decent": 5, "decid": 9, "decis": [5, 17, 19, 21], "decod": [1, 5, 6, 9, 16, 26], "decoderlay": 10, "decompos": [6, 10, 11, 12], "decomposit": [7, 11, 22], "decond": 10, "decor": [], "decoupl": 24, "decreas": [7, 10, 24], "deep": [0, 1, 5, 6, 7, 10, 11, 12, 20, 24], "deeper": [1, 8], "deeplearn": 20, "deepli": 6, "def": 17, "default": [], "defin": [1, 6, 7, 10, 11, 13, 20], "definit": 7, "defragment": 20, "degrad": [1, 12, 22, 24], "degre": [7, 16], "dehghani": [10, 22], "delet": [5, 9, 10, 12], "deliber": 5, "delimit": [5, 19], "deliv": 10, "delta": [12, 21, 22, 24], "delv": 0, "demand": 16, "demeonstr": 21, "demonstr": [0, 1, 5, 6, 7, 9, 10, 12, 13, 16, 17, 21, 24], "deng": [], "deni": 7, "denker": 12, "denni": [6, 16, 17, 22], "denois": [9, 10], "denomer": 7, "denomin": [7, 11, 13, 20], "denorm": 12, "denot": [6, 11, 12, 13, 20], "dens": [0, 6, 8, 10, 11], "densiti": [], "depend": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20, 21, 24], "depict": [], "deploi": [1, 6, 10, 12, 22], "deposit": 11, "depth": [1, 17], "deq": 12, "dequant": [], "deriv": [1, 10, 11, 12, 21, 24], "descend": [], "descendingli": 13, "descent": [5, 8, 11], "descreas": 1, "describ": [5, 9, 11, 17, 20], "descript": [5, 6, 7, 9, 22], "desig": 20, "design": [1, 5, 6, 9, 10, 20, 21, 22, 24], "desipt": 20, "desir": [1, 12, 13, 17, 21, 22], "despit": [], "destroi": 20, "detail": [1, 6, 9, 10, 12, 13, 17, 19, 20, 21, 24], "detect": [5, 6, 17], "deterior": 12, "determin": [6, 7, 9, 10, 12, 20, 21], "determinist": [7, 13, 21], "dettmer": 12, "develop": [0, 1, 6, 7, 11, 12, 19, 20, 22, 24], "devendra": 1, "deviat": [1, 12], "devic": [6, 12], "devlin": [6, 9, 10, 22], "devlin2018bert": [], "df": [], "dhariw": [1, 5, 7, 10], "dhingra": 21, "dhs11": 24, "di": [1, 10], "diagnoal": 12, "diagram": [9, 21], "dialog": 13, "dialogu": 9, "diamet": [], "diamo": 20, "dictionari": 11, "did": [5, 19], "diederik": 24, "diego": 1, "diff": [], "differ": [1, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 21, 22, 24], "different_precision_demo": [], "differenti": 12, "differentprecisiondemo": [], "difficult": [5, 6, 10, 13, 19, 22, 24], "difficulti": [1, 6, 8], "digit": 0, "dim": 12, "dimens": [1, 6, 10, 11, 12, 20, 22, 24], "dimension": [1, 6, 7, 8, 10, 11, 12, 22, 24], "dimensionaltii": 8, "diment": 1, "diminish": 0, "diogo": 21, "direct": [5, 6, 7, 8, 9, 10, 11, 17, 21, 24], "directli": [1, 6, 7, 9, 11, 12, 13, 17, 20, 21, 22], "director": 7, "directori": [], "dirk": 10, "disadvantag": [11, 12, 13], "disagr": 10, "disanc": 1, "disc": 6, "discard": [6, 11, 13, 16, 20], "discount": 13, "discov": 24, "discoveri": 0, "discrep": [6, 10], "discrimin": [6, 21], "discuss": [0, 1, 6, 7, 10, 11, 20, 21, 24], "disentangl": [], "disjoint": 9, "disk": 12, "dispar": 12, "displac": 6, "displai": [], "display_data": [], "disproportion": 12, "dissatisfact": [], "dissimilar": 11, "distanc": [1, 7, 8, 11], "distil": [0, 10], "distilbert": [6, 10], "distinct": [], "distinguish": [6, 10, 11], "distort": 6, "distribut": [1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 21, 24], "diverg": 6, "divers": [5, 6, 9, 10, 13, 16, 22, 24], "divid": [1, 11, 12, 19, 24], "divis": [1, 24], "divisor": 20, "dlbz22": 12, "dm": 9, "dnn": [10, 20], "do": [1, 5, 6, 7, 10, 11, 17, 20, 21], "doc": [1, 10, 20], "doc2vec": [], "doc_2_vec": [], "docder": 10, "document": [1, 5, 6, 7, 9, 10, 11, 17, 19, 24], "doe": [5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 22], "doesn": [20, 22], "dog": [8, 11], "dogcatch": 11, "doll": 24, "dollar": 11, "domain": [0, 5, 8, 10, 16, 19, 21, 22, 24], "domiant": 12, "domin": [6, 10, 24], "don": [6, 7], "done": [20, 24], "dong": [1, 6, 24], "dosovitskii": 10, "dot": [1, 6, 10], "down": [1, 6, 12, 17, 20, 24], "download": [], "downstream": [1, 5, 6, 9, 10, 22], "downweight": [11, 21], "dozen": [], "dpo": [], "dramat": [0, 12, 24], "drastic": 10, "draw": [10, 11], "drawback": [1, 6, 8, 11, 12, 13, 17, 21, 22], "drawn": 21, "drew": [5, 10], "drive": [0, 10], "driven": 0, "drop": [10, 12], "drope": [], "dropout": [6, 10, 20], "du": [1, 5, 6, 10, 22, 24], "dubei": 1, "ducharm": 8, "duchi": 24, "due": [1, 5, 6, 7, 8, 10, 17], "dumais2004lat": 11, "dummi": [], "durat": 12, "dure": [1, 5, 6, 9, 10, 11, 12, 16, 19, 21, 22, 24], "durm": 10, "dutch": 7, "dy": 1, "dynam": [1, 10, 12, 20, 24], "dz": [], "e": [1, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "e_": [6, 7, 8, 10, 21], "e_0": [6, 10], "e_1": [6, 8, 10], "e_2": [6, 10], "e_i": [6, 10], "e_l": [6, 10], "e_n": [6, 10], "e_t": 8, "each": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 20, 21, 22, 24], "earli": [1, 7, 12, 24, 26], "earn": [1, 9, 10], "easi": [5, 8, 11, 12, 20, 22], "easier": [6, 17, 21], "easiest": 11, "easili": [5, 7, 11, 13], "eat": 11, "econom": [], "ecosystem": [], "ed": [16, 17, 22], "edg": 17, "edgar": 16, "editor": 8, "edouard": [6, 11], "edward": 22, "effeci": 8, "effect": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 22, 24], "effici": [0, 1, 8, 10, 11, 12, 13, 19, 20, 21, 24], "efficieni": 20, "efficient_train": [], "effort": [6, 7, 10], "ega": 11, "eh": 6, "eid": 5, "eight": [5, 10], "ein": 10, "either": [6, 11, 16, 17], "ek": [], "el": 1, "elabor": [], "elad": 24, "electra": [], "electra_demo": [], "electrademo": [], "electron": 6, "eleg": [], "element": [5, 12, 13, 17, 21], "eli5": 9, "elicit": 17, "elif": 17, "elimin": [6, 12, 20], "ell": [5, 6], "ell_": 6, "elmo": 10, "els": [13, 17], "elsen": 20, "elsewher": 12, "emb": 16, "embark": 0, "embd": 6, "embed": [5, 8, 9, 10, 12, 16, 26], "embedding_interpret": [], "embeddinginterpret": [], "emerg": [0, 1, 5, 7, 10, 12, 24], "emit": 21, "emlo": 6, "emoji": 1, "emph": 11, "emphas": [1, 11], "empir": [7, 11, 22, 24], "empirci": [], "emploi": [6, 10, 11, 12, 16, 19, 20, 21, 24], "empti": [], "emptyset": 1, "en": 5, "enabl": [1, 5, 6, 9, 10, 11, 12, 19, 20, 22, 24], "enable_matplotlib": [], "encod": [5, 9, 11, 19, 22], "encodercomput": [], "encoderlaly": [6, 10], "encoderlay": [6, 10], "encompass": 12, "encourag": [11, 13, 16, 17, 21], "encyclopedia": 24, "end": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 20, 21, 22, 24], "endpoint": [], "energi": 12, "engag": 20, "engin": [5, 12, 16, 19, 22, 24], "english": [1, 5, 6, 7, 9, 10, 20, 24], "enhanc": [0, 1, 10, 16, 17, 19, 20, 24], "enjoi": 7, "enlarg": [], "enorm": [1, 10, 20], "enough": [6, 7, 20, 21, 24], "enrich": [6, 11], "ensur": [1, 7, 13, 22, 24], "entail": [5, 6, 9], "enter": 10, "entertain": 17, "entir": [1, 5, 9, 12, 16, 20, 22], "entiti": [6, 7, 10], "entorpi": 7, "entri": [6, 10, 11], "entropi": [5, 6, 9, 11], "env": [], "environ": [12, 21], "environment": [0, 22], "eo": [10, 13, 21], "ep": [], "episod": 21, "epsilon": [1, 21], "epsilon_": [], "epsilon_0": [], "epsilon_1": [], "epsilon_k": [], "epsilon_t": [], "eq": 12, "equal": [1, 6, 7, 10, 11, 20, 22, 24], "equat": [11, 12], "equip": 0, "equival": [6, 7, 9, 12, 20, 24], "er": 11, "era": [0, 10, 12], "eric": 21, "erich": 20, "ericmitchel": 21, "ermon": 21, "error": [6, 11, 16, 17], "esc": [], "escap": 24, "esearch": 9, "especi": [1, 7, 10, 12, 17, 20, 22, 24], "essenti": [7, 11, 21, 24], "establish": [7, 24], "estim": [5, 20, 21, 24], "et": [1, 5, 7, 9, 10, 12, 16, 20, 21], "etc": [1, 5, 10, 11, 12, 13, 24], "ethic": 11, "euclidean": 11, "eural": [1, 5, 7, 10], "euro": 1, "ev": [], "evalu": [1, 5, 11, 22, 24], "even": [0, 1, 5, 6, 7, 10, 12, 13, 21, 24], "event": 7, "eventu": [11, 20], "ever": [0, 7], "everi": [6, 9, 10, 11, 12, 20, 21, 22], "everywher": [], "evolut": [7, 10, 22], "evolv": [19, 22], "exact": 12, "exactli": 7, "examin": [0, 1, 5, 24], "exampifi": 1, "exampl": [5, 6, 7, 8, 9, 10, 12, 13, 16, 17, 20, 21, 22, 24], "exce": 21, "exceed": [5, 12], "excel": [5, 19], "except": [5, 6, 11, 20], "excess": 16, "excit": 0, "exclud": [6, 10, 17], "exclus": [10, 22], "execut": [12, 22], "executablebookproject": [], "exemplar": 16, "exercis": [1, 6], "exhibit": [0, 10, 12, 16, 19], "exist": [1, 6, 7, 17, 21, 22, 24], "exp": [6, 7, 11, 13, 20, 21], "expand": [0, 5], "expans": [11, 12], "expect": [5, 6, 11, 22], "expens": [8, 10, 11, 12, 17, 24], "experi": [1, 17, 20], "experienc": [], "experiment": 24, "expert": [0, 16, 21], "explain": 17, "explan": [1, 12, 19], "explicit": [11, 17, 24], "explicitli": [0, 6, 22], "explictli": 21, "explod": 1, "exploit": 8, "explor": [0, 1, 6, 8, 9, 10, 16, 19, 21, 22, 24], "expon": 20, "exponenti": [0, 7, 24], "expos": [10, 20, 21], "exposur": 10, "express": [5, 11, 12, 20], "extend": [1, 6, 8, 22], "extens": [1, 5, 10, 13, 17, 22, 24], "extent": 11, "extern": [0, 19, 21], "extra": [1, 5], "extract": [5, 7, 9, 10, 19], "extrapol": 1, "extrem": [5, 12, 20, 24], "extropol": 1, "f": [1, 6, 11, 12, 24], "f1": 9, "f16": 12, "f_": 24, "f_1": 12, "f_2": 12, "face": [11, 12, 19], "facebook": [6, 11], "facet": [], "facil": 12, "facilit": [6, 11], "fact": [1, 5, 7, 10, 12, 19], "factor": [0, 1, 6, 10, 11, 12, 13, 20, 22, 24], "factual": [1, 5, 19, 21, 24], "fail": [7, 13, 20, 21, 22], "failur": [1, 12], "fait": 5, "falcon": 24, "fall": [5, 10, 24], "fals": 6, "famili": [6, 10], "familiar": [], "fan": [], "fandong": 22, "fang": 6, "far": [1, 7, 11, 16, 24], "fashion": [10, 11], "fast": [1, 24], "faster": [6, 12, 20, 24], "fastest": 12, "fasttext": 11, "fasttexttextclassif": [], "favor": [], "favorit": [], "feasibl": 22, "feasibli": 12, "featur": [1, 6, 7, 10, 11, 12, 22], "feb": 8, "fed": [5, 6, 9, 10, 11, 22], "federico": 1, "fedu": [21, 22], "feed": [1, 6, 9, 10, 12, 22, 24], "feedback": [17, 21], "feedforward": [1, 8, 20], "feedforwardmodel_v2": [], "feedforwardmodelv2": [], "feel": 9, "fei": 10, "few": [1, 5, 6, 7, 10, 11, 12, 13, 16, 22, 24], "fewer": 12, "ff": [6, 10], "ffd": 22, "ffn": [6, 10, 12, 20], "ffn_": [], "fibonacci": 17, "fibonacci_50th": 17, "field": [0, 7, 19, 24], "fig": [1, 5, 6, 7, 9, 10, 11, 12, 16, 20, 21, 22, 24], "figur": [9, 10, 12, 21], "file": [], "fill": 9, "filter": [5, 24], "final": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 21, 22, 24], "financ": [], "find": [0, 1, 6, 9, 12, 13, 20, 21, 22], "find_gui_and_backend": [], "fine": [0, 7, 9, 10, 12, 16, 17, 21, 24], "finetun": [10, 17, 24, 26], "finish": 12, "finit": [12, 21], "finn": 21, "firat": 6, "first": [1, 5, 6, 7, 9, 10, 11, 12, 16, 20, 21, 22, 24], "firstli": 21, "fit": [12, 20, 21], "fix": [1, 6, 8, 9, 10, 11, 12, 13, 16, 21], "flan": 22, "flasch": 10, "flash": [], "flat": 24, "flavor": 20, "fledg": [], "flexibl": [6, 10, 17, 22], "flight1ess": 6, "flip": 21, "float": [1, 12], "float16": [12, 20], "float32": [12, 20], "floor": 7, "flop": 12, "florian": 1, "flow": 1, "fluctuat": 1, "fluenci": 13, "fluent": 7, "fmt": 6, "fn": [], "focu": [0, 1, 7, 12], "focus": [0, 6, 10, 19], "fold": 6, "follow": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "foo": [], "foo42": [], "food": 7, "fool": 5, "footnot": [7, 11], "footnotes": [], "footprint": [1, 10, 12, 20, 22], "foral": [5, 12, 24], "forc": [6, 13, 21], "forecast": 0, "forget": [22, 24], "forgett": 17, "form": [1, 6, 7, 10, 11, 12, 13, 16, 17, 21, 24], "formal": [6, 7, 8, 11, 13], "format": [5, 9, 12, 16, 17, 20], "former": 7, "formul": [5, 9, 11, 21], "formula": [1, 7, 10, 11, 12, 20], "fortran": [], "forum": 24, "forward": [0, 5, 6, 10, 12, 13, 17, 19, 20, 21, 22], "forword": 13, "found": [0, 5, 6, 11, 12, 19], "foundat": [0, 1, 7, 10, 16], "four": [1, 5, 9, 21], "fourth": [], "fp15": [], "fp16": 20, "fp32": [12, 20, 22], "fp8": 20, "fr": 5, "frac": [1, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22, 24], "fraction": [20, 22], "fraction1": [], "frag": [], "fragment": [12, 20], "frame": 10, "framework": [5, 6, 7, 9, 11, 13, 19, 24], "franc": 11, "francisco": 6, "frank": 24, "fraser": 21, "free": [5, 6, 21], "freez": 22, "french": [5, 6], "frequenc": [1, 6, 7, 8, 11], "frequent": [1, 6, 7, 8, 19], "frezz": 22, "friend": 7, "friendli": 22, "fro": 11, "from": [0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 22, 24], "fromstein": 7, "front": 7, "frontier": 0, "frozen": [21, 22], "fruit": 6, "full": [7, 9, 12, 13, 20, 22, 24], "fulli": [10, 22], "fun": 6, "funciton": [1, 21], "function": [1, 5, 6, 8, 11, 12, 13, 21, 24], "function_nam": [], "fund": 11, "fundament": [0, 5, 6, 7, 10, 19, 26], "further": [0, 5, 6, 7, 8, 9, 10, 11, 12, 17, 20, 21, 22, 24], "furthermor": 10, "furu": 6, "fuse": [10, 12, 20], "fusi": 16, "fusion": 6, "futur": [0, 5, 10], "g": [1, 5, 6, 7, 10, 11, 12, 13, 17, 20, 21, 22, 24], "g_": 24, "g_0": 24, "g_i": 12, "g_k": [], "g_t": [], "ga": 11, "gain": [0, 5, 6, 11, 12, 20], "galleri": [], "gallon": 6, "game": [0, 22], "gamma": [1, 21], "gan": 6, "ganesh": 20, "gao": 6, "gap": [6, 22, 24], "gar": 11, "garanti": 5, "garc": 6, "garcia": 20, "garcia2017translanguag": [], "garciajsvaldes17": 6, "gardner": 6, "gate": 1, "gather": [12, 20], "gaug": 7, "gaurav": 22, "gaussian": [], "gb": [6, 12, 20, 22], "gdollarg": 24, "ge": [], "geglu": [], "gelli": [10, 22], "gelu": [], "genearl": 8, "gener": [0, 1, 6, 7, 8, 10, 13, 17, 19, 20, 21, 22, 24], "generalis": 6, "generalist": 16, "generaliz": [], "generer": [], "genr": 5, "genuin": 7, "geoffrei": [6, 24], "georg": [10, 24], "geq": 6, "german": 9, "gesmundo": 22, "get": [5, 7, 8, 9, 10, 12, 13, 24], "get_ipython": [], "get_local_scop": [], "getattr": [], "ghazvininejad": 9, "gianna": 1, "gibberish": 13, "gimpel": [6, 10], "ginsburg": 20, "girish": [1, 5, 7, 10], "girshick": 24, "git": 25, "gitano": 7, "github": [12, 24], "giurgiu": 22, "give": [1, 6, 7, 8, 12, 17, 19, 20, 21], "given": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 21, 22, 24], "global": [11, 20], "globe": [], "glove": 6, "glu": 1, "glue": [10, 12], "go": [1, 5, 6, 9, 10, 11, 12, 13], "goal": [0, 5, 7, 9, 11, 13], "goe": [1, 11], "gold": 7, "goldberg2014word2vec": 11, "goldberg2017neur": 7, "gomez": 10, "gonzalez": 12, "good": [1, 6, 7, 8, 9, 10, 11, 21], "goodman": [6, 10], "googl": [1, 6], "gorilla": 7, "gotten": [], "gouvern": 5, "govern": [0, 5, 7], "goyal": [6, 9, 10, 24], "gpt": [0, 1, 7, 9, 10, 12, 16, 21, 22, 26], "gpt3": [5, 22], "gpt3_few_shot_learning_demo": [], "gpt3fewshotlearningdemo": [], "gpt_arch": [], "gpt_decoder_arch": [], "gptarch": [], "gptdecoderarch": [], "gpu": [10, 12, 22], "gpu_memory_alloc": [], "gpumemoryalloc": [], "gqa": 20, "grade": 22, "gradient": [1, 5, 6, 8, 11, 20, 21, 22], "gradual": [1, 5, 10, 24], "graham": 6, "grai": 24, "graident": 20, "grain": [6, 7, 12], "gram": [8, 13], "grammar": [7, 8, 11, 13], "granddaught": 11, "grandson": 11, "granular": 1, "graph": 20, "graphic": [], "grasp": 10, "grave": [6, 11], "gre": 11, "great": [5, 10, 11], "greater": [7, 10, 11, 12, 20], "greatli": [17, 22], "greec": 11, "greedi": 16, "greedili": 13, "green": [], "greg": 11, "gregari": 11, "gregori": [12, 20], "grei": [], "grid": [], "grip": 17, "groom": 7, "ground": [16, 17, 22], "group": [7, 12, 20], "grow": [1, 5, 10, 11, 12], "growth": 0, "gsm8k": 17, "gu": [17, 22], "guadalup": 6, "guant": [], "guarante": [11, 13], "guestrin": 20, "gui": 5, "guid": [0, 1, 11, 17, 20], "guido": [], "guillaum": [1, 6], "guo": [], "gut": 9, "gut16": [], "gutenberg": 24, "guterman": 7, "guttag": [], "guu": 22, "guzm": 6, "gym": 21, "h": [1, 6, 8, 10, 12, 20, 22], "h1": 17, "h_": [5, 6, 8, 12, 21], "h_0": 5, "h_1": 6, "h_l": 5, "h_n": 6, "h_t": [6, 8], "ha": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 22, 24], "had": [0, 5], "half": [1, 6, 12, 20], "hallucin": [1, 19, 21], "halv": [], "hamburg": 9, "hand": [1, 6, 7, 10, 11, 16, 17, 22], "handl": [1, 8, 12, 17, 22], "hangbo": 6, "hao": 12, "haoran": [], "happen": 6, "har": 16, "harar": 11, "hard": [1, 5, 13, 20], "harder": 6, "hardli": 7, "hardwar": [0, 12, 20], "harm": [21, 22], "harsha": 16, "hash": 11, "hassibi": 12, "hat": [6, 13, 21, 24], "hate": [5, 9], "have": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 20, 21, 22, 24], "hazan": 24, "he": [1, 6, 8, 10, 20, 24], "head": [5, 6, 9, 10, 12, 17, 20], "head_1": 10, "head_h": 10, "head_i": 10, "heard": 5, "heart": 13, "heat": 12, "heavi": 24, "heavili": [6, 10, 11, 24], "heigold": 10, "held": 20, "hello": 17, "help": [1, 5, 6, 10, 17, 20, 21, 24], "henc": [], "henighan": 24, "her": 11, "herd": 1, "here": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 17, 20, 21], "hessian": [], "heurist": [10, 13], "hfill": [], "hgj": 22, "hi": 5, "hidden": [1, 6, 8, 9, 10, 11, 12, 20], "hidden_dim": [], "hiddens": [], "hidn": 6, "high": [1, 7, 10, 11, 12, 13, 16, 17, 20, 22, 24], "higher": [1, 7, 12, 13, 16, 17, 22, 24], "highest": [1, 13, 16], "highli": [6, 21], "highlight": [12, 16], "hil16": [], "hill": [], "hilton": 21, "hin12": 24, "hing": 11, "hinrich": 7, "hint": [], "hinton": [6, 24], "hinton2015distil": [], "hiros": 8, "histogram": [], "histor": [5, 24], "histori": 22, "hit": [], "hline": 11, "hold": [], "homework": 7, "hongkun": [6, 22], "hopefulli": 24, "horizon": 21, "horizont": 24, "hors": 11, "host": [], "hot": [6, 11, 12], "hou": [1, 22, 24], "houlsbi": 22, "hour": 24, "houston": 20, "how": [0, 1, 5, 6, 7, 9, 12, 17, 20, 22, 24], "howev": [0, 1, 5, 6, 8, 10, 13, 17, 20, 21, 22, 24], "hr": 6, "href": [], "hsw": 22, "hsw93": 12, "html": [8, 17, 20], "http": [1, 5, 6, 7, 8, 10, 11, 12, 19, 20, 21, 22], "hu": [6, 22], "hu2020xtrem": [], "huan": [], "huang": [6, 22], "huge": [1, 6, 7, 11, 20], "huggingfac": 21, "hui": [1, 20], "huishuai": [1, 10], "human": [0, 1, 6, 7, 11, 13, 16, 17, 21, 22, 24], "hundr": [0, 1, 5, 11, 24], "hunt": [], "hurt": 6, "hutter": 24, "hv": 6, "hvd15": 6, "hybrid": 19, "hydro": 7, "hyper": [1, 13], "hypermet": 12, "hyperparamet": [1, 7, 24], "hypothes": [1, 13], "hypothesi": [1, 5, 6, 9, 13], "hyung": 22, "i": [0, 5, 6, 7, 8, 9, 13, 16, 17, 20, 21, 22, 24], "i8": 12, "i_1": [6, 10], "i_n": [6, 10], "i_p": [6, 10], "ib": 6, "ibarra": 6, "ibm": 11, "ic": 11, "ich": 10, "icon": [], "idea": [1, 6, 7, 8, 11, 12, 13, 17, 20, 21, 22, 24], "ideal": [11, 20], "iden": 1, "ident": [1, 10], "identif": 0, "identifi": [10, 12, 16, 19, 20], "idf": 11, "ieee": [12, 20], "ignor": [11, 12, 20, 21, 22], "ii": 12, "iid": [], "ij": [1, 7, 10, 11, 12], "ik": 1, "il": 5, "illia": 10, "illinoi": 11, "illustr": [1, 6, 7, 9, 10, 12, 17, 21, 24], "ilya": [5, 7, 9, 10, 11, 24], "imag": [0, 1, 5, 6, 7, 9, 10, 11, 12, 21, 22, 24], "imagenet": 24, "imaginari": 7, "imbal": [6, 20], "imbecil": 5, "imf": 11, "img": 9, "imit": 21, "immedi": [], "immens": [], "impact": [0, 1, 5, 6, 7, 12, 13, 22, 24], "imperfect": 6, "implement": [6, 12, 20, 24], "impli": [6, 9, 11, 12], "implic": [0, 12, 20], "implicit": [6, 11, 21], "import": [0, 1, 6, 7, 9, 10, 11, 12, 22, 24], "importantli": 11, "impos": [6, 13, 22], "imposs": 6, "impossibli": 11, "impract": [7, 22], "impress": [5, 10, 24], "improv": [0, 1, 5, 6, 7, 8, 9, 10, 12, 16, 17, 19, 20, 21, 22, 24], "inaccuraci": 8, "inaccurci": 12, "inadvert": 22, "inan2016ti": 11, "inappropri": 21, "inc": 24, "includ": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 19, 20, 21, 22, 24], "includegraph": [], "inclus": 22, "incomplet": 21, "inconsist": [8, 22], "incorpo": 13, "incorpor": [6, 10, 13, 19, 24], "incorrect": [1, 11, 19], "incorrectli": 7, "increas": [0, 1, 5, 6, 7, 8, 10, 12, 16, 17, 19, 20, 21, 22, 24], "increasingli": [0, 1, 12], "increment": [16, 22], "incres": 1, "incur": [20, 22], "inde": 11, "independ": [5, 6, 9, 10, 11, 12, 21, 22], "index": [1, 6, 10, 11, 19], "indic": [5, 6, 7, 9, 10, 11, 12, 21], "indirect": [], "indispens": 7, "individu": [1, 6, 11, 21], "induct": 11, "industri": [0, 7, 10, 19, 22], "ineffici": [6, 12, 21, 22, 24], "inf": [10, 13], "infeas": [], "infer": [0, 1, 5, 6, 7, 10, 11, 16, 20], "inferenc": 12, "inference_acceler": [], "inference_fundament": [], "infil": 9, "infin": [], "influenc": 12, "influenti": [6, 10], "inform": [0, 1, 5, 6, 9, 10, 11, 12, 19, 24], "infrastructur": 12, "infti": [7, 10, 24], "ing": [], "inher": [19, 21], "inherit": 21, "iniit": 24, "initi": [1, 5, 6, 9, 10, 12, 21, 24], "inject": 22, "inlin": [], "inner": [1, 6, 10, 12], "innov": [0, 6], "input": [1, 5, 7, 8, 9, 11, 12, 13, 16, 17, 20, 21, 22, 24], "insensit": [1, 20], "insert": [6, 9], "insid": 11, "insight": 1, "inspir": [5, 24], "instabl": [1, 21], "instanc": [1, 10, 13, 22], "instead": [1, 6, 7, 11, 12, 13, 16, 20, 21, 22, 24], "instruct": [5, 20, 21, 24], "instructgpt": [17, 21], "instruction_finetun": [], "instruction_finetuning_demo": [], "instructionfinetuningdemo": [], "insturct": 22, "insuffici": 6, "int": 12, "int16": 12, "int32": 12, "int4": 12, "int6": [], "int8": 20, "int_": [], "integ": [1, 6, 10, 11, 12, 20], "integr": [7, 16, 19, 22], "intel": 11, "intellig": [0, 1, 5, 6, 7], "intend": [6, 7, 10, 13], "intens": [12, 16, 19], "intensifi": 12, "intent": [17, 22], "intention": 6, "inter": [6, 7, 10, 21], "interact": [0, 1, 10, 11, 17, 19], "interactiveshel": [], "interest": [5, 10, 22], "interestingli": [], "interfac": [], "intermedi": [1, 10, 12, 17, 20, 22], "intermedid": 24, "intern": [1, 6, 10, 12, 19, 20, 24], "internet": [1, 21], "interplai": 0, "interpol": 17, "interpolat": 1, "interpret": [1, 6, 7, 17, 22], "interspeech": 8, "interspeech2010": 8, "interv": 5, "intract": 7, "intric": 1, "intricaci": 0, "intrins": 5, "introduc": [0, 1, 6, 7, 9, 10, 11, 12, 13, 16, 20, 22], "introduct": 10, "intuit": [1, 5, 7, 10, 12, 16, 22, 24], "invalu": 0, "invari": 1, "invent": 10, "invers": [1, 7, 11, 24], "invert": 6, "invest": 0, "investig": 5, "invit": 9, "invok": 1, "involv": [1, 5, 6, 7, 10, 12, 13, 16, 19, 20, 22, 24], "io": 12, "ioff": 1, "ion": 12, "iou": 11, "ipo": [7, 21], "ipynb": [], "ipython": [], "ir": 26, "iran": 11, "irrelev": [6, 11], "irrespect": [11, 24], "is15": 1, "isca": 8, "isinst": [], "isn": [], "isnext": 6, "issu": [1, 9, 10, 11, 12, 20, 21, 24], "ist": 9, "item": [20, 21], "iter": [1, 9, 12, 13, 21, 24], "its": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "itself": [5, 6, 10, 12, 20], "iv": [6, 9, 17, 22, 24], "iwasawa": 17, "iyyer": 6, "j": [1, 6, 7, 9, 10, 11, 12, 13, 20, 21, 22], "jacob": [6, 10, 21, 22], "jakob": 10, "jame": [1, 24], "jan": [8, 21], "jare": [1, 5, 7, 10, 24], "jargon": 20, "jason": [16, 17, 22], "jastrzebski": 22, "jauhri": 1, "jauvin": 8, "java": [], "je": 5, "jean": 8, "jeff": [6, 11, 20, 21, 22], "jeffrei": [5, 7, 9, 10, 11, 24], "jgbm16": 11, "ji": [1, 24], "jia": 24, "jialin": [], "jialong": [], "jian": [1, 10, 24], "jiang": [1, 6, 10, 21, 24], "jianhong": [], "jianlin": 1, "jianwei": [], "jianxin": [], "jiao": 6, "jiao2019tinybert": [], "jie": 22, "jimmi": 24, "jin": [], "jingfei": [6, 10], "jingren": [], "jingyaogong": 25, "jinhao": [1, 24], "jinz": [], "jinzheng": [], "john": [12, 21, 24], "johnson": 6, "join": 7, "joint": [6, 7, 8], "jointli": [1, 10, 22], "joliett": 5, "jonah": 20, "jonathan": 16, "jone": 10, "jong": 1, "joseph": 12, "joshi": [6, 10], "joshua": 1, "joulin": 11, "joulin2016bag": [], "journal": [6, 7, 8, 24], "journei": 0, "jsm": 1, "json": [], "jstor": 21, "judg": 21, "juic": 11, "jul": 24, "julien": 6, "jump": 5, "jumpstart": 24, "jun": 10, "junji": [1, 6, 24], "junyang": [], "junyi": [1, 24], "jupyt": [], "just": [1, 5, 6, 7, 10, 11, 12, 13, 17, 20, 21, 22], "justifi": 11, "jy": 6, "k": [1, 5, 6, 7, 8, 10, 11, 12, 16, 19, 20, 21, 22, 24], "k_": 1, "k_i": 1, "k_n": 1, "kai": [1, 10, 11], "kaim": 24, "kaiser": 10, "kaplan": [1, 5, 7, 10, 24], "karafi\u00e1t": 8, "karthik": [5, 7, 10], "kartikai": 6, "katarina": 21, "kate": 6, "katherin": 9, "kazakhstan": 11, "kb14": 24, "kd": 6, "keep": [1, 7, 10, 13], "kei": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 20, 21, 22, 24], "keikichi": 8, "kelton": 21, "kelvin": 22, "keme": [], "kenton": [6, 10], "kept": [17, 22], "keqin": [], "kernel": [6, 20], "keskar": 9, "keskar2019ctrl": 13, "kevin": [6, 10, 22], "kexin": [], "keyboard": [], "keystrok": [], "kgr": 17, "khandelw": 6, "khudanpur": 8, "kia": 7, "kind": 6, "king": 16, "kingma": 24, "kj": 1, "kk": [], "kl": [6, 21], "klau": 6, "klz": 12, "kl\u8d8a\u5c0f\u8d8a\u597d": 21, "kmh": 24, "kneser": 7, "knn": 16, "know": [5, 7, 12], "knowledg": [0, 5, 6, 10, 11, 16, 17, 19, 22, 24], "known": [6, 7, 10, 11, 12, 16, 19], "kobayashi": 8, "kojima": 17, "kojima2022larg": [], "kolesnikov": 10, "korean": 1, "krikun": 6, "kristina": [6, 10], "kuchaiev": 20, "kun": [1, 24], "kusner": 6, "kv": [], "kw": [1, 10], "kw_i": 10, "kwanza": 11, "kwarg": [], "kwin": [], "kwon": 12, "kwout": [], "kyrola": 24, "l": [1, 5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 22, 24], "l_": [6, 12, 21], "l_2": [], "l_q": 12, "la": 1, "label": [5, 6, 9, 10, 11, 16, 24], "lachaux": 1, "lack": [1, 6, 7, 12, 17, 22, 24], "lacroix": 1, "lag": [], "lagrang": [7, 12], "lagrangian": 12, "lambda": [7, 12, 24], "lambda_i": 7, "lamda": 16, "lampl": [1, 6], "lample2019cross": [], "lan": [1, 6, 10], "lan2019albert": [], "land": [], "landscap": 0, "langl": [1, 21], "languag": [1, 9, 11, 13, 16, 17, 19, 21, 22, 24, 26], "language_model": [], "language_modeling_benchmark": [], "languagemodel": [], "languagemodelingbenchmark": [], "languageunsupervis": [5, 7, 10], "languga": 24, "laplac": 7, "larg": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "larger": [0, 1, 5, 6, 7, 10, 11, 12, 20, 22, 24], "largest": [5, 10, 20], "larnguag": 7, "laroussilh": 22, "larson": 16, "last": [5, 6, 9], "latenc": [1, 22], "latent": [8, 11], "later": [], "latest": [1, 7], "latex": [], "latter": [], "lavaud": 1, "lavril": 1, "law": [0, 7, 24], "layer": [5, 8, 9, 11, 12, 16, 20, 21, 22], "layernorm": [1, 6, 10, 20], "layerwis": 6, "layout": 20, "lb": 13, "lc": [], "lc19": 6, "lcc": [], "lcccccc": [], "lcccccccccc": [], "lcg": [6, 10], "ldot": [1, 5, 6, 7, 11, 13], "lds89": 12, "le": [1, 6, 7, 16, 17, 22], "lead": [1, 10, 11, 12, 16, 17, 20, 22, 24], "leader": 5, "leap": 0, "learn": [1, 5, 6, 8, 9, 10, 11, 12, 20, 22, 24, 26], "learnabl": [1, 6], "learner": [1, 5, 6, 7, 9, 10, 22], "least": [12, 16, 20], "lebr\u00f3n": 1, "lectur": [], "lecun": 12, "led": [0, 6, 22], "lee": [1, 6, 9, 10, 16], "left": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22, 24], "leftarrow": [20, 24], "legal": 24, "legend": [], "leik": 21, "leimao": 12, "lemmat": 11, "len": 6, "length": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20], "lengyel": 1, "leq": [7, 11, 12, 21], "less": [1, 6, 7, 10, 11, 12, 13, 17, 19, 22], "lester": 22, "let": [0, 1, 6, 7, 8, 10, 11, 12, 13, 17, 21, 22, 24], "letter": 1, "level": [0, 5, 6, 7, 10, 11, 12, 21], "leverag": [6, 10, 12, 16, 19, 20, 21, 22], "levi": [6, 9, 10], "lewi": [1, 6, 9, 10, 12], "lewis2019bart": 9, "lexic": 11, "lfloor": 12, "lh17": 24, "li": [1, 6, 9, 10, 12, 16, 22, 24], "lianmin": 12, "lib": [], "librari": [], "licens": [], "lie": [1, 5], "lieu": [], "life": 22, "lifeng": 6, "lifetim": [], "lighter": 6, "lightweight": 16, "liguist": 24, "like": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "likelihood": [1, 5, 6, 7, 11, 13, 21, 24], "likert": 21, "likewis": 5, "lilianweng": 12, "lim_": 7, "limit": [0, 1, 5, 6, 7, 8, 9, 10, 12, 17, 19], "lin": 10, "lin20": [], "lin2021survei": [], "line": [6, 16], "linear": [1, 5, 6, 9, 10, 11, 20, 22, 24], "linearli": [1, 6, 8, 12, 20], "linewidth": [], "linform": [], "lingual": [6, 24], "linguist": [1, 6, 7, 9, 11], "link": [7, 11], "linli": 24, "linlin": 6, "linspac": [], "list": [1, 9, 13], "list_nam": [], "listen": 5, "lite": [6, 10], "liter": 5, "literatur": 24, "liti": 6, "littl": [12, 22, 24], "liu": [1, 6, 9, 10, 16, 24], "liu2019roberta": [], "liu2020survei": [], "live": 8, "liwei": [1, 10], "lkb20": 6, "ll": [6, 10, 12, 22, 24], "llama": [1, 21, 24], "llama2": [], "llama3": 1, "llama7b": 12, "llg": 9, "llion": 10, "lll": 6, "lllll": [], "llm": [5, 10, 16, 19], "llm_book": [], "llm_dense_architectur": [], "llm_env": 25, "llm_moe_sparse_architectur": [], "lm": [17, 20], "ln": [1, 7, 11], "load": [1, 12, 20], "local": [1, 10, 11, 24], "local_n": [], "localhost": [], "locat": [6, 8, 12, 24], "log": [5, 6, 7, 10, 11, 13, 21, 22, 24], "logi": [], "logic": [1, 7, 8, 10, 17], "logist": 11, "logit": [6, 11, 13, 21], "long": [0, 7, 8, 10, 12, 13, 21, 24], "longer": [1, 6, 7, 8, 10, 12, 13, 21], "longform": [], "longpr": 22, "look": [5, 6, 7, 9, 10, 11, 12, 13, 20, 22], "loop": 20, "lose": [11, 20], "loshchilov": 24, "loss": [5, 6, 7, 9, 10, 11, 12, 20], "lost": 9, "love": [6, 11], "low": [5, 6, 7, 8, 10, 11, 12, 20, 21, 24], "lower": [6, 7, 11, 12, 13, 20, 22], "lowercas": 7, "lowest": 13, "lpsbh": [], "lrrrr": [], "lsa": 11, "lstm": [6, 10], "lstmunitalg": [], "lty": 10, "lu": [1, 22], "luan": [5, 7, 9, 10], "luca": 10, "lucil": 1, "lucki": 11, "luckiest": 11, "lukasz": 24, "luke": [6, 9, 10, 12, 21], "luk\u00e1": 8, "luo": 22, "luong": 6, "lym": 22, "lysandr": 6, "lyu": 10, "l\u00e9lio": 1, "m": [1, 5, 6, 7, 9, 10, 11, 12, 20, 22, 24], "m_": [6, 11, 12, 20, 24], "m_1": 6, "m_i": 20, "m_k": 24, "m_m": 6, "m_n": 20, "m_t": 6, "ma": 6, "maarten": [17, 22], "mac": 11, "machel": 17, "macherei": 6, "machin": [6, 7, 8, 9, 10, 11, 13, 20, 24], "machinetransl": [], "macintosh": 11, "maddi": 21, "made": [5, 7, 9, 13], "magic": [], "magic_nam": [], "magic_output_can_be_silenc": [], "magnitud": [1, 12, 24], "mai": [1, 6, 12, 13, 17, 22, 24], "main": [5, 20, 22], "mainli": [1, 6, 12, 20], "mainstream": [1, 12], "maintain": [1, 6, 12, 20], "maintainentc": 22, "mainten": 22, "major": [1, 5, 6, 10, 11, 12, 16], "make": [1, 5, 6, 7, 9, 10, 11, 12, 17, 19, 20, 21, 22, 24], "man": [5, 6, 7, 11, 21], "manag": [0, 6, 10, 12], "mandar": [6, 10], "mani": [1, 5, 6, 7, 8, 9, 11, 12, 13, 20, 22, 24], "manipul": [], "mann": [1, 5, 7, 10], "manner": [0, 6, 9, 19], "manning1999found": [], "mantissa": 20, "manual": 6, "manufactur": 22, "map": [1, 6, 7, 10, 11, 12, 20, 22], "mapl": [], "mappign": 22, "mar94": 7, "marcinkiewicz": 7, "margin": 16, "mari": [1, 7, 22], "marjan": 9, "mark": [1, 5, 6, 10], "markdown": [], "marker": 6, "markov": [7, 21], "marku": 12, "marten": 24, "martin": 8, "mask": [1, 9, 20], "maskedmultiheadattent": 10, "mass": [5, 7], "massiv": [0, 1, 5, 6], "master": 20, "masterpiec": 17, "match": [5, 6, 7, 16, 20], "matena": 9, "materi": 24, "math": [1, 11], "mathbb": [1, 5, 6, 10, 11, 12, 21, 22, 24], "mathbf": [5, 6, 9, 12, 13, 20, 24], "mathcal": [5, 6, 7, 11, 13, 21, 22], "mathemat": [1, 17, 20, 21, 24], "mathematica": [], "mathrm": [6, 7, 9, 12, 21, 24], "matlab": [], "matplotlib": [], "matplotlib_inlin": [], "matric": [1, 6, 8, 10, 11, 12], "matrix": [1, 5, 6, 7, 9, 10, 11, 20, 22], "matsuo": 17, "matt": 6, "matter": 6, "matthew": 6, "matthia": 10, "max": [6, 10, 11, 12, 20, 21, 22], "max_": [11, 12], "max_len": [], "max_val": 12, "max_val_g1": [], "max_val_g2": [], "maxdepth": [], "maxim": [0, 5, 6, 7, 8, 11, 12, 13, 21, 22], "maximum": [1, 7, 11, 12, 13, 20], "mb": 22, "mbart": 5, "mccandlish": 24, "mccann": 9, "mccann2018natur": [], "mccd13": 11, "mdframe": [], "me": [6, 9, 17], "mean": [5, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22], "meaning": [7, 13], "measur": [5, 10, 11], "mechan": [6, 8, 10, 12, 22], "mechnism": 12, "media": [11, 24], "medic": 16, "medicin": [16, 24], "medium": [6, 24], "medprompt": 16, "medqa": 16, "meet": [8, 13], "megatron": 20, "mei": [], "melani": [1, 5, 7, 10], "melvin": 6, "mem_byt": [], "member": 13, "memor": 7, "memori": [1, 6, 10, 11, 22], "memotec": 7, "men": [], "meng": [21, 22], "mengzhou": 21, "mensch": 1, "mentat": [], "mentez": 5, "mention": [6, 8, 24], "menu": [], "mere": 10, "merg": [1, 8, 20, 22], "messag": [], "met": 24, "meta": 1, "metadata": 21, "meteorologi": [], "method": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 21], "methodolog": 22, "methodologi": 24, "metric": [0, 5, 21], "mha": [12, 20], "mi": 21, "mice": 11, "michael": [9, 10, 20], "michiel": 1, "micikeviciu": 20, "micikevicius2017mix": [], "microsoft": [1, 11], "mid": [5, 6, 7, 8, 10, 11, 12, 13, 21, 22, 24], "mid1": 10, "mid2": 10, "middl": [1, 10, 20, 22], "might": [1, 6, 7, 11, 12, 22], "mike": [1, 6, 9, 10, 12], "mikolov": [7, 8, 11], "mikolov2013distribut": 11, "mikolov2013effici": [], "mikolovkbck10": 8, "milakov2018onlinenormalizercalculationsoftmax": 20, "mile": 22, "mileston": [], "milk": 6, "miller": 21, "million": [5, 7, 10, 11, 24], "milton": 21, "mimic": 17, "mimick": 6, "min": [1, 12, 24], "min_": [6, 12], "min_length": 13, "min_val": 12, "min_val_g1": [], "min_val_g2": [], "minaj": [], "minder": 10, "ming": [6, 10], "mingda": [6, 10], "mingfeng": [], "minh": 6, "mini": 6, "minibatch": 20, "miniconda3": [], "minilm": [], "minilm_deep_attention_demo": [], "minilmdeepattentiondemo": [], "minim": [5, 6, 7, 11, 21, 24], "minimind": 25, "minimum": [10, 12, 24], "minor": 6, "minuend": [], "mirac": 22, "mishkin": 21, "mishra": 22, "mismatch": [6, 24], "miss": [6, 11], "mistral": [], "mit": 7, "mit23": 21, "mitchel": 21, "mitig": [1, 8, 10, 12, 13, 16, 20, 21, 24], "mix": [5, 6, 11, 12], "mixed_precis": [], "mixed_precision_process_demo": [], "mixed_precision_training_demo": [], "mixedprecisionprocessdemo": [], "mixedprecisiontrainingdemo": [], "mixtur": [0, 22], "mkb": 8, "mkxs18": 9, "mle": [], "mlm": [6, 10], "mlx": 7, "mmlm": 6, "mna": 20, "mnli": [9, 12], "mobile_bert_demo": [], "mobilebert": [], "mobilebertdemo": [], "mode": [], "model": [9, 13, 16, 17, 19, 22, 24, 26], "modeldistil": [], "modern": [0, 1, 7, 10, 11, 12, 20], "modest": 12, "modif": 24, "modifi": [1, 5, 7, 9, 10, 11, 19], "modul": [1, 5, 12, 20, 22], "modulenotfounderror": [], "moe": 26, "moham": 9, "mohammad": 6, "mohit": 6, "moment": [9, 22, 24], "momentum": 20, "mona": 22, "monetari": 11, "mono": [], "monolingu": [5, 6], "monoton": [1, 24], "mont": [], "more": [0, 1, 5, 6, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "moreov": [7, 10, 17], "morphem": 11, "morpholog": 11, "morron": 22, "most": [1, 5, 7, 9, 10, 11, 12, 13, 16, 19, 20, 21, 24], "mostafa": [10, 22], "mostli": [7, 13], "motiv": [5, 6, 9, 10, 12, 17, 24], "mous": 11, "move": [12, 24], "movement": 24, "movi": [5, 6], "mr": 7, "mrpc": 12, "msc": 11, "mschutze99": 7, "mse": 6, "mu": [1, 24], "much": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22, 24], "multi": [6, 9, 10, 11, 12, 17, 22], "multiarith": 17, "multicolumn": [], "multihead": [1, 20, 22], "multiheadattent": [6, 10], "multilingu": [1, 24], "multilingual_model": [], "multimedia": 11, "multimod": 0, "multimodality_fundament": [], "multipl": [1, 5, 6, 9, 10, 11, 16, 19, 20, 22], "multipli": [1, 7, 8, 10, 12, 13, 24], "multiprocessor": 12, "multirow": [], "multitask": [5, 7, 9, 10], "murtadha": 1, "must": [6, 20], "mutual": 11, "mxc24": 21, "my": [9, 17], "myle": [6, 10], "myref": [], "m\u00f6chte": 10, "n": [1, 5, 6, 8, 10, 11, 12, 13, 17, 21, 24, 25], "n1": 10, "n2": 10, "n_": [1, 6, 7, 11], "n_d": 20, "n_layer": [], "na": [], "nabla": 24, "nabla_": [21, 24], "nagel": 12, "nahb": 7, "naiv": [11, 16, 20], "nakamura": 8, "naman": [6, 9, 10], "name": [1, 6, 7, 9, 10, 21, 24], "namespac": [], "nan": [6, 20, 22], "narang": [9, 16, 20, 22], "narasimhan": [5, 7, 10], "narrow": [6, 13, 24], "nation": 11, "nativ": [], "natur": [0, 1, 6, 7, 8, 9, 10, 11, 13, 17, 19, 22], "natura": 5, "navig": 0, "nbviewer": [], "nccl": 20, "nce": 11, "nd": [], "ne": 5, "nearbi": [10, 11], "nearest": [11, 12], "nearli": 11, "nece": [], "necessari": [1, 7, 12, 13, 16, 20, 24], "necessarili": 13, "need": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 20, 21, 22, 24], "neelakantan": [1, 5, 7, 10], "neg": [1, 6, 7, 13, 17, 24], "neglig": [], "nei": 7, "neighbor": 11, "neighborhood": [], "neil": 22, "neither": 9, "neq": [11, 12], "nesterov": [], "net": 20, "netowk": 8, "networ": 11, "network": [0, 1, 5, 6, 7, 8, 10, 11, 20, 24], "neubig": 6, "neumann": 6, "neural": [0, 1, 6, 7, 10, 11, 20, 24, 26], "neuralmatch": [], "neuralnetworklanguagemodel": [], "neutral": [6, 9, 17], "never": [9, 21], "new": [0, 1, 6, 7, 9, 10, 12, 13, 16, 17, 19, 20, 21, 22, 24], "newli": 9, "newlin": 7, "newser": [], "newton": [], "next": [1, 5, 7, 8, 10, 12, 13, 20, 21, 24], "nformat": [1, 5, 7, 10], "ni": [], "nice": 1, "nichola": 16, "nick": [1, 5, 7, 10], "nicki": [], "nicolo": 16, "nie": [1, 24], "niki": 10, "nine": 22, "niti": [], "nitish": 9, "nj": 10, "nlg": 10, "nli": 22, "nlp": [0, 1, 5, 6, 7, 9, 10, 11, 21, 22], "nlu": [10, 13], "nlz": 16, "nm": 10, "noah": 1, "noam": [1, 9, 10], "node": 20, "nois": [1, 6, 9], "noisecontrastiveestim": [], "noisi": [9, 21], "nomin": 7, "non": [1, 6, 7, 10, 11, 12, 13, 16, 22, 24], "none": [], "nonetheless": [], "nonexecut": 7, "nonlinear": [6, 10, 12, 22], "nonneg": [], "nonperform": 6, "nonsens": 17, "nonsmooth": 1, "noordhui": 24, "noqa": [], "nori": 16, "nori2023can": [], "norm": [], "normal": [5, 6, 7, 10, 11, 12, 20, 21, 22], "norouzi": 6, "norwai": 11, "notabl": [6, 10, 11, 12], "notat": [13, 20], "note": [1, 6, 7, 8, 9, 10, 11, 12, 20, 21, 22, 24], "notebook": [], "noth": [8, 17], "notic": [5, 22], "notin": 12, "notnext": 6, "noun": [7, 11], "nov": 7, "novel": [0, 5, 6, 10], "now": [1, 5, 7, 10, 11, 12, 13, 17, 20, 24], "np": [], "nsp": 10, "nternat": [1, 10], "nuanc": [1, 10, 24], "num_head": [], "num_lay": [], "number": [0, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 22, 24], "numer": [7, 11, 12, 21], "numpi": [], "numref": 11, "nvidia": [12, 20], "o": [1, 6, 7, 10, 11, 12, 13, 20], "o_": [6, 20], "o_1": 10, "o_i": 20, "o_m": 10, "o_n": 10, "o_p": 10, "ob": [], "obd": [], "object": [5, 6, 9, 10, 11, 12, 21, 22, 24], "observ": [5, 6, 7, 8, 9, 10, 11, 12, 22], "obsolet": 19, "obtain": [1, 5, 6, 7, 9, 10, 11, 20, 21], "obvious": 7, "occasion": [], "occupi": 12, "occur": [5, 6, 7, 11, 12], "occurr": [7, 8, 11], "odd": [1, 10], "odot": 24, "ofelia": 6, "off": [13, 16], "offer": [5, 6, 7, 12, 17, 20, 22, 24], "offic": 7, "offlin": 21, "offset": [6, 9, 12, 20], "ofir": 1, "often": [0, 1, 6, 7, 12, 13, 17, 19, 20, 21, 22, 24], "oil": 22, "ok": [], "okai": 17, "olatunji": 20, "old": 7, "oleksii": 20, "omer": [6, 9, 10], "omit": [1, 10], "onc": 20, "one": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 21, 22, 24], "onehot2densevec": [], "ones": [0, 7, 11], "onfer": [1, 10], "ongo": 24, "onli": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 20, 21, 22], "onlin": 24, "onogo": 24, "onto": 11, "oov": 11, "opaqu": [], "open": [0, 1, 5, 7, 24], "openai": [0, 1, 5, 7, 9, 10, 16, 21], "openbookqa": 5, "oper": [1, 6, 8, 10, 12, 19, 22], "operatornam": [1, 5, 6, 7, 8, 10, 11, 12, 13, 21], "opportu": [], "opportun": 8, "oppos": [1, 7], "opposit": 11, "opt": 12, "optic": 7, "optim": [0, 1, 6, 8, 9, 10, 12, 13, 21, 22], "optiom": [], "option": [7, 8, 13], "orang": 16, "order": [5, 6, 7, 9, 10, 11, 12, 16, 24], "ordinari": 6, "org": [1, 6, 10, 11, 12, 17, 19, 20, 21, 22], "organ": [7, 10, 12], "orhan": 6, "orient": [], "origin": [1, 5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 22], "oriol": 6, "orthogon": [], "oslo": 11, "other": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 20, 24], "otherwis": [6, 7, 12, 16], "otim": [1, 12], "ott": [6, 10], "otuput": 10, "ou": [10, 11], "our": [0, 5, 6, 7, 9, 12, 16, 17, 21, 22], "ournal": 9, "out": [5, 6, 9, 10, 11, 12, 16, 20, 21], "outcom": [20, 21], "outcompet": 16, "outdat": 19, "outer": 12, "outlier": 12, "outlin": 21, "outperform": [0, 5, 6, 11, 21], "output": [0, 1, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "output_can_be_silenc": [], "outsid": 12, "ouyang": 21, "over": [0, 1, 5, 6, 7, 8, 9, 10, 11, 13, 16, 21, 22, 24], "overal": [1, 6, 11, 12, 13, 17, 19, 20, 22], "overcom": [1, 10, 11, 12, 20], "overestim": 7, "overfit": [6, 7, 21, 22, 24], "overflow": 20, "overhead": [1, 12, 22], "overst": 0, "overview": 6, "owj": 21, "own": [1, 10, 12, 19, 24], "p": [1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 20, 21, 24], "p_": [6, 7, 11, 12, 13, 20, 22], "p_0": 13, "p_i": 13, "p_n": 11, "p_x": 12, "pa": [5, 6], "packag": [], "package_nam": [], "pad": [6, 7, 10], "padmask": [6, 10], "page": [5, 17], "pagedat": [], "pagedattent": 12, "pagehello": [], "pain": [], "pair": [1, 6, 8, 10, 11, 21, 22, 24], "pairwis": 21, "palm": [0, 16], "pamela": 21, "pan": 1, "panda": [], "panel": [], "pangu": [], "paper": [1, 5, 7, 10, 16, 21, 22, 24], "paperswithcod": 5, "par": 1, "paradigm": [5, 9, 10, 20, 22], "paraemt": 12, "paragraph": [5, 6, 7, 11, 19], "paragraph_to_vector": [], "paragraphtovector": [], "paral": 20, "parallel": [1, 6, 10, 12, 24], "paralleliz": 10, "param": 1, "paramet": [0, 5, 8, 9, 10, 11, 12, 13, 20, 24], "parameter": [6, 8, 21], "paramt": 12, "parent": 21, "parfum": 5, "pari": 11, "parmar": 10, "part": [0, 5, 6, 7, 9, 10, 12, 19, 20, 22, 24], "parti": 9, "partial": [7, 12, 22], "participl": 11, "particular": [6, 16, 17, 19], "particularli": [1, 9, 10, 12, 13, 21, 24], "partit": [20, 21], "pascal": 8, "pass": [5, 6, 10, 12, 13, 16, 20, 21, 22], "passag": 10, "past": [1, 7, 11, 12], "patent": 5, "path": 16, "patit": 20, "patrick": 10, "pattern": [1, 7, 8, 10, 13], "paul": 21, "pauliu": 20, "pave": [], "payal": 6, "pca": 11, "pd": [], "pdf": [5, 7, 10, 19, 21], "pe": [1, 6, 10], "peak": 22, "pear": 11, "peft": 24, "pegasu": 10, "pei": 10, "peiyu": [1, 24], "pellat": 22, "penal": [13, 21, 24], "penalti": [13, 21], "peng": 10, "penguin": 6, "penn": [5, 7], "pennington2014glov": 11, "penntre": 7, "peopl": 7, "per": [6, 10, 20, 21], "percentag": 6, "perform": [0, 1, 6, 7, 10, 11, 13, 16, 17, 19, 20, 21, 22, 24], "perfum": 5, "period": [], "perk": 7, "permut": [9, 10], "perplex": [0, 5], "perspect": [7, 11, 12, 13], "peter": [6, 9, 21], "peters2018deep": [], "petrov": 22, "pff": [], "phase": [5, 7, 9, 10, 11, 24], "phenomenon": [6, 11, 12], "phi": [21, 22], "phi_0": 22, "phil": 6, "philadelphia": 6, "phillip": 22, "phrase": [7, 11, 22], "physic": [5, 7, 24], "pi": [10, 21], "pi_": 21, "pi_r": 21, "pick": [10, 11], "pie": [], "pie_and_polar_chart": [], "piec": 6, "pierr": [1, 7], "pieter": 24, "pigeon": 9, "pioneer": [0, 21], "piotr": [11, 24], "pipelin": [20, 21, 24], "piqa": 5, "pixel": [], "piyush": [6, 10], "place": [10, 20, 22], "plai": [1, 6, 10, 24], "plain": [], "plan": [], "plane": 11, "plateau": 5, "platform": 24, "plausibl": [1, 19], "player": [], "plc": 7, "pleas": [], "plot": 17, "plotli": [], "plt": [], "plu": [5, 6, 9, 10, 12, 17], "plural": [7, 11], "pmi": 11, "pmlr": [1, 6, 10], "png": 9, "pni": 6, "po": 6, "point": [1, 6, 10, 12, 20, 21, 22], "pointer": [], "pointwis": [1, 11, 20], "pointwiseffn": [], "polar": [], "polar_bar": [], "polici": 21, "polosukhin": 10, "polynomi": [], "polysemi": 11, "pool": [12, 16], "poor": [8, 11], "poorli": 7, "pop": [], "popul": 21, "popular": [6, 7, 10, 11, 12, 22, 24], "pormpt": 17, "port": [], "portion": [6, 10, 12, 20], "portit": 24, "pose": [11, 12], "posit": [5, 6, 9, 11, 12, 16, 17, 20, 21, 22, 24], "positionencod": [], "possess": 22, "possibl": [0, 5, 6, 7, 9, 10, 11, 12, 13, 19, 20, 21, 22], "possibli": 11, "post": [1, 5, 10, 12, 24], "postion": [], "postnorm": 1, "potenti": [0, 1, 10, 12, 17, 20, 22], "pour": 5, "power": [0, 1, 6, 10, 12, 19], "ppl": 9, "ppo": [], "pr": 21, "practic": [0, 1, 6, 8, 11, 12, 13, 20, 21, 22], "practis": 20, "practition": [], "practiv": [], "prafulla": [1, 5, 7, 10], "prajit": 1, "pranav": [1, 5, 7, 10], "pre": [1, 5, 7, 8, 10, 11, 13, 16, 17, 21, 22, 24], "pre_softmax": [], "preced": [1, 5, 6, 7, 8, 9, 10, 12, 13, 24], "precis": [7, 12, 17], "pred": 6, "predecessor": 0, "predefin": [], "predict": [0, 1, 5, 7, 8, 9, 10, 11, 12, 13, 16, 21, 24], "predominantli": 24, "prefer": [24, 26], "prefil": 12, "prefix": [9, 11], "premis": [5, 6, 9], "prenorm": 1, "preprint": [1, 6, 9, 10, 11, 16, 20, 24], "preprocess": [7, 9, 16], "presenc": 22, "present": [1, 5, 6, 11, 17, 24], "preserv": [10, 11, 12], "presoftmax": 1, "press": [1, 7], "press2016us": 11, "pretain": 6, "pretrain": [17, 21, 22], "pretrainedlm": 9, "prevent": [10, 12, 13, 20, 21, 24], "previou": [1, 8, 10, 11, 12, 20], "previous": [0, 9, 10, 12, 17, 24], "prf": [], "price": [], "primari": [10, 24], "primarili": [1, 5], "prime": [6, 7, 11, 20, 22], "princip": 11, "principl": [0, 7, 8, 12, 13, 20], "print": 17, "prior": [5, 6, 7, 16, 20, 22], "priori": [], "priya": 24, "pro": [6, 12, 22], "prob": 10, "probabilist": [5, 7, 8, 13], "probabilti": 13, "probabl": [5, 6, 7, 8, 10, 11, 13, 16, 21, 24], "probe": 5, "problem": [1, 6, 9, 12, 13, 16, 17, 20, 24], "problemat": 7, "proce": 12, "procedur": [6, 9, 10], "proceed": [10, 12], "process": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 24], "prod_": [7, 13], "produc": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22], "product": [1, 6, 10, 12, 13, 20, 22], "profession": [0, 6], "profound": [0, 5], "program": [], "programm": [], "prohibit": [6, 24], "project": [1, 6, 8, 9, 11, 12, 20, 22, 24], "projector": 11, "promin": 10, "promis": [0, 19, 21], "promot": 6, "prompt": [0, 1, 5, 10, 19, 21, 24], "propag": 1, "proper": 6, "properit": 1, "properli": [7, 21, 22], "properti": [6, 10, 20], "propog": 1, "proport": [6, 7, 11, 24], "propos": [1, 6, 8, 9, 11, 16], "proposit": 6, "propto": [], "prove": [1, 8], "proven": 0, "provid": [0, 1, 5, 6, 8, 10, 11, 12, 17, 19, 20, 21, 22, 24], "proxim": 21, "prune": [], "psbh": [], "pseudo": 7, "psi": 20, "psl22": 1, "pt": [], "ptb": 7, "ptq": 12, "ptx": 21, "public": 24, "publicli": [], "publish": [6, 7, 10], "pull": 11, "punctuat": [6, 7], "punt": 7, "purpos": [6, 9, 16, 17, 24], "pursuit": 0, "push": [0, 9, 11], "put": 11, "puzzl": 1, "pv": [], "py": [], "pylab": [], "pylab_gui_select": [], "pylabmag": [], "pylabtool": [], "pyplot": [], "python": [17, 25], "python3": [], "q": [1, 5, 10, 12, 20, 24], "q_": 12, "q_i": 1, "q_ik": 1, "q_m": 1, "q_max": 12, "qa": 9, "qat": 12, "qi": 6, "qin": 6, "qiu2020pretrain": 6, "qk": 1, "qkv": 1, "qnli": 12, "qq": 12, "qqp": 12, "qsx": 6, "quac": [], "quad": [1, 12, 20, 21], "quadrat": [1, 10, 20], "quadratur": [], "qualit": [], "qualiti": [1, 5, 7, 11, 13, 16, 17, 19, 20, 22, 24], "quantat": 12, "quantecon": [], "quantit": [], "quantiti": [5, 7, 20], "quantiz": [], "quasi": [], "quebec": 7, "quel": 5, "quelqu": 5, "quentin": 22, "queri": [0, 6, 10, 12, 19, 20], "question": [0, 1, 6, 9, 10, 11, 16, 17, 19, 22, 24], "quick": [17, 22], "quickli": [5, 16, 19, 22, 24], "quit": [5, 6, 11], "qun": 6, "quoc": [1, 6, 16, 17, 22], "qw": [1, 10], "qw_i": 10, "qwen": 1, "qwen2": [20, 22], "r": [1, 5, 7, 8, 9, 10, 11, 12, 21, 22, 24], "r_": 21, "r_l": 21, "race": 0, "radford": [5, 7, 9, 10, 21, 24], "radford2018improv": [], "radford2019languag": [], "radii": [], "radiu": [], "radu": [6, 10], "rae": 21, "rafael": 21, "rafailov": 21, "raffel": 9, "rag": [0, 24], "rai": 21, "rais": 0, "rajbhandari": 20, "rake": 7, "ralph": 21, "ramachandran": 1, "ran": [], "rand": [], "randn": [], "random": [6, 7, 9, 16, 24], "randomli": [6, 9, 13], "rang": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 20, 22, 24], "rangl": [1, 17, 21], "rank": [6, 11, 12, 20, 21], "rank0": 20, "ranker": 16, "rapid": [5, 11], "rapidli": 11, "rare": [1, 6, 8, 11, 12, 13], "raslei": 20, "rate": [1, 6, 16, 24], "rather": [1, 5, 6, 10, 11, 12, 17, 21], "ratio": [7, 11, 20, 24], "rational": 6, "raw": [1, 6], "rceil": 12, "re": [0, 1, 7, 8, 11, 12, 16, 20, 24], "reach": [1, 5, 6, 13, 16], "read": [5, 6, 11, 12, 20], "readabl": [], "reader": [], "readi": 6, "real": [0, 6, 7, 21, 22], "realist": [5, 10], "realiz": [6, 11, 24], "realli": 20, "realm": [], "reappli": [], "reason": [1, 6, 7, 10, 12, 13, 16, 17, 19, 21, 22, 24], "reasongin": 1, "recal": 8, "recalcul": [12, 20], "receiv": [11, 20], "recent": [0, 1, 5, 6, 7, 8, 9, 10], "recis": 20, "recogn": 10, "recognit": [6, 7, 10], "recommend": [10, 22], "recomput": 12, "reconstruct": [9, 10], "recov": [9, 10, 22], "recurr": [], "recurrentmodel_v2": [], "recurrentmodelv2": [], "recurs": 20, "reddit": 24, "redefin": 0, "redistribut": 7, "redo": 20, "redpajama": 24, "reduc": [1, 5, 6, 7, 10, 11, 12, 17, 19, 20, 21, 22, 24], "reduce_max": 20, "reduce_sum": 20, "reducescatt": 20, "reduct": [1, 6, 12, 16, 20], "redund": [12, 20], "ref": 21, "refer": [6, 12, 13, 20, 21], "referenc": [], "refin": 5, "refinedweb": 24, "reflect": [7, 11], "reg": 11, "regard": [5, 10, 22], "regatta": 7, "region": 24, "regress": [5, 9, 10, 11, 24], "regular": [1, 6, 10, 11, 12, 22, 24], "regularli": [], "reid": 17, "reignit": [], "reinforc": 17, "rel": [1, 5, 11, 12, 16, 24], "relat": [0, 6, 7, 9, 11, 13, 20, 24], "relationship": [1, 6, 8, 9, 10, 24], "releas": [], "relev": [5, 6, 11, 16, 19], "reli": [1, 6, 10, 17, 19, 21], "reliabl": [1, 7, 19, 22, 24], "relu": [1, 10, 12], "remain": [1, 5, 7, 12, 22, 24], "remark": [0, 1], "remedi": [7, 24], "rememb": [], "remind": [], "reminisc": 6, "remov": [6, 7, 9, 12, 20, 21, 22], "ren": [1, 24], "renard": 1, "renji": 6, "repeat": [1, 13, 24], "repeatedli": 22, "repetit": 13, "replac": [6, 7, 9, 16], "report": [1, 7, 20], "repres": [0, 1, 6, 7, 8, 10, 11, 12, 16, 19, 20, 21, 22, 24], "represent": [1, 5, 6, 8, 9, 10, 11, 12, 20, 24], "representationss": 11, "reprocess": 12, "reproduc": [], "request": [12, 20], "requir": [1, 5, 6, 7, 8, 10, 11, 13, 16, 17, 19, 21, 22, 24], "rescal": 13, "research": [0, 6, 8, 9, 10, 11, 12, 19, 20, 24], "researchcov": [5, 7, 10], "resembl": 6, "reserv": [12, 20], "reset": 6, "reshap": 0, "resid": 12, "residu": [1, 10, 20], "resolut": [], "resourc": [0, 6, 20, 22, 24], "respect": [6, 10, 11, 12, 20, 21, 22], "respond": 17, "respons": [13, 17, 19, 24], "rest": [7, 9, 12, 20], "restera": 5, "restor": 6, "restrict": [1, 10, 17], "result": [1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 22, 24], "retain": [7, 10, 20, 22], "retrain": [6, 12, 17, 19, 22], "retriev": [0, 5, 6, 16, 19], "return": [0, 1, 17, 19], "reus": 12, "reveal": [7, 10, 11, 12], "review": [1, 6], "revolut": 0, "revolution": [0, 1, 19], "revolutionari": 0, "reward": 13, "rewon": [5, 7, 9, 10, 24], "rho": [1, 24], "rho_1": 24, "rho_2": 24, "rho_i": 24, "rial": 11, "rich": [6, 10, 13], "richard": [9, 16], "rico": 1, "ride": 5, "right": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 24], "rightarrow": [7, 21], "ring": 20, "ringallreduc": 20, "ringreducescatt": 20, "rio": 11, "rise": [], "risk": [12, 20, 22], "river": 11, "rl": [], "rl4lm": 21, "rlhf": 17, "rm": 21, "rmsnorm": 1, "rnn": [8, 10], "rnss18": [5, 7, 10], "ro": [5, 22], "robert": [9, 22], "roberta": [6, 10], "robinson": 22, "robust": [1, 9, 16], "robustli": [6, 10], "rocess": [1, 5, 7, 10], "roform": 1, "role": [0, 1, 6, 10, 24], "romanc": 5, "rome": 11, "rong": [1, 24], "room": 8, "root": [6, 11], "rope": [], "ross": 24, "rossum": [], "rotari": [], "rotat": [1, 6, 9, 10], "roughli": [7, 24], "round": 12, "rout": 1, "routin": [], "row": [10, 11, 12], "rrrh20": 20, "rrs20": [], "rsm": 21, "rsr": 9, "rte": 12, "rtn": 12, "ru": [], "ruben": 7, "ruder": 6, "rudolph": 7, "rui": [], "ruibin": [1, 10], "ruiyang": [1, 24], "ruiz": [], "rule": [1, 6, 7, 8, 11, 13, 20, 24], "rumelhart": [], "rumor": 7, "run": [8, 11, 12, 16, 17, 22], "run_line_mag": [], "runji": [], "runtim": [7, 11, 12], "ruwas": 20, "rwc": [5, 7, 9, 10], "ryan": 21, "ryder": [1, 5, 7, 10], "rzl17": 1, "s3": [5, 7, 10], "s_": [6, 8, 12, 21], "s_0": 21, "s_i": [6, 21], "s_j": 21, "s_t": 21, "s_w": 12, "sablayrol": 1, "sagemak": 24, "sai": [1, 5, 6, 7, 11, 17, 21, 24], "saksham": 6, "salienc": 12, "saliman": [5, 7, 10], "sam": 24, "same": [1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 19, 20, 22], "sampl": [7, 9, 16, 17, 21, 24], "samyam": 20, "san": 5, "sandhini": 21, "sanghai": 1, "sanh": 6, "sanh2019distilbert": [], "sanjeev": 8, "sara": 12, "sargent": [], "sarili": [], "sastri": [1, 5, 7, 10], "satisfactori": [5, 6, 10], "satisfi": [1, 7, 20, 21], "satisifi": 21, "satoshi": 8, "satur": 10, "saulnier": 1, "saurabh": 6, "save": [10, 11, 12, 20, 22], "saw": [], "sbd": 20, "sbh": [], "scalabl": [11, 12], "scalar": [1, 13, 21], "scale": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 20, 21, 24], "scale_g1": [], "scale_g2": [], "scan": 24, "scao": 1, "scatter": 20, "scenario": [1, 6, 11], "sch": 7, "schedual": 24, "schedul": [], "schemat": 12, "scheme": [1, 5, 9, 10, 12, 16], "schulman": 21, "schuster": 6, "schuurman": [16, 17], "scienc": 0, "scientif": [5, 6, 24], "score": [1, 5, 7, 11, 12, 13, 21], "scott": 24, "scrape": 24, "scratch": [10, 24], "scratch1": [], "scriptsiz": [], "sdcw19": 6, "search": [0, 1, 11, 12, 19], "seat": 17, "sebastian": [6, 10], "sebastianraschka": [], "sec": [], "second": [1, 5, 6, 9, 10, 11, 12, 20], "secondli": 10, "secretli": 21, "section": [0, 1, 6, 7, 10, 11, 12, 20, 21], "secur": [], "see": [1, 10, 11, 12, 17, 20, 21, 24], "seed": [], "seen": [6, 7, 10, 11, 20, 22, 24], "seg": 6, "segmenet": 6, "segment": [6, 9, 10], "select": [5, 6, 9, 11, 12, 13, 16, 17, 20, 22], "self": [6, 9, 10, 12, 20, 21, 24], "selfattent": 10, "seltzer": 6, "semant": [1, 5, 6, 7, 8, 9, 24], "send": 20, "sennrich": 1, "sens": 7, "sensibl": 7, "sensit": [16, 20, 22], "sent": 20, "sentenc": [5, 7, 9, 10, 11, 12, 13, 17, 21], "sentiment": [6, 11], "sep": 6, "separ": [1, 5, 6, 10, 12, 22], "seq2seq": [10, 26], "seq_len": [], "seqlength": [], "seqmask": 10, "seqmask_i": 10, "sequenc": [1, 5, 6, 7, 8, 9, 11, 12, 13, 17, 20, 24], "sequencen": 8, "sequenti": [0, 1, 6, 7, 10, 20], "sequitur": [], "sergei": 1, "seri": [1, 10, 26], "serial": [], "serv": [6, 12, 16, 24], "servic": [], "set": [1, 5, 7, 9, 10, 11, 12, 13, 16, 17, 19, 22, 24], "setalgolin": [], "seven": [5, 10], "sever": [0, 1, 6, 7, 8, 10, 11, 12, 17, 19, 22, 24], "sexual": 21, "sft": [], "sgd": 24, "sgdmomentum": [], "sha19": 1, "sha20": 1, "shall": [], "shallow": 1, "shane": [17, 22], "shang": 6, "shaohan": 6, "shape": [0, 1, 12, 13], "shar": [], "sharan": [9, 16, 20, 22], "share": [1, 5, 6, 9, 10, 11, 12, 20], "sharma": [6, 10, 21], "shayn": 22, "shazeer": [1, 9, 10], "shean": 22, "shelf": 16, "shell": [], "shen": 22, "sheng": [12, 16], "shengfeng": 1, "shift": [0, 1, 9, 10, 12], "shiji": 10, "ship": 11, "shirish": 9, "shixiang": [17, 22], "shock": [], "short": [1, 10, 11], "shortag": 10, "shortcom": 11, "shorten": 20, "shorter": [1, 12], "shorthand": [7, 13, 21], "shortli": 10, "shot": [1, 5, 6, 7, 10, 16, 22], "should": [5, 6, 7, 9, 10, 12, 17, 20, 22], "show": [1, 5, 6, 7, 11, 12, 21, 22, 24], "shown": [1, 5, 6, 7, 10, 11, 13, 17, 20, 21, 22], "shrink": 24, "shuai": [], "shuffl": [7, 9], "shume": 6, "shuxin": [1, 10], "shyam": [1, 5, 7, 10], "siddhant": 6, "siddhartha": 22, "side": [5, 6, 10], "sigma": [1, 11, 21], "sigma_1": 1, "sigma_2": 1, "sigma_i": 20, "sigmoid": [1, 6, 8], "sign": 20, "signal": [7, 11], "signific": [0, 1, 5, 6, 7, 10, 12, 16, 19, 20, 22], "significantli": [0, 1, 5, 6, 10, 11, 12, 13, 16, 17, 19, 21, 22, 24], "sim": [7, 11, 12, 21], "sim3": [], "simen": 21, "simiarl": 16, "similar": [1, 5, 6, 7, 8, 9, 11, 16, 20, 21, 24], "similarli": [7, 10], "simpl": [1, 5, 10, 11, 12, 17, 20, 22, 24], "simpler": [7, 16, 17, 21], "simplesgd": [], "simplest": 13, "simpli": [1, 5, 6, 7, 9, 12, 13, 19, 21, 24], "simplic": [1, 6, 10, 22], "simplif": [1, 17], "simplifi": [1, 12, 19, 21], "simpo": 21, "simul": [], "simultan": [6, 12], "sin": [1, 10], "sinan": [], "sinc": [5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 24], "sine": 10, "singer": 24, "singh": 1, "singhal": 6, "singl": [1, 5, 6, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22], "singular": 11, "sink": [], "sinusoid": 1, "sister": 11, "sit": 20, "site": [], "situat": [], "six": [6, 20], "siyuan": 12, "sizabl": 1, "size": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 19, 22], "skew": 5, "skill": [0, 5], "skip": [], "skip_gram_cbow": [], "skipgramcbow": [], "skipgramoptim": [], "slama": 21, "slav": 22, "slice": [], "slide": [], "slightli": 9, "slimpajama": 24, "slope": 1, "slow": [5, 6, 20, 24], "slower": [1, 20], "slp": 1, "slw": 10, "small": [1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 20, 21, 22, 24], "smaller": [0, 1, 6, 7, 8, 10, 11, 12, 22, 24], "smallest": [11, 12], "smdh13": 24, "smith": 1, "smooth": [1, 5, 8, 13], "smoother": 1, "smoothli": [5, 22], "snack": 7, "snippet": 17, "so": [6, 7, 9, 10, 11, 12, 17, 24], "socher": 9, "social": 24, "soft": [6, 13], "softmax": [1, 5, 6, 8, 10, 11, 12, 13], "softwar": 12, "soheil": 5, "sole": 17, "solid": 11, "solla": 12, "solut": [6, 19, 21, 22], "solv": [1, 6, 9, 11, 12, 17, 20], "some": [1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22], "some_valu": [], "someth": [5, 17], "sometim": 1, "somewhat": 5, "somewher": [], "song": 6, "soon": [], "sop": [6, 10], "sophist": 0, "soricut": [6, 10], "sorri": [], "sort": [7, 10, 11, 13], "sota": [], "sound": [1, 5, 19], "sourc": [1, 6, 9, 19], "space": [6, 8, 9, 10, 11, 12, 13, 20, 21], "span": [6, 9], "spark": [], "spars": [0, 11, 26], "sparsiti": 8, "speak": 11, "special": [0, 1, 5, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 24], "specialist": 16, "specif": [0, 1, 5, 6, 7, 9, 10, 12, 16, 17, 19, 20, 21, 22, 24], "specifi": [1, 5, 6, 7, 9, 10, 11, 13, 17, 21], "specifici": 12, "specificlli": 21, "specul": [0, 7], "sped": 6, "speech": 7, "speed": [1, 5, 6, 20, 24], "spell": 6, "spend": 12, "spent": [], "sphinx": [], "spike": [], "split": 10, "spur": 0, "sqrt": [1, 6, 10, 11, 24], "squad": 9, "squad2": [], "squar": [6, 11], "ssangyong": 7, "sst": 12, "st": 12, "stabil": 1, "stabl": [1, 20, 21], "stabli": 24, "stabliz": 1, "stachurski": [], "stack": [1, 6, 10], "stack_depth": [], "stackoverflow": 24, "stage": [1, 5, 6, 7, 9, 10, 11, 24], "stage1": 20, "stai": 11, "staliz": 1, "stand": [0, 6, 10, 11, 20], "standard": [1, 6, 11, 20], "stanford": [], "stanislaw": 22, "star": [], "start": [1, 5, 6, 7, 9, 10, 12, 13, 21], "stat": [], "state": [5, 6, 7, 9, 10, 11, 21, 22], "statement": [], "static": [1, 6, 11], "static_vs_contextualembed": [], "staticvscontextualembed": [], "statist": [11, 22], "statisticallearn": [], "steadili": [], "steam": 11, "steep": 5, "stefano": 21, "stem": [11, 20, 22], "step": [1, 6, 9, 10, 11, 12, 13, 17, 19, 20, 21, 24], "stick": [], "stiennon": 21, "still": [1, 5, 8, 10, 12, 19, 24], "stochast": 13, "stock": 1, "stockton": 11, "stoica": 12, "stop": [6, 9, 12, 24], "storag": [12, 22], "store": [6, 7, 8, 10, 12, 16, 19, 20, 22], "stori": [13, 17], "stork": 12, "stoyanov": [6, 9, 10], "str": [], "straight": [6, 17], "straightforward": [], "strategi": [6, 7, 8, 9, 10, 12, 16, 20, 24], "stream": [6, 12], "street": 7, "strength": [6, 19, 21, 24], "stretch": 5, "strict": [], "strictli": [], "string": 21, "strip": 7, "strong": [5, 9, 12, 21], "stronger": [], "strongli": 24, "structur": [0, 1, 5, 6, 7, 10, 11, 16, 24], "struggl": [5, 12], "student": [0, 6], "studi": [0, 1, 5, 6, 10, 11, 16, 22], "stun": 17, "style": [6, 9, 17, 20, 21], "stylist": 21, "su": 1, "sub": [5, 6, 10, 11, 12], "subbiah": [1, 5, 7, 10], "subdirectori": [], "subgradi": 24, "subject": 7, "sublay": 1, "sublinear": 20, "subplot": [], "subscript": 10, "subsect": [], "subsequ": [0, 5, 12, 13], "subset": [6, 10, 11, 12], "subspac": [1, 10, 12], "substanti": [12, 20, 22], "substitut": [], "subsubsect": 7, "subtabl": [], "subtitl": 5, "subtl": 10, "subtract": [1, 20, 21, 22], "subunit": 11, "subword": [1, 6], "subwordwordembeddingmodel": [], "succ": 21, "success": [1, 5, 6, 10, 20], "successfulli": 22, "successor": 5, "sucess": 24, "suffer": [6, 7, 10, 22], "suffic": 17, "suffici": [12, 20], "suffix": 11, "suggest": [0, 5, 6, 24], "sui": 5, "suit": [6, 7, 10, 24], "suitabl": [1, 9, 12], "sum": [5, 10, 11, 12, 13, 21, 22], "sum_": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 22, 24], "sum_i": [7, 12, 13], "sum_j": [13, 20], "sumit": 1, "summar": [1, 5, 6, 7, 8, 9, 10, 12, 13, 17, 21, 24], "summari": [1, 12], "summat": [6, 11, 12, 13, 20], "summer": 11, "sun": [6, 10], "sun2020mobilebert": [], "superfici": 7, "superflu": [], "superglu": 10, "superglue_benchmark_gpt3": [], "supergluebenchmarkgpt3": [], "superior": [19, 21], "superl": 11, "supervis": [1, 6, 10, 21, 22, 24], "supplement": 19, "supplementari": 6, "suppli": [], "support": [1, 19, 20], "suppos": [1, 5, 6, 7, 13], "suprisinli": 1, "surfac": 24, "surgeon": 12, "surpris": 13, "surprisingli": 6, "surround": [6, 11], "survei": [1, 6, 10, 24], "susana": 6, "sustain": 22, "sutskev": [5, 7, 9, 10, 11, 24], "suzgun": 22, "svd": [], "svdcooccurencematrix": [], "svdwordembed": [], "swam": 11, "swap": 6, "swapo": 7, "swiglu": 1, "swim": 11, "swish": 1, "swish_1": 1, "swiss": 11, "switch": [6, 22], "switzerland": 11, "sy": 6, "sylvain": [10, 22], "symbol": [1, 5, 6, 7, 9, 10, 11], "sympi": [], "symposium": 12, "synact": 7, "syntact": 6, "syntat": 7, "syntax": 6, "synthesi": [], "system": [0, 1, 5, 6, 7, 10, 11, 12, 19], "systemat": [12, 16], "szegedi": 1, "szu": 24, "t": [1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 20, 21, 22, 24], "t5": [10, 20, 26], "t_": 6, "t_1": 10, "t_2": 10, "t_i": [6, 10, 13], "t_j": 10, "t_m": 10, "t_p": 10, "tab": [], "tabl": [1, 7, 9, 10, 11, 12, 20], "tabular": 11, "tackl": [6, 10, 17, 22], "tag": 6, "tai": 22, "tail": [7, 13], "takao": 8, "take": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 21], "taken": [6, 7, 10], "takeshi": 17, "tan": [], "tang": [1, 24], "tanh": 8, "target": [5, 6, 9, 10, 11, 20, 21, 22, 24], "task": [0, 1, 7, 10, 11, 12, 13, 16, 19, 21, 22, 24], "tat": 16, "tau": 6, "taylor": 12, "tb": 22, "teach": [6, 24], "teacher": [6, 21], "team": 21, "tech": 1, "technic": [1, 20, 24], "techniqu": [0, 1, 6, 9, 10, 11, 17, 19, 22, 24, 26], "technologi": [0, 10, 19], "tell": 19, "temperatur": [6, 16], "templat": [], "temporari": 20, "ten": [5, 6, 24], "tend": [7, 9, 11, 13, 21, 24], "tens": 11, "tensor": [], "tensorfloat": 20, "tensorflow": 11, "tention": [], "term": [1, 6, 7, 10, 11, 12, 13, 17, 21, 22, 24], "termin": [], "terri": 21, "terribl": 17, "test": [1, 5, 6, 7, 11, 16], "teven": 1, "text": [0, 1, 6, 7, 8, 10, 11, 12, 13, 16, 19, 20, 21, 22, 24], "textbf": 7, "textbook": [], "textit": [7, 8, 10, 11], "textual": [5, 9], "tf": 11, "tf32": 20, "th": [1, 6, 10, 12], "than": [1, 5, 6, 7, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "thang": 6, "thank": [7, 9], "theater": 5, "thei": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 19, 20, 21, 22, 24], "them": [1, 7, 9, 10, 11, 12, 20, 24], "themselv": [], "theoret": [8, 21], "theori": 10, "therebi": [1, 16], "therefor": [1, 5, 6, 7, 9, 10, 11, 12, 20, 22], "theta": [1, 5, 6, 7, 11, 13, 21, 22, 24], "theta_": [1, 6, 7, 24], "theta_1": [1, 6], "theta_2": [1, 6], "theta_i": 1, "theta_k": [1, 24], "theta_q": 1, "theta_t": [], "theta_x": 1, "thi": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "thibaut": 1, "thin": 17, "thing": 11, "think": [11, 16, 17], "third": 6, "thirti": 6, "thoma": [1, 6, 10], "thoppilan": [16, 21], "thorough": [], "thorp": 1, "those": [1, 6, 7, 11, 12, 21, 22], "though": [7, 9], "thought": [0, 6, 7], "thousand": [1, 5, 24], "three": [1, 5, 6, 10, 11, 19, 20, 21], "threshold": [7, 11, 13], "through": [0, 1, 5, 6, 9, 10, 11, 16, 19, 21, 22], "throughout": [5, 6, 24], "throughput": 12, "thu": [1, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22], "thumbnail": [], "ti": 1, "tianhang": [], "tianhao": [], "tianqi": 20, "tianyi": [1, 24], "tianyu": [], "tieyan": [1, 10], "tijmen": 12, "tild": [10, 11, 24], "tim": [5, 7, 10, 12], "time": [1, 5, 6, 7, 10, 11, 12, 13, 16, 20, 21, 22], "timelin": 1, "times1038": [], "timoth\u00e9": 1, "tini": [1, 6], "tinybert": 10, "tip": [], "titl": [5, 17], "tiwari": 6, "tlm": 6, "todai": 5, "togeth": [5, 8, 10, 11, 12], "tok": 6, "token": [5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 24], "tokenzi": [], "tom": [1, 5, 7, 10, 24], "toma": [8, 11], "tomorrow": 7, "tong": 10, "too": [6, 7, 12, 24], "tool": [0, 1], "top": [1, 6, 7, 9, 10, 11, 16, 19, 20], "topic": [6, 11, 13], "tori": 5, "toronto": 24, "total": [1, 6, 7, 10, 11, 12, 24], "totoal": [], "tough": 11, "tougher": 11, "toujour": 5, "toutanova": [6, 10], "toward": [0, 6, 9, 20, 24], "traceback": [], "track": 13, "trade": [], "tradeoff": [], "tradit": [1, 5, 8, 12, 19, 22], "tradition": 10, "train": [0, 1, 5, 7, 10, 11, 12, 13, 16, 17, 19, 21], "trainabl": 22, "training_data": [], "training_data_distribution_summari": [], "training_fundament": [], "trainingdatadistributionsummari": [], "trane": 1, "transact": 11, "transfer": [5, 6, 9, 22, 24], "transform": [0, 5, 6, 9, 12, 19, 20, 22, 26], "transformer_encod": [], "transformerencod": [], "transformerlay": 5, "transit": [7, 21], "translanguag": 6, "translat": [0, 1, 6, 7, 9, 10, 13, 20], "transpar": 17, "transpos": 1, "treat": [1, 7, 11], "treatment": 1, "tree": [5, 7], "treebank": [5, 7], "trend": 5, "triangl": 10, "trick": [7, 11], "trier": 8, "trigram": 7, "trillion": [0, 20, 24], "tripl": [6, 19], "tripleloss": 6, "trivial": 13, "trivialqa_benchmark_gpt3": [], "trivialqabenchmarkgpt3": [], "triviaqa": 5, "true": [7, 13, 21], "truncat": [6, 7, 11, 16], "trust": [16, 19], "trustworthi": 19, "truth": [16, 17], "try": [17, 19, 20], "ts_length": [], "tt": 20, "tu": [5, 10], "tulloch": 24, "tun": 22, "tune": [0, 1, 9, 10, 12, 13, 16, 17, 21, 24], "tupl": 17, "ture": [], "turn": [11, 21], "twice": [13, 20], "twitter": 24, "two": [1, 5, 7, 9, 10, 11, 12, 13, 20, 21, 24], "ty": 11, "type": [1, 6, 9, 10, 12, 16, 22, 24], "typic": [1, 5, 6, 7, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "typolog": 6, "tze": 7, "u": [0, 1, 5, 7, 8, 10, 11, 12, 13, 20, 22], "u_": [], "u_1": [], "u_n": [], "u_q": 12, "ukasz": 10, "ul2": 16, "ulrv2": [], "ultim": [5, 6, 16], "un": [5, 6, 10, 21], "unabl": [], "unattain": 0, "unbias": [7, 24], "unbound": 1, "unchang": [6, 16], "unclear": 19, "uncommon": [11, 13], "unconvent": 1, "uncorrupt": 10, "under": [5, 6, 7, 21, 24], "underbrac": [1, 6, 11, 20, 21], "underflow": 20, "undergo": [10, 24], "underli": [0, 9], "underlin": [], "underperform": 5, "underpin": [], "underset": 13, "understand": [0, 5, 6, 7, 9, 10, 11, 12, 13, 17, 19, 22, 24], "understood": [6, 7], "undesir": 22, "undoubtedli": 12, "unembed": 21, "uneth": 11, "unfairli": 5, "unfortun": [], "uni": [8, 9, 11], "unicod": 1, "unidirection": 10, "unifi": [1, 6, 9, 10], "uniform": [7, 11, 24], "uniformli": [1, 12, 13], "unigram": 7, "unintend": 21, "unintention": 6, "uniqu": 16, "unit": [1, 6, 10, 11, 12, 20], "univers": [5, 6, 7, 9, 10, 13, 24], "unk": 7, "unknown": 7, "unlabel": [1, 5, 6], "unlik": [0, 1, 19], "unlimit": 8, "unlock": [5, 22], "unnatur": 1, "unnecessarili": 12, "unnorm": [1, 6], "unobserv": 7, "unpreced": 0, "unrealist": 7, "unrel": [], "unseen": [1, 7, 8, 17, 22], "unsmooth": 7, "unstabl": 1, "unstructur": 24, "unsuperivsedlearn": [], "unsupervis": [6, 7, 9, 10, 16], "unsupervisedlearn": [], "unterthin": 10, "until": [13, 21, 24], "untrac": 19, "unus": [12, 20], "unveil": [], "up": [0, 1, 5, 6, 7, 9, 10, 11, 13, 19, 20, 22, 24], "updat": [1, 5, 10, 11, 12, 13, 19, 20, 22, 24], "upgrad": [], "upon": [1, 19], "upper": 10, "uptak": [], "upward": 5, "upweight": 21, "url": [1, 5, 6, 7, 8, 10, 12, 20, 21, 22], "urvashi": 6, "us": [5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 22, 24], "usag": [1, 6, 12, 17, 20, 22], "user": [13, 17, 19, 20, 22], "usual": [5, 6, 11, 12, 20, 22, 24], "uszkoreit": 10, "utf": 1, "util": [1, 6, 9, 10, 11, 12, 16], "utm_medium": [], "utm_oi": [], "utm_psn": [], "utm_sourc": [], "uv": 11, "v": [1, 6, 7, 8, 10, 11, 12, 13, 20, 22], "v2": [], "v_": [1, 11, 24], "v_c": 11, "v_i": [1, 11, 20], "v_j": [11, 20], "v_k": 24, "v_t": 11, "v_w": 11, "vald": 6, "valid": [0, 1, 7, 21], "vallei": 24, "valter": 22, "valu": [1, 6, 7, 10, 11, 12, 13, 20, 21, 22, 24], "valuabl": [], "van": 10, "vanilla": [19, 20], "vanish": 1, "var": 1, "vari": [1, 9, 12, 17, 24], "variabl": [1, 7, 17], "variable_nam": [], "varianc": [1, 20, 24], "variant": [6, 7, 9, 10, 24], "variat": [1, 7, 11], "varieti": 12, "variou": [0, 1, 7, 10, 13, 21, 22, 24], "vast": [0, 1, 6, 11], "vastli": [6, 13], "vaswani": 10, "vdot": [1, 10], "ve": [6, 9], "vecotr": 10, "vector": [1, 5, 6, 8, 9, 10, 11, 12, 16, 19], "vehicl": 22, "veloc": 24, "venkatesh": 20, "verb": [7, 11], "veri": [1, 5, 11, 13, 20, 22, 24], "verifi": [16, 19], "versa": 13, "versatil": [0, 1, 22], "version": [6, 7, 10, 11, 22], "vertic": [], "veselin": [6, 10], "via": [1, 5, 6, 7, 8, 9, 10, 11, 16, 24], "vice": 13, "victor": 6, "video": 22, "view": [5, 6, 11, 19, 21], "vijayakumar2016divers": 13, "vincent": [8, 22], "vinyal": 6, "viridi": [], "virtual": [], "vishrav": 6, "vision": [0, 10], "vision_transform": [], "visit": 21, "visual": [17, 21], "vocab": 6, "vocabulari": [5, 6, 8, 9, 10, 11, 13, 21, 24], "vocabulary_s": [], "volum": 20, "vote": 16, "vr": 6, "vram": [], "vsp": 10, "vw": [1, 10], "vw_i": 10, "w": [1, 6, 7, 8, 9, 10, 11, 12, 22], "w0": [], "w32a8": 12, "w8a32": 12, "w8a8": 12, "w_": [5, 6, 7, 8, 10, 11, 12, 22], "w_0": [7, 10, 22], "w_1": [1, 6, 7, 10, 11], "w_2": [1, 6, 7, 10, 11], "w_c": 11, "w_i": [7, 11, 12, 13], "w_j": [1, 7, 11, 12], "w_k": 11, "w_l": 21, "w_m": 11, "w_n": 7, "w_o": [1, 12, 20], "w_q": 12, "w_quant": 12, "w_t": [8, 11], "w_xx_t": 8, "w_y": 8, "wa": [1, 5, 6, 7, 10, 16, 17, 20, 22, 24], "wachter": 7, "wai": [0, 1, 5, 6, 7, 8, 10, 11, 16, 20, 21, 24], "wainwright": 21, "walk": [8, 11], "wall": 7, "walli": 22, "wan": [], "wang": [1, 6, 10, 16, 17, 22, 24], "wang2020minilm": [], "wang2022self": [], "want": [10, 12, 13, 17, 20, 21], "warm": 1, "warranti": 5, "wasn": [], "wasser": 10, "wast": [12, 20], "watch": 6, "water": [10, 11], "wave": [1, 10], "wavelength": 10, "wayn": [1, 24], "wbz": 22, "we": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "weak": [], "weapon": [], "web": [5, 24], "webpag": 21, "webquest": 5, "websit": [5, 10], "webson": 22, "webtext": [5, 10, 24], "webtext2": 5, "wechat_sess": [], "week": 9, "wei": [6, 9, 10, 16, 17, 22], "wei2021finetun": [], "wei2022chain": [], "weight": [5, 6, 7, 8, 10, 11, 12, 20, 21, 22], "weiglit": 12, "weishung": 16, "weissenborn": 10, "weizhu": 22, "welind": 21, "well": [1, 5, 6, 7, 8, 9, 10, 11, 17, 20, 21, 22], "wen": [1, 24], "wenbin": [], "wenhui": 6, "went": [6, 11], "wenwu": 10, "wenzek": 6, "were": [0, 1, 7, 9, 10, 17, 20, 21, 22, 24], "weren": [], "wesolowski": 24, "west": [5, 7, 10], "wh": 11, "what": [0, 5, 6, 17, 20, 21], "whatev": [], "whe": 11, "when": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "whenev": 21, "where": [0, 1, 5, 6, 7, 8, 9, 10, 11, 13, 17, 19, 20, 21, 22, 24], "wherea": [1, 5, 12], "whether": [0, 6, 9], "which": [0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24], "while": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 21, 22, 24], "whitespac": [], "who": 21, "whole": [6, 10, 20, 22, 24], "whose": [1, 7, 10, 11, 22], "why": [1, 6, 17, 22], "wic": [], "wide": [0, 1, 5, 6, 7, 10, 16, 17, 19, 20, 22], "wider": [6, 12], "widespread": 1, "width": [1, 12, 13], "wiggin": [], "wikipedia": [5, 6, 7, 10, 24], "wikipidia": 6, "wikitext": [1, 7], "william": [1, 9, 22], "win": [], "window": [5, 8, 11, 20, 24], "wine": 11, "winner": 5, "winter2022": [], "wip": 26, "wise": [5, 6, 10, 12, 22], "wish": [], "wit": 0, "withdraw": [], "within": [0, 1, 5, 6, 9, 10, 11, 12, 20], "without": [1, 5, 6, 8, 10, 12, 13, 16, 17, 20, 21, 22, 24], "wolf": 6, "wolff": 12, "wolfgang": 6, "woman": 11, "won": 22, "woosuk": 12, "word": [1, 6, 8, 9, 10, 12, 13, 17, 19, 24, 26], "word2vec": 6, "word2vec_visu": [], "word2vecvisu": [], "word_embedding_demo": [], "wordembed": [], "wordpiec": 6, "work": [1, 5, 9, 11, 12, 16, 20], "world": [0, 1, 5, 7, 17, 22, 24], "worldthi": [], "worldwid": [], "worri": [], "wors": 20, "worth": 10, "would": [0, 6, 7, 8, 9, 10, 11, 12, 13, 20], "wrap": [], "write": [0, 1, 7, 11, 12, 13, 17, 20, 21], "writer": 7, "written": [6, 7, 11, 12], "wrong": [9, 16], "wrote": 5, "wsc": 6, "wu": [5, 6, 7, 9, 10, 21, 24], "wu2016googl": [], "ww": [16, 17], "wwd": 6, "www": 21, "x": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20, 21, 22, 24], "x_": [5, 6, 11, 12, 24], "x_0": 21, "x_1": [5, 6, 10, 20, 24], "x_2": 10, "x_i": [1, 10, 20], "x_j": 20, "x_m": 21, "x_n": [10, 20], "x_p": 10, "x_t": [5, 6, 8, 24], "xia": [6, 10, 21], "xiao": [6, 10], "xiaodan": 6, "xiaodong": [], "xiaohua": 10, "xiaohuan": [], "xiaolei": [1, 24], "xiaoqi": 6, "xin": [1, 6, 24], "xing": [1, 10], "xingzhang": [], "xinyu": [1, 24], "xinyun": 22, "xiong": [1, 9, 10], "xipin": [], "xl": [], "xlarg": [], "xlco": [], "xlm": 5, "xlm_demo": [], "xlm_e_demo": [], "xlmdemo": [], "xlmedemo": [], "xsum": 9, "xtreme": 6, "xu": [20, 21], "xuancheng": [], "xue": [], "xuej": [], "xuezhi": [16, 17, 22], "xv": 1, "xw": 1, "xw_1": 1, "xwvd20": 10, "xxlarg": [], "xyh": [1, 10], "x\u1d62": [], "x\u2081": [], "x\u2082": [], "x\u2099": [], "y": [1, 5, 7, 8, 9, 10, 11, 13, 21, 22, 24], "y_": [8, 13, 22], "y_1": [10, 13, 21], "y_2": [10, 21], "y_i": 10, "y_l": 21, "y_m": 10, "y_n": 13, "y_p": 10, "y_t": [6, 13, 22], "y_w": 21, "yafu": 22, "yang": [1, 6, 10, 20, 22, 24], "yangq": 24, "yann": 12, "yanp": 22, "yanqi": 9, "yanyan": [1, 10], "yao": [], "ye": [], "year": [0, 1, 7, 10], "yellow": 1, "yelong": 22, "yelysei": 12, "yet": 13, "yi": 22, "yichang": [], "yichun": 6, "yield": [0, 1, 10, 12, 17, 24], "yifan": [1, 24], "yime": 6, "yin": [6, 16], "ying": 12, "yingqian": [1, 24], "yinhan": [6, 9, 10], "yonghui": 6, "yoram": 24, "york": 6, "yoshua": 8, "you": [0, 1, 5, 6, 9, 10, 12, 17, 19, 20, 22], "youn": 12, "your": [9, 19, 21, 22], "yourself": 19, "ystem": [1, 5, 7, 10], "yu": [1, 6, 12, 21, 22], "yuan": 6, "yuanzhi": [16, 22], "yue": 22, "yun": [1, 22, 24], "yunchang": [1, 10], "yunfei": [], "yunfeng": 1, "yunxuan": 22, "yupeng": [1, 24], "yuqiong": [], "yuri": 1, "yushuo": [1, 24], "yusuk": 17, "yutaka": 17, "yuxiong": 20, "yyh": [], "yyhbz24": [1, 20], "z": [5, 6, 9, 11, 12, 21, 22], "z_": 13, "z_g": 11, "z_i": [6, 13], "z_j": [6, 13], "zei12": [], "zeiler": [], "zemlyanskii": 1, "zero": [1, 5, 6, 7, 8, 9, 10, 12, 16, 21, 22, 24], "zero_point": 12, "zero_point_g1": [], "zero_point_g2": [], "zeropoint": 12, "zeroshot": 12, "zettlemoy": [6, 9, 10, 12], "zewen": 6, "zeyu": [], "zeyuan": 22, "zhai": 10, "zhang": [1, 10, 12, 16, 20, 21, 22, 24], "zhao": [1, 22, 24], "zhao2023survei": [], "zhaopeng": 10, "zhen": 22, "zheng": [1, 10, 12, 20], "zhenru": [], "zhenzhong": [6, 10], "zhifang": [], "zhifeng": 6, "zhihao": [], "zhihu": [], "zhipeng": [1, 24], "zhiqe": 6, "zhou": [1, 6, 9, 16, 17, 22, 24], "zhu": 22, "zhuang": 12, "zhuanlan": [], "zhuohan": 12, "zhuyun": 22, "zican": [1, 24], "ziegler": 21, "zikang": [1, 24], "zimbabw": 11, "ziya": 21, "zoph": [1, 22], "zs19": 1, "zzl": [1, 24], "\u00e1": [6, 24], "\u00e9": [6, 8], "\u00ed": 6, "\u00fc": 7, "\u0142": 10, "\u03b1": [], "\u03b1_valu": [], "\u03b8": [], "\u03bb": [], "\u03c0": [], "\u03c3": [], "\u03d5": [], "\u03f5_valu": [], "\u2081": [], "\u4e2a\u5143\u7d20": [], "\u4e5f\u5c31\u662f\u8bf4\u8f93\u51fa\u77e9\u9635": [], "\u4ee5\u77e9\u9635\u4e58\u4e3a\u4f8b": [], "\u4f5c\u4e3a\u6240\u6709\u8f93\u5165token\u7684\u6253\u5206\u7ed3\u679c": 21, "\u5176\u5b9e\u4e5f\u53ef\u4ee5\u53d6\u6240\u6709token\u751f\u6210\u7684score\u8fdb\u884c\u5e73\u5747": 21, "\u53c2\u6570\u540d": [], "\u53c2\u6570\u91cf": [], "\u548c": [], "\u56e0\u6b64\u589e\u52a0\u4e86\u548c\u539f\u59cb\u6a21\u578b\u8f93\u51fa\u7684kl\u635f\u5931": 21, "\u5982\u679c\u4ec5\u4ec5\u4f7f\u7528reward": 21, "\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u5728\u504f\u597d\u6570\u636e\u4e0a\u8fc7\u62df\u5408": 21, "\u5bf9\u4e8ellm\u6765\u8bf4": 21, "\u603b\u8ba1": [], "\u635f\u5931\u539f\u672c\u7684\u80fd\u529b": 21, "\u64cd\u4f5c": [], "\u6620\u5c04": [], "\u6700\u540e\u4e00\u4e2a\u8f93\u5165token\u7684\u5904\u7406\u7ed3\u679c\u4f1a\u91c7\u6837\u53d8\u6210next_token": 21, "\u6a21\u5757": [], "\u6bcf\u4e00\u4e2a\u8f93\u5165token\u6700\u7ec8\u90fd\u80fd\u591f\u751f\u6210\u4e00\u4e2a\u6807\u91cf\u503c": 21, "\u6bcf\u4e2a\u5143\u7d20\u7ecf\u8fc7\u4e00\u6b21\u4e58\u6cd5\u548c\u4e00\u6b21\u52a0\u6cd5\u8fd0\u7b97": [], "\u73b0\u5728\u53d8\u6210\u4e86score": 21, "\u77e9\u9635\u4e58\u6cd5": [], "\u8ba1\u7b97\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a": [], "\u8bad\u7ec3\u7684\u6548\u679c\u66f4\u597d\u4e00\u4e9b": 21, "\u8f93\u5165": [], "\u901a\u5e38\u662f\u76f4\u63a5\u53d6\u6700\u540e\u4e00\u4e2ascore": 21, "\u9884\u8bad\u7ec3\u597d\u7684reward\u6a21\u578b\u53ef\u4ee5\u53c2\u8003": 21}, "titles": ["<span class=\"section-number\">1. </span>Introduction: LLM in the Age of AI", "<span class=\"section-number\">9. </span>LLM Architectures Fundamentals", "<span class=\"section-number\">10. </span>MOE Sparse Architectures (WIP)", "<span class=\"section-number\">21. </span>Application of LLM in IR", "<span class=\"section-number\">20. </span>Information Retrieval Fundamentals", "<span class=\"section-number\">8. </span>GPT Series", "<span class=\"section-number\">6. </span>BERT", "<span class=\"section-number\">2. </span>Language Models", "<span class=\"section-number\">3. </span>Early Neural Language Models", "<span class=\"section-number\">7. </span>Seq2Seq: T5 and BART", "<span class=\"section-number\">5. </span>Transformers", "<span class=\"section-number\">4. </span>Word Embeddings", "<span class=\"section-number\">16. </span>Inference Acceleration", "<span class=\"section-number\">15. </span>Decoding", "Multimodality fundamentals", "Vision transformers", "<span class=\"section-number\">18. </span>Advanced prompt techniques", "<span class=\"section-number\">17. </span>Basic prompt", "Advanced rag techniques", "<span class=\"section-number\">19. </span>RAG", "<span class=\"section-number\">14. </span>LLM Training Acceleration", "<span class=\"section-number\">13. </span>LLM Alignement and Preference learning", "<span class=\"section-number\">12. </span>LLM Finetuning", "*Reinforcement Learning Essentials", "<span class=\"section-number\">11. </span>LLM Training Fundamentals", "&lt;no title&gt;", "Table of Contents"], "titleterms": {"": 7, "1": 5, "2": 5, "200": 5, "3": 5, "4": [], "5": [], "50th": [], "A": 19, "And": [6, 7], "For": 20, "In": 10, "It": 6, "Of": [7, 10], "On": 7, "One": 20, "The": [0, 1, 6, 7, 10, 11, 12, 13, 20, 21, 22], "To": 20, "With": [6, 10], "about": 0, "absolut": 1, "acceler": [12, 20], "accuraci": 5, "activ": 20, "adadelta": [], "adagrad": 24, "adam": [20, 24], "adamw": 24, "adapt": [22, 24], "add": 7, "addit": 21, "advanc": [12, 16, 18], "advantag": 19, "ag": 0, "ai": 0, "albert": 6, "algebra": [], "algorithm": [12, 20, 21, 24], "alibi": 1, "align": 21, "alloc": 20, "alpha": 7, "altern": [], "among": 5, "an": [], "anaconda": [], "analysi": [9, 10, 22], "anatomi": [6, 10], "anoth": [], "answer": 5, "appear": 5, "appendix": 20, "applic": [3, 26], "applicationnlp": [], "approach": 22, "ar": [5, 6], "architectur": [1, 2, 6, 10, 26], "arithmet": 5, "around": 5, "articl": 5, "artifici": [], "assumpt": 12, "attent": [1, 10, 12, 20], "augment": [], "awq": 12, "back": 7, "bart": 9, "base": [11, 17, 22], "basic": [1, 12, 13, 17, 22], "bbpe": 1, "beam": 13, "behavior": 13, "benchmark": [6, 7], "bert": 6, "bertbas": 6, "bertlarg": 6, "between": [], "bia": 7, "bibliographi": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 24], "block": 12, "book": [0, 5], "bpe": 1, "branch": 10, "breadown": 1, "breakdown": [1, 10, 12], "byte": 1, "cach": 12, "can": 5, "card": [], "case": 12, "caveat": 7, "cbow": 11, "cell": [], "ch": [], "chain": [16, 17], "challeng": 12, "channel": 12, "checkpoint": 20, "choic": [1, 7, 16, 24], "classif": 17, "clean": 24, "close": 5, "collect": 21, "combin": [12, 16, 24], "comment": [], "common": 5, "commonli": 6, "commun": 20, "compar": 6, "comparis": 22, "comparison": [5, 10, 22], "complet": [], "complex": 13, "compon": 20, "componen": 6, "composit": 1, "comput": [1, 6, 10, 12, 13], "concept": 12, "configur": [1, 6], "consider": [], "consist": 16, "content": 26, "context": [1, 16, 17], "contextu": [], "continu": 24, "contrast": 11, "control": 13, "convent": 10, "corpu": 5, "cost": 12, "cot": [16, 17], "cross": 7, "data": [20, 21, 24], "dataset": 7, "decai": 24, "decod": [10, 13], "deep": [], "deepspe": 20, "denot": [], "dens": 1, "dequant": 12, "deriv": 7, "descent": 24, "design": [], "detail": [], "develop": 10, "devic": 20, "diagon": 12, "differ": [10, 20], "directli": [], "discount": 7, "distil": 6, "distillbert": 6, "distribut": 20, "dmodel": [], "doe": 1, "down": 11, "dpo": 21, "draw": [], "drive": 21, "dure": 20, "dynam": 16, "e": 6, "earli": 8, "edit": [], "effici": [6, 22], "electra": 6, "element": [], "elmo": 6, "embed": [1, 6, 11], "encod": [1, 6, 10], "engin": [], "ensembl": 16, "entropi": 7, "environ": [], "error": 12, "essenti": 23, "estim": [1, 7, 11], "evalu": [6, 7, 21], "exampl": [1, 11, 19], "exercis": [], "expans": 24, "extract": 17, "extrem": 6, "featur": [], "feed": 8, "feedforward": 10, "few": 17, "ffn": 1, "fibonacci": [], "fill": 12, "fine": [5, 6, 22], "finetun": 22, "five": 11, "flash": 20, "float": 20, "flop": 1, "ford": [], "forward": [1, 8], "foundat": 26, "fp8": 12, "framework": 12, "frequent": 11, "from": [1, 20], "fulkerson": [], "fundament": [1, 2, 4, 12, 13, 14, 24], "further": [], "g": [], "g_k": 24, "g_t": [], "gener": [5, 9, 12, 16], "glove": 11, "gpt": 5, "gptq": 12, "gpu": 20, "gqa": [1, 12], "gradient": 24, "gram": [7, 11], "granular": 12, "graphic": [], "greedi": 13, "greek": [], "group": 1, "groupwis": 12, "h": [], "happen": 12, "head": 1, "help": [], "here": [], "hessian": 12, "hidden": [], "how": 21, "human": 5, "hyperparamet": 6, "hypothesi": 22, "i": [1, 10, 11, 12, 19], "identifi": 5, "ii": 11, "implement": [], "import": [], "indent": [], "index": [], "infer": [12, 22, 26], "inform": [4, 26], "initi": 22, "input": [6, 10], "insert": [], "instal": [], "instruct": [17, 22], "int8": 12, "intellig": [], "introduct": [0, 5, 6, 19, 26], "introductori": [], "ir": 3, "jupyt": [], "k": 13, "katz": 7, "kei": [], "kv": [1, 12], "l": [], "l_2": 24, "label": 21, "languag": [0, 5, 6, 7, 8, 10, 12], "larg": 0, "layer": [1, 6, 10], "learn": [16, 17, 21, 23], "length": [], "let": 20, "letter": [], "level": 1, "limit": [], "line": [], "lingual": 5, "list": [], "llama": [], "lll": [], "llm": [0, 1, 2, 3, 12, 17, 20, 21, 22, 24, 26], "lm": 6, "logist": 21, "long": 1, "loop": [], "lora": 22, "loss": 21, "low": 22, "machin": 5, "mani": [], "mask": [6, 10], "matric": 22, "matrix": 12, "maximum": [], "mbert": 6, "mcl": [], "mdp": 21, "mean": 1, "mechan": 1, "med": 16, "memori": [12, 20], "method": [22, 24], "methodologi": 21, "metric": 7, "mha": 1, "minibatch": 24, "minilm": 6, "minim": [12, 19], "mistral": [1, 2], "mix": 20, "mixtur": 24, "mle": 7, "mlp": [], "mobilebert": 6, "modal": [], "model": [0, 1, 5, 6, 7, 8, 10, 11, 12, 20, 21], "modul": [6, 10], "moe": 2, "momentum": 24, "more": 7, "most": 6, "motiv": [7, 8, 19, 20, 21, 22], "movi": 17, "mqa": 1, "multi": [1, 5], "multihead": 10, "multilingu": 6, "multimod": 14, "multipl": 12, "n": [7, 20], "name": [], "natur": 5, "necessari": 10, "neg": 11, "network": 12, "neural": [5, 8, 12], "new": 5, "next": 6, "nine": 11, "nois": 11, "noisecontrastiveestim": [], "nonlinear": 1, "norm": 1, "normal": 1, "notebook": [], "nsp": 6, "number": [1, 20], "numpi": [], "ob": 12, "off": [7, 12], "offlin": [], "one": 20, "onlin": 20, "oov": 7, "oper": 20, "optim": [11, 20, 24], "other": 22, "out": 7, "output": 10, "overal": [10, 21], "overview": [1, 5, 9, 10, 11, 12, 19, 20, 21, 22, 24], "p": 13, "packag": [], "page": 12, "pair": 5, "panda": [], "paper": [], "paradigam": 19, "parallel": 20, "paramet": [1, 6, 7, 22], "part": [], "pass": 1, "pe": [], "peft": 22, "per": 12, "perform": [5, 9, 12], "perplex": 7, "phi": 20, "plot": [], "pointwis": 10, "polici": [], "popular": [], "posit": [1, 10], "post": [], "postion": 1, "power": [], "ppo": 21, "practic": [2, 7], "practiv": [], "pre": [6, 9, 12], "precis": 20, "predict": 6, "prefer": 21, "preliminari": 21, "pretrain": [5, 6, 9, 10, 24], "problem": 11, "process": 20, "program": 17, "prompt": [12, 16, 17, 22, 26], "properti": 1, "prune": 12, "public": [], "put": 6, "python": [], "qualiti": 21, "quant": 12, "quantiz": 12, "queri": 1, "quest": [], "question": 5, "quickstart": [], "qwen2": 1, "r": 6, "rag": [18, 19, 26], "random": [], "rank": 22, "rare": 7, "read": [], "reason": 5, "recurr": [8, 10], "refer": [], "regress": 21, "reinforc": [21, 23], "rel": [], "relationship": [7, 11, 21], "remark": 21, "requir": [12, 20], "respons": [21, 22], "retriev": [4, 26], "review": 17, "reward": 21, "rise": 0, "rl": 21, "rlhf": 21, "rm": 1, "rmsprop": 24, "root": 1, "rope": 1, "rotari": 1, "rtn": [], "run": [], "sampl": [6, 11, 13], "scale": 22, "schedul": 24, "scientif": [], "scipi": [], "search": 13, "sec": [], "select": [], "self": [1, 16], "semant": 11, "sens": 5, "sentenc": 6, "sentiment": 17, "seq2seq": 9, "sequenc": 10, "seri": 5, "set": 6, "sever": [], "sft": 21, "share": [], "short": 5, "shot": 17, "shuffl": 16, "simpl": [7, 21], "size": [20, 24], "skip": 11, "slide": 1, "smooth": [7, 12, 21], "so": [], "softmax": 20, "softwar": [], "solut": [], "solv": [], "sota": 5, "sourc": 24, "spars": 2, "speed": 12, "speical": 12, "squar": 1, "stage": 20, "standard": 12, "star": 7, "start": [], "state": 20, "statist": 7, "stochast": 24, "storag": 20, "strategi": [], "subpackag": [], "subword": 11, "summari": [10, 20], "superglu": 5, "supervis": 5, "svd": 11, "symbol": [], "syntact": 11, "syntax": [], "system": [], "t": [], "t5": 9, "tab": [], "tabl": 26, "task": [5, 6, 9, 17], "techniqu": [7, 12, 16, 18, 20], "temperatur": 13, "tensor": [12, 20], "test": [], "text": [5, 9, 17], "thi": 0, "thought": [16, 17], "tinybert": 6, "todai": 6, "togeth": [6, 16, 24], "token": 1, "tokenzi": 1, "top": 13, "total": 20, "trade": [7, 12], "train": [6, 9, 20, 22, 24, 26], "transform": [1, 10, 15], "translat": 5, "tune": [5, 6, 22], "two": 6, "ty": 1, "type": [11, 20], "un": [], "understand": 1, "unicod": [], "uninstrut": [], "unsupervis": 5, "unveil": [], "up": 12, "updat": [], "url": [], "us": [1, 6, 20], "v": [17, 21], "varianc": 7, "variant": [1, 21], "variou": 6, "version": [], "via": [12, 20, 21], "vision": 15, "visual": [1, 11], "vocabulari": [1, 7], "volumn": 20, "weight": [1, 24], "what": [1, 12, 19], "where": 12, "whether": 5, "which": 1, "while": [], "white": [], "why": [], "window": 1, "wip": 2, "word": [5, 7, 11], "word2vec": 11, "work": 21, "xlm": 6, "your": [], "zero": [17, 20]}})