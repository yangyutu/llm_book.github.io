
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. Seq2Seq: T5 and BART &#8212; LLM Foundations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/chapter_foundation/t5';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8. GPT Series" href="GPT_series.html" />
    <link rel="prev" title="6. BERT" href="bert.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/qe-logo-large.png" class="logo__image only-light" alt="LLM Foundations - Home"/>
    <script>document.write(`<img src="../../_static/qe-logo-large.png" class="logo__image only-dark" alt="LLM Foundations - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Introduction.html">1. Introduction: LLM in the Age of AI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Foundations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="language_models.html">2. Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_language_models.html">3. Early Neural Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="word_embeddings.html">4. Word Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformers.html">5. Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="bert.html">6. BERT</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Seq2Seq: T5 and BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="GPT_series.html">8. GPT Series</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_dense_architectures.html">9. LLM Architectures Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_moe_sparse_architectures.html">10. MoE Sparse Architectures (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Training</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/training_fundamentals.html">11. LLM Training Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/finetuning.html">12. LLM Finetuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/alignment.html">13. LLM Alignement and Preference Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/reinforcement_learning.html">14. *Reinforcement Learning Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/accelerated_training.html">15. LLM Training Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_inference/inference_fundamentals.html">16. Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_inference/inference_acceleration.html">17. Inference Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prompting</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/basic_prompt.html">18. Basic Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/advanced_prompt.html">19. Advanced Prompting Techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Embedding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_text_embedding/text_embedding_fundamentals.html">20. Text Embedding Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_text_embedding/text_embedding_LLM.html">21. LLM Text Embedding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vision LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/multimodality_fundamentals.html">22. Multimodality fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/vision_transformers.html">23. Vision Language Pretraining</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Application in Information Retrieval and RAG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/information_retrieval_fundamentals_part1.html">24. Information Retrieval and Sparse Retrieval</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/information_retrieval_fundamentals_part2.html">25. Information Retrieval and Dense Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/application_LLM_in_IR.html">26. Application of LLM in IR (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/conversational_IR.html">27. Conversational IR (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/basic_rag.html">28. RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/advanced_rag.html">29. Advanced RAG (WIP)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Seq2Seq: T5 and BART</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#t5">7.1. T5</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">7.1.1. Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pretraining">7.1.2. Pretraining</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bart">7.2. BART</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">7.2.1. Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">7.2.2. Pre-training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pretraining-performance-analysis">7.2.3. Pretraining performance analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-fine-tuning">7.2.4. Model Fine Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#language-understanding-tasks">7.2.4.1. Language Understanding Tasks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation-tasks">7.2.4.2. Text Generation Tasks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">7.3. Bibliography</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="seq2seq-t5-and-bart">
<h1><span class="section-number">7. </span>Seq2Seq: T5 and BART<a class="headerlink" href="#seq2seq-t5-and-bart" title="Link to this heading">#</a></h1>
<section id="t5">
<h2><span class="section-number">7.1. </span>T5<a class="headerlink" href="#t5" title="Link to this heading">#</a></h2>
<section id="overview">
<h3><span class="section-number">7.1.1. </span>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h3>
<p>Pretrained language models and transfer learning enable a diverse range of NLP tasks to be solved by a generic and unified architecture paradigm consisting of an representation encoder from the pretrained language model plus a task-dependent prediction head. T5 (Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer) <span id="id1">[<a class="reference internal" href="#id426" title="Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1–67, 2020.">RSR+20</a>]</span> push this limits further. Based on encoder-decoder Transformer model, T5 proposed a unifying framework to solve many tasks by casting them to a text-to-text problem, where  input and output, as well as the task description, are a list of text tokens.</p>
<p>The following diagram <a class="reference internal" href="#chapter-foundation-fig-seq2seq-t5arch"><span class="std std-numref">Fig. 7.1</span></a> illustrates how T5 solves four different NLP problems within a unified framework, including machine learning, linguistic acceptability, semantic similarity, and text summarization.</p>
<figure class="align-default" id="chapter-foundation-fig-seq2seq-t5arch">
<a class="reference internal image-reference" href="../../_images/T5_arch.png"><img alt="../../_images/T5_arch.png" src="../../_images/T5_arch.png" style="width: 657.6px; height: 284.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.1 </span><span class="caption-text">Illustration of the text-to-text universal transfer learning framework for a diverse range of tasks.</span><a class="headerlink" href="#chapter-foundation-fig-seq2seq-t5arch" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Particularly, the model is fed with text that is made up of a task prefix and the input attached to it. We convert a labeled textual dataset to a format like {Task: ‘….’, ‘targets’ : … ‘ } format, where we insert the purpose in the input as a prefix.</p>
<div class="proof example admonition" id="example-0">
<p class="admonition-title"><span class="caption-number">Example 7.1 </span></p>
<section class="example-content" id="proof-content">
<p>In order to train a single model on the diverse set of tasks described above, we need a consistent input and output format across all tasks. As recently noted by <span id="id2">[<a class="reference internal" href="transformers.html#id1172" title="Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9, 2019.">RWC+19</a>, <a class="reference internal" href="#id1469" title="Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon: multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.">MKXS18</a>]</span>, it is possible to formulate most NLP tasks in a text-to-text format - that is, a task where the model is fed some text for context or conditioning and is then asked to produce some output text.</p>
<p>To specify which task the model should perform, we add a task-specific (text) prefix to the original input sequence before feeding it to the model. As an example,</p>
<ul class="simple">
<li><p>To ask the model to translate the sentence “That is good.” from English to German, the model would be fed the sequence “translate English to German: That is good.” and would be trained to output “Das ist gut.”</p></li>
<li><p>For text classification tasks, the model simply predicts a single word corresponding to the target label. For example, on the MNLI benchmark the goal is to predict whether a premise implies <strong>entailment</strong>, <strong>contradicts</strong>, or neither <strong>neutral</strong>. With our preprocessing, the input sequence becomes “mnli premise: I hate pigeons. hypothesis: My feelings towards pigeons are filled with animosity.”</p></li>
<li><p>For the English-German translation task, the “translate English to German: That is good.” input is going to produce “das is gut.”.</p></li>
</ul>
</section>
</div><p>Based on the task-agnostic architecture proposed by T5, solving different NLP tasks becomes how to convert the task into suitable text input output. T5 apply the same model, objective, training procedure, and decoding process for every NLP task.</p>
</section>
<section id="pretraining">
<h3><span class="section-number">7.1.2. </span>Pretraining<a class="headerlink" href="#pretraining" title="Link to this heading">#</a></h3>
<p>T5 has explored a variant of  masking strategies for masked language modeling based pretraining. These masking strategies shares some span of texts with different mask tokens and train the model to only predict masked texts and use mask tokens to indicate the position of recovered texts.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Original Text</p></th>
<th class="head text-left"><p>Thank you for inviting me to your party last week.</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Input masked text ( <span class="math notranslate nohighlight">\(15 \%\)</span> random masking)</p></td>
<td class="text-left"><p>Thank you <span class="math notranslate nohighlight">\(&lt;\mathrm{X}&gt;\)</span> me to your party <span class="math notranslate nohighlight">\(&lt;\mathrm{Y}&gt;\)</span> week.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Target text</p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(&lt;\mathrm{X}&gt;\)</span> for inviting <span class="math notranslate nohighlight">\(&lt;\mathrm{Y}&gt;\)</span> last <span class="math notranslate nohighlight">\(&lt;\mathrm{Z}&gt;\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<p>Besides using large-scale corpus of masked language pretraining, T5 model also utilizes labeled data from different downstream tasks for <strong>multi-task pretraining</strong>. The purpose is to obtain an improved task-agnostic representations via multi-task learning, since learning from multiple related tasks can improve the robustness.</p>
</section>
</section>
<section id="bart">
<h2><span class="section-number">7.2. </span>BART<a class="headerlink" href="#bart" title="Link to this heading">#</a></h2>
<section id="id3">
<h3><span class="section-number">7.2.1. </span>Overview<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>The key contribution of BART (Bidirectional and Auto-Regressive Transformers) <span id="id4">[<a class="reference internal" href="#id431" title="Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. ArXiv:1910.13461, 2019.">LLG+19</a>]</span> is using Seq2Seq Transformer architecture to combine the advantage of bidirectional auto-encoder scheme (like BERT) and Auto-regressive scheme (like GPT).</p>
<p>With well-design pretraining tasks, BART, when fine tuned, is particularly effective for both text generation and for language comprehension tasks. BART has achieved state-of-the-art performance in generative tasks, such extractive summarization, dialogue, and abstractive QA.</p>
</section>
<section id="pre-training">
<h3><span class="section-number">7.2.2. </span>Pre-training<a class="headerlink" href="#pre-training" title="Link to this heading">#</a></h3>
<p>BART adopts a slightly modified Transformer architecture with a bidirectional encoder over corrupted text and a uni-directional autoregressive decoder to recover the original text.</p>
<p>The most important pre-training task for BART is to predict a masked token and use the entire input to get more complete information to make more accurate predictions, with two steps:</p>
<ul class="simple">
<li><p>First, add noise and mask to the input and then use the encoder part to encode noisy input text.</p></li>
<li><p>Second, use an uni-directional decoder to reconstruct the original text, including recover the order and masked words.</p></li>
</ul>
<p>In the masked language model pretraining task in BERT, the prediction of masked words are independent and does not condition on the prediction of other masked words. In BART, masked words are predicted  through auto-regression, allowing the prediction of one masked work to condition other preceding masked words. The BART style pretraining therefore tend to produce representations that are amenable to text generation downstream tasks, in which each word depends on the previously generated words.</p>
<figure class="align-default" id="chapter-foundation-fig-seq2seq-bart-arch">
<a class="reference internal image-reference" href="../../_images/BART_arch.png"><img alt="../../_images/BART_arch.png" src="../../_images/BART_arch.png" style="width: 641.6999999999999px; height: 189.9px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.2 </span><span class="caption-text">Illustration of BART architecture, which consists of a bidirectional encoder (like BERT) and an auto-regressive decoder (like GPT). The original input is <em>ABCDE</em>, while the masked input has text <em>CD</em> masked out and an additional mask inserted before <em>B</em>. The decoder needs to predict the original input offset by one step using the encoder’s output and the original input.</span><a class="headerlink" href="#chapter-foundation-fig-seq2seq-bart-arch" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>BART is pretrained by optimizing a reconstruction loss, which is the cross-entropy between the decoder’s output and the original document. Because of the adoption of the Seq2Seq architecture, BART allows the application of any type of input corruption. When all the information to the encoder is lost, the BART’s decoder part is equivalent to a language model.</p>
<p>We will look at each input corruption scheme and its underlying motivation in detail [<a class="reference internal" href="#chapter-foundation-fig-seq2seq-bart-corruption"><span class="std std-numref">Fig. 7.3</span></a>]:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Technique</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Token Masking</p></td>
<td><p>Tokens are randomly masked with a [MASK] symbol, same as with the BERT model. The model is pre-trained to predict a token based on its context.</p></td>
</tr>
<tr class="row-odd"><td><p>Token Deletion</p></td>
<td><p>Tokens are randomly removed from the documents. The model is pre-trained to determine tokens at which positions are removed.</p></td>
</tr>
<tr class="row-even"><td><p>Text Infilling</p></td>
<td><p>A number of text spans with different lengths (including zero length) are sampled, and then they are replaced by a single [MASK] token. The model is pre-trained to decide how many tokens a span corresponds to.</p></td>
</tr>
<tr class="row-odd"><td><p>Sentence Permutation</p></td>
<td><p>The sentences in the input are segmented based on full stops and shuffled in random order. The model is pre-trained to understand the relationship between sentences.</p></td>
</tr>
<tr class="row-even"><td><p>Document Rotation</p></td>
<td><p>The input is rotated (i.e., is right shifted) so that it begins with a randomly selected token. The model is pre-trained to find the start position of a document.</p></td>
</tr>
</tbody>
</table>
</div>
<figure class="align-default" id="chapter-foundation-fig-seq2seq-bart-corruption">
<a class="reference internal image-reference" href="../../_images/BART_corruption.png"><img alt="../../_images/BART_corruption.png" src="../../_images/BART_corruption.png" style="width: 470.7px; height: 309.59999999999997px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.3 </span><span class="caption-text">Different input text corruption schemes in BART.</span><a class="headerlink" href="#chapter-foundation-fig-seq2seq-bart-corruption" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="pretraining-performance-analysis">
<h3><span class="section-number">7.2.3. </span>Pretraining performance analysis<a class="headerlink" href="#pretraining-performance-analysis" title="Link to this heading">#</a></h3>
<p>The followings shows the performance on pretraining objectives. (Table from <span id="id5">[<a class="reference internal" href="#id431" title="Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. ArXiv:1910.13461, 2019.">LLG+19</a>]</span>).</p>
<div class="pst-scrollable-table-container"><table class="table" id="id1595">
<caption><span class="caption-number">Table 7.1 </span><span class="caption-text">Comparison of pre-training objectives. Performance varies considerably across tasks, but the BART models with text infilling demonstrate the most consistently strong performance. .</span><a class="headerlink" href="#id1595" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head text-left"><p>Model</p></th>
<th class="head text-center"><p>SQuAD 1.1</p></th>
<th class="head text-center"><p>MNLI</p></th>
<th class="head text-center"><p>ELI5</p></th>
<th class="head text-center"><p>XSum</p></th>
<th class="head text-center"><p>ConvAI2</p></th>
<th class="head text-center"><p>CNN/DM</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p></p></td>
<td class="text-center"><p>F1</p></td>
<td class="text-center"><p>Acc</p></td>
<td class="text-center"><p>PPL</p></td>
<td class="text-center"><p>PPL</p></td>
<td class="text-center"><p>PPL</p></td>
<td class="text-center"><p>PPL</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>BERT Base (Devlin et al., 2019)</p></td>
<td class="text-center"><p>88.5</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{8 4 . 3}\)</span></p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
<td class="text-center"><p>-</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Language Model</p></td>
<td class="text-center"><p>76.7</p></td>
<td class="text-center"><p>80.1</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{2 1 . 4 0}\)</span></p></td>
<td class="text-center"><p>7.00</p></td>
<td class="text-center"><p>11.51</p></td>
<td class="text-center"><p>6.56</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>BART Base</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>w/ Token Masking</p></td>
<td class="text-center"><p>90.4</p></td>
<td class="text-center"><p>84.1</p></td>
<td class="text-center"><p>25.05</p></td>
<td class="text-center"><p>7.08</p></td>
<td class="text-center"><p>11.73</p></td>
<td class="text-center"><p>6.10</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>w/ Token Deletion</p></td>
<td class="text-center"><p>90.4</p></td>
<td class="text-center"><p>84.1</p></td>
<td class="text-center"><p>24.61</p></td>
<td class="text-center"><p>6.90</p></td>
<td class="text-center"><p>11.46</p></td>
<td class="text-center"><p>5.87</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>w/ Text Infilling</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{9 0 . 8}\)</span></p></td>
<td class="text-center"><p>84.0</p></td>
<td class="text-center"><p>24.26</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{6 . 6 1}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{1 1 . 0 5}\)</span></p></td>
<td class="text-center"><p>5.83</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>w/ Document Rotation</p></td>
<td class="text-center"><p>77.2</p></td>
<td class="text-center"><p>75.3</p></td>
<td class="text-center"><p>53.69</p></td>
<td class="text-center"><p>17.14</p></td>
<td class="text-center"><p>19.87</p></td>
<td class="text-center"><p>10.59</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>w/ Sentence Shuffling</p></td>
<td class="text-center"><p>85.4</p></td>
<td class="text-center"><p>81.5</p></td>
<td class="text-center"><p>41.87</p></td>
<td class="text-center"><p>10.93</p></td>
<td class="text-center"><p>16.67</p></td>
<td class="text-center"><p>7.89</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>w/ Text Infilling + Sentence Shuffling</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{9 0 . 8}\)</span></p></td>
<td class="text-center"><p>83.8</p></td>
<td class="text-center"><p>24.17</p></td>
<td class="text-center"><p>6.62</p></td>
<td class="text-center"><p>11.12</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathbf{5 . 4 1}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="model-fine-tuning">
<h3><span class="section-number">7.2.4. </span>Model Fine Tuning<a class="headerlink" href="#model-fine-tuning" title="Link to this heading">#</a></h3>
<p>The pre-trained BART model has both text representation and generation capabilities, so it is applicable for both language understanding and text generation downstream tasks.</p>
<section id="language-understanding-tasks">
<h4><span class="section-number">7.2.4.1. </span>Language Understanding Tasks<a class="headerlink" href="#language-understanding-tasks" title="Link to this heading">#</a></h4>
<p><strong>Sequence classification</strong> For sequence or token classification tasks, the encoder and decoder of BART use the same input, and the state of the hidden layer at the final moment of the decoder is used as the vector representation of the input text. The vector representation is fed into the multi-class linear classifier. Similar to the [CLS] token of the BERT model, the BART model adds an additional special token at the last position of the decoder input, and uses the hidden layer state of this token as the representation of the text.</p>
<p><strong>Token classification.</strong> For sequence or token classification tasks, the encoder and decoder of BART use the same input, the top hidden state of the decoder as a representation for each
word. The vector representation is fed into the multi-class linear classifier.</p>
<figure class="align-default" id="chapter-foundation-fig-seq2seq-bart-finetuning-classification">
<a class="reference internal image-reference" href="../../_images/BART_fine_tuning_classification.png"><img alt="../../_images/BART_fine_tuning_classification.png" src="../../_images/BART_fine_tuning_classification.png" style="width: 595.2px; height: 221.20000000000002px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.4 </span><span class="caption-text">To use BART for classification problems, the same
input is fed into the encoder and decoder, and the representation from the final output is used.  Image from <span id="id6">[<a class="reference internal" href="#id431" title="Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. ArXiv:1910.13461, 2019.">LLG+19</a>]</span>.</span><a class="headerlink" href="#chapter-foundation-fig-seq2seq-bart-finetuning-classification" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="text-generation-tasks">
<h4><span class="section-number">7.2.4.2. </span>Text Generation Tasks<a class="headerlink" href="#text-generation-tasks" title="Link to this heading">#</a></h4>
<p><strong>Text generation.</strong> BART models can be used directly for conditional text generation tasks such as text summarization. Take text summarization as an example, the input of the encoder is the text to be summarized, and the decoder generates the corresponding target text in an auto-regressive manner.</p>
<p><strong>Machine translation.</strong> When used for machine translation tasks, the BART model cannot be directly fine-tuned because the source and target languages use different vocabulary sets. Therefore, the researchers propose to replace the input embedding layer of the BART model encoder with a small Transformer encoder, <strong>which is used to align the vocabulary in the source language to the input representation space of the target language</strong>. During the fine-tuning phase, the parameters of this newly introduced source language encoder are randomly initialized, and most of the other parameters of the BART model are pre-trained.</p>
<p>There are two stages in the fine-tuning phase.</p>
<ul class="simple">
<li><p>First, only the source language encoder, the BART model position vector, and the self-attention input projection matrix of the first layer of the BART pretrained encoder are trained; The rest of model parameters are fixed.</p></li>
<li><p>Second, a small number of iterations are performed on all model parameters.</p></li>
</ul>
<figure class="align-default" id="chapter-foundation-fig-seq2seq-bart-finetuning-translation">
<a class="reference internal image-reference" href="../../_images/BART_fine_tuning_translation.png"><img alt="../../_images/BART_fine_tuning_translation.png" src="../../_images/BART_fine_tuning_translation.png" style="width: 380.40000000000003px; height: 236.4px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.5 </span><span class="caption-text">For machine translation, we learn a small additional
encoder that replaces the word embeddings in BART. The
new encoder can use a disjoint vocabulary. Image from <span id="id7">[<a class="reference internal" href="#id431" title="Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. ArXiv:1910.13461, 2019.">LLG+19</a>]</span>.</span><a class="headerlink" href="#chapter-foundation-fig-seq2seq-bart-finetuning-translation" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
</section>
<section id="bibliography">
<h2><span class="section-number">7.3. </span>Bibliography<a class="headerlink" href="#bibliography" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id8">
<div role="list" class="citation-list">
<div class="citation" id="id431" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LLG+19<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id4">1</a>,<a role="doc-backlink" href="#id5">2</a>,<a role="doc-backlink" href="#id6">3</a>,<a role="doc-backlink" href="#id7">4</a>)</span>
<p>Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. <em>ArXiv:1910.13461</em>, 2019.</p>
</div>
<div class="citation" id="id1469" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">MKXS18</a><span class="fn-bracket">]</span></span>
<p>Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon: multitask learning as question answering. <em>arXiv preprint arXiv:1806.08730</em>, 2018.</p>
</div>
<div class="citation" id="id1166" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">RWC+19</a><span class="fn-bracket">]</span></span>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. <em>OpenAI Blog</em>, 1(8):9, 2019.</p>
</div>
<div class="citation" id="id426" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">RSR+20</a><span class="fn-bracket">]</span></span>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. <em>Journal of Machine Learning Research</em>, 21(140):1–67, 2020.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/chapter_foundation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bert.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">6. </span>BERT</p>
      </div>
    </a>
    <a class="right-next"
       href="GPT_series.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>GPT Series</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#t5">7.1. T5</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">7.1.1. Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pretraining">7.1.2. Pretraining</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bart">7.2. BART</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">7.2.1. Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">7.2.2. Pre-training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pretraining-performance-analysis">7.2.3. Pretraining performance analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-fine-tuning">7.2.4. Model Fine Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#language-understanding-tasks">7.2.4.1. Language Understanding Tasks</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation-tasks">7.2.4.2. Text Generation Tasks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">7.3. Bibliography</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yuguang Yang
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>