
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>11. LLM Training Fundamentals &#8212; LLM Foundations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/chapter_training/training_fundamentals';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="12. LLM Finetuning" href="finetuning.html" />
    <link rel="prev" title="10. MoE Sparse Architectures (WIP)" href="../chapter_LLM_arch/LLM_moe_sparse_architectures.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/qe-logo-large.png" class="logo__image only-light" alt="LLM Foundations - Home"/>
    <script>document.write(`<img src="../../_static/qe-logo-large.png" class="logo__image only-dark" alt="LLM Foundations - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Introduction.html">1. Introduction: LLM in the Age of AI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/language_models.html">2. Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/neural_language_models.html">3. Early Neural Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/word_embeddings.html">4. Word Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/transformers.html">5. Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/bert.html">6. BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/t5.html">7. Seq2Seq: T5 and BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/GPT_series.html">8. GPT Series</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_dense_architectures.html">9. LLM Architectures Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_moe_sparse_architectures.html">10. MoE Sparse Architectures (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Training</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">11. LLM Training Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="finetuning.html">12. LLM Finetuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="alignment.html">13. LLM Alignement and Preference Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_learning.html">14. *Reinforcement Learning Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="accelerated_training.html">15. LLM Training Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_inference/inference_fundamentals.html">16. Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_inference/inference_acceleration.html">17. Inference Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prompting</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/basic_prompt.html">18. Basic Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/advanced_prompt.html">19. Advanced Prompting Techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Embedding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_text_embedding/text_embedding.html">20. Text Embedding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vision LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/multimodality_fundamentals.html">21. Multimodality fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/vision_transformers.html">22. Vision Language Pretraining</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Application in Information Retrieval and RAG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/information_retrieval_fundamentals_part1.html">23. Information Retrieval and Text Ranking: I</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/information_retrieval_fundamentals_part2.html">24. Information Retrieval and Text Ranking: II</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/application_LLM_in_IR.html">25. Application of LLM in IR (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_application_IR/conversational_IR.html">26. Conversational IR (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/basic_rag.html">27. RAG and Conversational IR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/advanced_rag.html">28. Advanced RAG (WIP)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>LLM Training Fundamentals</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-overview">11.1. Training Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pretraining">11.2. Pretraining</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentals">11.2.1. Fundamentals</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-sources-and-cleaning">11.2.2. Data sources and cleaning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-mixture-and-schedule">11.2.3. Data mixture and schedule</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continued-pretraining">11.2.4. Continued Pretraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-token-prediction">11.2.5. Multiple Token Prediction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-algorithms">11.3. Optimization Algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minibatch-stochastic-gradient-descent">11.3.1. Minibatch Stochastic Gradient Descent</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-gradient-method">11.3.2. Adaptive Gradient Method</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-gradient-adagrad">11.3.2.1. Adaptive Gradient (AdaGrad)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rmsprop">11.3.2.2. RMSProp</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#momentum-method">11.3.3. Momentum Method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-together-adam-and-adamw">11.3.4. Combined Together: Adam and AdamW</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adam">11.3.4.1. Adam</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#l-2-weight-decay-and-adamw">11.3.4.2. <span class="math notranslate nohighlight">\(L_2\)</span> Weight Decay and AdamW</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">11.4. Bibliography</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="llm-training-fundamentals">
<h1><span class="section-number">11. </span>LLM Training Fundamentals<a class="headerlink" href="#llm-training-fundamentals" title="Link to this heading">#</a></h1>
<section id="training-overview">
<h2><span class="section-number">11.1. </span>Training Overview<a class="headerlink" href="#training-overview" title="Link to this heading">#</a></h2>
<p>The chapter discuss LLM training, which can be broadly divided into two stages, each with its own purpose and methodologies:</p>
<ol class="arabic simple">
<li><p><strong>Pretraining</strong>: This initial phase involves using self-supervised learning (e.g., autoregressive learning objective) let the model to learn language structures of a diverse and extensive corpus of text data. The model learns to predict words or tokens based on context, developing a broad understanding of language structure and semantics. We’ll discuss the basics of pretraining and explore the concept of continuing pretraining, which allows models to adapt to new domains or languages.</p></li>
<li><p><strong>Post-training</strong>: After the initial pretraining, models often undergo additional training phases to enhance their performance on specific tasks or to better follow instructions. This includes:</p>
<ul class="simple">
<li><p><strong>Finetuning</strong>: Adapting the pretrained model to specific tasks or domains. Particularly, <strong>instruction finetuning</strong> involves teaching the model to follow explicit instructions or prompts by training on large-scale and diverse (instruction, response) pair data. We cover this in <a class="reference internal" href="finetuning.html#chapter-training-sec-llm-finetuning"><span class="std std-ref">LLM Finetuning</span></a>.</p></li>
<li><p><strong>Alignment and Preference Learning</strong>: Ensuring the model’s outputs align with human values and preferences.
we cover this direction in <a class="reference internal" href="alignment.html#chapter-training-sec-llm-alignment"><span class="std std-ref">LLM Alignement and Preference Learning</span></a>.</p></li>
</ul>
</li>
</ol>
<p>Finally, we cover fundamentals in  <strong>LLM optimization algorithms</strong>. Throughout the LLM training process, various optimization algorithms are employed to adjust the model’s parameters efficiently. We’ll examine popular techniques such as stochastic gradient descent (SGD), Adam, and their variants, discussing how they contribute to the model’s learning process.</p>
</section>
<section id="pretraining">
<h2><span class="section-number">11.2. </span>Pretraining<a class="headerlink" href="#pretraining" title="Link to this heading">#</a></h2>
<section id="fundamentals">
<h3><span class="section-number">11.2.1. </span>Fundamentals<a class="headerlink" href="#fundamentals" title="Link to this heading">#</a></h3>
<p>Pretraining has become a cornerstone in the development of LLM, which contributes to</p>
<ul class="simple">
<li><p>the general langugae understand and generation ability</p></li>
<li><p>acquire world knowledge</p></li>
<li><p>other emergent abilities like reasoning</p></li>
</ul>
<p>The dominant LLM pretraining objective is auto-regressive language modeling, which predict the next words given preceding word sequence. Given an input sequence <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1,...,x_T)\)</span>, auto-regressive language modeling minimize the negative log likelihood given by</p>
<div class="math notranslate nohighlight">
\[L = - \sum_{t=1}^{T} \log p\left(x_{t} \mid \mathbf{x}_{t-k-1:t-1},\theta\right)\]</div>
<p>where <span class="math notranslate nohighlight">\(p\left(x_{t} \mid \mathbf{x}_{t-k-1:t-1}\right)\)</span> is the predicted probability distribution for token <span class="math notranslate nohighlight">\(x_t\)</span> given preceding token sequence <span class="math notranslate nohighlight">\(\mathbf{x}_{t-k-1:t-1}\)</span> with a context window size <span class="math notranslate nohighlight">\(k\)</span> (<span class="math notranslate nohighlight">\(k\)</span> can range from hundreds to tens of thousands, depending on the model configuration).</p>
<p>There are scaling laws <span id="id1">[<a class="reference internal" href="#id46" title="Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo Jun, Tom B Brown, Prafulla Dhariwal, Scott Gray, and others. Scaling laws for autoregressive generative modeling. arXiv preprint arXiv:2010.14701, 2020.">HKK+20</a>, <a class="reference internal" href="#id45" title="Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.">KMH+20</a>]</span> discovered on LLM pretraining, which establishes mathematical relationships model performance given model size, dataset size, and the amount of compute. The availability of scaling laws has several benefits:</p>
<ul class="simple">
<li><p>It provides to benchmark to enable LLM pretraining to be done in a predictable way.</p></li>
<li><p>It help design better training strategy by optimizing the model size and data size under compute constraint.</p></li>
</ul>
</section>
<section id="data-sources-and-cleaning">
<h3><span class="section-number">11.2.2. </span>Data sources and cleaning<a class="headerlink" href="#data-sources-and-cleaning" title="Link to this heading">#</a></h3>
<p>The quality and diversity of training data significantly impact the performance of pretrained models. Common sources include:</p>
<ol class="arabic simple">
<li><p>Web Crawls: Web are avilable in large scale and serve as the primary data source to provide diverse, multilingual data, but web data usually require extensive filtering and cleaning. Example data source include CommonCrawl, C4 (The Colossal Clean Crawled Corpus), RedPajama-Data, RefinedWeb, WebText, etc.</p></li>
<li><p>Books and Literature: Projects like BookCorpus, the Gutenberg Project, arXiv offer high-quality, long-form text.This is an important source for LLM to learn world knowledge and liguistic information.</p></li>
<li><p>Wikipedia: A reliable source of factual information across many languages and domains.</p></li>
<li><p>Social Media and Forums: Platforms like Reddit or X (twitter) provide more informal, conversational language.</p></li>
<li><p>Code: Github code (as used in Codex <span id="id2">[<a class="reference internal" href="#id47" title="Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, and others. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.">CTJ+21</a>]</span>) and code-related question-answering
platforms (e.g., StackOverflow).</p></li>
<li><p>Domain specific Corpora: Domain-specific datasets (e.g., scientific papers, legal documents) for targeted pretraining.</p></li>
</ol>
<p>The following <a class="reference internal" href="#chapter-training-fig-fundamentals-pretrain-data-distribution"><span class="std std-numref">Fig. 11.1</span></a> summarize the data source and ratio for existing LLM pretraining.</p>
<figure class="align-default" id="chapter-training-fig-fundamentals-pretrain-data-distribution">
<a class="reference internal image-reference" href="../../_images/training_data_distribution_summary.png"><img alt="../../_images/training_data_distribution_summary.png" src="../../_images/training_data_distribution_summary.png" style="width: 850.5px; height: 320.5px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 11.1 </span><span class="caption-text">Pretrain data source distribution for existing LLMs. Image from <span id="id3">[<a class="reference internal" href="#id1534" title="Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.">ZZL+23</a>]</span>.</span><a class="headerlink" href="#chapter-training-fig-fundamentals-pretrain-data-distribution" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>While the scale is one factor impacting resulting model performance (i.e., the scaling law), the quality of data and the ratio of different data types play an equally important role. As dominant pretraining data is from the web, data clearning and quality control is a crucial step for sucessful LLM pretraining [<a class="reference internal" href="#chapter-training-fig-fundamentals-pretrain-data-distribution"><span class="std std-numref">Fig. 11.1</span></a>].
The following <a class="reference internal" href="#chapter-training-fig-fundamentals-pretrain-data-clean-pipeline"><span class="std std-numref">Fig. 11.2</span></a> summarize the key steps on cleaning training data..</p>
<figure class="align-default" id="chapter-training-fig-fundamentals-pretrain-data-clean-pipeline">
<a class="reference internal image-reference" href="../../_images/pretraining_data_cleaning_pipeline.png"><img alt="../../_images/pretraining_data_cleaning_pipeline.png" src="../../_images/pretraining_data_cleaning_pipeline.png" style="width: 866.4px; height: 187.2px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 11.2 </span><span class="caption-text">Illustration of data cleaning pipeline for curating LLM pretraining data. Image from <span id="id4">[<a class="reference internal" href="#id1534" title="Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.">ZZL+23</a>]</span>.</span><a class="headerlink" href="#chapter-training-fig-fundamentals-pretrain-data-clean-pipeline" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Onogoing challenges for constructing LLM pretraining data include:</p>
<ul class="simple">
<li><p>Data quality and bias: Ensuring data quality and mitigating biases present in web-scraped data is an ongoing challenge.</p></li>
<li><p>Multilingual representation: Balancing representation across languages, especially for low-resource languages, remains difficult.</p></li>
</ul>
</section>
<section id="data-mixture-and-schedule">
<h3><span class="section-number">11.2.3. </span>Data mixture and schedule<a class="headerlink" href="#data-mixture-and-schedule" title="Link to this heading">#</a></h3>
<p>With cleaned data from different data sources, it is essential to design data feeding strategies to pretrain LLM with target capabilities. Two important aspects of data feeding strategy are</p>
<ul class="simple">
<li><p>the portition of different data sources</p></li>
<li><p>the order of each data source used in pretraining</p></li>
</ul>
</section>
<section id="continued-pretraining">
<h3><span class="section-number">11.2.4. </span>Continued Pretraining<a class="headerlink" href="#continued-pretraining" title="Link to this heading">#</a></h3>
<p>Continued pretraining of LLM involves updating pre-trained models with new data (usually in large scale) instead of re-training them from scratch.
addresses a fundamental challenge in the application of large language models (LLMs): the mismatch between the general knowledge acquired during initial pretraining and the specific knowledge required for domain-specific tasks.
While pretrained LLMs demonstrate impressive general language understanding, they may lack the nuanced knowledge and vocabulary necessary for specialized domains such as medicine, law, or specific scientific fields. Continued pretraining aims to bridge this gap by further training the model on domain-specific corpora, allowing it to adapt its learned representations and knowledge to better suit the target domain or task.
It improve LLM’s performance in the target domain by enhance language understanding and acquiring domain knowledge in the target domain.</p>
<p>There are also cost associated with continued pretraining, including</p>
<ul class="simple">
<li><p><strong>Catastrophic forgetting</strong>: The model may degrade its general language understanding when it is heavily continued pretrained on the domain data.</p></li>
<li><p><strong>Computational cost</strong>: Although more efficient than full pretraining, continued pretraining can still be computationally expensive for very large models.</p></li>
<li><p><strong>Data requirements</strong>: High-quality, domain-specific data is crucial for effective continued pretraining.</p></li>
</ul>
<p>One example of continued pretraining is the <strong>Linly-Chinese-LLaMA-2</strong> project (<a class="github reference external" href="https://github.com/CVI-SZU/Linly">CVI-SZU/Linly</a>). The motivation behind this project is to improve the cross-lingual capability, particularly in Chinese, of many open Large Language Models (LLMs) such as Llama and Falcon. These models were initially pretrained on text data that is predominantly in English.</p>
<p>Key technical details on the continued pretraining:</p>
<p><strong>Training data composition</strong>: The continued pretraining used hundreds of millions of high-quality public Chinese text data, including news, community Q&amp;A, encyclopedias, literature, and scientific publications. Besides, the project incorporated 1) a large amount of Chinese-English parallel corpora in the early stages of training to help the model quickly transfer English language capabilities to Chinese and 2) English text corpus like SlimPajama and RefinedWeb to prevent the model from forgetting previously acquired knowledge.</p>
<p><strong>Training data schedule</strong>: A curriculum learning strategy was employed. In the early stages of training, more English language materials and parallel corpora were used. As the number of training steps increased, the proportion of Chinese data was gradually increased. This helps the convergence of the model training.</p>
</section>
<section id="multiple-token-prediction">
<h3><span class="section-number">11.2.5. </span>Multiple Token Prediction<a class="headerlink" href="#multiple-token-prediction" title="Link to this heading">#</a></h3>
<p>Besides training using a next-token prediction loss, there are efforts exploring training language models to predict multiple future tokens at once [<a class="reference internal" href="#chapter-training-fig-fundamentals-multiple-token-prediction-demo"><span class="std std-numref">Fig. 11.3</span></a>].  More specifically, at each position in the training corpus, we ask the model to predict the following <span class="math notranslate nohighlight">\(n\)</span> tokens using <span class="math notranslate nohighlight">\(n\)</span> independent output heads, operating on top of a shared model trunk.</p>
<p>The advantages are:</p>
<ul class="simple">
<li><p>in higher sample efficiency.</p></li>
<li></li>
</ul>
<p><span id="id5">[<a class="reference internal" href="#id1569" title="Fabian Gloeckle, Badr Youbi Idrissi, Baptiste Rozière, David Lopez-Paz, and Gabriel Synnaeve. Better &amp; faster large language models via multi-token prediction. arXiv preprint arXiv:2404.19737, 2024.">GIRoziere+24</a>]</span>
During inference, we employ only the next-token output head. Optionally, the other three heads may be used to speed-up
inference time.</p>
<figure class="align-default" id="chapter-training-fig-fundamentals-multiple-token-prediction-demo">
<a class="reference internal image-reference" href="../../_images/mtp_demo.png"><img alt="../../_images/mtp_demo.png" src="../../_images/mtp_demo.png" style="width: 700.1999999999999px; height: 391.2px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 11.3 </span><span class="caption-text">Overview of multi-token prediction. During training, the model predicts 4 future tokens at once, by
means of a shared trunk and 4 dedicated output heads. Image from <span id="id6">[<a class="reference internal" href="#id1569" title="Fabian Gloeckle, Badr Youbi Idrissi, Baptiste Rozière, David Lopez-Paz, and Gabriel Synnaeve. Better &amp; faster large language models via multi-token prediction. arXiv preprint arXiv:2404.19737, 2024.">GIRoziere+24</a>]</span>.</span><a class="headerlink" href="#chapter-training-fig-fundamentals-multiple-token-prediction-demo" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>In this work, we generalize the above by implementing a multi-token prediction task, where at each position of the training corpus, the model is instructed to predict <span class="math notranslate nohighlight">\(n\)</span> future tokens at once. This translates into the cross-entropy loss</p>
<div class="math notranslate nohighlight">
\[
L_n=-\sum_t \log P_\theta\left(x_{t+n: t+1} \mid x_{t: 1}\right)
\]</div>
<p>To make matters tractable, we assume that our large language model <span class="math notranslate nohighlight">\(P_\theta\)</span> employs a shared trunk to produce a latent representation <span class="math notranslate nohighlight">\(z_{t: 1}\)</span> of the observed context <span class="math notranslate nohighlight">\(x_{t: 1}\)</span>, then fed into <span class="math notranslate nohighlight">\(n\)</span> independent heads to predict in parallel each of the <span class="math notranslate nohighlight">\(n\)</span> future tokens (see Figure 1). This leads to the following factorization of the multi-token prediction cross-entropy loss:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
L_n &amp; =-\sum_t \log P_\theta\left(x_{t+n: t+1} \mid z_{t: 1}\right) \cdot P_\theta\left(z_{t: 1} \mid x_{t: 1}\right) \\
&amp; =-\sum_t \sum_{i=1}^n \log P_\theta\left(x_{t+i} \mid z_{t: 1}\right) \cdot P_\theta\left(z_{t: 1} \mid x_{t: 1}\right)
\end{aligned}
\end{split}\]</div>
<p>In practice, our architecture consists of a shared transformer trunk <span class="math notranslate nohighlight">\(f_s\)</span> producing the hidden representation <span class="math notranslate nohighlight">\(z_{t: 1}\)</span> from the observed context <span class="math notranslate nohighlight">\(x_{t: 1}, n\)</span> independent output heads implemented in terms of transformer layers <span class="math notranslate nohighlight">\(f_{h_i}\)</span>, and a shared unembedding matrix <span class="math notranslate nohighlight">\(f_u\)</span>. Therefore, to predict <span class="math notranslate nohighlight">\(n\)</span> future tokens, we compute:</p>
<div class="math notranslate nohighlight">
\[
P_\theta\left(x_{t+i} \mid x_{t: 1}\right)=\operatorname{softmax}\left(f_u\left(f_{h_i}\left(f_s\left(x_{t: 1}\right)\right)\right)\right)
\]</div>
<p>for <span class="math notranslate nohighlight">\(i=1, \ldots n\)</span>, where, in particular, <span class="math notranslate nohighlight">\(P_\theta\left(x_{t+1} \mid x_{t: 1}\right)\)</span> is our next-token prediction head. See Appendix B for other variations of multi-token prediction architectures.</p>
<!-- ## Comparison

| Approach | Training set | Training set size | Implementation <br> Complexity | Total training cost (inc. experimentation) |
| :---: | :---: | :---: | :---: | :---: |
| Prompt engineering | Not needed | 0 | Low | 0 (no training) |
| RAG | Not needed | 0 | Low - Medium | 0 (no training) |
| Supervised-Fine-tuning | labelled | Can be as little as few hundreds examples (e.g. with PEFT approaches) but can increase to several thousands depending on number of tasks | Medium - High <br> depending on use case | $ $100-5 \mathrm{~K}$ |
| Continuous pre-training | unstructured | Can vary - from 10 K <br> tokens to Bitlions | Medium on Bedrock and Jumpstart, Higher with SageMaker Training | $-\$ 2500$ for scanning 18 <br> tokens for a 7B model |
| Full Pretraining | unstructured | 100s of billion/trillion tokens (e.g. 700 billion tokens for BloombergGPT for 50B model) | Very High | $$500K | -->
</section>
</section>
<section id="optimization-algorithms">
<h2><span class="section-number">11.3. </span>Optimization Algorithms<a class="headerlink" href="#optimization-algorithms" title="Link to this heading">#</a></h2>
<section id="minibatch-stochastic-gradient-descent">
<h3><span class="section-number">11.3.1. </span>Minibatch Stochastic Gradient Descent<a class="headerlink" href="#minibatch-stochastic-gradient-descent" title="Link to this heading">#</a></h3>
<p>The classical gradient descent algorithm requires the evaluation of the gradient over the whole set of training data. This is both computational prohibitive and sample inefficient - many samples are similar, making the gradient of the whole data sample is simply the multiplier of the gradient of a much smaller, representative sample data set.
<strong>Minibatch stochastic gradient descent</strong> is much efficient way of gradient descent, which uses a random sample of the training data set to estimate the gradient on each step.</p>
<p>A typical algorithm is showed as follows.</p>
<div class="proof algorithm admonition" id="Minibatch_stochastic_gradient_descent_algorithm">
<p class="admonition-title"><span class="caption-number">Algorithm 11.1 </span> (Minibatch stochastic gradient descent algorithm)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Learning rate <span class="math notranslate nohighlight">\(\alpha_k\)</span>, iniital model parameter <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p><strong>Output</strong> <span class="math notranslate nohighlight">\(\theta_k\)</span></p>
<ol class="arabic">
<li><p>Set <span class="math notranslate nohighlight">\(k=1\)</span></p></li>
<li><p>Repeat until stopping criteria is met:</p>
<ol class="arabic simple">
<li><p>Sample a minibatch of training samples of size <span class="math notranslate nohighlight">\(m\)</span>: <span class="math notranslate nohighlight">\((x^{(i)},y^{(i)}),i=1,2,...,m\)</span>.</p></li>
<li><p>Compute a gradient estimate over this minibatch samples via</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\hat{g}_k = \frac{1}{m}\nabla_{\theta} \sum_{i=1}^{m} L(f(x^{(i)};\theta),y^{(i)}).\]</div>
<ol class="arabic simple" start="3">
<li><p>Apply update <span class="math notranslate nohighlight">\(\theta_k = \theta_k - \alpha_k \hat{g}_k\)</span>.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(k=k+1\)</span>.</p></li>
</ol>
</li>
</ol>
</section>
</div><div class="proof remark admonition" id="remark-1">
<p class="admonition-title"><span class="caption-number">Remark 11.1 </span> (choice of minibatch size)</p>
<section class="remark-content" id="proof-content">
<ul class="simple">
<li><p>The estimation quality of gradient via minibatch gradient descent is strongly affected by the minibatch size. In general, the gradient estimate is unbiased, irrespective of the choice of minibatch size, but its variance will decrease as the minibatch increases.</p></li>
<li><p>For larger minibatch size, we can increase learning rate since the estimated gradient is more certain. There is an empirical <em><strong>Linear Scaling Rule</strong></em>: When the minibatch size is multiplied by <span class="math notranslate nohighlight">\(k\)</span>, multiply the learning rate by <span class="math notranslate nohighlight">\(k\)</span> <span id="id7">[<a class="reference internal" href="#id1127" title="Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.">GDollarG+17</a>]</span>.</p></li>
</ul>
</section>
</div></section>
<section id="adaptive-gradient-method">
<h3><span class="section-number">11.3.2. </span>Adaptive Gradient Method<a class="headerlink" href="#adaptive-gradient-method" title="Link to this heading">#</a></h3>
<section id="adaptive-gradient-adagrad">
<h4><span class="section-number">11.3.2.1. </span>Adaptive Gradient (AdaGrad)<a class="headerlink" href="#adaptive-gradient-adagrad" title="Link to this heading">#</a></h4>
<p>For simple stochastic gradient methods, we need to set the learning rate hyperparameter or even dynamically schedule learning rate, which is usually a difficult task or problem specific. Further, a uniform learning rate is usually not an effective way for high-dimensional gradient descent methods, since one learning rate could be too large for one-dimension but, on the contrary, too small for another dimension.</p>
<p>The AdaGrad algorithm<span id="id8">[<a class="reference internal" href="#id1126" title="John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011.">DHS11</a>]</span> addresses the issue by choosing different learning rates for each dimension. The algorithm adaptively scales the learning rate for each dimension based on the <strong>accumulated gradient magnitude</strong> on that dimension so far.</p>
<p>Let <span class="math notranslate nohighlight">\(G_k\)</span> be the <strong>accumulated gradient</strong> up to iteration <span class="math notranslate nohighlight">\(k\)</span>, given by</p>
<div class="math notranslate nohighlight">
\[G_k = G_{k-1} + \hat{g}_k\odot \hat{g}_k, G_0 = 0.\]</div>
<p>The parameter update is given by</p>
<div class="math notranslate nohighlight">
\[\theta_k = \theta_{k-1} - \frac{\alpha_0}{\delta + \sqrt{G_k}} \hat{g}_k\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha_0\)</span> is the initial learning speed, usually set at a small number (say, 1e-9 to 1e-7) and <span class="math notranslate nohighlight">\(\delta\)</span> is a small positive constant to avoid division by zero.</p>
<p>As we can see, the learning rate in AdaGrad is monotonically decreasing, which may dramatically slow down the convergence as the learning rate becomes too small. In general, AdaGrad algorithm performs best for <strong>convex optimization</strong> (however, neural network optimization is usually non-convex).</p>
</section>
<section id="rmsprop">
<h4><span class="section-number">11.3.2.2. </span>RMSProp<a class="headerlink" href="#rmsprop" title="Link to this heading">#</a></h4>
<p>As we mentioned before, AdaGrad tend to shrink learning rate too aggressively. This is an advantage when applying AdaGrad to convex function optimization as it enables the algorithm to converge fast and stably. However, non-convex function optimization usually require large, adaptive learning rate to escape bad local minimum and converge stably to better local minimums.</p>
<p>The first remedy is to prevent the learning rate from shrinking too fast. Let <span class="math notranslate nohighlight">\(G_k\)</span> be the accumulated gradient up to iteration <span class="math notranslate nohighlight">\(k\)</span>, given by</p>
<div class="math notranslate nohighlight">
\[G_k = \rho G_{k-1} + (1- \rho) g_k\odot g_k, G_0 = 0.\]</div>
<p>Then we compute update</p>
<div class="math notranslate nohighlight">
\[\theta_k= \theta_{k-1} - \frac{\alpha_0}{\delta + \sqrt{G_k}} \hat{g}_k.\]</div>
<p>which is the core part of the RMSProp algorithm <span id="id9">[<a class="reference internal" href="#id1125" title="Geoffrey Hinton. Neural Networks for Machine Learning. University of Toronto, 2012.">Hin12</a>]</span>.</p>
<p>How this modification can make the <span class="math notranslate nohighlight">\(G_k\)</span> smaller than that in the AdaGrad, as can be seen from following expansion.</p>
<div class="proof remark admonition" id="remark-2">
<p class="admonition-title"><span class="caption-number">Remark 11.2 </span> (Expansion of <span class="math notranslate nohighlight">\(G_k\)</span>)</p>
<section class="remark-content" id="proof-content">
<p>In RMSProp, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
G_k &amp;= \rho G_{k-1} + (1- \rho) g_k\odot g_k \\
	&amp;= \rho G_{k-2} + \rho(1- \rho) g_k\odot g_k + \rho(1 - \rho)g_{k-1}\odot g_{k-1} \\
	&amp;\approx g\cdot g (1 - \rho) (1 + \rho + \cdot + \rho^{k-1})\\
	&amp;= (1 - \rho^k) g\cdot g
\end{align}
\end{split}\]</div>
<p>where we assume <span class="math notranslate nohighlight">\(g_k\cdot g_k \approx g\cdot g, \forall k\)</span>. Clearly, we have
roughly,</p>
<div class="math notranslate nohighlight">
\[G_k^{RMSProp} \approx  \frac{(1 - \rho^k)}{k} G_k^{AdaGrad}, G_k^{AdaGrad}\approx k g\odot g.\]</div>
</section>
</div><div class="proof remark admonition" id="remark-3">
<p class="admonition-title"><span class="caption-number">Remark 11.3 </span> (Importance of adaptive learning rate)</p>
<section class="remark-content" id="proof-content">
<p>One example to demonstrate the importance of having adaptive learing rate is learning word embeddings. Embeddings of rare words only get limited chances to update because they have limited presence in the training data. On the other hand, embeddings of common words get update frequently. With adaptive learning rate, embeddings of rare words will have large learning rate whenever it gets update. This help the model learn better embeddings for rare words.</p>
</section>
</div></section>
</section>
<section id="momentum-method">
<h3><span class="section-number">11.3.3. </span>Momentum Method<a class="headerlink" href="#momentum-method" title="Link to this heading">#</a></h3>
<p>Simple SGD with small learning rate can lead to extremely slow learning for functional surfaces with long, narrow valleys <span id="id10">[<a class="reference internal" href="#id1123" title="Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and momentum in deep learning. In International conference on machine learning, 1139–1147. 2013.">SMDH13</a>]</span>. One intuition inspired by the physics of a heavy ball falling down is to add momentum to the gradient descent steps. Mathematically, adding momentum is equivalent to adding historical weighted averaged gradient to the current gradient. The total gradient will then be hopefully large enough to enable fast movement on relatively flat regions.</p>
<figure class="align-default" id="chapter-training-fig-optimizer-sgd-momentum">
<a class="reference internal image-reference" href="../../_images/SGDMomentum.jpg"><img alt="../../_images/SGDMomentum.jpg" src="../../_images/SGDMomentum.jpg" style="width: 927.5999999999999px; height: 210.29999999999998px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 11.4 </span><span class="caption-text">SGD without momentum and with momentum. SGD with momentum can accumulate gradient/velocity in horizontal direction and move faster towards the minimum located at the center.</span><a class="headerlink" href="#chapter-training-fig-optimizer-sgd-momentum" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Consider the gradient</p>
<div class="math notranslate nohighlight">
\[\hat{g}_k = \frac{1}{m}\nabla_{\theta} \sum_{i=1}^{m} L(f(x^{(i);\theta}),y^{(i)}),\]</div>
<p>we can compute a <strong>speed</strong> (an intermedidate parameter) via</p>
<div class="math notranslate nohighlight">
\[v_k = \mu v_{k-1} - \alpha_k \hat{g}_k,\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu \in [0, 1]\)</span> is the momentum coefficiency, and <span class="math notranslate nohighlight">\(\alpha_k\)</span> is the learning rate.</p>
<p>The speed (with momentum considered) is then used to update parameter <span class="math notranslate nohighlight">\(\theta\)</span> via</p>
<div class="math notranslate nohighlight">
\[\theta_k = \theta_k + v_k.\]</div>
<p>To see that the update velocity is the weighted average gradient, we now show that the velocity is an exponentially decaying moving average (similar to AR(1) process) of the negative gradients, given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
v_k &amp;= \alpha v_{k-1} - \hat{g}_k\\
&amp;= \alpha (\alpha v_{k-2} - \hat{g}_{k-1}) - \hat{g}_k \\
&amp;= \alpha^2 v_{k-2} - \alpha \hat{g}_{k-1} - \hat{g}_k \\
&amp;= \cdots \\
&amp;= \sum_{i=0}^\infty  \alpha^{i} \hat{g}_{k-i}.
\end{align}	
\end{split}\]</div>
</section>
<section id="combined-together-adam-and-adamw">
<h3><span class="section-number">11.3.4. </span>Combined Together: Adam and AdamW<a class="headerlink" href="#combined-together-adam-and-adamw" title="Link to this heading">#</a></h3>
<section id="adam">
<h4><span class="section-number">11.3.4.1. </span>Adam<a class="headerlink" href="#adam" title="Link to this heading">#</a></h4>
<p>By combining the ideas of momentum and adaptive learning rate, we yield Adam, one of most popular gradient descent algorithm in deep learning community<span id="id11">[<a class="reference internal" href="#id1122" title="Diederik P Kingma and Jimmy Ba. Adam: a method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.">KB14</a>]</span>. The name Adam is derived from adaptive moment estimation. As its name suggests, Adam will compute velocity via momentum type of averaging and adjust the learning rate using inverse of accumulated gradients.</p>
<p>Specifically, the velocity is computed via</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
M_k &amp;= \rho_1 M_{k-1} + (1-\rho_1)\hat{g}_k \\
\tilde{M}_k &amp;= \frac{M_k}{1-\rho_1^k}
\end{align}
\end{split}\]</div>
<p>and the accumulated gradient magnitude is compute via</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
G_k &amp;= \rho_2 G_{k-1} + (1-\rho_2)\hat{g}_k \odot \hat{g}_k \\
\tilde{G}_k &amp;= \frac{G_k}{1-\rho_2^k}
\end{align}
\end{split}\]</div>
<p>Note that we correct the <span class="math notranslate nohighlight">\(M_k\)</span> and <span class="math notranslate nohighlight">\(G_k\)</span> be dividing the factor <span class="math notranslate nohighlight">\(1 - \rho_i^k, i= 1, 2\)</span> to get the average estimation.</p>
<p>The final algorithm is given by the following.</p>
<div class="proof algorithm admonition" id="Adam_stochastic_gradient_descent_algorithm">
<p class="admonition-title"><span class="caption-number">Algorithm 11.2 </span> (Adam stochastic gradient descent algorithm)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Learning rate <span class="math notranslate nohighlight">\(\alpha\)</span>(set to 0.001), iniital model parameter <span class="math notranslate nohighlight">\(\theta\)</span>, decay parameters <span class="math notranslate nohighlight">\(\rho_1\)</span>(set to 0.9), <span class="math notranslate nohighlight">\(\rho_2\)</span>(set to 0.999). <span class="math notranslate nohighlight">\(\delta = 1e-8\)</span></p>
<p><strong>Output</strong> <span class="math notranslate nohighlight">\(\theta_k\)</span></p>
<ol class="arabic">
<li><p>Set <span class="math notranslate nohighlight">\(k=1\)</span>.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(M_k = 0, G_k = 0\)</span>.</p></li>
<li><p>Repeat until stopping criteria is met：</p>
<ol class="arabic">
<li><p>Sample a minibatch of training samples of size <span class="math notranslate nohighlight">\(m\)</span> <span class="math notranslate nohighlight">\((x^{(i)},y^{(i)}),i=1,2,...,m\)</span>.\</p></li>
<li><p>compute gradient estimate over minibatch <span class="math notranslate nohighlight">\(N\)</span> samples via</p>
<div class="math notranslate nohighlight">
\[\hat{g}_k = \frac{1}{m}\nabla_{\theta} \sum_{i=1}^{m} L(f(x^{(i);\theta}),y^{(i)}).\]</div>
</li>
<li><p>Accumulate <span class="math notranslate nohighlight">\(M_k = \rho_1 M_{k-1} + (1-\rho_1)\hat{g}_k\)</span>. Accumulate <span class="math notranslate nohighlight">\(G_k = \rho_2 G_{k-1} + (1-\rho_2)\hat{g}_k \odot \hat{g}_k\)</span>.</p></li>
<li><p>Correct biases</p>
<div class="math notranslate nohighlight">
\[\tilde{M}_k = \frac{M_k}{1-\rho_1^k}, \tilde{G}_k = \frac{G_k}{1-\rho_2^k}.\]</div>
</li>
<li><p>Apply update $<span class="math notranslate nohighlight">\(\theta_k = \theta_{k-1} -\frac{\alpha \cdot \tilde{M}_k}{\delta + \sqrt{\tilde{G}_k }}.\)</span>$</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(k=k+1\)</span>.</p></li>
</ol>
</li>
</ol>
</section>
</div></section>
<section id="l-2-weight-decay-and-adamw">
<h4><span class="section-number">11.3.4.2. </span><span class="math notranslate nohighlight">\(L_2\)</span> Weight Decay and AdamW<a class="headerlink" href="#l-2-weight-decay-and-adamw" title="Link to this heading">#</a></h4>
<p><span class="math notranslate nohighlight">\(L_2\)</span> regularization on model parameters often reduce model overfitting and improves the generalization ability of the model. In the SGD optimization framework, the implementation of <span class="math notranslate nohighlight">\(L_2\)</span> regularization term is often realized via <strong>weight decay</strong>, resulting in an additional term in the gradient that penalize large weights. That is,</p>
<div class="math notranslate nohighlight">
\[{g}_{k} \leftarrow \nabla f_{k}\left({\theta}_{k-1}\right)+\lambda {\theta}_{k-1},\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda\)</span> is the decay parameter, corresponding the strength of the regularization.</p>
<p>AdamW <span id="id12">[<a class="reference internal" href="#id1369" title="Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.">LH17</a>]</span> is the algorithm that correctly implements Adam with <span class="math notranslate nohighlight">\(L_2\)</span> regularization, which is also called Adam with decoupled weight decay.</p>
<p>The algorithm is given by the following.</p>
<div class="proof algorithm admonition" id="Adam_stochastic_gradient_descent_algorithm_with_weight_decay">
<p class="admonition-title"><span class="caption-number">Algorithm 11.3 </span> (Adam stochastic gradient descent algorithm with weight decay)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Learning rate <span class="math notranslate nohighlight">\(\alpha\)</span>(set to 0.001), iniital model parameter <span class="math notranslate nohighlight">\(\theta\)</span>, decay parameters <span class="math notranslate nohighlight">\(\rho_1\)</span>(set to 0.9), <span class="math notranslate nohighlight">\(\rho_2\)</span>(set to 0.999). <span class="math notranslate nohighlight">\(\delta = 1e-8\)</span>.  <span style="background-color: #e4ac94">Weight decay parameter <span class="math notranslate nohighlight">\(\lambda \in \mathbb{R}\)</span></span>.</p>
<p><strong>Output</strong> <span class="math notranslate nohighlight">\(\theta_k\)</span></p>
<ol class="arabic">
<li><p>Set <span class="math notranslate nohighlight">\(k=1\)</span>.</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(M_k = 0, G_k = 0\)</span>.</p></li>
<li><p>Repeat until stopping criteria is met：</p>
<ol class="arabic">
<li><p>Sample a minibatch of training samples of size <span class="math notranslate nohighlight">\(m\)</span> <span class="math notranslate nohighlight">\((x^{(i)},y^{(i)}),i=1,2,...,m\)</span>.\</p></li>
<li><p>compute gradient estimate over minibatch <span class="math notranslate nohighlight">\(N\)</span> samples via</p>
<div class="math notranslate nohighlight">
\[\hat{g}_k = \frac{1}{m}\nabla_{\theta} \sum_{i=1}^{m} L(f(x^{(i);\theta}),y^{(i)}).\]</div>
</li>
<li><p>Accumulate <span class="math notranslate nohighlight">\(M_k = \rho_1 M_{k-1} + (1-\rho_1)\hat{g}_k\)</span>. Accumulate <span class="math notranslate nohighlight">\(G_k = \rho_2 G_{k-1} + (1-\rho_2)\hat{g}_k \odot \hat{g}_k\)</span>.</p></li>
<li><p>Correct biases</p>
<div class="math notranslate nohighlight">
\[\tilde{M}_k = \frac{M_k}{1-\rho_1^k}, \tilde{G}_k = \frac{G_k}{1-\rho_2^k}.\]</div>
</li>
<li><p><span style="background-color: #e4ac94"> Apply update</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\theta_k = \theta_{k-1} -\frac{\alpha \cdot \tilde{M}_k}{\delta + \sqrt{\tilde{G}_k }} - \lambda \theta_{k}.\]</div>
 </span>
 6. Set $k=k+1$.
</li>
</ol>
</section>
</div></section>
</section>
</section>
<section id="bibliography">
<h2><span class="section-number">11.4. </span>Bibliography<a class="headerlink" href="#bibliography" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id13">
<div role="list" class="citation-list">
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">CTJ+21</a><span class="fn-bracket">]</span></span>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, and others. Evaluating large language models trained on code. <em>arXiv preprint arXiv:2107.03374</em>, 2021.</p>
</div>
<div class="citation" id="id1126" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">DHS11</a><span class="fn-bracket">]</span></span>
<p>John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. <em>Journal of Machine Learning Research</em>, 12(Jul):2121–2159, 2011.</p>
</div>
<div class="citation" id="id1569" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GIRoziere+24<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id5">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p>Fabian Gloeckle, Badr Youbi Idrissi, Baptiste Rozière, David Lopez-Paz, and Gabriel Synnaeve. Better &amp; faster large language models via multi-token prediction. <em>arXiv preprint arXiv:2404.19737</em>, 2024.</p>
</div>
<div class="citation" id="id1127" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">GDollarG+17</a><span class="fn-bracket">]</span></span>
<p>Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: training imagenet in 1 hour. <em>arXiv preprint arXiv:1706.02677</em>, 2017.</p>
</div>
<div class="citation" id="id46" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">HKK+20</a><span class="fn-bracket">]</span></span>
<p>Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo Jun, Tom B Brown, Prafulla Dhariwal, Scott Gray, and others. Scaling laws for autoregressive generative modeling. <em>arXiv preprint arXiv:2010.14701</em>, 2020.</p>
</div>
<div class="citation" id="id1125" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">Hin12</a><span class="fn-bracket">]</span></span>
<p>Geoffrey Hinton. <em>Neural Networks for Machine Learning</em>. University of Toronto, 2012.</p>
</div>
<div class="citation" id="id45" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">KMH+20</a><span class="fn-bracket">]</span></span>
<p>Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. <em>arXiv preprint arXiv:2001.08361</em>, 2020.</p>
</div>
<div class="citation" id="id1122" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">KB14</a><span class="fn-bracket">]</span></span>
<p>Diederik P Kingma and Jimmy Ba. Adam: a method for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>, 2014.</p>
</div>
<div class="citation" id="id1369" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">LH17</a><span class="fn-bracket">]</span></span>
<p>Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. <em>arXiv preprint arXiv:1711.05101</em>, 2017.</p>
</div>
<div class="citation" id="id1123" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">SMDH13</a><span class="fn-bracket">]</span></span>
<p>Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and momentum in deep learning. In <em>International conference on machine learning</em>, 1139–1147. 2013.</p>
</div>
<div class="citation" id="id1534" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ZZL+23<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id4">2</a>)</span>
<p>Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models. <em>arXiv preprint arXiv:2303.18223</em>, 2023.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/chapter_training"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../chapter_LLM_arch/LLM_moe_sparse_architectures.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">10. </span>MoE Sparse Architectures (WIP)</p>
      </div>
    </a>
    <a class="right-next"
       href="finetuning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12. </span>LLM Finetuning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-overview">11.1. Training Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pretraining">11.2. Pretraining</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentals">11.2.1. Fundamentals</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-sources-and-cleaning">11.2.2. Data sources and cleaning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-mixture-and-schedule">11.2.3. Data mixture and schedule</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continued-pretraining">11.2.4. Continued Pretraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-token-prediction">11.2.5. Multiple Token Prediction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-algorithms">11.3. Optimization Algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minibatch-stochastic-gradient-descent">11.3.1. Minibatch Stochastic Gradient Descent</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-gradient-method">11.3.2. Adaptive Gradient Method</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-gradient-adagrad">11.3.2.1. Adaptive Gradient (AdaGrad)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rmsprop">11.3.2.2. RMSProp</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#momentum-method">11.3.3. Momentum Method</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-together-adam-and-adamw">11.3.4. Combined Together: Adam and AdamW</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adam">11.3.4.1. Adam</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#l-2-weight-decay-and-adamw">11.3.4.2. <span class="math notranslate nohighlight">\(L_2\)</span> Weight Decay and AdamW</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">11.4. Bibliography</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yuguang Yang
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>