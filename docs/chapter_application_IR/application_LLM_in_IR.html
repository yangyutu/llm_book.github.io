
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>28. Application of LLM in IR (WIP) &#8212; LLM Foundations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/chapter_application_IR/application_LLM_in_IR';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="27. Information Retrieval and Text Ranking" href="information_retrieval_fundamentals.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/qe-logo-large.png" class="logo__image only-light" alt="LLM Foundations - Home"/>
    <script>document.write(`<img src="../../_static/qe-logo-large.png" class="logo__image only-dark" alt="LLM Foundations - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Introduction.html">1. Introduction: LLM in the Age of AI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/language_models.html">2. Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/neural_language_models.html">3. Early Neural Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/word_embeddings.html">4. Word Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/transformers.html">5. Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/bert.html">6. BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/t5.html">7. Seq2Seq: T5 and BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_foundation/GPT_series.html">8. GPT Series</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_dense_architectures.html">9. LLM Architectures Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_LLM_arch/LLM_moe_sparse_architectures.html">10. MoE Sparse Architectures (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chapter_LLM_arch/annotated_llama_custom.html">11. *Lab: Minimal LLama</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Training</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/training_fundamentals.html">12. LLM Training Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/finetuning.html">13. LLM Finetuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/alignment.html">14. LLM Alignement and Preference Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/reinforcement_learning.html">15. *Reinforcement Learning Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_training/accelerated_training.html">16. LLM Training Acceleration (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chapter_LLM_training/annotated_pretraining.html">17. *Lab: LLM Pretraining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chapter_LLM_training/annotated_llama_custom_for_finetuning.html">18. *Lab: Finetuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chapter_LLM_training/annotated_llama_custom_for_DPO.html">19. *Lab: DPO Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_inference/inference_fundamentals.html">20. Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_inference/inference_acceleration.html">21. Inference Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prompting</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/basic_prompt.html">22. Basic Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_prompt/advanced_prompt.html">23. Advanced Prompting Techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">RAG and Agents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/basic_rag.html">24. RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rag/advanced_rag.html">25. Advanced RAG (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vision LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../chapter_multimodality/vision_transformers.html">26. Vision Language Pretraining</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Application in Information Retrieval</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="information_retrieval_fundamentals.html">27. Information Retrieval and Text Ranking</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">28. Application of LLM in IR (WIP)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Application of LLM in IR (WIP)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#query-understanding-optimization">28.1. Query Understanding &amp; Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#query-categorization">28.1.1. Query Categorization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#natural-language-queries">28.1.1.1. Natural Language Queries</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#query-optimization-overview">28.1.2. Query Optimization Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gefeed-retrieval-feedback">28.1.3. GEFEED (Retrieval Feedback)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#query-doc-ranking">28.2. Query-Doc Ranking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-list-generation">28.2.1. Rank List Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ranker-distillation">28.2.2. Ranker Distillation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-embedding-model">28.3. LLM Embedding Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nv-embed">28.3.1. NV-Embed</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-in-rag">28.4. Application in RAG</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-serp">28.5. Generative SERP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collections">28.6. Collections</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">28.7. Bibliography</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="application-of-llm-in-ir-wip">
<h1><span class="section-number">28. </span>Application of LLM in IR (WIP)<a class="headerlink" href="#application-of-llm-in-ir-wip" title="Link to this heading">#</a></h1>
<section id="query-understanding-optimization">
<h2><span class="section-number">28.1. </span>Query Understanding &amp; Optimization<a class="headerlink" href="#query-understanding-optimization" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/pdf/2412.17558">A Survey of Query Optimization in Large Language Models</a></p>
<p><a class="reference external" href="https://arxiv.org/pdf/2305.14283">Query Rewriting for Retrieval-Augmented Large Language Models</a></p>
<p><a class="reference external" href="https://arxiv.org/pdf/2402.11129">BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering</a></p>
<section id="query-categorization">
<h3><span class="section-number">28.1.1. </span>Query Categorization<a class="headerlink" href="#query-categorization" title="Link to this heading">#</a></h3>
<section id="natural-language-queries">
<h4><span class="section-number">28.1.1.1. </span>Natural Language Queries<a class="headerlink" href="#natural-language-queries" title="Link to this heading">#</a></h4>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Question Type</p></th>
<th class="head text-left"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Fact-based</p></td>
<td class="text-left"><p>Questions that seek specific facts or information.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Multi-hop</p></td>
<td class="text-left"><p>Questions that require reasoning over multiple pieces of information or relationships.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Numerical</p></td>
<td class="text-left"><p>Questions that involve numerical values or calculations.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Tabular</p></td>
<td class="text-left"><p>Questions that relate to data presented in tables.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Temporal</p></td>
<td class="text-left"><p>Questions that involve time-related information or events.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Multi-constraint</p></td>
<td class="text-left"><p>Questions that involve multiple constraints or conditions.</p></td>
</tr>
</tbody>
</table>
</div>
<p>Examples</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Question Type</p></th>
<th class="head text-left"><p>Query Examples</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>Fact-based</p></td>
<td class="text-left"><p>What is the capital of France? <br> Who invented the telephone? <br> What is the population of Tokyo?</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Multi-hop</p></td>
<td class="text-left"><p>Who is the CEO of the company that manufactures the iPhone? <br> What is the name of the river that flows through London? <br> What is the highest mountain in the country where the Taj Mahal is located?</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Numerical</p></td>
<td class="text-left"><p>What is the average temperature in July in London? <br> What is the distance between New York and Los Angeles? <br> What is the GDP of Japan?</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Tabular</p></td>
<td class="text-left"><p>Which country has the highest population density? <br> What is the average number of mobile phones sold by all the showrooms in the year 2007 ? <br> How many restaurants are in the American cuisine type?</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Temporal</p></td>
<td class="text-left"><p>When did World War II end? <br> Who was the president of the United States in 1963? <br> What was the price of gold in 2008?</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Multi-constraint</p></td>
<td class="text-left"><p>Find a hotel in Paris that has a swimming pool and is within walking distance of the Eiffel Tower. <br> What are some laptops that have a 15 -inch screen, 16 GB of RAM, and cost less than <span class="math notranslate nohighlight">\(\$ 1,000\)</span> ? <br> Is it possible to constrain the flat face of a say 6 countersunk screws to a single face?</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="query-optimization-overview">
<h3><span class="section-number">28.1.2. </span>Query Optimization Overview<a class="headerlink" href="#query-optimization-overview" title="Link to this heading">#</a></h3>
<p><strong>Query Expansion</strong> - aims to capture a wider range of relevant information and potentially uncover connections that may not have been apparent in the query.This process involves analyzing the initial query, identifying key concepts, and incorporating related terms, synonyms, or associated ideas to form a new query for creating a more comprehensive search.</p>
<p><strong>Query Decomposition</strong> - aims to effectively break down complex, multihop queries into simpler, more manageable subqueries or tasks. This approach involves dissecting a query that requires facts from multiple sources or steps into smaller, more direct queries that can be answered individually.</p>
<p><strong>Query Disambiguation</strong> - aims to identify and eliminate ambiguity in complex queries, ensuring they are unequivocal. This involves pinpointing elements of the query that could be interpreted in multiple ways and refining the query to ensure a single, precise interpretation.</p>
<p><strong>Query Abstraction</strong> - aims to provide a broader perspective on the fact need, potentially leading to more diverse and comprehensive results. This involves identifying and distilling the fundamental intent and core conceptual elements of the query, then creating a higher-level representation that captures the essential meaning while removing specific details.</p>
</section>
<section id="gefeed-retrieval-feedback">
<h3><span class="section-number">28.1.3. </span>GEFEED (Retrieval Feedback)<a class="headerlink" href="#gefeed-retrieval-feedback" title="Link to this heading">#</a></h3>
<p>When using LLM to optimize query and retrievel processes, there has been efforts on using LLM to generate relevent context for the query <span id="id1">[<a class="reference internal" href="#id1570" title="Liang Wang, Nan Yang, and Furu Wei. Query2doc: query expansion with large language models. arXiv preprint arXiv:2303.07678, 2023.">WYW23</a>, <a class="reference internal" href="#id1569" title="Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, and Meng Jiang. Generate rather than retrieve: large language models are strong context generators. arXiv preprint arXiv:2209.10063, 2022.">YIW+22</a>]</span> based on the <strong>internal knowledge of LLM</strong>. These relevant context can be used to further refine the query or the retrievel process. However, there are several fundamental drawback in this approach when it comes to knowledge intensive tasks.</p>
<ul class="simple">
<li><p>LLM has a tendency to hallucinate content, generating information not grounded
by world knowledge, leading to untrustworthy outputs and a diminished capacity to provide accurate information.</p></li>
<li><p>The quality and scope of the internal knowledge of LLM may be incomplete or out-of-date due to the reliability of the sources in the pre-training corpus. Moreover, due to model capacity limitation, <strong>LLMs cannot memorize all world information</strong>, particularly the long tail of knowledge from their training corpus <span id="id2">[<a class="reference internal" href="#id1571" title="Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. Large language models struggle to learn long-tail knowledge. In International Conference on Machine Learning, 15696–15707. PMLR, 2023.">KDR+23</a>]</span>.</p></li>
</ul>
<p>The key steps in GEFEED [<a class="reference internal" href="#chapter-application-ir-llm-fig-queryunderstandingoptimization-gefeed-demo"><span class="std std-numref">Fig. 28.1</span></a>] are:</p>
<ul class="simple">
<li><p>Given a query, the language model generates initial outputs (more than one)[<a class="reference internal" href="#chapter-application-ir-llm-fig-queryunderstandingoptimization-gefeed-workflow"><span class="std std-numref">Fig. 28.2</span></a>].</p></li>
<li><p>A retrieval module retrieve expanded relevant information using the original query and generated outputs as a new query.</p></li>
<li><p>The language model reader produce the final output based on the expanded retrieved information.</p></li>
</ul>
<p>The potential benefits from GEFEED are:</p>
<ul class="simple">
<li><p>By directly generating the expected answer, rather than performing query paraphrasing, the lack of lexical or semantic overlap with the question and the document can be reduced.</p></li>
<li><p>As more relevant documents are retrieved from the corpus using expected answers, the recall and the precision of the retrieved documents can be both improved.</p></li>
</ul>
<figure class="align-default" id="chapter-application-ir-llm-fig-queryunderstandingoptimization-gefeed-demo">
<a class="reference internal image-reference" href="../../_images/GEFEED_demo.png"><img alt="../../_images/GEFEED_demo.png" src="../../_images/GEFEED_demo.png" style="width: 826.1999999999999px; height: 378.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 28.1 </span><span class="caption-text">REFEED operates by initially prompting a large language model to generate an answer in response to a given query, followed by the retrieval of documents from extensive document collections. Subsequently, the pipeline refines the initial answer by incorporating the information gleaned from the retrieved documents. Image from <span id="id3">[<a class="reference internal" href="#id1568" title="Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal. Improving language models via plug-and-play retrieval feedback. arXiv preprint arXiv:2305.14002, 2023.">YZL+23</a>]</span>.</span><a class="headerlink" href="#chapter-application-ir-llm-fig-queryunderstandingoptimization-gefeed-demo" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="chapter-application-ir-llm-fig-queryunderstandingoptimization-gefeed-workflow">
<a class="reference internal image-reference" href="../../_images/GEFEED_workflow.png"><img alt="../../_images/GEFEED_workflow.png" src="../../_images/GEFEED_workflow.png" style="width: 835.1999999999999px; height: 130.2px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 28.2 </span><span class="caption-text">The language model is prompted to sample multiple answers, allowing for a more comprehensive retrieval feedback based on different answers. Image from <span id="id4">[<a class="reference internal" href="#id1568" title="Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal. Improving language models via plug-and-play retrieval feedback. arXiv preprint arXiv:2305.14002, 2023.">YZL+23</a>]</span>.</span><a class="headerlink" href="#chapter-application-ir-llm-fig-queryunderstandingoptimization-gefeed-workflow" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="query-doc-ranking">
<h2><span class="section-number">28.2. </span>Query-Doc Ranking<a class="headerlink" href="#query-doc-ranking" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/pdf/2304.09542v2">Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/2310.09497">A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models</a></p>
<p><a class="reference external" href="https://aclanthology.org/2024.findings-naacl.97/">Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/2305.02156">Zero-Shot Listwise Document Reranking with a Large Language Model</a></p>
<section id="rank-list-generation">
<h3><span class="section-number">28.2.1. </span>Rank List Generation<a class="headerlink" href="#rank-list-generation" title="Link to this heading">#</a></h3>
<figure class="align-default" id="chapter-application-ir-llm-fig-querydocranking-slidingwindow-ranklist-generation">
<a class="reference internal image-reference" href="../../_images/slidingwindow_ranklist_generation.png"><img alt="../../_images/slidingwindow_ranklist_generation.png" src="../../_images/slidingwindow_ranklist_generation.png" style="width: 874.1999999999999px; height: 307.2px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 28.3 </span><span class="caption-text">llustration of re-ranking 8 passages using sliding windows with a window size of 4 and a step size of 2. The blue color represents the first two windows, while the yellow color represents the last window. The sliding windows are applied in back-to-first order,. Image from <span id="id5">[<a class="reference internal" href="#id1572" title="Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. Is chatgpt good at search? investigating large language models as re-ranking agents. arXiv preprint arXiv:2304.09542, 2023.">SYM+23</a>]</span>.</span><a class="headerlink" href="#chapter-application-ir-llm-fig-querydocranking-slidingwindow-ranklist-generation" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="ranker-distillation">
<h3><span class="section-number">28.2.2. </span>Ranker Distillation<a class="headerlink" href="#ranker-distillation" title="Link to this heading">#</a></h3>
<p><strong>Pairwise distillation</strong>: Suppose we have a query <span class="math notranslate nohighlight">\(q\)</span> and <span class="math notranslate nohighlight">\(D\)</span> candidate documents  <span class="math notranslate nohighlight">\(\left(d_1, \ldots, d_M\right)\)</span> for ranking. Let the LLM-based ranking results of the <span class="math notranslate nohighlight">\(D\)</span> documents be <span class="math notranslate nohighlight">\(R=\left(r_1, \ldots, r_M\right)\)</span> (e.g, <span class="math notranslate nohighlight">\(r_i=3\)</span> means <span class="math notranslate nohighlight">\(d_i\)</span> ranks third among the candidates).</p>
<p>Let <span class="math notranslate nohighlight">\(s_i=f_\theta\left(q, d_i\right)\)</span> be the student model’s relevance prediction score between <span class="math notranslate nohighlight">\(\left(q, d_i\right)\)</span>.</p>
<p>We can use pairwise Ranking loss to optimize the student model, which is given by</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text {RankNet }}=\sum_{i=1}^M \sum_{j=1}^M \mathbb{1}_{r_i&lt;r_j} \log \left(1+\exp \left(s_i-s_j\right)\right)
\]</div>
</section>
</section>
<section id="llm-embedding-model">
<h2><span class="section-number">28.3. </span>LLM Embedding Model<a class="headerlink" href="#llm-embedding-model" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/pdf/2401.00368">Improving text embeddings with large language models</a>
<a class="reference external" href="https://arxiv.org/pdf/2405.17428">NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models.</a></p>
<section id="nv-embed">
<h3><span class="section-number">28.3.1. </span>NV-Embed<a class="headerlink" href="#nv-embed" title="Link to this heading">#</a></h3>
<p>NV-Embed from Nvidia <span id="id6">[<a class="reference internal" href="#id1573" title="Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nv-embed: improved techniques for training llms as generalist embedding models. arXiv preprint arXiv:2405.17428, 2024.">LRX+24</a>]</span> proposed several improvement techniques on LLM-based embedding model, which include:</p>
<ul class="simple">
<li><p>Model architecture improvement, which introduces a <strong>latent attention layer</strong> to obtain better pooled embeddings.</p></li>
<li><p>Traing process improvement, which introduces a <strong>two-stage contrastive instruction-tuning method</strong>.</p></li>
</ul>
<p>There are two popular methods to obtain the embedding for a sequence of tokens:</p>
<ul class="simple">
<li><p>Mean pooling of the all hidden vectors of the last layer, which is commonly used in bidirectional embedding models.</p></li>
<li><p>Last <EOS> token embedding, which is more popular for decoder-only LLM based embedding models.</p></li>
</ul>
<p>However, both methods have certain limitations. Mean pooling simply takes the average of token embeddings and may dilute the important information from key phrases, meanwhile the semantics of the last <EOS> token embedding may be dominated by last few tokens.</p>
<p>The latent attention layer aims to improve the <strong>mean pooling method</strong>. Denote the last layer hidden from decoder as the query <span class="math notranslate nohighlight">\(Q \in \mathbb{R}^{l \times d}\)</span>, where <span class="math notranslate nohighlight">\(l\)</span> is the length of sequence, and <span class="math notranslate nohighlight">\(d\)</span> is the hidden dimension. They are sent to attend the latent array <span class="math notranslate nohighlight">\(K=V \in \mathbb{R}^{r \times d}\)</span>, which are <strong>trainable matrices</strong>, used to obtain better representation, where <span class="math notranslate nohighlight">\(r\)</span> is the number of latents in the dictionary. The output of this cross-attention is denoted by <span class="math notranslate nohighlight">\(O \in \mathbb{R}^{l \times d}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
O=\operatorname{softmax}\left(Q K^T\right) V.
\]</div>
<p>Intuitively, each token’s represention in <span class="math notranslate nohighlight">\(O\)</span> (which is a <span class="math notranslate nohighlight">\(d\)</span> vector) is a linear combination of the <span class="math notranslate nohighlight">\(r\)</span> row vectors in <span class="math notranslate nohighlight">\(V\)</span>(or <span class="math notranslate nohighlight">\(K\)</span>).</p>
<p>This has the spirit of <strong>sparse dictionary learning</strong><span id="id7">[<a class="reference internal" href="#id1093" title="Julien Mairal, Francis Bach, Jean Ponce, and Guillermo Sapiro. Online dictionary learning for sparse coding. In Proceedings of the 26th annual international conference on machine learning, 689–696. ACM, 2009.">MBPS09</a>]</span>, which aims to learn a <strong>sparse set of atom vectors</strong>, such that each representation can be transformed to a linear combination of atom vectors.</p>
<p>An additional 2-layer MLP was added to further transfrom the <span class="math notranslate nohighlight">\(O\)</span> vectors.  Finally, a mean pooling after MLP layers to obtain the embedding of whole sequences.</p>
<p>In the paper, authors used latent attention layer with <span class="math notranslate nohighlight">\(r\)</span> of 512 and the number of heads as 8 for multi-head attention.</p>
<figure class="align-default" id="chapter-application-ir-llm-fig-embedding-nv-embedding-latent-attention-layer">
<a class="reference internal image-reference" href="../../_images/latent_attention_layer.png"><img alt="../../_images/latent_attention_layer.png" src="../../_images/latent_attention_layer.png" style="width: 644.0px; height: 252.8px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 28.4 </span><span class="caption-text">The illustration of proposed architecture design comprising of decoder-only LLM followed
by latent attention layer. Latent attention layer functions as a form of cross-attention where the decoder-only LLM output serves as queries (Q) and trainable latent array passes through the keyvalue inputs, followed by MLP. Image from <span id="id8">[<a class="reference internal" href="#id1573" title="Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nv-embed: improved techniques for training llms as generalist embedding models. arXiv preprint arXiv:2405.17428, 2024.">LRX+24</a>]</span>.</span><a class="headerlink" href="#chapter-application-ir-llm-fig-embedding-nv-embedding-latent-attention-layer" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The two-stage instruction tuning method include</p>
<ul class="simple">
<li><p>First-stage contrastive training with instructions on a variety of retrieval datasets, utilizing in-batch negatives and curated hard-negative examples.</p></li>
<li><p>Second stage contrastive instruction-tuning on a combination of retrieval and non-retrieval datasets (e.g., classification ) without applying the trick of in-batch negatives.</p></li>
</ul>
<p>The design rationale behind the two-stage finetunings are:</p>
<ul class="simple">
<li><p>It is found that retrieval task presents greater difficulty compared to the non-retrieval tasks there is one stage training fully dedicated to the retrieval task.</p></li>
<li><p>In second stage, as the retrieval and non-retrieval tasks are blended, it is necessary to remove in-batch negatives trick. Since the negative may come from the the class and are not true negatives.</p></li>
</ul>
</section>
</section>
<section id="application-in-rag">
<h2><span class="section-number">28.4. </span>Application in RAG<a class="headerlink" href="#application-in-rag" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://aclanthology.org/2024.acl-long.242.pdf">Small Models, Big Insights: Leveraging Slim Proxy Models to Decide When
and What to Retrieve for LLMs</a></p>
</section>
<section id="generative-serp">
<h2><span class="section-number">28.5. </span>Generative SERP<a class="headerlink" href="#generative-serp" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/2402.14301">GenSERP: Large Language Models for Whole Page Presentation</a></p>
</section>
<section id="collections">
<h2><span class="section-number">28.6. </span>Collections<a class="headerlink" href="#collections" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://github.com/IR-LLM/Awesome-Information-Retrieval-in-the-Age-of-Large-Language-Model">Awesome Information Retrieval in the Age of Large Language Model</a></p>
</section>
<section id="bibliography">
<h2><span class="section-number">28.7. </span>Bibliography<a class="headerlink" href="#bibliography" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id9">
<div role="list" class="citation-list">
<div class="citation" id="id1571" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">KDR+23</a><span class="fn-bracket">]</span></span>
<p>Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. Large language models struggle to learn long-tail knowledge. In <em>International Conference on Machine Learning</em>, 15696–15707. PMLR, 2023.</p>
</div>
<div class="citation" id="id1573" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LRX+24<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id6">1</a>,<a role="doc-backlink" href="#id8">2</a>)</span>
<p>Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, and Wei Ping. Nv-embed: improved techniques for training llms as generalist embedding models. <em>arXiv preprint arXiv:2405.17428</em>, 2024.</p>
</div>
<div class="citation" id="id1093" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">MBPS09</a><span class="fn-bracket">]</span></span>
<p>Julien Mairal, Francis Bach, Jean Ponce, and Guillermo Sapiro. Online dictionary learning for sparse coding. In <em>Proceedings of the 26th annual international conference on machine learning</em>, 689–696. ACM, 2009.</p>
</div>
<div class="citation" id="id1572" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">SYM+23</a><span class="fn-bracket">]</span></span>
<p>Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. Is chatgpt good at search? investigating large language models as re-ranking agents. <em>arXiv preprint arXiv:2304.09542</em>, 2023.</p>
</div>
<div class="citation" id="id1570" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">WYW23</a><span class="fn-bracket">]</span></span>
<p>Liang Wang, Nan Yang, and Furu Wei. Query2doc: query expansion with large language models. <em>arXiv preprint arXiv:2303.07678</em>, 2023.</p>
</div>
<div class="citation" id="id1569" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">YIW+22</a><span class="fn-bracket">]</span></span>
<p>Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, and Meng Jiang. Generate rather than retrieve: large language models are strong context generators. <em>arXiv preprint arXiv:2209.10063</em>, 2022.</p>
</div>
<div class="citation" id="id1568" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>YZL+23<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id4">2</a>)</span>
<p>Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal. Improving language models via plug-and-play retrieval feedback. <em>arXiv preprint arXiv:2305.14002</em>, 2023.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/chapter_application_IR"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="information_retrieval_fundamentals.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">27. </span>Information Retrieval and Text Ranking</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#query-understanding-optimization">28.1. Query Understanding &amp; Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#query-categorization">28.1.1. Query Categorization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#natural-language-queries">28.1.1.1. Natural Language Queries</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#query-optimization-overview">28.1.2. Query Optimization Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gefeed-retrieval-feedback">28.1.3. GEFEED (Retrieval Feedback)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#query-doc-ranking">28.2. Query-Doc Ranking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-list-generation">28.2.1. Rank List Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ranker-distillation">28.2.2. Ranker Distillation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-embedding-model">28.3. LLM Embedding Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nv-embed">28.3.1. NV-Embed</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-in-rag">28.4. Application in RAG</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-serp">28.5. Generative SERP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collections">28.6. Collections</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">28.7. Bibliography</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yuguang Yang
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>