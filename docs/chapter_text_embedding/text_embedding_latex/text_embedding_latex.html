
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Sentence embeddings and its applications &#8212; LLM Foundations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/chapter_text_embedding/text_embedding_latex/text_embedding_latex';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/qe-logo-large.png" class="logo__image only-light" alt="LLM Foundations - Home"/>
    <script>document.write(`<img src="../../../_static/qe-logo-large.png" class="logo__image only-dark" alt="LLM Foundations - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Introduction.html">1. Introduction: LLM in the Age of AI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/language_models.html">2. Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/neural_language_models.html">3. Early Neural Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/word_embeddings.html">4. Word Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/transformers.html">5. Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/bert.html">6. BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/t5.html">7. Seq2Seq: T5 and BART</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_foundation/GPT_series.html">8. GPT Series</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Architectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_LLM_arch/LLM_dense_architectures.html">9. LLM Architectures Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_LLM_arch/LLM_moe_sparse_architectures.html">10. MoE Sparse Architectures (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Training</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_training/training_fundamentals.html">11. LLM Training Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_training/finetuning.html">12. LLM Finetuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_training/alignment.html">13. LLM Alignement and Preference Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_training/reinforcement_learning.html">14. *Reinforcement Learning Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_training/accelerated_training.html">15. LLM Training Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">LLM Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_inference/inference_fundamentals.html">16. Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_inference/inference_acceleration.html">17. Inference Acceleration (WIP)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Prompting</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_prompt/basic_prompt.html">18. Basic Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_prompt/advanced_prompt.html">19. Advanced Prompting Techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Embedding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../text_embedding_fundamentals.html">20. Text Embedding Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_embedding_LLM.html">21. LLM Text Embedding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Vision LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_multimodality/multimodality_fundamentals.html">22. Multimodality fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_multimodality/vision_transformers.html">23. Vision Language Pretraining</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Application in Information Retrieval and RAG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chapter_application_IR/information_retrieval_fundamentals_part1.html">24. Information Retrieval and Sparse Retrieval</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_application_IR/information_retrieval_fundamentals_part2.html">25. Information Retrieval and Dense Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_application_IR/application_LLM_in_IR.html">26. Application of LLM in IR (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_application_IR/conversational_IR.html">27. Conversational IR (WIP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_rag/basic_rag.html">28. RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter_rag/advanced_rag.html">29. Advanced RAG (WIP)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sentence embeddings and its applications</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Sentence embeddings and its applications</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#infersent">InferSent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sentence-bert">Sentence-BERT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#universal-sentence-encoder">Universal Sentence Encoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contrastive-learning">Contrastive learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contrastive-learning-via-data-augmentation">Contrastive learning via data augmentation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simcse">SimCSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cert">CERT</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark-dataset">Benchmark dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multinli-data">MultiNLI data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#snli">SNLI</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standard-semantic-textual-similarity-tasks">Standard semantic textual similarity tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qqp">QQP</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#software">Software</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="sentence-embeddings-and-its-applications">
<h1>Sentence embeddings and its applications<a class="headerlink" href="#sentence-embeddings-and-its-applications" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>There are many NLP tasks involves determining the relationship of two sentences, including semantic similarity, semantic relation reasoning, questioning answering etc. For example, Quora needs to determine if a question asked by a user has a semantically similar duplicate. The GLUE benchmark as an example [\autoref{ch:neural-network-and-deep-learning:ApplicationNLP:sec:BERTDownstreamTasks}], 6 of them are tasks that require learning sentences Inter-relationship. Specifically,</p>
<p><strong>MRPC</strong>: The Microsoft Research Paraphrase Corpus <span id="id1">[<a class="reference internal" href="../text_embedding_fundamentals.html#id1342" title="William B Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In Proceedings of the Third International Workshop on Paraphrasing (IWP2005). 2005.">DB05</a>]</span> is a corpus of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent.\</p>
<p><strong>QQP</strong>: The Quora Question Pairs<sup><a class="footnote-reference brackets" href="#id8" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></sup> dataset is a collection of question pairs from the community question-answering website Quora. The task is to determine whether a pair of questions are semantically equivalent. As in MRPC, the class distribution in <span class="math notranslate nohighlight">\(\mathrm{QQP}\)</span> is unbalanced <span class="math notranslate nohighlight">\((63 \%\)</span> negative), so we report both accuracy and F1 score. We use the standard test set, for which we obtained private labels from the authors. We observe that the test set has a different label distribution than the training set. \</p>
<p><strong>STS-B</strong>: The Semantic Textual Similarity Benchmark <span id="id3">[<a class="reference internal" href="../text_embedding_fundamentals.html#id1343" title="Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. Semeval-2017 task 1: semantic textual similarity-multilingual and cross-lingual focused evaluation. arXiv preprint arXiv:1708.00055, 2017.">CDA+17</a>]</span> is a collection of sentence pairs drawn from news headlines, video and image captions, and natural language inference data.</p>
<p><strong>Natural language inference</strong>: Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. The semantic concepts of entailment and contradiction are central to all aspects of natural language meaning,
from the lexicon to the content of entire texts.
Natural language inference is the task of determining whether a <em>hypothesis</em> is true (entailment), false (contradiction), or undetermined (neutral) given a <em>premise</em>.
\cite{bowman2015large}
\begin{table}
\scriptsize
\centering
\begin{tabular}{c|c|c}
\hline
Premise &amp; Label &amp; Hypothesis \ \hline
\begin{tabular}[c]{&#64;{}l&#64;{}}A man inspects the uniform of a figure\ in some East Asian country.\end{tabular}
&amp; Contraction &amp; The man is sleeping. \
An older and younger man smiling. &amp;
Neutral &amp;
\begin{tabular}[c]{&#64;{}l&#64;{}}Two men are smiling and laughing at \ the cats playing on the floor.\end{tabular}
\	
A soccer game with multiple males playing. &amp;
Entailment &amp; Some men are playing a sport. \ \hline
\end{tabular}	
\caption{<em>Entailment</em>, <em>contradiction</em>, and <em>neural</em> examples in a natural language inference task.}
\end{table}</p>
<p>Although BERT model and its variant have achieved new state-of-the-art among many sentence-pair classification and regression tasks. It has many practical challenges in tasks like large-scale semantic similarity comparison, clustering, and information retrieval via semantic search, etc. These tasks require that both sentences are fed into the network, which causes a massive computational overhead for large BERT model. Considering the task of finding the most similar pair among <span class="math notranslate nohighlight">\(N\)</span> sentences, then it requires <span class="math notranslate nohighlight">\(N^2/2\)</span> forward pass computation of BERT.</p>
<p>An alternative approach is to derive a semantically meaningful sentence embeddings for each sentence. A sentence embedding is a dense vector representation of a sentence. Sentences with similar semantic meanings are close and sentences with different meanings are apart. With sentence embeddings, similarity search can be realized simply via a distance or similarity metrics, such as cosine similarity. Besides performing similarity comparison between two sentences, the sentence embedding can also be used as generic sentence feature for different NLP tasks.</p>
<p>Early on, there have been efforts directed to derive sentence embedding by aggregating word embeddings. For example, one can average the BERT token embedding output as the sentence embedding. Another common practice is to use the output of the first token (the [CLS] token) as the sentence, which is found to be worse than averaging GloVe embeddings\cite{reimers2019sentence}. Recently, contrastive learning and Siamese type of learning have been successfully applied in deriving sentence embeddings, which will be the focus of our following sections.</p>
<p>\begin{remark}[Why we need sentence embedding fine tuning]</p>
<p>Pre-trained BERT models do not produce efficient and independent sentence embeddings as they always need to be fine-tuned in an end-to-end supervised setting. This is because we can think of a pre-trained BERT model as an indivisible whole and semantics is spread across all layers, not just the final layer. Without fine-tuning, it may be ineffective to use its internal representations independently. It is also hard to handle unsupervised tasks such
as clustering, topic modeling, information retrieval, or semantic search. Because we have to evaluate many sentence pairs during clustering tasks, for instance, this causes massive computational overhead.
\end{remark}</p>
</section>
<section id="infersent">
<h2>InferSent<a class="headerlink" href="#infersent" title="Link to this heading">#</a></h2>
<p>InferSent is a sentence embeddings training method invented by Facebook AI\cite{conneau2017supervised}. Sentence encoder is trained on natural language inference data\cite{bowman2015large} and can provide semantic sentence representations generalizing well to many different tasks.</p>
<p>InferSent uses the Siamese type of learning scheme [\autoref{ch:neural-network-and-deep-learning:ApplicationNLP:fig:infersent}]. A sentence pair are encoded by sentence encoders into separate sentence representations. Sentence representations are then concatenated and combined before being fed into a linear Softmax classifier with three labels: entailment, contradiction, and neutral.</p>
<p>In the inference stage, we can compute and store sentence embedding offline for large scale semantic search tasks.</p>
<figure class="align-default" id="ch-neural-network-and-deep-learning-applicationnlp-fig-infersent">
<img alt="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/textMatching/sentenceEmbedding/inferSent" src="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/textMatching/sentenceEmbedding/inferSent" />
<figcaption>
<p><span class="caption-text">Siamese type of training scheme to learning sentence embedding from natural language inference task. The sentence encoder is bi-directional LSTM architecture with max pooling and it takes 300 dimension of Glove word embeddings of constituents as the input.</span><a class="headerlink" href="#ch-neural-network-and-deep-learning-applicationnlp-fig-infersent" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>InferSent represents a new paradigm of solving sentence-pair related tasks: each sentence has an representation derived separately, and the representation is used to solve downstream tasks. This contrasts BERT approach, which is a joint method that uses cross-features
or attention from one sentence to the other.</p>
<p>\iffalse
Sentence level classification tasks
\begin{table}
\centering
\scriptsize
\begin{tabular}{l|r|l|l|l|c}
name &amp; <span class="math notranslate nohighlight">\(\mathbf{N}\)</span> &amp; task &amp; C &amp; examples &amp; label(s) \
\hline MR &amp; <span class="math notranslate nohighlight">\(11 \mathrm{k}\)</span> &amp; sentiment (movies) &amp; 2 &amp; “Too slow for a younger crowd, too shallow for an older one.” &amp; neg \
CR &amp; <span class="math notranslate nohighlight">\(4 \mathrm{k}\)</span> &amp; product reviews &amp; 2 &amp; “We tried it out christmas night and it worked great <span class="math notranslate nohighlight">\(. &quot;\)</span> &amp; pos \
SUBJ &amp; <span class="math notranslate nohighlight">\(10 \mathrm{k}\)</span> &amp; subjectivity/objectivity &amp; 2 &amp; “A movie that doesn’t aim too high, but doesn’t need to.” &amp; subj \
MPQA &amp; <span class="math notranslate nohighlight">\(11 \mathrm{k}\)</span> &amp; opinion polarity &amp; 2 &amp; “don’t want”, “would like to tell”; &amp; neg, pos \
TREC &amp; <span class="math notranslate nohighlight">\(6 \mathrm{k}\)</span> &amp; question-type &amp; 6 &amp; “What are the twin cities ?” &amp; LOC:city \
SST-2 &amp; <span class="math notranslate nohighlight">\(70 \mathrm{k}\)</span> &amp; sentiment (movies) &amp; 2 &amp; “Audrey Tautou has a knack for picking roles that magnify her <span class="math notranslate nohighlight">\([. .] &quot;\)</span> &amp; pos \
SST-5 &amp; <span class="math notranslate nohighlight">\(12 \mathrm{k}\)</span> &amp; sentiment (movies) &amp; 5 &amp; “nothing about this movie works.” &amp; 0
\end{tabular}
\end{table}</p>
<p>The sentence evaluation tool<sup><a class="footnote-reference brackets" href="#id9" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></sup> <span id="id5">[]</span></p>
<p>Our aim is to obtain general-purpose sentence embeddings that capture generic information that is
\fi</p>
</section>
<section id="sentence-bert">
<h2>Sentence-BERT<a class="headerlink" href="#sentence-bert" title="Link to this heading">#</a></h2>
<p>While BERT has demonstrated remarkable performance across NLP tasks, a large disadvantage of the BERT approach is that no independent sentence embeddings are computed, which makes it difficult to derive sentence embeddings from BERT.</p>
<p>Sentence-BERT enables sentence embedding extraction via Siamese type of learning like InferSent. The major difference between the InferSent and Sentence-BERT is that Sentence-BERT utilizes BERT to encode the sentence. Specifically, three strategies can be used to derived sentence embedding</p>
<ul class="simple">
<li><p>the output of the CLS-token</p></li>
<li><p>the mean of all output vectors</p></li>
<li><p>max-over-time of the output vectors</p></li>
</ul>
<figure class="align-default" id="ch-neural-network-and-deep-learning-applicationnlp-fig-sentencebert">
<img alt="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/textMatching/sentenceEmbedding/sentenceBERT" src="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/textMatching/sentenceEmbedding/sentenceBERT" />
<figcaption>
<p><span class="caption-text">(<strong>left</strong>) Sentence-BERT architecture with classification objective function for training. The two BERT networks are pre-trained have tied weights (Siamese network structure). (<strong>right</strong>) Sentence-BERT architecture at inference. The similarity between two input sentences can be computed as the similarity score between two sentence embeddings.</span><a class="headerlink" href="#ch-neural-network-and-deep-learning-applicationnlp-fig-sentencebert" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="universal-sentence-encoder">
<h2>Universal Sentence Encoder<a class="headerlink" href="#universal-sentence-encoder" title="Link to this heading">#</a></h2>
<p>\cite{cer2018universal}</p>
</section>
<section id="contrastive-learning">
<h2>Contrastive learning<a class="headerlink" href="#contrastive-learning" title="Link to this heading">#</a></h2>
<section id="contrastive-learning-via-data-augmentation">
<h3>Contrastive learning via data augmentation<a class="headerlink" href="#contrastive-learning-via-data-augmentation" title="Link to this heading">#</a></h3>
<p>\cite{shen2020simple}</p>
<figure class="align-default" id="fig-datacutoffdemo">
<img alt="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/sentence_representation/data_augmented_contrastive_learning/data_cut_off_demo" src="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/sentence_representation/data_augmented_contrastive_learning/data_cut_off_demo" />
<figcaption>
<p><span class="caption-text">Figure 1: Schematic illustration of the proposed cutoff augmentation strategies, including token cutoff, feature
cutoff and span cutoff, respectively. Blue area indicates that the corresponding elements within the sentence’s
input embedding matrix are removed and converted to 0. Notably, this is distinct from Dropout, which randomly
transforms elements to 0 (without considering any underlying structure of the matrix).</span><a class="headerlink" href="#fig-datacutoffdemo" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="simcse">
<h3>SimCSE<a class="headerlink" href="#simcse" title="Link to this heading">#</a></h3>
<p>\cite{gao2021simcse}</p>
<p>Simple contrastive learning of sentence embeddings</p>
<p>Unsupervised SimCSE</p>
<p>Positive example pair: passing one sentence passing through the encoder network with different dropout masking</p>
<p>Negative example: in batch negatives</p>
<p>Contrastive learning aims to learn effective representation by pulling semantically close neighbors together and pushing apart non-neighbors (Hadsell et al., 2006). It assumes a set of paired examples <span class="math notranslate nohighlight">\(\mathcal{D}=\left\{\left(x_{i}, x_{i}^{+}\right)\right\}_{i=1}^{m}\)</span>, where <span class="math notranslate nohighlight">\(x_{i}\)</span> and <span class="math notranslate nohighlight">\(x_{i}^{+}\)</span>are semantically related. We follow the contrastive framework in Chen et al. (2020) and take a cross-entropy objective with in-batch negatives (Chen et al., 2017 ; Henderson et al., 2017): let <span class="math notranslate nohighlight">\(\mathbf{h}_{i}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{h}_{i}^{+}\)</span>denote the representations of <span class="math notranslate nohighlight">\(x_{i}\)</span> and <span class="math notranslate nohighlight">\(x_{i}^{+}\)</span>, the training objective for <span class="math notranslate nohighlight">\(\left(x_{i}, x_{i}^{+}\right)\)</span>with a mini-batch of <span class="math notranslate nohighlight">\(N\)</span> pairs is:
$<span class="math notranslate nohighlight">\(
\ell_{i}=-\log \frac{e^{\operatorname{sim}\left(\mathbf{h}_{i}, \mathbf{h}_{i}^{+}\right) / \tau}}{\sum_{j=1}^{N} e^{\operatorname{sim}\left(\mathbf{h}_{i}, \mathbf{h}_{j}^{+}\right) / \tau}}
\)</span><span class="math notranslate nohighlight">\(
where \)</span>\tau<span class="math notranslate nohighlight">\( is a temperature hyperparameter and \)</span>\operatorname{sim}\left(\mathbf{h}<em>{1}, \mathbf{h}</em>{2}\right)<span class="math notranslate nohighlight">\( is the cosine similarity \)</span>\frac{\mathbf{h}<em>{1}^{\top} \mathbf{h}</em>{2}}{\left|\mathbf{h}<em>{1}\right| \cdot\left|\mathbf{h}</em>{2}\right|} .<span class="math notranslate nohighlight">\( In this work, we encode input sentences using a pre-trained language model such as BERT (Devlin et al., 2019) or RoBERTa (Liu et al., 2019): \)</span>\mathbf{h}=f_{\theta}(x)$, and then fine-tune all the parameters using the contrastive learning objective (Eq. 1).</p>
<p><strong>supervised contrastive learning with hard negatives</strong></p>
<p>Contradiction as hard negatives. Finally, we further take the advantage of the NLI datasets by using its contradiction pairs as hard negatives <span class="math notranslate nohighlight">\({ }^{6}\)</span>. In NLI datasets, given one premise, annotators are required to manually write one sentence that is absolutely true (entailment), one that might be true (neutral), and one that is definitely false (contradiction). Therefore, for each premise and its entailment hypothesis, there is an accompanying contradiction hypothesis <span class="math notranslate nohighlight">\({ }^{7}\)</span> (see Figure 1 for an example).</p>
<p>Formally, we extend <span class="math notranslate nohighlight">\(\left(x_{i}, x_{i}^{+}\right)\)</span>to <span class="math notranslate nohighlight">\(\left(x_{i}, x_{i}^{+}, x_{i}^{-}\right)\)</span>, where <span class="math notranslate nohighlight">\(x_{i}\)</span> is the premise, <span class="math notranslate nohighlight">\(x_{i}^{+}\)</span>and <span class="math notranslate nohighlight">\(x_{i}^{-}\)</span>are entailment and contradiction hypotheses. The training objec-
tive <span class="math notranslate nohighlight">\(\ell_{i}\)</span> is then defined by <span class="math notranslate nohighlight">\((N\)</span> is mini-batch size
$<span class="math notranslate nohighlight">\(-\log \frac{e^{\operatorname{sim}\left(\mathbf{h}_{i}, \mathbf{h}_{i}^{+}\right) / \tau}}{\sum_{j=1}^{N}\left(e^{\operatorname{sim}\left(\mathbf{h}_{i}, \mathbf{h}_{j}^{+}\right) / \tau}+e^{\operatorname{sim}\left(\mathbf{h}_{i}, \mathbf{h}_{j}^{-}\right) / \tau}\right)}\)</span><span class="math notranslate nohighlight">\(
As shown in Table 4 , adding hard negatives can further improve performance \)</span>(84.9 \rightarrow 86.2)$ and</p>
</section>
<section id="cert">
<h3>CERT<a class="headerlink" href="#cert" title="Link to this heading">#</a></h3>
<p>\cite{fang2020cert}</p>
<p>CERT: Contrastive self-supervised Encoder Representations
from Transformers, which pretrains language representation models using contrastive selfsupervised learning at the sentence level. CERT creates augmentations of original sentences
using back-translation. Then it finetunes a pretrained language encoder (e.g., BERT) by
predicting whether two augmented sentences originate from the same sentence.</p>
<p>CERT takes a pretrained language representation model (e.g., BERT) and finetunes it using
contrastive self-supervised learning on the input data of the target task.</p>
<figure class="align-default" id="fig-certworkflow">
<img alt="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/sentence_representation/CERT/CERT_workflow" src="docs/chapter_text_embedding/text_embedding_latex/deepLearning/ApplicationsNLP/sentence_representation/CERT/CERT_workflow" />
<figcaption>
<p><span class="caption-text">The workflow of CERT. Given the large-scale input texts (without labels) from
source tasks, a BERT model is first pretrained on these texts. Then we continue
to train this pretrained BERT model using CSSL on the input texts (without
labels) from the target task. We refer to this model as pretrained CERT model.
Then we finetune the CERT model using the input texts and their associated
labels in the target task and get the final model that performs the target task.</span><a class="headerlink" href="#fig-certworkflow" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="benchmark-dataset">
<h2>Benchmark dataset<a class="headerlink" href="#benchmark-dataset" title="Link to this heading">#</a></h2>
<section id="multinli-data">
<h3>MultiNLI data<a class="headerlink" href="#multinli-data" title="Link to this heading">#</a></h3>
<p>\cite{williams2017broad}</p>
<p>The Multi-Genre Natural Language Inference (MultiNLI) corpus <sup><a class="footnote-reference brackets" href="#id10" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></sup> is a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. It has over 433,000 examples and is one of the largest datasets available for natural language inference (a.k.a recognizing textual entailment). The dataset is also designed so that existing machine learning models trained on the Stanford NLI corpus can also be evaluated using MultiNLI.</p>
</section>
<section id="snli">
<h3>SNLI<a class="headerlink" href="#snli" title="Link to this heading">#</a></h3>
<p>\cite{bowman2015large}</p>
</section>
<section id="standard-semantic-textual-similarity-tasks">
<h3>Standard semantic textual similarity tasks<a class="headerlink" href="#standard-semantic-textual-similarity-tasks" title="Link to this heading">#</a></h3>
<p>\cite{ agirre2012semeval, agirre2013sem, agirre2014semeval, agirre2015semeval, agirre2016semeval, cer2017semeval}</p>
<p>\cite{marelli2014sick}</p>
</section>
<section id="qqp">
<h3>QQP<a class="headerlink" href="#qqp" title="Link to this heading">#</a></h3>
<p>QQP. Quora Question Pairs (QQP)<sup><a class="footnote-reference brackets" href="#id11" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></sup>; consists of pairs of potentially duplicate questions collected from Quora, a
question-and-answer website. The binary label of
each question pair indicates redundancy.</p>
</section>
</section>
</section>
<section id="software">
<h1>Software<a class="headerlink" href="#software" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://github.com/deepset-ai/haystack">haystack</a></p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id8" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">1</a><span class="fn-bracket">]</span></span>
<p>\url{<a class="reference external" href="https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs">https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs</a>}</p>
</aside>
<aside class="footnote brackets" id="id9" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">2</a><span class="fn-bracket">]</span></span>
<p>\url{<a class="github reference external" href="https://github.com/facebookresearch/SentEval">facebookresearch/SentEval</a>}</p>
</aside>
<aside class="footnote brackets" id="id10" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">3</a><span class="fn-bracket">]</span></span>
<p>\url{<a class="reference external" href="https://cims.nyu.edu/">https://cims.nyu.edu/</a> sbowman/multinli/}</p>
</aside>
<aside class="footnote brackets" id="id11" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">4</a><span class="fn-bracket">]</span></span>
<p>\url{<a class="reference external" href="https://www.kaggle.com/sambit7/first-quora-dataset">https://www.kaggle.com/sambit7/first-quora-dataset</a>}</p>
</aside>
</aside>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/chapter_text_embedding/text_embedding_latex"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Sentence embeddings and its applications</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#infersent">InferSent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sentence-bert">Sentence-BERT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#universal-sentence-encoder">Universal Sentence Encoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contrastive-learning">Contrastive learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contrastive-learning-via-data-augmentation">Contrastive learning via data augmentation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simcse">SimCSE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cert">CERT</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benchmark-dataset">Benchmark dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multinli-data">MultiNLI data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#snli">SNLI</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standard-semantic-textual-similarity-tasks">Standard semantic textual similarity tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qqp">QQP</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#software">Software</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yuguang Yang
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>