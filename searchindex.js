Search.setIndex({"alltitles": {"": [[1, "example-1"], [1, "example-3"], [6, "remark-2"], [7, "example-0"], [7, "example-1"], [9, "example-0"], [11, "example-0"], [11, "example-1"], [12, "example-0"], [17, "example-3"], [20, "example-0"]], " (Adam stochastic gradient descent algorithm with weight decay)": [[23, "Adam_stochastic_gradient_descent_algorithm_with_weight_decay"]], " (Adam stochastic gradient descent algorithm)": [[23, "Adam_stochastic_gradient_descent_algorithm"]], " (BPE)": [[1, "BPE-algorithm"]], " (Caveats)": [[7, "remark-3"]], " (Comparision of base LLM and instructed LLM in response to a prompt)": [[22, "example-0"]], " (Encoder layer)": [[6, "definition-0"], [10, "chapter_foundation_def_pretrained_LM_transformer_encoder_layer"]], " (Expansion of G_k)": [[23, "remark-2"]], " (How DPO loss work)": [[21, "remark-1"]], " (Is feedforward layer necessary for Transformer?)": [[10, "remark-1"]], " (LoRA low rank matrices initialization)": [[22, "remark-1"]], " (Minibatch stochastic gradient descent algorithm)": [[23, "Minibatch_stochastic_gradient_descent_algorithm"]], " (OBS Neural Network Pruning Algorithm)": [[12, "OBS_network_pruning_algorithm"]], " (Per-channel quantization)": [[12, "example-2"]], " (Per-tensor quantization)": [[12, "example-1"]], " (Practical simple back-off)": [[7, "remark-2"]], " (Relationship to Cross Entropy)": [[7, "remark-4"]], " (Relationship to logistic regression)": [[21, "remark-0"]], " (Skip-gram and CBOW optimization problem)": [[11, "chapter_foundation_word_embedding_def_skipGramOptimization"]], " (Translation pairs can appear naturally in pretraining text corpus)": [[5, "example-0"]], " (What does Byte-level mean?)": [[1, "remark-2"]], " (Zero shot prompt for movie review sentiment classification)": [[17, "example-0"]], " (Zero shot prompt for programming task)": [[17, "example-2"]], " (Zero shot prompt for text extracting)": [[17, "example-1"]], " (choice of minibatch size)": [[23, "remark-1"]], " (computation in decoder module)": [[10, "definition-3"]], " (computation in encoder module)": [[6, "chapter_foundation_def_pretrained_LM_transformer_bert_encoder_computation"], [10, "chapter_foundation_def_pretrained_LM_transformer_encoder_computation"]], "A minimal RAG example": [[19, "a-minimal-rag-example"]], "ALBERT": [[6, "albert"]], "AWQ": [[12, "awq"]], "About This Book": [[0, "about-this-book"]], "Absolute Position": [[1, "absolute-position"]], "Activation": [[1, "activation"]], "Activation Checkpointing Techniques": [[20, "activation-checkpointing-techniques"]], "Activations": [[20, "activations"]], "Adam": [[23, "adam"]], "Adapter Tuning": [[22, "adapter-tuning"]], "Adaptive Gradient (AdaGrad)": [[23, "adaptive-gradient-adagrad"]], "Adaptive Gradient Method": [[23, "adaptive-gradient-method"]], "Add \\alpha Smoothing And Discounting": [[7, "add-alpha-smoothing-and-discounting"]], "Additional remark RL vs SFT vs DPO": [[21, "additional-remark-rl-vs-sft-vs-dpo"]], "Advanced prompt techniques": [[16, null]], "Advanced quantization techniques": [[12, "advanced-quantization-techniques"]], "Advanced rag techniques": [[18, null]], "Analysis": [[22, "analysis"]], "Appendix": [[20, "appendix"]], "Application in Information Retrieval": [[25, null]], "Application of LLM in IR": [[3, null]], "Arithmetic tasks": [[5, "arithmetic-tasks"]], "Attention layer": [[1, "attention-layer"]], "BART": [[9, "bart"]], "BERT": [[6, null]], "BERT Architecture": [[6, "bert-architecture"]], "BERT Architecture Componenents": [[6, "bert-architecture-componenents"]], "BERT model parameters": [[6, "id1541"]], "BPE Tokenization": [[1, "bpe-tokenization"]], "Base LLM vs instructed LLM": [[17, "base-llm-vs-instructed-llm"]], "Basic Concepts": [[12, "basic-concepts"]], "Basic RAG": [[19, null]], "Basic prompt": [[17, null]], "Basics": [[12, "basics"], [13, "basics"], [22, "basics"]], "Beam search decoding": [[13, "beam-search-decoding"]], "Benchmarking": [[7, "benchmarking"]], "Bibliography": [[1, "bibliography"], [5, "bibliography"], [6, "bibliography"], [7, "bibliography"], [8, "bibliography"], [9, "bibliography"], [10, "bibliography"], [11, "bibliography"], [12, "bibliography"], [13, "bibliography"], [16, "bibliography"], [17, "bibliography"], [20, "bibliography"], [21, "bibliography"], [22, "bibliography"], [23, "bibliography"]], "Chain-of-Thought (CoT) Prompting": [[17, "chain-of-thought-cot-prompting"]], "Choice Shuffling Ensembling": [[16, "choice-shuffling-ensembling"]], "Choices Of n And Bias-variance Trade-off": [[7, "choices-of-n-and-bias-variance-trade-off"]], "Closed-book question answering": [[5, "closed-book-question-answering"]], "Combined Together: Adam and AdamW": [[23, "combined-together-adam-and-adamw"]], "Combined with GQA": [[12, "combined-with-gqa"]], "Combining Together: the Med prompt": [[16, "combining-together-the-med-prompt"]], "Common Sense Reasoning": [[5, "common-sense-reasoning"]], "Communication volumne summary for different operations. Let \\Phi be the total data size in one device and N be the total number of devices.": [[20, "id1517"]], "Compared With ELMO": [[6, "compared-with-elmo"]], "Comparison With Recurrent Layer In Sequence Modeling": [[10, "comparison-with-recurrent-layer-in-sequence-modeling"]], "Comparison with other approaches": [[22, "comparison-with-other-approaches"]], "Computation breakdown": [[1, "id1525"]], "Computational Breakdown Analysis": [[10, "computational-breakdown-analysis"]], "Computational complexity": [[13, "computational-complexity"]], "Controling beam search behavior": [[13, "controling-beam-search-behavior"]], "DPO": [[21, "dpo"]], "DPO variants": [[21, "dpo-variants"]], "Datasets": [[7, "datasets"]], "Decoder Anatomy": [[10, "decoder-anatomy"]], "Decoding Fundamentals": [[13, "decoding-fundamentals"]], "Dense Architecture Examples": [[1, "dense-architecture-examples"]], "Different Branches Of Developments": [[10, "different-branches-of-developments"]], "DistillBERT": [[6, "distillbert"]], "Distributed Parallel Training": [[20, "distributed-parallel-training"]], "Driving the DPO": [[21, "driving-the-dpo"]], "Dynamic in-context learning": [[16, "dynamic-in-context-learning"]], "Early Neural Language Models": [[8, null]], "Efficient BERT Models": [[6, "efficient-bert-models"]], "Encoder Layer Computation Summary": [[10, "encoder-layer-computation-summary"]], "Evaluation Metrics": [[7, "evaluation-metrics"]], "Examples of five types of semantic relationships.": [[11, "id1517"]], "Examples of nine types of syntactic relationships.": [[11, "id1518"]], "FP8": [[12, "fp8"]], "Feed-forward Neural Language Model": [[8, "feed-forward-neural-language-model"]], "Feed-forward layer": [[1, "feed-forward-layer"]], "Few-shot and in-context learning": [[17, "few-shot-and-in-context-learning"]], "Fine-tuning And Evaluation": [[6, "fine-tuning-and-evaluation"]], "Flash Attention": [[20, "flash-attention"]], "Floating Data Types": [[20, "floating-data-types"]], "Forward Pass Computation Breadown": [[1, "forward-pass-computation-breadown"]], "From BPE to BBPE": [[1, "from-bpe-to-bbpe"]], "From Online Softmax To Flash Attention": [[20, "from-online-softmax-to-flash-attention"]], "GPT Series": [[5, null]], "GPT-1": [[5, "gpt-1"]], "GPT-1 Fine Tuning": [[5, "gpt-1-fine-tuning"]], "GPT-2": [[5, "gpt-2"]], "GPT-3": [[5, "gpt-3"]], "GPTQ": [[12, "gptq"]], "GPU Memory Allocation": [[20, "gpu-memory-allocation"]], "GPU Parallel Operations": [[20, "gpu-parallel-operations"]], "General Case": [[12, "general-case"]], "GloVe": [[11, "glove"]], "Greedy decoding": [[13, "greedy-decoding"]], "Grouped Query Attention (GQA)": [[1, "grouped-query-attention-gqa"]], "Groupwise quantization": [[12, "groupwise-quantization"]], "How labeler evaluates the response quality": [[21, "id1523"]], "Human accuracy in identifying whether short (around 200 word) news articles are model generated.": [[5, "id1518"]], "Inference": [[22, "inference"]], "Inference acceleration": [[12, null]], "Inference acceleration: Quantization": [[12, "inference-acceleration-quantization"]], "Information Retrieval Fundamentals": [[4, null]], "Input Embeddings": [[6, "input-embeddings"]], "Input Output Conventions": [[10, "input-output-conventions"]], "Input layer": [[1, "input-layer"]], "Instruction Finetuning": [[22, "instruction-finetuning"]], "Introduction": [[5, "introduction"], [5, "id4"], [6, "introduction"], [6, "id19"], [19, "introduction"], [25, null]], "Introduction: LLM in the Age of AI": [[0, null]], "Katz\u2019s Back-off": [[7, "katz-s-back-off"]], "LLM Alignement and Preference learning": [[21, null]], "LLM Architectures": [[25, null]], "LLM Architectures Fundamentals": [[1, null]], "LLM Decoding": [[13, null]], "LLM Finetuning": [[22, null]], "LLM Foundations": [[25, null]], "LLM Inference": [[25, null]], "LLM Training": [[25, null]], "LLM Training Acceleration": [[20, null]], "LLM Training Fundamentals": [[23, null]], "LLM.int8()": [[12, "llm-int8"]], "LLama architectures": [[1, "llama-architectures"]], "L_2 Weight Decay and AdamW": [[23, "l-2-weight-decay-and-adamw"]], "Language Models": [[7, null]], "Language modeling": [[5, "language-modeling"]], "Layer normalization": [[1, "layer-normalization"]], "Layer normalization basics": [[1, "layer-normalization-basics"]], "Layer normalization example choices": [[1, "layer-normalization-example-choices"]], "Layer normalization position": [[1, "layer-normalization-position"]], "LoRA (Low-Rank Adaptation)": [[22, "lora-low-rank-adaptation"]], "MLP Part": [[20, "mlp-part"]], "MOE LLM in practice": [[2, "moe-llm-in-practice"]], "MOE architecture fundamentals": [[2, "moe-architecture-fundamentals"]], "MOE sparse models": [[2, null]], "Machine Translation": [[5, "machine-translation"]], "Masked Language Modeling (Masked LM)": [[6, "masked-language-modeling-masked-lm"]], "Memory requirement with KV Cache": [[12, "memory-requirement-with-kv-cache"]], "MiniLM": [[6, "minilm"]], "Minibatch Stochastic Gradient Descent": [[23, "minibatch-stochastic-gradient-descent"]], "Mistral MOE": [[2, "mistral-moe"]], "Mixed Precision Training": [[20, "mixed-precision-training"]], "MobileBERT": [[6, "mobilebert"]], "Model Distillation": [[6, "model-distillation"]], "Model Evaluation": [[7, "model-evaluation"]], "Model Parameter Estimation": [[7, "model-parameter-estimation"]], "Model States": [[20, "model-states"]], "Model cards of several selected LLMs with public configuration details. Here, PE denotes position embedding, #L denotes the number of layers, #H denotes the number of attention heads, dmodel denotes the size of hidden states, and MCL denotes the maximum context length during training.": [[1, "id1524"]], "Model parallelism (tensor parallelism)": [[20, "model-parallelism-tensor-parallelism"]], "Momentum Method": [[23, "momentum-method"]], "More On Perplexity": [[7, "more-on-perplexity"]], "Motivation": [[7, "motivation"], [8, "motivation"], [19, "motivation"], [21, "motivation"], [22, "motivation"]], "Multi Query Attention (MQA)": [[1, "multi-query-attention-mqa"]], "Multi-Head Attention (MHA)": [[1, "multi-head-attention-mha"]], "Multihead Attention With Masks": [[10, "multihead-attention-with-masks"]], "Multilingual Models": [[6, "multilingual-models"]], "Multilingual-BERT (mBERT)": [[6, "multilingual-bert-mbert"]], "Multimodality fundamentals": [[14, null]], "News article generation": [[5, "news-article-generation"]], "Next Sentence Prediction (NSP)": [[6, "next-sentence-prediction-nsp"]], "Noise Contrastive Estimation}": [[11, "noise-contrastive-estimation"]], "Online Softmax Algorithm": [[20, "online-softmax-algorithm"]], "Online Softmax Motivation": [[20, "online-softmax-motivation"]], "Optimization Algorithms": [[23, "optimization-algorithms"]], "Optimization I: negative sampling": [[11, "optimization-i-negative-sampling"]], "Optimization II: down-sampling of frequent words": [[11, "optimization-ii-down-sampling-of-frequent-words"]], "Out Of Vocabulary (OOV) Words And Rare Words": [[7, "out-of-vocabulary-oov-words-and-rare-words"]], "Output layer": [[1, "output-layer"]], "Overall Architecture": [[10, "overall-architecture"]], "Overall methodology": [[21, "overall-methodology"]], "Overview": [[1, "overview"], [9, "overview"], [9, "id3"], [10, "overview"], [11, "overview"], [12, "overview"], [20, "overview"]], "Overview of parallel training techniques": [[20, "overview-of-parallel-training-techniques"]], "Parameter composition in Transformer models": [[1, "parameter-composition-in-transformer-models"]], "Parameter-Efficient Fine Tuning": [[22, "parameter-efficient-fine-tuning"]], "Parameters in a Transformer": [[1, "id1523"]], "Per-channel quantization": [[12, "per-channel-quantization"]], "Per-tensor quantization": [[12, "per-tensor-quantization"]], "Per-token quantization": [[12, "per-token-quantization"]], "Performance Overview": [[5, "performance-overview"]], "Performance comparison among  supervised SOTA neural machine translation models, unsupervised multi-lingual pretrained language models, and GPT-3.": [[5, "id1519"]], "Pointwise FeedForward Layer": [[10, "pointwise-feedforward-layer"]], "Position Embeddings": [[1, "position-embeddings"]], "Position Encodings": [[10, "position-encodings"]], "Post-training": [[23, "post-training"]], "Practival Implementations": [[1, "practival-implementations"]], "Pre-training": [[9, "pre-training"]], "Pre-training Tasks": [[6, "pre-training-tasks"]], "Preference data collection": [[21, "preference-data-collection"]], "Preliminary": [[12, "preliminary"]], "Preliminary: MDP": [[21, "preliminary-mdp"]], "Preliminary: Preference modeling": [[21, "preliminary-preference-modeling"]], "Pretrained Language Models": [[10, "pretrained-language-models"]], "Pretraining": [[5, "pretraining"], [9, "pretraining"], [23, "pretraining"]], "Pretraining performance analysis": [[9, "pretraining-performance-analysis"]], "Prompting and RAG": [[25, null]], "Put It Together": [[6, "put-it-together"]], "Quantization granularities": [[12, "quantization-granularities"]], "Quantization-performance trade-off in language models": [[12, "quantization-performance-trade-off-in-language-models"]], "Quantized matrix multiplication": [[12, "quantized-matrix-multiplication"]], "RAG Advantages": [[19, "rag-advantages"]], "RAG paradigam overview": [[19, "rag-paradigam-overview"]], "RLHF via PPO": [[21, "rlhf-via-ppo"]], "RMS Norm (Root Mean Square Norm)": [[1, "rms-norm-root-mean-square-norm"]], "RMSProp": [[23, "rmsprop"]], "Recurrent Neural Language Model": [[8, "recurrent-neural-language-model"]], "References and software": [[12, "references-and-software"]], "Reinforcement learning": [[21, "reinforcement-learning"]], "Reward modeling": [[21, "reward-modeling"]], "Rotary Postion Embedding": [[1, "rotary-postion-embedding"]], "SFT": [[21, "sft"]], "SFT Vs RLHF": [[23, "sft-vs-rlhf"]], "SVD based word embeddings": [[11, "svd-based-word-embeddings"]], "Sample Efficient: ELECTRA": [[6, "sample-efficient-electra"]], "Scaling Instruction Finetuning": [[22, "scaling-instruction-finetuning"]], "Self-attention Part": [[20, "self-attention-part"]], "Self-attention and Variants": [[1, "self-attention-and-variants"]], "Self-generated chain of thought": [[16, "self-generated-chain-of-thought"]], "Seq2Seq: T5 and BART": [[9, null]], "Simple DPO": [[21, "simple-dpo"]], "Sliding Window Attention": [[1, "sliding-window-attention"]], "Smooth Quant": [[12, "smooth-quant"]], "Smoothing And Discounting Techniques": [[7, "smoothing-and-discounting-techniques"]], "Smoothing preference label": [[21, "smoothing-preference-label"]], "Sparse Attention": [[1, "sparse-attention"]], "Speed-Up Hessian Computation": [[12, "speed-up-hessian-computation"]], "Speical Case: Diagonal Hessian Assumption": [[12, "speical-case-diagonal-hessian-assumption"]], "Standard quantization techniques": [[12, "standard-quantization-techniques"]], "Statistical Language Models": [[7, "statistical-language-models"]], "Storage requirement for different components during LLM training using Adam.": [[20, "id1516"]], "Subword model": [[11, "subword-model"]], "Summary": [[1, "summary"]], "SuperGLUE": [[5, "superglue"]], "T5": [[9, "t5"]], "Table of Contents": [[25, null]], "Temperature-controlled sampling": [[13, "temperature-controlled-sampling"]], "Text Generation Tasks": [[9, "text-generation-tasks"]], "The Decoder Branch": [[10, "the-decoder-branch"]], "The EXTREME Benchmark": [[6, "the-extreme-benchmark"]], "The Encoder Anatomy": [[6, "the-encoder-anatomy"]], "The Encoder Branch": [[10, "the-encoder-branch"]], "The Encoder-decoder Branch": [[10, "the-encoder-decoder-branch"]], "The Error Minimization Framework": [[12, "the-error-minimization-framework"]], "The KV Cache": [[12, "the-kv-cache"]], "The Memory Requirement For Training LLM": [[20, "the-memory-requirement-for-training-llm"]], "The PPO algorithm": [[21, "the-ppo-algorithm"]], "The Rise of Large Language Models": [[0, "the-rise-of-large-language-models"]], "The basics": [[13, "the-basics"]], "The computational cost with KV Cache": [[12, "the-computational-cost-with-kv-cache"]], "The fundamental challenge of LLM inference": [[12, "the-fundamental-challenge-of-llm-inference"]], "The hyperparameter settings of various pretrained BERT configurations.  BERTBase and BERTLarge are the two most commonly used configurations today;": [[6, "id1540"]], "The hypothesis and method": [[22, "the-hypothesis-and-method"]], "The mechanism": [[1, "the-mechanism"]], "The model": [[11, "the-model"]], "TinyBERT": [[6, "tinybert"]], "Tokenziation, vocabulary, and weight tying": [[1, "tokenziation-vocabulary-and-weight-tying"]], "Top-k and top-p sampling": [[13, "top-k-and-top-p-sampling"]], "Total weight": [[1, "total-weight"]], "Training": [[22, "training"]], "Training Overview": [[23, "training-overview"]], "Training Process": [[20, "training-process"]], "Transformers": [[10, null], [10, "content-chapter-foundation-transformers-transformers"]], "Vision transformers": [[15, null]], "Visualization": [[11, "visualization"]], "What is RAG": [[19, "what-is-rag"]], "Where quantization and dequant happen? What is the trade off": [[12, "where-quantization-and-dequant-happen-what-is-the-trade-off"]], "Word Embeddings": [[11, null]], "Word2Vec": [[11, "word2vec"]], "XLM, XLM-R, And XLM-E": [[6, "xlm-xlm-r-and-xlm-e"]], "ZeRO Via DeepSpeed": [[20, "zero-via-deepspeed"]], "ZeRO-Stage-One": [[20, "zero-stage-one"]], "Zero-shot prompt": [[17, "zero-shot-prompt"]], "\\star Deriving The MLE": [[7, "star-deriving-the-mle"]], "ensemble CoT with self-consistency": [[16, "ensemble-cot-with-self-consistency"]], "n-gram Language Model": [[7, "n-gram-language-model"]]}, "docnames": ["docs/Introduction", "docs/chapter_LLM_arch/LLM_dense_architectures", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures", "docs/chapter_application_IR/application_LLM_in_IR", "docs/chapter_application_IR/information_retrieval_fundamentals", "docs/chapter_foundation/GPT_series", "docs/chapter_foundation/bert", "docs/chapter_foundation/language_models", "docs/chapter_foundation/neural_language_models", "docs/chapter_foundation/t5", "docs/chapter_foundation/transformers", "docs/chapter_foundation/word_embeddings", "docs/chapter_inference/inference_acceleration", "docs/chapter_inference/inference_fundamentals", "docs/chapter_multimodality/multimodality_fundamentals", "docs/chapter_multimodality/vision_transformers", "docs/chapter_prompt/advanced_prompt", "docs/chapter_prompt/basic_prompt", "docs/chapter_rag/advanced_rag", "docs/chapter_rag/basic_rag", "docs/chapter_training/accelerated_training", "docs/chapter_training/alignment", "docs/chapter_training/finetuning", "docs/chapter_training/training_fundamentals", "docs/chapter_training/training_lab", "docs/index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["docs/Introduction.md", "docs/chapter_LLM_arch/LLM_dense_architectures.md", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures.md", "docs/chapter_application_IR/application_LLM_in_IR.md", "docs/chapter_application_IR/information_retrieval_fundamentals.md", "docs/chapter_foundation/GPT_series.md", "docs/chapter_foundation/bert.md", "docs/chapter_foundation/language_models.md", "docs/chapter_foundation/neural_language_models.md", "docs/chapter_foundation/t5.md", "docs/chapter_foundation/transformers.md", "docs/chapter_foundation/word_embeddings.md", "docs/chapter_inference/inference_acceleration.md", "docs/chapter_inference/inference_fundamentals.md", "docs/chapter_multimodality/multimodality_fundamentals.md", "docs/chapter_multimodality/vision_transformers.md", "docs/chapter_prompt/advanced_prompt.md", "docs/chapter_prompt/basic_prompt.md", "docs/chapter_rag/advanced_rag.md", "docs/chapter_rag/basic_rag.md", "docs/chapter_training/accelerated_training.md", "docs/chapter_training/alignment.md", "docs/chapter_training/finetuning.md", "docs/chapter_training/training_fundamentals.md", "docs/chapter_training/training_lab.md", "docs/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 5, 6, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22], "0": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "00": 9, "000": [1, 6, 7, 11, 22], "001": 23, "002": 16, "0041": 1, "00510": 12, "00751": 22, "00854": 10, "01": [12, 22], "01000001": 1, "01108": 6, "01652": 22, "01759": 11, "02": 12, "02054": 20, "021": 7, "02116": 6, "02150": 1, "02155": 21, "025": 17, "02531": 6, "02677": 23, "02984": 6, "03": 12, "03167": 1, "03740": 20, "038": 5, "04": 7, "04341": 6, "044715x": 1, "04805": [6, 10], "05": [7, 9, 12], "05101": 23, "05365": 6, "06": 12, "07": [7, 12], "07278": 6, "07291": 6, "07339": 12, "07467": 1, "08": 9, "08144": 6, "08510": 6, "08730": 9, "08747": 22, "088": 7, "09": [12, 21], "09685": 22, "0b": 1, "1": [1, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "10": [5, 6, 7, 8, 9, 10, 11, 12, 17, 20], "100": [5, 10, 12], "10000": 10, "100000": [], "10000010": 1, "10001010": 1, "10011000": 1, "10011111": 1, "100m": 20, "10101100": 1, "10183": 10, "1024": [1, 6, 12], "103": 7, "10351": 6, "104": 6, "1045": 8, "1048": 8, "10524": [1, 10], "10533": [1, 10], "10555": 6, "1058346884778766336": [], "10671": 1, "108": 6, "108m": 6, "109": [], "10997": 19, "10b": 1, "10k": [7, 20], "11": [5, 6, 7, 9, 10, 20], "110": [6, 7], "110k": 6, "110m": 6, "111": [], "11100010": 1, "11110000": 1, "11171": 16, "112": 20, "1120": 20, "1137": 8, "1139": 23, "11416": 22, "1147": 23, "1155": 8, "11692": [6, 10], "118": 12, "11903": 17, "11916": 17, "11929": 10, "11942": [6, 10], "11b": 20, "12": [1, 5, 6, 9, 10, 12, 17, 20, 22, 23], "120": [7, 20], "1212": [], "12288": 1, "1234": [], "125m": 5, "127": [12, 20], "128": [1, 6, 20], "12948": 12, "13": [1, 11, 21], "1301": 11, "13245": 1, "13461": 9, "135": 11, "137": 12, "137b": 16, "13b": [1, 5], "14": [5, 9], "140": 9, "1412": 23, "1441": 10, "1450": 10, "146": 11, "14734": 21, "149": 20, "15": [6, 9, 11, 17, 20], "1502": 1, "1503": 6, "1536": [], "156": 12, "16": [5, 6, 9, 12, 20], "1607": 11, "1609": 6, "16138": 6, "16384": 1, "16452": 16, "16_": [], "16x16": 10, "17": [9, 10, 16, 17, 20, 23], "1706": 23, "1710": 20, "1711": 23, "1723701178611920896": [], "175": [0, 1, 5, 22], "17576": 11, "175b": [1, 5, 21, 22], "176": 12, "179b": 1, "18": [5, 6, 10], "1802": 6, "1806": 9, "1809": 6, "1810": [6, 10], "18223": 1, "18290": 21, "1877": [5, 7, 10], "19": [5, 6, 7, 9, 10, 12, 20, 22], "1901": [5, 6, 7, 10], "1902": 22, "1906": 6, "1907": [6, 10], "1909": [6, 10], "1910": [1, 6, 9, 20], "1911": [1, 6], "1952": 21, "196": 12, "19680801": [], "1986": [], "1989": 12, "1993": 12, "1994": 7, "1999": 7, "1b": 22, "1d": 6, "1e": 23, "1f60a": 1, "1g": [5, 12], "1i": 5, "1j": 10, "1m": 10, "1mb": 12, "2": [1, 6, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22, 23], "20": [1, 5, 6, 7, 9, 10, 11, 21], "200": 7, "2003": [6, 8], "2004": 6, "2007": 10, "2010": [8, 10], "2011": 23, "2012": 23, "2013": [11, 23], "2014": 23, "2015": [1, 6], "2016": [6, 11, 21], "2017": [6, 9, 10, 11, 20, 21, 23], "2018": [5, 6, 7, 9, 10], "2019": [1, 5, 6, 7, 9, 10, 21, 22], "2020": [1, 5, 6, 7, 9, 10, 20, 21], "2021": [6, 12, 16, 21, 22], "2022": [12, 16, 17, 21, 22], "2023": [1, 12, 16, 21], "2024": [1, 21, 22], "2048": [1, 6, 10, 12], "207b": 1, "20ac": 1, "20b": 16, "21": [5, 6, 9, 10, 16, 22], "2106": [6, 22], "2109": [12, 22], "2121": 23, "215": [5, 12], "2159": 23, "217": 7, "22": [7, 10, 16, 17, 21, 22], "2201": 17, "2203": [16, 21], "2205": 17, "2208": 12, "2210": 22, "227": 7, "23": [1, 12, 16, 20], "2303": 1, "2305": [1, 21], "2308": 22, "2311": 16, "2312": 19, "2334029": 21, "235": 12, "24": [1, 5, 6, 9, 12, 20, 21, 22], "2405": 21, "2407": 1, "245": 7, "2454": [], "2455": [], "2456": [], "2458": [], "2459": [], "2460": [], "2461": [], "25": [5, 7, 9, 11, 12], "255": [12, 20], "256": [1, 6, 10], "2560": [], "257": 1, "26": [5, 9, 11], "267": 7, "269": 17, "27": [5, 12, 16], "278": 7, "28": [5, 7], "288": [5, 22], "28th": 10, "29": [5, 6], "293": 12, "299": 12, "2_": 10, "2b": 20, "2d": 11, "2d_": 10, "2j": 10, "2m": 10, "2pas\u00b2b": 20, "2psbh": 20, "3": [0, 1, 6, 7, 8, 9, 10, 11, 12, 16, 20, 21, 22, 24], "30": [5, 6, 10], "31": [5, 12, 20], "3111": 11, "3119": 11, "32": [5, 12, 20], "324": 21, "33": [5, 6, 7, 10, 17], "334": 6, "34": 5, "340": 6, "340m": 6, "345": 21, "35": [5, 22], "350": 22, "350m": [], "36": [11, 12], "3609": [], "3610": [], "3611": [], "3612": [], "3628": [], "3629": [], "3630": [], "3632": [], "3633": [], "37": 5, "3781": 11, "38": 5, "39": [5, 21], "390": 7, "3b": 20, "3d": [], "3psbh": 20, "3rd": 7, "4": [0, 1, 5, 6, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22], "40": [1, 5, 6, 9, 12, 16, 17], "405b": 1, "4096": 12, "41": [5, 9], "410": 5, "42": 6, "43": 12, "44": [7, 12], "4411": 6, "4421": 6, "45": 5, "46": 9, "475": 7, "48": [7, 17], "49": 5, "4d": 10, "4d_": 1, "4h": 20, "4n_": 1, "4psbh": 20, "4x": 12, "5": [5, 7, 9, 10, 11, 12, 16, 17, 20, 21, 22], "50": [1, 6, 12, 17], "500": [1, 6, 11, 22], "504": 20, "50th": 17, "51": [5, 9, 12, 17], "512": [6, 10], "5140": 1, "52": [5, 12], "521": 7, "53": [5, 9, 12], "54": [5, 12], "540": 0, "540b": 16, "55": [1, 5, 12], "56": [5, 9, 12], "569": 7, "57": [5, 12], "5701": [], "5776": 6, "5788": 6, "58": [5, 12], "586": 17, "59": 9, "5998": 10, "5b": [1, 20], "5d_": 1, "5psbh": 20, "5x": [1, 16], "5x2": [], "6": [5, 6, 7, 8, 9, 10, 11, 12, 17, 23], "60": [5, 7], "600": 7, "6008": 10, "61": 9, "62": [5, 9], "628": 7, "63": [5, 12], "64": [1, 12, 20], "643969218": [], "646": 7, "64k": 20, "65": [5, 20], "66": [], "669": 7, "67": [7, 9], "674874586": [], "68": 5, "68g": 12, "69": 9, "6980": 23, "6b": [1, 21], "7": [5, 7, 9, 11, 12, 16, 17, 20, 21, 22, 23], "70": [5, 7, 12], "70b": 20, "71": [5, 12], "72": [5, 12], "72b": [1, 22], "73": 9, "735": 7, "74": [7, 12], "74m": 5, "75": [9, 13], "76": [5, 9], "760m": [], "768": [5, 6, 12], "77": 9, "78": [5, 7, 12, 17], "79": 5, "7b": [1, 5, 12, 20, 21], "8": [1, 5, 6, 7, 9, 10, 11, 12, 17, 20, 23], "80": [1, 5, 6, 9, 12, 19], "800": 6, "81": [9, 12], "8192": 1, "82": [5, 12], "83": [5, 9, 12], "836": 22, "84": [9, 12], "85": 9, "86": [5, 12], "87": [5, 9, 12], "88": [9, 12], "887": 7, "8888": [], "89": [9, 12], "8d_": 1, "9": [1, 5, 6, 7, 9, 10, 11, 12, 20, 23, 24], "90": [5, 9, 16], "91": 12, "92": [5, 12, 17], "929": 7, "93": [5, 9, 12, 17], "94": [], "95": 5, "96": [1, 5, 11], "97": 6, "98": 12, "99": 12, "999": 23, "9psbh": 20, "A": [0, 1, 6, 7, 8, 9, 11, 12, 17, 20, 21, 22, 23], "AT": 6, "And": [12, 20], "As": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21, 22, 23], "At": [5, 10, 12, 13, 16, 20, 21, 22], "Be": 19, "Being": 11, "But": [7, 11, 17, 20, 22], "By": [0, 1, 5, 6, 7, 10, 11, 12, 13, 16, 19, 21, 23], "FOR": 22, "For": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 21, 22, 23], "IT": 12, "If": [5, 6, 7, 10, 12, 13, 16, 19, 20], "In": [0, 1, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 20, 21, 22, 23], "It": [0, 1, 5, 7, 8, 10, 11, 12, 16, 17, 20, 21, 22, 23], "Its": [], "No": [7, 12, 17, 22], "Not": [11, 20], "OR": 10, "Of": [], "On": [1, 5, 6, 10, 11, 17, 20, 22, 23], "One": [5, 6, 7, 8, 10, 11, 12, 13, 19, 22, 23], "Such": [11, 23], "That": [5, 6, 9, 11, 12, 21, 23], "The": [5, 8, 9, 16, 17, 19, 23], "Their": [1, 6], "Then": [1, 6, 7, 12, 23], "There": [1, 5, 6, 7, 9, 10, 11, 12, 13, 21, 23], "These": [0, 1, 6, 7, 8, 9, 10, 11, 12, 16, 19, 22], "To": [1, 5, 6, 7, 8, 9, 10, 12, 16, 19, 21, 22, 23], "With": [9, 11, 12, 16, 20, 21], "_": [1, 5, 6, 10, 11, 12, 13, 17, 21, 22, 23], "_0": 21, "_1": [1, 10], "_2": 10, "__init__": [], "__version__": [], "_h": 1, "_i": [1, 7, 10, 11], "_j": 10, "_k": [11, 23], "_len": 1, "_length": [], "_m": 10, "_n": 13, "_q": 12, "_show_matplotlib_backend": [], "_stack_depth": [], "_t": [11, 13], "_w": 12, "_x": 12, "a_": [5, 6, 21], "a_0": 21, "a_i": 20, "a_j": 20, "a_t": 21, "aakanksha": [16, 22], "aapo": 23, "ab": [1, 6, 10, 12, 17, 20, 21, 22], "abcd": 9, "abdelrahman": 9, "abil": [0, 1, 5, 6, 11, 19, 21, 22, 23], "abl": [5, 6, 7, 10, 11, 20], "ablat": [6, 12, 16], "about": [1, 5, 6, 12, 22], "abov": [1, 6, 7, 8, 9, 10, 11, 12, 17, 20, 22, 23], "abs_x": [], "absent": 10, "absmax": 12, "absolut": [7, 12, 20], "absorb": 5, "abstract": 9, "acc": 9, "acceler": [0, 1, 10, 25], "accelerated_train": [], "accept": 9, "access": [0, 10, 20, 22], "accommod": 12, "accomplish": [5, 10, 17, 20, 21], "accord": [12, 13, 20, 22], "accordingli": 5, "account": 6, "accum": 12, "accumul": [12, 20, 23], "accur": [6, 7, 9, 12, 16, 17, 19, 22, 23], "accuraci": [0, 1, 7, 12, 16, 19, 20, 21], "achiev": [1, 5, 6, 7, 9, 10, 11, 12, 16, 20, 21, 22, 23], "achin": [1, 9, 10], "acm": 10, "acquir": [5, 6], "across": [0, 1, 5, 6, 9, 10, 11, 12, 16, 17, 19, 20, 22], "act": [1, 10, 17, 22], "action": [17, 21], "activ": [5, 6, 10, 12], "activations_memori": 20, "actor": 21, "actual": [6, 7, 11, 22], "ad": [1, 5, 6, 7, 10, 12, 13, 22, 23], "ada": 16, "adam": [9, 22], "adapt": [1, 5, 6, 10, 13, 16, 17], "adaptor": 22, "add": [1, 6, 9, 10, 12, 13, 20, 21, 22, 23], "addit": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 22, 23], "addition": 20, "address": [1, 10, 11, 12, 17, 19, 20, 22, 23], "adept": 22, "aditya": 6, "adject": [7, 11], "adjust": [6, 11, 12, 23], "admit": 16, "adopt": [1, 5, 6, 9, 10, 20, 22, 23], "advanc": [0, 5, 6, 7, 10, 11, 22, 25], "advanced_prompt": [], "advanced_rag": [], "advantag": [1, 6, 7, 8, 9, 10, 11, 12, 23], "advent": [0, 6], "adventur": 5, "adverb": 11, "adversari": 6, "ae": 10, "aer": 7, "affect": [1, 7, 23], "affin": 12, "afflin": 12, "aforement": [], "after": [1, 6, 7, 10, 11, 12, 20, 22, 23], "ag": 25, "again": 12, "against": [6, 19, 21], "agarw": 21, "aggreg": [11, 20], "aggress": [1, 12, 22, 23], "aghajanyan": 6, "aghajanyan2018toward": [], "agi": 0, "agnost": [5, 6, 9], "agreement": 7, "ai": [1, 7, 11, 19, 21, 22, 25], "aidan": 10, "aim": [0, 1, 5, 6, 7, 8, 10, 13, 16, 19, 20, 22], "ain": 11, "ainsli": 1, "aka": 1, "al": [5, 7, 9, 10, 12, 16, 21], "alben": 20, "albert": [10, 22], "alec": [5, 7, 9, 10], "alex": [21, 22], "alexand": 10, "alexei": 10, "alexi": 6, "alg": [], "algebra": 21, "algorithm": [1, 11, 16], "align": [0, 1, 5, 6, 8, 9, 10, 11, 12, 17, 20, 22, 23, 25], "all": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 19, 20, 21, 22], "allan": 21, "alleg": 7, "allen": 22, "aller": 5, "allevi": [1, 7, 8, 10], "allgath": 20, "alloc": [], "allow": [0, 1, 6, 8, 9, 10, 11, 12, 17, 19, 20, 22], "allreduc": 20, "almeida": 21, "almost": [], "alon": [5, 6, 10], "along": [5, 19], "aloud": 17, "alpha": [6, 11, 13, 22, 23], "alpha_0": 23, "alpha_k": 23, "alreadi": [], "also": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "altdj": 1, "altern": [6, 7, 11, 13], "although": [6, 8, 10, 11, 20, 22], "alwai": [5, 7, 9, 17, 20], "am": 6, "amanda": [5, 7, 10, 21], "amaz": 17, "amazonaw": [5, 7, 10], "ambigu": 5, "amen": [9, 10], "america": 11, "amodei": [5, 7, 9, 10], "among": [7, 8, 10, 11], "amount": [0, 1, 5, 6, 7, 10, 12, 13, 20], "amper": 20, "an": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "anaconda3": [], "analysi": [6, 11, 12, 21], "analyt": 10, "analyz": [10, 12], "andrea": 22, "andrei": 22, "andrew": [22, 23], "angl": 1, "angola": 11, "ani": [5, 7, 8, 9, 10, 11, 12, 16, 17, 19, 20], "anim": [], "animos": 9, "anli": [], "ann": 7, "annot": [7, 16, 23], "anoth": [1, 6, 7, 8, 10, 11, 22, 23], "answer": [1, 6, 9, 10, 11, 16, 17, 19, 22], "anymor": [], "anyth": [], "apart": [], "api": [], "appar": 11, "appeal": [], "appear": [7, 8, 11, 12, 13], "append": [16, 21], "appendix": 25, "appl": [6, 11], "appli": [1, 5, 6, 8, 9, 10, 11, 12, 16, 20, 21, 22, 23], "applic": [0, 1, 6, 7, 8, 9, 10, 11, 13, 19, 22, 23], "applicationnlp": [], "applicationrecommendersi": [], "applicationsnlp": [], "applicationsnlp_llm": 23, "apporach": 13, "approach": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 21, 23], "appropri": 7, "approx": [1, 7, 10, 11, 12, 20, 22, 23], "approx1": 11, "approxim": [1, 7, 11, 12, 20, 22], "ar": [0, 1, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "arab": 1, "arbitrari": 6, "arbitrarili": [5, 7], "arc": 5, "archit": 21, "architectur": [0, 5, 8, 9, 11, 12, 20, 22], "architecturecombin": [], "architur": 22, "area": [16, 20], "area_estim": [], "arg": [], "argmax": [11, 13], "argmax_": [], "argmin": 11, "argmin_": [], "arguabl": 10, "argument": 1, "aris": [0, 6, 9], "arithemat": 5, "arithemetic_task_gpt3": [], "arithemetictaskgpt3": [], "arithmet": [1, 16, 20], "armand": 11, "armen": 6, "arora2016lat": 11, "around": [1, 7, 11], "arrai": [1, 6, 10, 11, 22], "arriv": [11, 16, 21], "art": [0, 5, 7, 9, 10], "articl": [6, 7, 10, 12], "artifici": [0, 7], "artperform": 10, "arvind": [5, 7, 10], "arxiv": [1, 6, 9, 10, 11, 12, 16, 17, 19, 20, 21, 22, 23], "ascii": 1, "ashish": 10, "ask": [5, 9, 17], "askel": [5, 7, 10, 21], "aspect": [8, 10, 21, 22], "assembl": 11, "assess": [5, 19], "asset": [5, 7, 10], "assign": [7, 21], "assist": [0, 19, 21, 22], "associ": [6, 10, 11, 13, 16, 20, 22], "assum": [6, 7, 10, 11, 20, 23], "assumpt": [6, 8, 10, 16], "ast18": 6, "astana": 11, "astronomi": [], "asymmetr": 12, "as\u00b2b": 20, "athen": 11, "atom": 11, "att": 10, "attach": 9, "attariyan": 22, "attempt": [5, 17], "attend": [1, 6, 10], "attent": [5, 6, 7, 9, 12, 22], "attn": 6, "attract": [6, 7], "attribut": [], "au": 5, "audio": 7, "aug": 5, "augment": [0, 6, 19], "author": [6, 16], "auto": [5, 9, 10], "autom": 21, "automat": [5, 6, 8, 12], "autonom": [], "autoref": [], "autoregress": [9, 12], "autr": 5, "auxiliari": [5, 6, 16], "auxillari": 21, "auxilliari": [], "avail": [0, 6, 21], "averag": [11, 16, 23], "avoid": [6, 13, 16, 17, 20, 21, 23], "awai": [5, 10, 11], "awar": 12, "awesom": [], "ax": [], "axi": [], "b": [1, 6, 8, 9, 11, 12, 13, 17, 20, 22], "b_": [10, 11], "b_0": [], "b_1": [1, 6, 10], "b_2": [1, 6, 10], "b_t": [], "b_x": 8, "b_y": 8, "ba": 23, "babak": 12, "babi": 6, "back": [1, 5, 6, 22], "backend": [], "backend_agg": [], "backend_inlin": [], "backends_list": [], "backoff": 7, "backpropag": [], "backpropg": 5, "backtick": 19, "backward": [6, 10, 20, 22], "bad": [5, 17, 23], "bag": 11, "bai": 1, "baichuan": 1, "baidu": 20, "bajaj": 6, "balanc": [0, 1, 6, 12], "ball": 23, "bandwidth": [1, 12, 20], "bank": [5, 7, 11], "banknot": 7, "bao": 6, "baosong": [1, 10], "bar": [], "barret": 22, "bart": [10, 25], "bart_fine_tun": [], "bart_fine_tuning_classif": 9, "bartcorrupt": [], "base": [1, 5, 6, 7, 8, 9, 10, 12, 13, 16, 19, 20, 23], "baselin": [1, 7, 12, 21], "basi": 11, "basic": [0, 6, 7, 11, 25], "basic_prompt": [], "basic_rag": [], "batch": [1, 6, 10, 12, 20, 21, 23], "batch_siz": [1, 20], "batchsiz": 12, "bce": [5, 21], "bdvj03": 8, "beam": 12, "beauti": [], "becam": 0, "becaus": [1, 5, 6, 7, 9, 10, 11, 12, 20, 21, 22], "becom": [1, 8, 9, 10, 11, 12, 19, 20, 22, 23], "bedroom": 8, "been": [0, 5, 6, 7, 10, 19, 20, 21, 22], "befor": [1, 5, 6, 9, 10, 12, 13, 16, 17, 20, 23], "began": 0, "begin": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23], "beginn": [], "behav": [1, 21], "behavior": [5, 6, 9, 20, 21, 22, 23], "behind": [7, 13, 17, 20], "beichen": 1, "beij": 11, "being": [0, 1, 5, 6, 7, 10, 11, 12, 13, 17], "beings": 7, "believ": 7, "belkada": 12, "below": [1, 7, 11, 12], "benchmark": [5, 9, 10, 12, 16], "benefici": [1, 12], "benefit": [1, 6, 12, 16, 17, 20], "bengio": 8, "bengio2003neur": [], "benjamin": [5, 7, 10], "berlin": 11, "berlitz": 7, "bert": [1, 5, 9, 10, 11, 12, 25], "bert4rec": 10, "bert_albert": [], "bert_input": [], "bert_model_distil": [], "bert_pretrainedlanguagemodel": [], "bert_task": [], "bertbas": [], "bertdownstreamtask": [], "bertencoderlay": [], "bertinput": [], "bertlarg": [], "bertpretrain": [], "bertpretrainfinetun": [], "berttask": [], "besid": [9, 10, 17], "best": [5, 16, 20, 21, 23], "beta": [1, 7, 21], "beta_": 7, "beta_i": 21, "beta_j": 21, "better": [1, 5, 6, 7, 8, 11, 17, 22, 23], "between": [0, 1, 5, 6, 7, 9, 10, 11, 12, 17, 20, 21, 22, 23], "beyer": 10, "beyond": [6, 16, 20, 23], "bf16": 20, "bfloat16": [12, 20], "bgjm17": 11, "bia": [1, 11, 12, 16, 22], "biao": 1, "bias": [8, 21, 22, 23], "bib": [], "bibliographi": [], "bidirect": [6, 9, 10], "bidirection": [], "big": [1, 6, 7, 11], "bigger": [0, 5], "biggest": [6, 12], "bigram": 7, "bilingu": 6, "billion": [0, 1, 5, 10, 12, 20, 22], "binari": [5, 6, 10, 11, 20, 21], "bind": [], "binom": 21, "binyuan": 1, "biologi": [], "biometrika": 21, "bird": [1, 6], "bit": [1, 5, 12, 20], "bivari": [], "blank": [], "blankevoort": 12, "blend": 5, "bleu": 5, "blindli": 22, "blink": [], "block": [1, 5, 10, 11, 19, 20, 21], "blog": [5, 7, 9, 10], "bloom": 1, "blue": 16, "blunsom": 6, "bm": [], "bmatrix": 10, "bmr": [5, 7, 10], "bnb21": 12, "bo": 1, "board": 7, "bodi": 17, "bojanowski": 11, "bojanowski2017enrich": [], "bokeh": [], "bold": 7, "boldsymbol": [1, 6, 12, 21], "bondarenko": 12, "book": [10, 11], "bookcorpu": [5, 10], "books1": 5, "books2": 5, "bookscorpu": [5, 6], "boolean": [], "boost": [1, 5, 6], "border": [], "bore": [13, 17], "bori": 20, "borrow": 7, "bosma": [17, 22], "both": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 19, 20, 22], "bottl": 10, "bottleneck": [6, 10, 22], "bottom": 6, "bought": 6, "bound": [1, 10, 11, 12], "boundari": [0, 1, 11], "bowen": 1, "box": [5, 20], "bpe": [], "bracket": [], "bradlei": 21, "brahma": 22, "brain": [1, 12], "branch": 1, "breadown": 12, "break": [11, 12, 17], "breakthrough": [0, 20], "brevet": 5, "breviti": 13, "brian": 22, "bridg": [6, 22], "brief": 22, "bring": [1, 5, 8], "british": 7, "broad": [5, 13, 17, 22], "broadcast": 20, "broader": 23, "broadli": [6, 16], "brockman": 21, "brother": 11, "brought": 0, "brown": [5, 7, 10, 21], "brown2020languag": [], "browser": [], "bruna": 22, "brute": 13, "bryan": 9, "bsd": [], "bt": 21, "bt52": 21, "btml": 17, "bucket": 11, "budget": [0, 6], "buffer": 20, "bug": [], "build": [1, 6, 7, 10, 11], "built": 19, "builtin_trap": [], "burden": 1, "burget": 8, "burr": 5, "button": [], "byte": [12, 20], "c": [1, 5, 6, 7, 10, 11, 12, 13], "c4": 10, "c_": [], "c_0": 7, "c_1": 7, "c_2": 7, "c_3": 7, "c_4": 7, "c_5": 7, "c_6": 7, "c_i": 7, "cach": [1, 8], "caim": 9, "calcuat": 12, "calcul": [1, 6, 10, 11, 12, 17, 20, 22], "california": 11, "call": [5, 6, 7, 10, 11, 20, 23], "callowai": 7, "cambodia": 11, "cambodian": 11, "cambridg": [], "came": [], "can": [0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "canada": 11, "cancel": 21, "candid": [5, 7, 12, 13, 16], "cannot": [0, 1, 5, 9, 11, 12, 13, 16, 20], "cao": 6, "cap": 11, "capabl": [0, 1, 5, 6, 9, 10, 12, 16, 17, 19, 22], "capac": [1, 5, 6, 10, 23], "capit": 11, "caption": [7, 23], "captur": [1, 5, 6, 7, 8, 10, 11], "car": 22, "carbon": 22, "cardin": 13, "care": 20, "carefulli": [1, 5, 13, 21, 22], "carignan": 16, "carlo": [], "carri": [7, 16], "carrol": 21, "case": [1, 5, 6, 7, 9, 10, 11, 13, 16, 20], "caslon": 6, "cast": 9, "castro": 22, "casual": 7, "cat": 8, "catastroph": 22, "categor": 10, "categori": [5, 10], "caus": [1, 6, 7, 12, 13, 22], "causal": 10, "cbow": [], "cc": [1, 11], "ccc": [], "cccc": 11, "ccccc": [], "ccnl": 21, "cd": 9, "cdot": [1, 6, 7, 8, 10, 11, 12, 13, 21, 23], "cdpo": 21, "ce": 7, "ceil": 20, "cell": [], "center": [1, 11, 23], "central": [10, 11], "centrust": 7, "cernock\u00fd": 8, "certain": [1, 6, 7, 11, 12, 20, 22, 23], "certainli": [1, 17], "cgi": [], "ch": [], "chain": [7, 13, 20], "chain_of_thought": [], "chain_of_thought_prompt_demo": [], "chainofthoughtpromptdemo": [], "chairman": 7, "challeng": [0, 1, 5, 6, 7, 8, 10, 13, 16, 17, 19, 20, 22], "chanc": 12, "chang": [1, 5, 6, 7, 10, 11, 12, 22], "changer": 0, "changhua": 10, "channel": [], "chap_llm_architectur": [], "chap_llm_found": [], "chap_llm_infer": [], "chap_llm_prompt_engin": [], "chap_llm_rag": [], "chap_llm_train": [], "chap_multimod": [], "chapter": 10, "chapter_found": 9, "chapter_foundation_def_pretrained_lm_transformer_bert_encoder_lay": 6, "chapter_foundation_def_pretrained_lm_transformer_encoder_comput": [], "chapter_foundation_def_pretrained_lm_transformer_encoder_lay": [], "chapter_foundation_fig_language_model_feedforward_model": 8, "chapter_foundation_fig_seq2seq_bart_finetun": [], "chapter_foundation_fig_seq2seq_bart_finetuning_classif": 9, "chapter_foundation_fig_word_embedding_word2vec_visu": 11, "chapter_foundation_sec_word_embed": [], "chapter_foundation_word_embedding_def_skipgramoptim": 11, "chapter_foundation_word_embedding_subwordwordembeddingmodel": [], "chapter_inference_eq_inference_acceleration_gptq_error_minimization_objective_matrix_form": 12, "chapter_inference_inference_fundamentals_beam_decoding_demo": [], "chapter_inference_inference_fundamentals_greedy_decoding_demo": [], "chapter_llm_arch_layer_nomalization_formula": [], "chapter_prompt_fig_advanced_prompt_cot_self_consist": [], "chapter_prompt_fig_advanced_prompt_cot_self_consistency_exampl": [], "chapter_prompt_fig_advanced_prompt_cot_self_consistency_num_path": [], "chapter_prompt_fig_advanced_prompt_self_cot": [], "charact": [1, 6, 7, 11, 17], "characterist": 7, "chart": [], "chatglm": 1, "chatglm2": 1, "chatgpt": [], "chaudhari": 6, "chaumond": 6, "chd": 6, "cheaper": [6, 12], "check": 19, "checkmark": 1, "checkpoint": [1, 23], "chelsea": 21, "chemistri": [], "chen": [1, 6, 10, 11, 21, 22], "chen1999empir": 7, "chengpeng": 1, "chengyuan": 1, "chi": [6, 16, 17, 22], "chi2021xlm": [], "chicago": 11, "child": [5, 7, 9, 10], "china": 11, "chines": [1, 6], "chl": 22, "choic": [6, 11, 13], "chois": 16, "chong": 21, "choos": [6, 7, 13, 21, 23], "chose": 5, "chosen": [11, 13], "chowdheri": [16, 22], "chri": [], "christian": [1, 8], "christiano": 21, "christoph": [6, 7, 21], "chu": 1, "chuck": 20, "chung": 22, "chung2022scal": [], "chunk": 19, "cinema": 17, "cin\u00e9ma": 5, "circl": [], "circumst": 12, "citat": 19, "cite": [7, 9, 11, 13, 20, 23], "citi": [6, 11], "ckg": 6, "cklm19": 6, "cl": [6, 9], "cl_": [], "clarifi": [], "clark": 6, "clark2019do": [], "clark2020electra": [], "class": [5, 6, 9, 11], "classic": [6, 7, 11, 17, 21, 23], "classif": [5, 6, 9, 10, 11, 20, 21], "classifi": [6, 9, 11, 17], "classroom": 6, "claus": [], "clean": [], "clear": [5, 10, 22], "clearli": [1, 5, 11, 23], "cleverest": 5, "click": [], "clip": 12, "cllm20": 6, "clm": 10, "clone": [23, 24], "close": [1, 6, 7, 11, 20], "closer": [0, 11], "cloth": 11, "cluett": 7, "cluster": 8, "clutter": [], "cm": [], "cn": [], "cnn": [9, 10], "co": [1, 6, 7, 8, 10, 11, 21], "cobb": 16, "code": [6, 10, 17], "coeffici": [21, 23], "coexist": 11, "cognit": [], "coher": [5, 6, 7, 10, 19], "cohes": [11, 13], "coin": [], "cola": 12, "colin": 9, "colleagu": [], "collect": [5, 7, 16, 20], "collison": 11, "collobert2008unifi": 11, "colon": [], "color": 1, "column": [11, 12], "columnwidth": [], "com": [5, 7, 10, 20], "combat": 1, "combin": [1, 6, 8, 9, 10, 11, 19, 20, 22], "come": [1, 6, 7, 10, 16, 21], "command": [], "comment": 5, "commnic": 20, "common": [1, 6, 10, 11, 13, 16, 17, 20], "commoncrawl": 6, "commonli": [1, 10, 11, 13], "commonsens": [5, 16], "commun": [0, 7, 17, 23], "compact": [6, 8], "compani": 11, "compar": [1, 7, 8, 10, 11, 12, 16, 17, 19, 20, 21, 22], "comparison": [1, 6, 7, 9, 16, 17, 20, 21], "comparisonbertvsalbert": [], "compat": 1, "compens": 11, "compet": 11, "competit": 22, "compil": [], "complet": [5, 6, 7, 9, 10, 11, 17, 20, 21], "complex": [0, 1, 10, 11, 12, 16, 17, 20], "compon": [1, 5, 6, 7, 10, 11, 16, 19, 22], "compos": 7, "composition": 11, "comprehens": [0, 5, 6, 9, 22], "compress": [6, 10], "compris": [], "compromis": [1, 6, 12, 22], "comput": [0, 5, 7, 8, 11, 16, 17, 20, 22, 23], "computatio": 12, "computation": [1, 12, 21], "con": [12, 22], "concat": [1, 8, 10], "concaten": [5, 6, 8, 11], "conceiv": [], "concept": [0, 7, 11, 17], "concern": 22, "concis": [19, 22], "conda": 24, "condit": [5, 6, 7, 8, 9, 10, 11, 12, 13, 22], "conduct": [6, 12], "conf": 8, "confer": [6, 10, 12, 23], "confid": [5, 13, 19, 21], "config": [], "configur": [5, 12], "configure_inline_support": [], "conglomer": 7, "conjectur": [], "conjunct": [], "conneau": 6, "conneau2019unsupervis": [], "connect": [1, 6, 7, 8, 10], "consecut": [1, 6, 7], "consensu": 16, "consequ": [6, 12], "conserv": 21, "consid": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 22, 23], "consider": [6, 7, 9, 16, 20, 22], "consist": [0, 1, 5, 6, 7, 9, 10, 11, 13, 17, 20, 21, 22], "consol": 22, "consolid": 7, "constant": [6, 10, 12, 21, 23], "constantli": 0, "constitu": [7, 11], "constraint": [0, 7, 12, 13, 20, 21, 22], "construct": [1, 7, 8, 10, 11, 17, 21, 22], "consum": [12, 22], "consumpt": [20, 22], "contain": [1, 5, 6, 7, 8, 12, 20, 21], "contamin": 22, "content": [19, 20, 21, 22], "context": [5, 6, 7, 8, 9, 10, 11, 13, 19, 21], "contextu": [5, 6, 10], "contextualencod": 6, "contextualizedembed": [], "contexu": 10, "contigu": 20, "continu": [0, 5, 10, 11, 12, 19, 21, 22], "contour": [], "contract": 11, "contradict": [6, 9], "contrari": 23, "contrast": [5, 6, 21, 23], "contribut": [5, 9, 10, 11, 12, 16, 22], "control": [1, 5, 6, 7, 10, 21], "convai2": 9, "conveni": 10, "convens": 12, "convent": [], "converg": [1, 5, 6, 12, 20, 23], "convers": [5, 6], "convert": [5, 7, 9, 10, 11, 12, 13, 21], "convex": 23, "convolut": [6, 12], "coordin": [], "copi": 20, "copyright": [], "core": [1, 8, 10, 12, 21, 22, 23], "corpora": [6, 7, 11], "corpu": [6, 7, 9, 10, 11], "corrado": 11, "correct": [6, 16, 17, 21, 23], "correctli": 23, "correl": [], "correspond": [1, 5, 6, 7, 9, 10, 11, 12, 16, 20, 21, 22, 23], "corrupt": [6, 9, 10], "cosin": [6, 10], "cossimilar": 6, "cost": [1, 11, 13, 16, 17, 20, 22], "costli": 11, "cot": 22, "cot\u00e9": 5, "could": [1, 6, 8, 10, 11, 22, 23], "count": [5, 7, 8, 9], "counter": 8, "counterpart": 20, "cours": [], "covari": 1, "cover": [0, 1, 6, 7, 11, 22], "coverag": 22, "coverg": 1, "craft": [16, 22], "crash": 7, "crawl": [5, 10], "creat": [1, 7, 10, 16, 19, 20, 22, 23, 24], "creativ": [0, 13], "criteria": [12, 23], "criterion": [12, 16], "critic": [5, 10, 12, 13, 22], "cross": [5, 6, 9, 11, 12], "crossentropi": 6, "crowd": 6, "crucial": [0, 1, 6, 10, 22], "cs324": [], "ctrl": [], "cui": 1, "cumul": 1, "cup": [1, 11], "currenc": 11, "current": [1, 5, 6, 10, 12, 19, 20, 21, 23], "curs": [7, 8], "cursor": [], "curv": 1, "cusp": 0, "custom": 21, "cut": [1, 13], "cv": 11, "d": [1, 5, 6, 7, 8, 10, 11, 12, 20, 21, 22], "d2l_book": [], "d_": [1, 5, 6, 7, 10, 12, 20, 21, 22], "d_0": [10, 20], "d_1": [10, 20], "d_2": [10, 20], "d_i": [7, 20], "d_k": [1, 10], "d_model": [1, 5], "d_n": [10, 20], "d_v": 10, "d_x": 12, "da": 9, "dahl": 23, "dai": 22, "dale": [16, 17], "damag": [12, 22], "danc": 11, "dang": 1, "danqi": [6, 10, 21], "dario": [5, 7, 9, 10], "dasha": 22, "dashboard": [], "data": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 22, 23], "databas": 19, "datafram": [], "datapoint": 21, "dataset": [0, 1, 5, 9, 10, 16, 21, 22], "date": [10, 19], "date_rang": [], "david": [5, 7, 9, 10, 12, 20], "dayiheng": 1, "db": 8, "dbk": 10, "dblp": 8, "dclt18": [6, 10], "dded": 11, "ddot": 10, "de": [1, 5, 8, 11, 12, 22], "deal": 1, "dean": [6, 11, 16, 22], "debat": [], "deberta": [], "debut": 6, "decad": 7, "decai": [], "decathlon": 9, "decent": 5, "decid": 9, "decis": [5, 17, 19, 21], "decod": [1, 5, 6, 9, 16, 25], "decoderlay": 10, "decompos": [6, 10, 11, 12], "decomposit": [7, 11, 22], "decond": 10, "decor": [], "decoupl": 23, "decreas": [7, 10, 20, 23], "deep": [0, 1, 5, 6, 7, 10, 11, 12, 20, 23], "deeper": [1, 8], "deeplearn": [20, 23], "deepli": 6, "def": [17, 20], "default": [], "defin": [1, 6, 7, 10, 11, 13, 20], "definit": 7, "defragment": 20, "degrad": [1, 12, 22], "degre": [1, 7, 16], "dehghani": [10, 22], "delet": [5, 9, 10, 12], "deliber": 5, "delimit": [5, 19], "deliv": 10, "delta": [12, 21, 22, 23], "delv": 0, "demand": 16, "demeonstr": 21, "demonstr": [0, 1, 5, 6, 7, 9, 10, 12, 13, 16, 17, 21, 23], "deng": 1, "deni": 7, "denker": 12, "denni": [6, 16, 17, 22], "denois": [9, 10], "denomer": 7, "denomin": [7, 11, 13, 20], "denorm": 12, "denot": [6, 11, 12, 13, 20], "dens": [0, 6, 8, 10, 11], "densiti": [], "depend": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20, 21], "depict": [], "deploi": [1, 6, 10, 12, 22], "deposit": 11, "depth": [1, 12, 17], "deq": 12, "dequant": [], "deriv": [1, 10, 11, 12, 21, 23], "descend": [], "descendingli": 13, "descent": [5, 8, 11], "describ": [5, 9, 11, 17, 20], "descript": [5, 6, 7, 9, 22], "desig": 20, "design": [1, 5, 6, 9, 10, 20, 21, 22], "desipt": 20, "desir": [1, 12, 13, 17, 20, 21, 22], "despit": 1, "destroi": 20, "detail": [6, 9, 10, 12, 13, 17, 19, 20, 21], "detect": [5, 6, 17], "deterior": 12, "determin": [1, 6, 7, 9, 10, 12, 20, 21], "determinist": [7, 13, 21], "dettmer": 12, "develop": [0, 1, 6, 7, 11, 12, 19, 22], "deviat": [1, 12], "devic": [6, 12], "devlin": [6, 9, 10, 22], "devlin2018bert": [], "df": [], "dhariw": [5, 7, 10], "dhingra": 21, "dhs11": 23, "di": [1, 10], "diagnoal": 12, "diagram": [9, 21], "dialog": 13, "dialogu": 9, "diamet": [], "diamo": 20, "dictionari": 11, "did": [5, 19], "diederik": 23, "diff": [], "differ": [1, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 21, 22, 23], "different_precision_demo": [], "differenti": [1, 12], "differentprecisiondemo": [], "difficult": [5, 6, 10, 13, 19, 22, 23], "difficulti": [1, 6, 8], "digit": 0, "dim": 20, "dimens": [1, 6, 10, 11, 12, 20, 22, 23], "dimension": [1, 6, 7, 8, 10, 11, 12, 22, 23], "dimensionaltii": 8, "diminish": 0, "diogo": 21, "direct": [5, 6, 7, 8, 9, 10, 11, 17, 21, 23], "directli": [6, 7, 9, 11, 12, 13, 17, 21, 22, 23], "director": 7, "directori": [], "dirk": 10, "disadvantag": [11, 12, 13], "disagr": 10, "disc": 6, "discard": [6, 11, 13, 16], "discount": 13, "discoveri": 0, "discrep": [6, 10], "discrimin": [6, 23], "discuss": [0, 6, 7, 10, 11, 20, 23], "disentangl": [], "disjoint": 9, "disk": 12, "dispar": 12, "displac": 6, "displai": [], "display_data": [], "disproportion": 12, "dissatisfact": [], "dissimilar": 11, "distanc": [7, 8, 11], "distil": [0, 10], "distilbert": [6, 10], "distinct": [], "distinguish": [6, 10, 11], "distort": 6, "distribut": [1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 21], "diverg": 6, "divers": [5, 6, 9, 10, 13, 16, 22], "divid": [1, 11, 12, 19, 20, 23], "divis": [1, 23], "divisor": 20, "dlbz22": 12, "dm": 9, "dnn": [10, 20], "do": [5, 6, 7, 10, 11, 17, 20, 21], "doc": [1, 10, 20], "doc2vec": [], "doc_2_vec": [], "docder": 10, "document": [5, 6, 7, 9, 10, 11, 17, 19], "doe": [5, 6, 7, 9, 10, 11, 12, 13, 20, 22, 23], "doesn": [20, 22], "dog": [8, 11], "dogcatch": 11, "doll": 23, "dollar": 11, "domain": [0, 1, 5, 8, 10, 16, 19, 21, 22], "domin": [6, 10], "don": [6, 7], "done": 20, "dong": [1, 6], "dosovitskii": 10, "dot": [6, 10], "down": [6, 12, 17, 23], "download": [], "downstream": [1, 5, 6, 9, 10, 22], "downweight": [11, 21], "dozen": [], "dpo": [], "dramat": [0, 12, 23], "drastic": 10, "draw": [10, 11], "drawback": [1, 6, 8, 11, 12, 13, 17, 22, 23], "drawn": 21, "drew": [5, 10], "drive": [0, 10], "driven": 0, "drop": [10, 12], "drope": 20, "dropout": [6, 10, 20], "du": [1, 5, 6, 10, 22], "ducharm": 8, "duchi": 23, "due": [1, 5, 6, 7, 8, 10, 17], "dumais2004lat": 11, "dummi": [], "dure": [5, 6, 9, 10, 11, 12, 16, 19, 21, 22], "durm": 10, "dutch": 7, "dynam": [1, 10, 12, 20, 23], "dz": [], "e": [1, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "e_": [6, 7, 8, 10, 21], "e_0": [6, 10], "e_1": [6, 8, 10], "e_2": [6, 10], "e_i": [6, 10], "e_l": [6, 10], "e_n": [6, 10], "e_t": 8, "each": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 20, 21, 22, 23], "earli": [1, 7, 12, 25], "earn": [1, 9, 10], "easi": [5, 8, 11, 12, 20, 22], "easier": [6, 17, 23], "easiest": 11, "easili": [5, 7, 11, 13, 20], "eat": 11, "econom": [], "ecosystem": [], "ed": [16, 17, 22], "edg": 17, "edgar": 16, "editor": 8, "edouard": [6, 11], "edward": 22, "effeci": 8, "effect": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 22, 23], "effici": [0, 1, 8, 10, 11, 12, 13, 19, 20, 21, 23], "efficieni": 20, "efficient_train": 23, "effort": [6, 7, 10], "ega": 11, "eh": 6, "eid": 5, "eight": [5, 10], "ein": 10, "either": [6, 11, 16, 17, 20], "ek": [], "elabor": [], "elad": 23, "electra": [], "electra_demo": [], "electrademo": [], "electron": 6, "eleg": [], "element": [1, 5, 12, 13, 17, 20, 21], "eli5": 9, "elicit": 17, "elif": 17, "elimin": [6, 20], "ell": [5, 6], "ell_": 6, "elmo": 10, "els": [13, 17], "elsen": 20, "elsewher": 12, "emb": 16, "embark": 0, "embd": 6, "embed": [5, 8, 9, 10, 16, 25], "embedding_interpret": [], "embeddinginterpret": [], "emerg": [0, 1, 5, 7, 10, 12], "emit": 21, "emlo": 6, "emoji": 1, "emph": 11, "emphas": 11, "empir": [7, 11, 22, 23], "empirci": [], "emploi": [6, 10, 11, 12, 16, 19, 23], "empti": [], "emptyset": 1, "en": 5, "enabl": [5, 6, 9, 10, 11, 19, 20, 22, 23], "enable_matplotlib": [], "encod": [1, 5, 9, 11, 19, 20, 22], "encodercomput": [], "encoderlaly": [6, 10], "encoderlay": [6, 10], "encompass": 12, "encourag": [11, 13, 16, 17, 23], "end": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 20, 21, 22, 23], "endpoint": [], "energi": 12, "engag": 20, "engin": [5, 12, 16, 19, 22], "english": [1, 5, 6, 7, 9, 10, 20], "enhanc": [0, 1, 10, 16, 17, 19, 20], "enjoi": 7, "enlarg": 20, "enorm": [1, 10], "enough": [6, 7, 20, 21, 23], "enrich": [6, 11], "ensur": [1, 7, 13, 22], "entail": [5, 6, 9], "enter": [10, 20], "entertain": 17, "entir": [5, 9, 12, 16, 20, 22], "entiti": [6, 7, 10], "entorpi": 7, "entri": [6, 10, 11], "entropi": [5, 6, 9, 11], "env": [], "environ": [12, 21], "environment": [0, 22], "eo": [10, 13, 21], "ep": [], "episod": 21, "epsilon": [1, 21], "epsilon_": [], "epsilon_0": [], "epsilon_1": [], "epsilon_k": [], "epsilon_t": [], "eq": 12, "equal": [1, 6, 7, 10, 11, 20, 22], "equat": [11, 12], "equip": 0, "equival": [6, 7, 9, 12, 20, 23], "er": 11, "era": [0, 10, 12], "eric": 21, "erich": 20, "ericmitchel": 21, "ermon": 21, "error": [1, 6, 11, 16, 17], "esc": [], "escap": 23, "esearch": 9, "especi": [1, 7, 10, 12, 17, 22], "essenti": [7, 11, 23], "establish": 7, "estim": [1, 5, 20, 21, 23], "et": [5, 7, 9, 10, 12, 16, 21], "etc": [1, 5, 10, 11, 12, 13], "ethic": 11, "euclidean": 11, "eural": [5, 7, 10], "euro": 1, "ev": [], "evalu": [5, 11, 22, 23], "even": [0, 1, 5, 6, 7, 10, 12, 13, 23], "event": 7, "eventu": [11, 20], "ever": [0, 7], "everi": [6, 9, 10, 11, 20, 21, 22], "everywher": 1, "evolut": [7, 10, 22], "evolv": [19, 22], "exact": 12, "exactli": 7, "examin": [0, 5], "exampifi": 1, "exampl": [5, 6, 7, 8, 9, 10, 12, 13, 16, 17, 20, 21, 22], "exce": 21, "exceed": [5, 12], "excel": [5, 19], "except": [5, 6, 11, 20], "excess": 16, "excit": 0, "exclud": [6, 10, 17], "exclus": [10, 22], "execut": [12, 20, 22], "executablebookproject": [], "exemplar": 16, "exercis": 6, "exhibit": [0, 10, 12, 16, 19], "exist": [1, 6, 7, 17, 21, 22, 23], "exp": [6, 7, 11, 13, 20, 21], "expand": [0, 1, 5], "expans": [11, 12], "expect": [5, 6, 11, 22], "expens": [8, 10, 11, 12, 17], "experi": [1, 17, 20], "experienc": [], "experiment": 20, "expert": [0, 16, 23], "explain": [1, 17], "explan": [1, 12, 19], "explicit": [11, 17], "explicitli": [0, 1, 6, 10, 22], "explictli": 21, "explod": 1, "exploit": 8, "explor": [0, 6, 8, 9, 10, 16, 19, 22, 23], "expon": 20, "exponenti": [0, 7, 23], "expos": [10, 20, 21], "exposur": 10, "express": [5, 11, 12, 20], "extend": [6, 8, 22], "extens": [5, 10, 13, 17, 22], "extent": 11, "extern": [0, 19, 23], "extra": [1, 5, 20], "extract": [5, 7, 9, 10, 19], "extrapol": 1, "extrem": [5, 12, 23], "f": [1, 6, 11, 12, 23], "f1": 9, "f16": 12, "f_": 23, "f_1": 1, "f_2": 1, "face": [11, 19], "facebook": [6, 11], "facil": 12, "facilit": [6, 11], "fact": [1, 5, 7, 10, 19], "factor": [0, 1, 6, 10, 11, 12, 13, 22, 23], "factual": [1, 5, 19, 21], "fail": [7, 13, 20, 21, 22], "failur": [1, 12], "fait": 5, "falcon": 1, "fall": [5, 10, 20, 23], "fals": 6, "famili": [6, 10], "familiar": [], "fan": 1, "fandong": 22, "fang": 6, "far": [7, 11, 16, 23], "fashion": [10, 11], "fast": [1, 23], "faster": [6, 12, 23], "fastest": 12, "fasttext": 11, "fasttexttextclassif": [], "favor": [], "favorit": [], "feasibl": 22, "feasibli": 12, "featur": [1, 6, 7, 10, 11, 12, 22], "feb": 8, "fed": [5, 6, 9, 10, 11, 22], "federico": 1, "fedu": [21, 22], "feed": [6, 9, 10, 12, 22], "feedback": [17, 21], "feedforward": [1, 8], "feedforwardmodel_v2": [], "feedforwardmodelv2": [], "feel": 9, "fei": [1, 10], "few": [1, 5, 6, 7, 10, 11, 12, 13, 16, 22], "fewer": [12, 20], "ff": [1, 6, 10], "ffd": 22, "ffn": [1, 6, 10, 12], "ffn_": 1, "fibonacci": 17, "fibonacci_50th": 17, "field": [0, 7, 19], "fig": [5, 6, 7, 9, 10, 11, 16, 21, 22, 23], "figur": [9, 10, 12, 20, 21, 23], "file": [], "fill": 9, "filter": 5, "final": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 21, 22, 23], "financ": [], "find": [0, 1, 6, 9, 12, 13, 20, 21, 22], "find_gui_and_backend": [], "fine": [0, 1, 7, 9, 10, 12, 16, 17, 20, 21], "finetun": [10, 17, 25], "finish": 12, "finit": [12, 21], "finn": 21, "firat": 6, "first": [1, 5, 6, 7, 9, 10, 11, 12, 16, 20, 21, 22, 23], "firstli": 23, "fit": [12, 20, 21], "fix": [1, 6, 8, 9, 10, 11, 12, 13, 16, 21], "flan": 22, "flasch": 10, "flash": [], "flat": 23, "flavor": 20, "fledg": [], "flexibl": [1, 6, 10, 12, 17, 22], "flight1ess": 6, "flip": 21, "float": 12, "float16": [12, 20], "float32": [12, 20], "floor": 7, "flop": 1, "flow": 1, "fluctuat": 1, "fluenci": 13, "fluent": 7, "fmt": 6, "fn": [], "focu": [0, 7, 12], "focus": [0, 6, 10, 19], "fold": 6, "follow": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "foo": [], "foo42": [], "food": 7, "fool": 5, "footnot": [7, 11], "footnotes": [], "footprint": [10, 12, 22], "foral": [5, 12, 23], "forc": [6, 13, 23], "forecast": 0, "forget": 22, "forgett": 17, "form": [1, 6, 7, 10, 11, 12, 13, 16, 17, 21], "formal": [6, 7, 8, 11, 13], "format": [5, 9, 12, 16, 17, 20], "former": 7, "formul": [1, 5, 9, 11, 21], "formula": [1, 7, 11, 12, 20], "fortran": [], "forward": [0, 5, 6, 10, 12, 13, 17, 19, 20, 21, 22], "forword": 13, "found": [0, 5, 6, 11, 12, 19], "foundat": [0, 1, 7, 10, 16], "four": [1, 5, 9, 12, 21], "fourth": [], "fp15": [], "fp16": 20, "fp32": [12, 20, 22], "fp8": 20, "fr": 5, "frac": [1, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22, 23], "fraction": [20, 22], "fraction1": 20, "fragment": 20, "frame": 10, "framework": [5, 6, 7, 9, 11, 13, 19, 23], "franc": 11, "francisco": 6, "frank": 23, "fraser": 21, "free": [5, 6, 21], "freez": 22, "french": [5, 6], "frequenc": [1, 6, 7, 8, 11], "frequent": [1, 6, 7, 8, 19], "frezz": 22, "friend": 7, "friendli": 22, "fro": 11, "from": [0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 22, 23], "fromstein": 7, "front": 7, "frontier": 0, "frozen": [21, 22], "fruit": 6, "full": [7, 9, 12, 13, 20, 22], "fulli": [10, 22], "fun": 6, "funciton": 21, "function": [1, 5, 6, 8, 11, 12, 13, 21, 23], "function_nam": [], "fund": 11, "fundament": [0, 5, 6, 7, 10, 19, 25], "further": [0, 5, 6, 7, 8, 9, 10, 11, 12, 17, 20, 22, 23], "furthermor": 10, "furu": 6, "fuse": [10, 12, 20], "fusi": 16, "fusion": 6, "futur": [0, 5, 10], "g": [1, 5, 6, 7, 10, 11, 12, 13, 17, 20, 21, 22, 23], "g_": 23, "g_0": 23, "g_i": 12, "g_k": [], "g_t": [], "ga": 11, "gain": [0, 5, 6, 11, 12], "galleri": [], "gallon": 6, "game": [0, 20, 22], "gamma": [1, 21], "gan": 6, "ganesh": 20, "gao": [1, 6], "gap": [6, 22], "gar": 11, "garanti": 5, "garc": 6, "garcia": 20, "garcia2017translanguag": [], "garciajsvaldes17": 6, "gardner": 6, "gate": 1, "gather": [12, 20], "gaug": 7, "gaurav": 22, "gaussian": 1, "gb": [6, 20, 22], "gdollarg": 23, "ge": 1, "geglu": 1, "gelli": [10, 22], "gelu": [1, 20], "genearl": 8, "gener": [0, 1, 6, 7, 8, 10, 13, 17, 19, 20, 21, 22, 23], "generalis": 6, "generalist": 16, "generer": [], "genr": 5, "genuin": 7, "geoffrei": [6, 23], "georg": [10, 23], "geq": 6, "german": 9, "gesmundo": 22, "get": [5, 7, 8, 9, 10, 12, 13, 23], "get_ipython": [], "get_local_scop": [], "getattr": [], "ghazvininejad": 9, "gibberish": 13, "gimpel": [6, 10], "ginsburg": 20, "girish": [5, 7, 10], "girshick": 23, "git": 24, "gitano": 7, "github": 12, "giurgiu": 22, "give": [6, 7, 8, 12, 17, 19, 20, 21], "given": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 21, 22, 23], "global": [1, 11, 20], "globe": [], "glove": 6, "glu": 1, "glue": [10, 12], "go": [5, 6, 9, 10, 11, 12, 13], "goal": [0, 5, 7, 9, 11, 13], "goe": [1, 11], "gold": 7, "goldberg2014word2vec": 11, "goldberg2017neur": 7, "gomez": 10, "good": [1, 6, 7, 8, 9, 10, 11, 12, 23], "goodman": [6, 10], "googl": [1, 6], "gorilla": 7, "gotten": [], "gouvern": 5, "govern": [0, 5, 7], "goyal": [6, 9, 10, 23], "gpt": [0, 1, 7, 9, 10, 16, 21, 22, 25], "gpt3": [1, 5, 22], "gpt3_few_shot_learning_demo": [], "gpt3fewshotlearningdemo": [], "gpt_arch": [], "gpt_decoder_arch": [], "gptarch": [], "gptdecoderarch": [], "gpu": [10, 12, 22], "gpu_memory_alloc": [], "gpumemoryalloc": [], "gqa": [], "grade": 22, "gradient": [1, 5, 6, 8, 11, 12, 20, 21, 22], "gradual": [1, 5, 10], "graham": 6, "graident": 20, "grain": [6, 7, 12], "gram": [8, 13], "grammar": [7, 8, 11, 13], "granddaught": 11, "grandson": 11, "granular": 1, "graph": [], "graphic": [], "grasp": 10, "grave": [6, 11], "gre": 11, "great": [5, 10, 11], "greater": [7, 10, 11, 12], "greatli": [17, 22], "greec": 11, "greedi": 16, "greedili": 13, "green": [], "greg": 11, "gregari": 11, "gregori": [12, 20], "grei": [], "grid": [], "grip": 17, "groom": 7, "ground": [12, 16, 17, 22], "group": [7, 12], "grow": [1, 5, 10, 11, 12], "growth": 0, "gsm8k": 17, "gu": [17, 22], "guadalup": 6, "guant": 1, "guarante": [11, 13], "gui": 5, "guid": [0, 1, 11, 17, 20], "guido": [], "guillaum": 6, "guo": 1, "gut": 9, "gut16": [], "guterman": 7, "guttag": [], "guu": 22, "guzm": 6, "gym": 21, "h": [6, 8, 10, 12, 20, 22, 23], "h1": 17, "h_": [5, 6, 8, 12, 21], "h_0": 5, "h_1": 6, "h_l": 5, "h_n": 6, "h_t": [6, 8], "ha": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 22], "had": [0, 5], "half": [1, 6, 12, 20], "hallucin": [1, 19, 21, 23], "halv": 20, "hamburg": 9, "hand": [1, 6, 7, 10, 11, 16, 17, 22], "handl": [1, 8, 12, 17, 22], "hangbo": 6, "haoran": 1, "happen": 6, "har": 16, "harar": 11, "hard": [5, 13, 20], "harder": 6, "hardli": 7, "hardwar": [0, 12, 20], "harm": [21, 22], "harsha": 16, "hash": 11, "hassibi": 12, "hat": [6, 13, 21, 23], "hate": [5, 9], "have": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 20, 21, 22, 23], "hazan": 23, "he": [1, 6, 8, 10, 20, 23], "head": [5, 6, 9, 10, 17, 20], "head_1": 10, "head_h": 10, "head_i": 10, "heard": 5, "heart": 13, "heat": 12, "heavi": 23, "heavili": [6, 10, 11], "heigold": 10, "held": 20, "hello": 17, "help": [1, 5, 6, 10, 17, 21], "henc": [], "her": 11, "here": [0, 5, 6, 7, 8, 10, 11, 12, 13, 17, 20, 21], "hessian": [], "heurist": [10, 13], "hfill": [], "hgj": 22, "hi": 5, "hidden": [6, 8, 9, 10, 11, 12, 20], "hidden_dim": 20, "hiddens": 12, "hidn": 6, "high": [1, 7, 10, 11, 12, 13, 16, 17, 22, 23], "higher": [1, 7, 12, 13, 16, 17, 22], "highest": [1, 13, 16], "highli": [6, 21], "highlight": [12, 16], "hil16": [], "hill": [], "hilton": 21, "hin12": 23, "hing": 11, "hinrich": 7, "hint": [], "hinton": [6, 23], "hinton2015distil": [], "hiros": 8, "histogram": [], "histor": [5, 23], "histori": 22, "hit": [], "hline": 11, "hold": [], "homework": 7, "hongkun": [6, 22], "hopefulli": 23, "horizon": 21, "horizont": 23, "hors": 11, "host": [], "hot": [6, 11, 12], "hou": [1, 22], "houlsbi": 22, "hour": 23, "houston": 20, "how": [0, 1, 5, 6, 7, 9, 12, 17, 20, 22, 23], "howev": [0, 1, 5, 6, 8, 10, 12, 13, 17, 20, 21, 22, 23], "hr": 6, "href": [], "hsw": 22, "hsw93": 12, "html": [8, 17, 20], "http": [1, 5, 6, 7, 8, 10, 11, 12, 19, 20, 21, 22], "hu": [6, 22], "hu2020xtrem": [], "huan": 1, "huang": [1, 6, 22], "huge": [1, 6, 7, 11, 20], "huggingfac": 21, "hui": 1, "huishuai": [1, 10], "human": [0, 6, 7, 11, 13, 16, 17, 21, 22, 23], "hundr": [0, 1, 5, 11], "hunt": [], "hurt": 6, "hutter": 23, "hv": 6, "hvd15": 6, "hybrid": 19, "hydro": 7, "hyper": [1, 13], "hypermet": 12, "hyperparamet": [7, 23], "hypothes": [1, 13], "hypothesi": [1, 5, 6, 9, 13], "hyung": 22, "i": [0, 1, 5, 6, 7, 8, 9, 13, 16, 17, 20, 21, 22, 23], "i8": 12, "i_1": [6, 10], "i_n": [6, 10], "i_p": [6, 10], "ib": 6, "ibarra": 6, "ibm": 11, "ic": 11, "ich": 10, "icon": [], "idea": [1, 6, 7, 8, 11, 12, 13, 17, 21, 22, 23], "ideal": [11, 20, 23], "iden": 1, "ident": [1, 10], "identif": 0, "identifi": [10, 12, 16, 19, 20], "idf": 11, "ieee": [12, 20], "ignor": [11, 12, 21, 22], "ii": 12, "iid": [], "ij": [7, 10, 11, 12], "il": 5, "illia": 10, "illinoi": 11, "illustr": [6, 7, 9, 10, 17, 21], "ilya": [5, 7, 9, 10, 11, 23], "imag": [0, 1, 5, 6, 7, 9, 10, 11, 12, 20, 21, 22, 23], "imagenet": 23, "imaginari": 7, "imbal": [6, 20], "imbecil": 5, "imf": 11, "img": 9, "imit": 23, "immedi": [], "immens": [], "impact": [0, 1, 5, 6, 7, 12, 13, 22], "imperfect": 6, "implement": [6, 12, 20, 23], "impli": [6, 9, 11, 12], "implic": [0, 12], "implicit": [6, 11, 21], "import": [0, 1, 6, 7, 9, 10, 11, 12, 22, 23], "importantli": 11, "impos": [6, 13, 22], "imposs": 6, "impossibli": 11, "impract": [7, 22], "impress": [5, 10], "improv": [0, 1, 5, 6, 7, 8, 9, 10, 12, 16, 17, 19, 21, 22, 23], "inaccuraci": 8, "inaccurci": 12, "inadvert": 22, "inan2016ti": 11, "inappropri": 21, "includ": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 19, 20, 21, 22], "includegraph": 23, "inclus": 22, "incomplet": 21, "inconsist": [8, 22], "incorpo": 13, "incorpor": [1, 6, 10, 13, 19], "incorrect": [1, 11, 19], "incorrectli": 7, "increas": [0, 1, 5, 6, 7, 8, 10, 12, 16, 17, 19, 20, 22, 23], "increasingli": [0, 1, 12], "increment": [16, 22], "incres": 1, "incur": [20, 22], "inde": 11, "independ": [5, 6, 9, 10, 11, 12, 21, 22], "index": [1, 6, 10, 11, 19], "indic": [1, 5, 6, 7, 9, 10, 11, 12, 21], "indirect": [], "indispens": 7, "individu": [1, 6, 11, 21], "induct": 11, "industri": [0, 7, 10, 19, 22], "ineffici": [6, 22, 23], "inf": [10, 13], "infeas": [], "infer": [0, 1, 5, 6, 7, 10, 11, 16, 20], "inference_acceler": [], "inference_fundament": [], "infil": 9, "infin": [], "influenc": 12, "influenti": [6, 10], "inform": [0, 1, 5, 6, 9, 10, 11, 12, 19], "infrastructur": 12, "infti": [7, 10, 23], "inher": [19, 21], "inherit": 23, "iniit": 23, "initi": [1, 5, 6, 9, 10, 12, 20, 21, 23], "inject": 22, "inlin": [], "inner": [1, 6, 10, 12], "innov": [0, 6], "input": [5, 7, 8, 9, 11, 12, 13, 16, 17, 20, 21, 22, 23], "insert": [6, 9], "insid": 11, "insight": [], "inspir": [5, 23], "instabl": [1, 12, 23], "instanc": [1, 10, 13, 22], "instead": [1, 6, 7, 11, 12, 13, 16, 20, 21, 22], "instruct": [5, 20, 21], "instructgpt": [17, 21], "instruction_finetun": [], "instruction_finetuning_demo": [], "instructionfinetuningdemo": [], "insturct": 22, "insuffici": 6, "int": 12, "int16": 12, "int32": 12, "int4": 12, "int6": 12, "int8": 20, "int_": [], "integ": [1, 6, 10, 11, 12, 20], "integr": [7, 16, 19, 22], "intel": 11, "intellig": [0, 5, 6, 7], "intend": [6, 7, 10, 13], "intens": [12, 16, 19], "intensifi": 12, "intent": [17, 22], "intention": 6, "inter": [6, 7, 10, 21], "interact": [0, 10, 11, 17, 19], "interactiveshel": [], "interest": [5, 10, 22], "interestingli": [], "interfac": [], "intermedi": [1, 10, 12, 17, 20, 22], "intermedid": 23, "intern": [1, 6, 10, 12, 19, 20, 23], "internet": [1, 21], "interplai": 0, "interpol": 17, "interpolat": 1, "interpret": [1, 6, 7, 17, 22], "interspeech": 8, "interspeech2010": 8, "interv": 5, "intract": 7, "intric": 1, "intricaci": 0, "intrins": 5, "introduc": [0, 1, 6, 7, 9, 10, 11, 12, 13, 16, 20, 22], "introduct": 10, "intuit": [1, 5, 7, 10, 12, 16, 22, 23], "invalu": 0, "invent": 10, "invers": [1, 7, 11, 23], "invert": 6, "invest": 0, "investig": 5, "invit": 9, "involv": [1, 5, 6, 7, 10, 12, 13, 16, 19, 20, 22, 23], "io": 12, "ioff": 1, "iou": 11, "ipo": [7, 21], "ipynb": [], "ipython": [], "ir": 25, "iran": 11, "irrelev": [6, 11], "irrespect": [11, 23], "is15": 1, "isca": 8, "isinst": [], "isn": [], "isnext": 6, "issu": [1, 9, 10, 11, 12, 20, 23], "ist": 9, "item": [20, 21], "iter": [1, 9, 12, 13, 21, 23], "its": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "itself": [5, 6, 10, 12, 20], "iv": [6, 9, 17, 22], "iwasawa": 17, "iyyer": 6, "j": [6, 7, 9, 10, 11, 12, 13, 20, 21, 22], "jacob": [6, 10, 21, 22], "jakob": 10, "jame": [1, 23], "jan": [8, 21], "jare": [5, 7, 10], "jargon": 20, "jason": [16, 17, 22], "jastrzebski": 22, "jauvin": 8, "java": [], "je": 5, "jean": 8, "jeff": [6, 11, 20, 21, 22], "jeffrei": [5, 7, 9, 10, 11], "jgbm16": 11, "ji": 1, "jia": 23, "jialin": 1, "jialong": 1, "jian": [1, 10], "jiang": [1, 6, 10, 21], "jianhong": 1, "jianwei": 1, "jianxin": 1, "jiao": 6, "jiao2019tinybert": [], "jie": 22, "jimmi": 23, "jin": 1, "jingfei": [6, 10], "jingren": 1, "jingyaogong": 24, "jinhao": 1, "jinz": 1, "jinzheng": 1, "john": [12, 21, 23], "johnson": 6, "join": 7, "joint": [6, 7, 8], "jointli": [1, 10, 22], "joliett": 5, "jonah": 20, "jonathan": 16, "jone": 10, "jong": 1, "joshi": [6, 10], "joshua": 1, "joulin": 11, "joulin2016bag": [], "journal": [6, 7, 8, 23], "journei": 0, "json": [], "jstor": 21, "judg": 23, "juic": 11, "jul": 23, "julien": 6, "jump": 5, "jun": 10, "junji": [1, 6], "junyang": 1, "junyi": 1, "jupyt": [], "just": [1, 5, 6, 7, 10, 11, 12, 13, 17, 20, 21, 22], "justifi": 11, "jy": 6, "k": [1, 5, 6, 7, 8, 10, 11, 12, 16, 19, 20, 21, 22, 23], "k_": 1, "k_i": 1, "kai": [1, 10, 11], "kaim": 23, "kaiser": 10, "kaplan": [5, 7, 10], "karafi\u00e1t": 8, "karthik": [5, 7, 10], "kartikai": 6, "katarina": 21, "kate": 6, "katherin": 9, "kazakhstan": 11, "kb14": 23, "kd": 6, "keep": [1, 7, 10, 13], "kei": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 20, 21, 22, 23], "keikichi": 8, "kelton": 21, "kelvin": 22, "keme": 1, "kenton": [6, 10], "kept": [17, 22], "keqin": 1, "kernel": [6, 20], "keskar": 9, "keskar2019ctrl": 13, "kevin": [6, 10, 22], "kexin": 1, "keyboard": [], "keystrok": [], "kgr": 17, "khandelw": 6, "khudanpur": 8, "kia": 7, "kind": 6, "king": 16, "kingma": 23, "kk": [], "kl": [6, 21], "klau": 6, "kl\u8d8a\u5c0f\u8d8a\u597d": 21, "kneser": 7, "knn": 16, "know": [5, 7, 12], "knowledg": [0, 5, 6, 10, 11, 16, 17, 19, 22], "known": [6, 7, 10, 11, 16, 19], "kobayashi": 8, "kojima": 17, "kojima2022larg": [], "kolesnikov": 10, "korean": 1, "krikun": 6, "kristina": [6, 10], "kuchaiev": 20, "kun": 1, "kusner": 6, "kv": [], "kw": [1, 10], "kw_i": 10, "kwanza": 11, "kwarg": [], "kwin": [], "kwout": [], "kyrola": 23, "l": [5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 22, 23], "l_": [6, 21], "l_2": [], "l_q": 12, "label": [5, 6, 9, 10, 11, 16, 23], "lack": [6, 7, 17, 22], "lag": [], "lagrang": [7, 12], "lagrangian": 12, "lambda": [7, 12, 23], "lambda_i": 7, "lamda": 16, "lampl": 6, "lample2019cross": [], "lan": [1, 6, 10], "lan2019albert": [], "land": [], "landscap": 0, "langl": [1, 21], "languag": [1, 9, 11, 13, 16, 17, 19, 20, 21, 22, 23, 25], "language_model": [], "language_modeling_benchmark": [], "languagemodel": [], "languagemodelingbenchmark": [], "languageunsupervis": [5, 7, 10], "laplac": 7, "larg": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "larger": [0, 1, 5, 6, 7, 10, 11, 12, 20, 22, 23], "largest": [5, 10, 20], "larnguag": 7, "laroussilh": 22, "larson": 16, "last": [5, 6, 9], "latenc": 22, "latent": [8, 11], "later": [], "latest": 7, "latex": [], "latter": [], "law": [0, 7], "layer": [5, 8, 9, 11, 12, 16, 20, 21, 22], "layernorm": [1, 6, 10, 20], "layerwis": 6, "layout": 20, "lb": 13, "lc": [], "lc19": 6, "lcc": [], "lcccccc": [], "lcccccccccc": [], "lcg": [6, 10], "ldot": [5, 6, 7, 11, 13], "lds89": 12, "le": [6, 7, 16, 17, 22], "lead": [1, 10, 11, 12, 16, 17, 20, 22, 23], "leader": 5, "leap": 0, "learn": [1, 5, 6, 8, 9, 10, 11, 12, 20, 22, 23, 25], "learnabl": [1, 6], "learner": [5, 6, 7, 9, 10, 22], "least": [12, 16, 20], "lebr\u00f3n": 1, "lectur": [], "lecun": 12, "led": [0, 6, 22], "lee": [1, 6, 9, 10, 16], "left": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22, 23], "leftarrow": [20, 23], "legend": [], "leik": 21, "leimao": 12, "lemmat": 11, "len": 6, "length": [5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20], "leq": [7, 11, 12, 21], "less": [1, 6, 7, 10, 11, 12, 13, 17, 19, 22], "lester": 22, "let": [0, 1, 6, 7, 8, 10, 11, 12, 13, 17, 21, 22, 23], "letter": 1, "level": [0, 5, 6, 7, 10, 11, 12, 21, 23], "leverag": [1, 6, 10, 16, 19, 21, 22], "levi": [6, 9, 10], "lewi": [6, 9, 10, 12], "lewis2019bart": 9, "lexic": 11, "lfloor": 12, "lh17": 23, "li": [1, 6, 9, 10, 16, 22], "lib": [], "librari": [], "licens": [], "lie": [1, 5], "lieu": [], "life": 22, "lifeng": 6, "lifetim": [], "lighter": 6, "lightweight": 16, "like": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22], "likelihood": [1, 5, 6, 7, 11, 13, 21, 23], "likert": 21, "likewis": 5, "lilianweng": 12, "lim_": 7, "limit": [0, 1, 5, 6, 7, 8, 9, 10, 12, 17, 19, 20], "lin": [1, 10], "lin20": [], "lin2021survei": [], "line": [6, 16], "linear": [1, 5, 6, 9, 10, 11, 20, 22, 23], "linearli": [1, 6, 8, 12], "linewidth": 23, "linform": [], "lingual": 6, "linguist": [1, 6, 7, 9, 11], "link": [7, 11], "linlin": 6, "linspac": [], "list": [1, 9, 13], "list_nam": [], "listen": 5, "lite": [6, 10], "liter": 5, "literatur": [], "liti": 6, "littl": [12, 22], "liu": [1, 6, 9, 10, 16], "liu2019roberta": [], "liu2020survei": [], "live": 8, "liwei": [1, 10], "lkb20": 6, "ll": [1, 6, 10, 12, 22], "llama": 21, "llama2": 1, "llama7b": 12, "llg": 9, "llion": 10, "lll": 6, "lllll": [], "llm": [5, 10, 16, 19], "llm_book": [], "llm_dense_architectur": [], "llm_env": 24, "llm_moe_sparse_architectur": [], "lm": [17, 20], "ln": [1, 7, 11], "load": [1, 12, 20], "local": [1, 10, 11, 23], "local_n": [], "localhost": [], "locat": [6, 8, 23], "log": [5, 6, 7, 10, 11, 13, 21, 22], "logi": 20, "logic": [1, 7, 8, 10, 17], "logist": 11, "logit": [6, 11, 13, 21], "long": [0, 1, 7, 8, 10, 12, 13, 21, 23], "longer": [6, 7, 8, 10, 13, 21, 23], "longform": 1, "longpr": 22, "look": [5, 6, 7, 9, 10, 11, 12, 13, 20, 22], "loop": 20, "lose": [11, 20], "loshchilov": 23, "loss": [5, 6, 7, 9, 10, 11, 12, 20], "lost": 9, "love": [6, 11], "low": [5, 6, 7, 8, 10, 11, 12, 21], "lower": [6, 7, 11, 12, 13, 20, 22], "lowercas": 7, "lowest": 13, "lpsbh": 20, "lrrrr": [], "lsa": 11, "lstm": [6, 10], "lstmunitalg": [], "lty": 10, "lu": [1, 22], "luan": [5, 7, 9, 10], "luca": 10, "lucki": 11, "luckiest": 11, "lukasz": 23, "luke": [6, 9, 10, 12, 21], "luk\u00e1": 8, "luo": 22, "luong": 6, "lym": 22, "lysandr": 6, "lyu": 10, "m": [1, 5, 6, 7, 9, 10, 11, 20, 22, 23], "m_": [6, 11, 20, 23], "m_1": 6, "m_i": 20, "m_k": 23, "m_m": 6, "m_n": 20, "m_t": 6, "ma": [1, 6], "maarten": [17, 22], "mac": 11, "machel": 17, "macherei": 6, "machin": [6, 7, 8, 9, 10, 11, 13, 20, 23], "machinetransl": [], "macintosh": 11, "maddi": 21, "made": [5, 7, 9, 13], "magic": [], "magic_nam": [], "magic_output_can_be_silenc": [], "magnitud": [1, 12, 20, 23], "mai": [1, 6, 12, 13, 17, 20, 22, 23], "main": [5, 20, 22], "mainli": [1, 6, 12, 20], "mainstream": [1, 12], "maintain": [1, 6, 12, 20], "maintainentc": 22, "mainten": 22, "major": [5, 6, 10, 11, 12, 16], "make": [1, 5, 6, 7, 9, 10, 11, 12, 17, 19, 20, 22, 23], "man": [5, 6, 7, 11, 21], "manag": [0, 6, 10, 20], "mandar": [6, 10], "mani": [1, 5, 6, 7, 8, 9, 11, 12, 13, 20, 22, 23], "manipul": [], "mann": [5, 7, 10], "manner": [0, 6, 9, 19], "manning1999found": [], "mantissa": 20, "manual": 6, "manufactur": 22, "map": [1, 6, 7, 10, 11, 12, 20, 22], "mapl": [], "mappign": 22, "mar94": 7, "marcinkiewicz": 7, "margin": 16, "mari": [7, 22], "marjan": 9, "mark": [1, 5, 6, 10, 20], "markdown": [], "marker": 6, "markov": [7, 21], "marku": 12, "marten": 23, "martin": 8, "mask": [9, 20], "maskedmultiheadattent": 10, "mass": [5, 7], "massiv": [0, 1, 5, 6], "master": 20, "masterpiec": 17, "match": [5, 6, 7, 16, 20], "matena": 9, "math": [1, 11], "mathbb": [5, 6, 10, 11, 12, 21, 22, 23], "mathbf": [5, 6, 9, 12, 13, 20], "mathcal": [5, 6, 7, 11, 13, 21, 22], "mathemat": [1, 17, 20, 21, 23], "mathematica": [], "mathrm": [6, 7, 9, 12, 21], "matlab": [], "matplotlib": [], "matplotlib_inlin": [], "matric": [1, 6, 8, 10, 11, 12], "matrix": [1, 5, 6, 7, 9, 10, 11, 20, 22], "matsuo": 17, "matt": 6, "matter": 6, "matthew": 6, "matthia": 10, "max": [1, 6, 10, 11, 12, 20, 21, 22], "max_": [11, 12], "max_len": [], "max_val": 12, "max_val_g1": 12, "max_val_g2": 12, "maxdepth": [], "maxim": [0, 5, 6, 7, 8, 11, 12, 13, 21, 22], "maximum": [7, 11, 12, 13, 20], "mb": 22, "mbart": 5, "mccann": 9, "mccann2018natur": [], "mccd13": 11, "mdframe": [], "me": [6, 9, 17], "mean": [5, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22], "meaning": [7, 13], "measur": [5, 10, 11], "mechan": [6, 8, 10, 12, 22], "media": 11, "medic": 16, "medicin": 16, "medium": 6, "medprompt": 16, "medqa": 16, "meet": [8, 13], "megatron": 20, "mei": 1, "melani": [5, 7, 10], "melvin": 6, "mem_byt": 20, "member": 13, "memor": 7, "memori": [1, 6, 10, 11, 22], "memotec": 7, "men": 1, "meng": [21, 22], "mengzhou": 21, "mentez": 5, "mention": [6, 8, 23], "menu": [], "mere": 10, "merg": [1, 8, 20, 22], "messag": [], "met": 23, "meta": 1, "metadata": 21, "meteorologi": [], "method": [0, 1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 21], "methodolog": 22, "methodologi": [], "metric": [0, 5, 21], "mha": [], "mi": 21, "mice": 11, "michael": [9, 10, 20], "michiel": 1, "micikeviciu": 20, "micikevicius2017mix": [], "microsoft": 11, "mid": [5, 6, 7, 8, 10, 11, 12, 13, 21, 22], "mid1": 10, "mid2": 10, "middl": [10, 12, 22], "might": [1, 6, 7, 11, 12, 22], "mike": [6, 9, 10, 12], "mikolov": [7, 8, 11], "mikolov2013distribut": 11, "mikolov2013effici": [], "mikolovkbck10": 8, "milakov2018onlinenormalizercalculationsoftmax": 20, "mile": 22, "mileston": [], "milk": 6, "miller": 21, "million": [5, 7, 10, 11], "milton": 21, "mimic": 17, "mimick": 6, "min": [1, 12], "min_": [6, 12], "min_length": 13, "min_val": 12, "min_val_g1": 12, "min_val_g2": 12, "minaj": [], "minder": 10, "ming": [6, 10], "mingda": [6, 10], "mingfeng": 1, "minh": 6, "mini": 6, "minibatch": 20, "miniconda3": [], "minilm": [], "minilm_deep_attention_demo": [], "minilmdeepattentiondemo": [], "minim": [5, 6, 7, 11, 21], "minimind": 24, "minimum": [10, 12, 23], "minor": 6, "minuend": [], "mirac": 22, "mishkin": 21, "mishra": 22, "mismatch": 6, "miss": [6, 11], "mistral": 1, "mit": 7, "mit23": 21, "mitchel": 21, "mitig": [1, 8, 10, 12, 13, 16, 21, 23], "mix": [5, 6, 11, 12], "mixed_precis": [], "mixed_precision_process_demo": [], "mixed_precision_training_demo": [], "mixedprecisionprocessdemo": [], "mixedprecisiontrainingdemo": [], "mixtur": [0, 22], "mkb": 8, "mkxs18": 9, "mle": [], "mlm": [6, 10], "mlx": 7, "mmlm": 6, "mna": 20, "mnli": [9, 12], "mobile_bert_demo": [], "mobilebert": [], "mobilebertdemo": [], "mode": [], "model": [9, 13, 16, 17, 19, 22, 23, 25], "modeldistil": [], "modern": [0, 1, 7, 10, 11, 12], "modest": 12, "modif": 23, "modifi": [1, 5, 7, 9, 10, 11, 19], "modul": [1, 5, 20, 22], "modulenotfounderror": [], "moe": 25, "moham": 9, "mohammad": 6, "mohit": 6, "moment": [9, 22, 23], "momentum": 20, "mona": 22, "monetari": 11, "mono": [], "monolingu": [5, 6], "monoton": [1, 23], "mont": [], "more": [0, 1, 5, 6, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "moreov": [7, 10, 17, 23], "morphem": 11, "morpholog": 11, "morron": 22, "most": [1, 5, 7, 9, 10, 11, 12, 13, 16, 19, 20, 21, 23], "mostafa": [10, 22], "mostli": [7, 13], "motiv": [5, 6, 9, 10, 12, 17], "mous": 11, "move": [12, 23], "movement": 23, "movi": [5, 6], "mr": 7, "mrpc": 12, "msc": 11, "mschutze99": 7, "mse": 6, "mu": [1, 23], "much": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 21, 22, 23], "multi": [6, 9, 10, 11, 17, 22], "multiarith": 17, "multicolumn": [], "multihead": [1, 22], "multiheadattent": [6, 10], "multilingu": 1, "multilingual_model": [], "multimedia": 11, "multimod": 0, "multimodality_fundament": [], "multipl": [1, 5, 6, 9, 10, 11, 16, 19, 20, 22], "multipli": [1, 7, 8, 10, 12, 13, 23], "multiprocessor": 12, "multirow": [], "multitask": [5, 7, 9, 10], "must": [6, 20], "mutual": 11, "mxc24": 21, "my": [9, 17], "myle": [6, 10], "myref": [], "m\u00f6chte": 10, "n": [1, 5, 6, 8, 10, 11, 12, 13, 17, 21, 23, 24], "n1": 10, "n2": 10, "n_": [1, 6, 7, 11], "n_d": 20, "n_layer": 1, "na": 1, "nabla": 23, "nabla_": [21, 23], "nagel": 12, "nahb": 7, "naiv": [11, 16, 20], "nakamura": 8, "naman": [6, 9, 10], "name": [1, 6, 7, 9, 10, 21, 23], "namespac": [], "nan": [6, 20, 22], "narang": [9, 16, 20, 22], "narasimhan": [5, 7, 10], "narrow": [6, 13, 20, 23], "nation": 11, "nativ": [], "natur": [0, 6, 7, 8, 9, 10, 11, 13, 17, 19, 22, 23], "natura": 5, "navig": 0, "nbviewer": [], "nccl": 20, "nce": 11, "nd": [], "ne": 5, "nearbi": [10, 11], "nearest": [11, 12], "nearli": 11, "necessari": [1, 7, 12, 13, 16, 20], "necessarili": 13, "need": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 20, 21, 22, 23], "neelakantan": [5, 7, 10], "neg": [1, 6, 7, 13, 17, 23], "neglig": [], "nei": 7, "neighbor": [1, 11], "neighborhood": [], "neil": 22, "neither": 9, "neq": [11, 12], "nesterov": [], "netowk": 8, "networ": 11, "network": [0, 1, 5, 6, 7, 8, 10, 11, 20, 23], "neubig": 6, "neumann": 6, "neural": [0, 1, 6, 7, 10, 11, 20, 23, 25], "neuralmatch": [], "neuralnetworklanguagemodel": [], "neutral": [6, 9, 17], "never": [9, 21], "new": [0, 1, 6, 7, 9, 10, 12, 13, 16, 17, 19, 20, 21, 22], "newli": 9, "newlin": 7, "newser": [], "newton": [], "next": [1, 5, 7, 8, 10, 13, 20, 21], "nformat": [5, 7, 10], "ni": 1, "nice": [], "nichola": 16, "nick": [5, 7, 10], "nicki": [], "nicolo": 16, "nie": 1, "niki": 10, "nine": 22, "nitish": 9, "nj": 10, "nlg": 10, "nli": 22, "nlp": [0, 1, 5, 6, 7, 9, 10, 11, 21, 22], "nlu": [10, 13], "nlz": 16, "nm": 10, "noam": [1, 9, 10], "node": 20, "nois": [1, 6, 9], "noisecontrastiveestim": [], "noisi": [9, 21], "nomin": 7, "non": [1, 6, 7, 10, 11, 13, 16, 20, 22, 23], "none": [], "nonetheless": [], "nonexecut": 7, "nonlinear": [6, 10, 12, 22], "nonneg": [], "nonperform": 6, "nonsens": [1, 17], "noordhui": 23, "noqa": [], "nori": 16, "nori2023can": [], "norm": [12, 20], "normal": [5, 6, 7, 10, 11, 12, 21, 22], "norouzi": 6, "norwai": 11, "notabl": [6, 10, 11, 12], "notat": [13, 20], "note": [1, 6, 7, 8, 9, 10, 11, 12, 20, 21, 22, 23], "notebook": [], "noth": [8, 17], "notic": [5, 22], "notin": 12, "notnext": 6, "noun": [7, 11], "nov": 7, "novel": [0, 5, 6, 10], "now": [1, 5, 7, 10, 11, 12, 13, 17, 20, 23], "np": [], "nsp": 10, "nternat": [1, 10], "nuanc": [1, 10], "num_head": 20, "num_lay": 20, "number": [0, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 22, 23], "numer": [7, 11, 12, 20, 21], "numpi": [], "numref": 11, "nvidia": [12, 20], "o": [1, 6, 7, 10, 11, 12, 13, 20], "o_": [6, 20], "o_1": 10, "o_i": 20, "o_m": 10, "o_n": 10, "o_p": 10, "ob": [], "obd": [], "object": [5, 6, 9, 10, 11, 12, 21, 22], "observ": [5, 6, 7, 8, 9, 10, 11, 12, 22], "obsolet": 19, "obtain": [1, 5, 6, 7, 9, 10, 11, 20, 21], "obvious": 7, "occasion": [], "occupi": 12, "occur": [1, 5, 6, 7, 11, 12], "occurr": [7, 8, 11], "odd": 10, "odot": 23, "ofelia": 6, "off": [13, 16], "offer": [5, 6, 7, 12, 17, 22], "offic": 7, "offlin": 21, "offset": [6, 9, 12, 20], "often": [0, 1, 6, 7, 12, 13, 17, 19, 20, 21, 22, 23], "oil": 22, "ok": [], "okai": 17, "olatunji": 20, "old": 7, "oleksii": 20, "omer": [6, 9, 10], "omit": [1, 10], "onc": 20, "one": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 21, 22, 23], "onehot2densevec": [], "ones": [0, 7, 11], "onfer": [1, 10], "ongo": 1, "onli": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 20, 21, 22], "onlin": 23, "onto": 11, "oov": 11, "opaqu": [], "open": [0, 1, 5, 7], "openai": [0, 5, 7, 9, 10, 16, 21], "openbookqa": 5, "oper": [1, 6, 8, 10, 12, 19, 22], "operatornam": [1, 5, 6, 7, 8, 10, 11, 12, 13, 21], "opportun": 8, "oppos": 7, "opposit": 11, "opt": 12, "optic": 7, "optim": [0, 1, 6, 8, 9, 10, 12, 13, 20, 21, 22], "optiom": [], "option": [7, 8, 13, 20], "orang": 16, "order": [5, 6, 7, 9, 10, 11, 12, 16], "ordinari": 6, "org": [1, 6, 10, 11, 12, 17, 19, 20, 21, 22], "organ": [7, 10, 12], "orhan": 6, "orient": [], "origin": [1, 5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 22], "oriol": 6, "orthogon": [], "oslo": 11, "other": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 20], "otherwis": [6, 7, 12, 16], "otim": [1, 12], "ott": [6, 10], "ou": [10, 11], "our": [0, 5, 6, 7, 9, 12, 16, 17, 21, 22], "ournal": 9, "out": [5, 6, 9, 10, 11, 12, 16, 20, 21], "outcom": [20, 21], "outcompet": 16, "outdat": 19, "outer": 12, "outlier": 12, "outlin": 21, "outperform": [0, 1, 5, 6, 11, 21], "output": [0, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "output_can_be_silenc": [], "outsid": 12, "ouyang": 21, "over": [0, 5, 6, 7, 8, 9, 10, 11, 13, 16, 21, 22, 23], "overal": [1, 6, 11, 12, 13, 17, 19, 20, 22, 23], "overcom": [1, 10, 11, 12, 20], "overestim": 7, "overfit": [6, 7, 21, 22, 23], "overflow": 20, "overhead": [1, 12, 22], "overst": 0, "overview": [6, 22], "owj": 21, "own": [1, 10, 12, 19], "p": [5, 6, 7, 8, 9, 10, 11, 17, 20, 21, 23], "p_": [6, 7, 11, 12, 13, 20, 22], "p_0": 13, "p_i": 13, "p_n": 11, "p_x": 12, "pa": [5, 6, 20], "packag": [], "package_nam": [], "pad": [6, 7, 10], "padmask": [6, 10], "page": [5, 17], "pagehello": [], "pain": [], "pair": [1, 6, 8, 10, 11, 21, 22], "pairwis": 21, "palm": [0, 16], "pamela": 21, "panda": [], "panel": [], "pangu": [], "paper": [1, 5, 7, 10, 16, 21, 22], "paperswithcod": 5, "par": 1, "paradigm": [5, 9, 10, 20, 22], "paragraph": [5, 6, 7, 11, 19], "paragraph_to_vector": [], "paragraphtovector": [], "paral": 20, "parallel": [1, 6, 10, 12], "paralleliz": 10, "param": 1, "paramet": [0, 5, 8, 9, 10, 11, 12, 13, 20, 23], "parameter": [6, 8, 21], "parent": 21, "parfum": 5, "pari": 11, "parmar": 10, "part": [0, 5, 6, 7, 9, 10, 12, 19, 22, 23], "parti": 9, "partial": [7, 12, 22], "participl": 11, "particular": [6, 16, 17, 19], "particularli": [1, 9, 10, 12, 13, 23], "partit": [20, 21], "pascal": 8, "pass": [5, 6, 10, 12, 13, 16, 20, 21, 22], "passag": 10, "past": [7, 11, 12], "patent": 5, "path": 16, "patit": 20, "patrick": 10, "pattern": [1, 7, 8, 10, 13], "paul": 21, "pauliu": 20, "pave": [], "payal": 6, "pca": 11, "pd": [], "pdf": [5, 7, 10, 19, 21], "pe": [6, 10], "peak": 22, "pear": 11, "pegasu": 10, "pei": [1, 10], "peiyu": 1, "pellat": 22, "penal": [13, 21, 23], "penalti": [13, 21], "peng": [1, 10], "penguin": 6, "penn": [5, 7], "pennington2014glov": 11, "penntre": 7, "peopl": 7, "per": [6, 10, 20, 21], "percentag": 6, "perform": [0, 1, 6, 7, 10, 11, 13, 16, 17, 19, 20, 21, 22, 23], "perfum": 5, "period": [], "perk": 7, "permut": [9, 10], "perplex": [0, 5], "perspect": [7, 11, 12, 13], "peter": [6, 9, 21], "peters2018deep": [], "petrov": 22, "pff": [], "phase": [5, 7, 9, 10, 11], "phenomenon": [6, 11, 12], "phi": [21, 22], "phi_0": 22, "phil": 6, "philadelphia": 6, "phillip": 22, "phrase": [7, 11, 22], "physic": [5, 7, 23], "pi": [1, 10, 21], "pi_": 21, "pi_r": 21, "pick": [10, 11], "pie": [], "pie_and_polar_chart": [], "piec": 6, "pierr": 7, "pieter": 23, "pigeon": 9, "pioneer": [0, 21], "piotr": [11, 23], "pipelin": [20, 21], "piqa": 5, "pixel": [], "piyush": [6, 10], "place": [10, 20, 22], "plai": [6, 10, 20], "plain": [], "plan": [], "plane": 11, "plateau": 5, "platform": [], "plausibl": [1, 19], "player": [], "plc": 7, "pleas": [], "plot": 17, "plotli": [], "plt": [], "plu": [5, 6, 9, 10, 12, 17], "plural": [7, 11], "pmi": 11, "pmlr": [1, 6, 10], "png": 9, "pni": 6, "po": 6, "point": [6, 10, 12, 20, 22, 23], "pointer": [], "pointwis": 11, "pointwiseffn": [], "polar": [], "polar_bar": [], "polici": [21, 23], "polosukhin": 10, "polynomi": [], "polysemi": 11, "pool": [12, 16], "poor": [8, 11], "poorli": 7, "pop": [], "popul": 21, "popular": [6, 7, 10, 11, 12, 22, 23], "pormpt": 17, "port": [], "portion": [6, 10], "pose": [11, 12], "posit": [5, 6, 9, 11, 12, 16, 17, 20, 21, 22, 23], "positionencod": [], "possess": 22, "possibl": [0, 5, 6, 7, 9, 10, 11, 12, 13, 19, 20, 22, 23], "possibli": 11, "post": [1, 5, 10, 12], "postnorm": 1, "potenti": [0, 1, 10, 12, 17, 20, 22], "pour": 5, "power": [0, 1, 6, 10, 12, 19], "ppl": 9, "ppo": 23, "pr": 21, "practic": [0, 6, 8, 11, 12, 13, 20, 21, 22], "practis": 20, "prafulla": [5, 7, 10], "pranav": [5, 7, 10], "pre": [1, 5, 7, 8, 10, 11, 12, 13, 16, 17, 22, 23], "preced": [5, 6, 7, 8, 9, 10, 13], "precis": [7, 12, 17], "pred": 6, "predecessor": 0, "predefin": 1, "predict": [0, 1, 5, 7, 8, 9, 10, 11, 12, 13, 16, 21], "prefer": [23, 25], "prefix": [9, 11], "premis": [5, 6, 9], "prenorm": 1, "preprint": [1, 6, 9, 10, 11, 16, 20, 23], "preprocess": [7, 9, 16], "presenc": 22, "present": [5, 6, 11, 12, 17], "preserv": [10, 11, 12], "press": 7, "press2016us": 11, "pretain": 6, "pretrain": [17, 20, 21, 22], "pretrainedlm": 9, "prevent": [10, 13, 20, 21, 23], "previou": [1, 8, 10, 11, 12, 20], "previous": [0, 9, 10, 17], "price": [], "primari": 10, "primarili": [1, 5], "prime": [6, 7, 11, 20, 22], "princip": 11, "principl": [0, 7, 8, 13, 20], "print": 17, "prior": [5, 6, 7, 16, 20, 22], "priya": 23, "pro": [6, 12, 22], "prob": 10, "probabilist": [5, 7, 8, 13], "probabilti": 13, "probabl": [5, 6, 7, 8, 10, 11, 13, 16, 21], "probe": 5, "problem": [1, 6, 9, 12, 13, 16, 17, 20, 23], "problemat": 7, "proce": 12, "procedur": [6, 9, 10], "proceed": 10, "process": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 23], "prod_": [7, 13], "produc": [5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22], "product": [1, 6, 10, 12, 13, 20, 22], "profession": [0, 6], "profound": [0, 5], "program": [], "programm": [], "prohibit": [6, 23], "project": [1, 6, 8, 9, 11, 20, 22], "projector": 11, "promin": 10, "promis": [0, 19, 23], "promot": 6, "prompt": [0, 1, 5, 10, 19, 21], "propag": [1, 12], "proper": 6, "properli": [7, 21, 22], "properti": [1, 6, 10, 20], "propog": 1, "proport": [6, 7, 11], "propos": [1, 6, 8, 9, 11, 16], "proposit": 6, "propto": [], "prove": 8, "proven": 0, "provid": [0, 1, 5, 6, 8, 10, 11, 12, 17, 19, 20, 21, 22], "proxim": 21, "prune": [], "psbh": 20, "pseudo": 7, "psi": 20, "pt": [], "ptb": 7, "ptq": 12, "ptx": 21, "public": [], "publicli": [], "publish": [6, 7, 10], "pull": 11, "punctuat": [6, 7], "punt": 7, "purpos": [6, 9, 16, 17], "pursuit": 0, "push": [0, 9, 11], "put": 11, "puzzl": 1, "pv": [], "py": [], "pylab": [], "pylab_gui_select": [], "pylabmag": [], "pylabtool": [], "pyplot": [], "python": [17, 24], "python3": [], "q": [1, 5, 10, 12], "q_": 12, "q_i": 1, "q_max": 12, "qa": 9, "qat": 12, "qi": 6, "qin": 6, "qiu2020pretrain": 6, "qk": 1, "qkv": 1, "qnli": 12, "qq": 12, "qqp": 12, "qsx": 6, "quac": [], "quad": [12, 20, 21], "quadrat": [1, 10], "quadratur": [], "qualit": [], "qualiti": [1, 5, 7, 11, 13, 16, 17, 19, 20, 22, 23], "quantat": 12, "quantecon": [], "quantit": [], "quantiti": [5, 7], "quantiz": 25, "quasi": [], "quebec": 7, "quel": 5, "quelqu": 5, "quentin": 22, "queri": [0, 6, 10, 12, 19, 20], "question": [0, 1, 6, 9, 10, 11, 16, 17, 19, 22], "quick": [17, 22], "quickli": [5, 16, 19, 22], "quit": [5, 6, 11], "qun": 6, "quoc": [6, 16, 17, 22], "qw": [1, 10], "qw_i": 10, "qwen": 1, "qwen2": [1, 22], "r": [1, 5, 7, 8, 9, 10, 11, 12, 21, 22, 23], "r_": 21, "r_l": 21, "race": 0, "radford": [5, 7, 9, 10, 21], "radford2018improv": [], "radford2019languag": [], "radii": [], "radiu": [], "radu": [6, 10], "rae": 21, "rafael": 21, "rafailov": 21, "raffel": 9, "rag": 0, "rai": 21, "rais": 0, "rajbhandari": 20, "rake": 7, "ralph": 21, "ran": [], "rand": [], "randn": [], "random": [1, 6, 7, 9, 16, 23], "randomli": [6, 9, 13], "rang": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 19, 20, 22], "rangl": [1, 17, 21], "rank": [6, 11, 12, 20, 21], "rank0": 20, "ranker": 16, "rapid": [5, 11], "rapidli": 11, "rare": [1, 6, 8, 11, 12, 13], "raslei": 20, "rate": [1, 6, 16, 23], "rather": [1, 5, 6, 10, 11, 12, 17, 21], "ratio": [7, 11, 20, 23], "rational": 6, "raw": [1, 6], "rceil": 12, "re": [0, 1, 7, 8, 11, 12, 16, 20], "reach": [1, 5, 6, 13, 16], "read": [5, 6, 11, 12, 20], "readabl": [], "reader": [], "readi": 6, "real": [0, 6, 7, 21, 22], "realist": [5, 10], "realiz": [6, 11, 23], "realli": 20, "reason": [1, 6, 7, 10, 12, 13, 16, 17, 19, 21, 22], "recal": 8, "receiv": [11, 20], "recent": [0, 1, 5, 6, 7, 8, 9, 10], "recogn": [10, 23], "recognit": [6, 7, 10], "recommend": [10, 20, 22], "reconstruct": [9, 10], "recov": [9, 10, 22], "recurr": [], "recurrentmodel_v2": [], "recurrentmodelv2": [], "recurs": 20, "redefin": 0, "redistribut": 7, "redo": 20, "reduc": [1, 5, 6, 7, 10, 11, 12, 17, 19, 20, 21, 22, 23], "reduce_max": 20, "reduce_sum": 20, "reducescatt": 20, "reduct": [6, 12, 16, 20], "redund": [12, 20], "ref": 21, "refer": [6, 13, 20, 21], "referenc": [], "refin": 5, "reflect": [7, 11], "reg": 11, "regard": [5, 10, 22], "regatta": 7, "region": 23, "regress": [5, 9, 10, 11], "regular": [1, 6, 10, 11, 12, 22, 23], "regularli": [], "reid": 17, "reignit": [], "reinforc": 17, "rel": [1, 5, 11, 12, 16, 23], "relat": [0, 6, 7, 9, 11, 13, 20], "relationship": [6, 8, 9, 10], "releas": [], "relev": [5, 6, 11, 16, 19], "reli": [1, 6, 10, 17, 19, 23], "reliabl": [1, 7, 19, 22], "relu": [1, 10, 12], "remain": [1, 5, 7, 12, 22], "remark": [0, 20], "remedi": [7, 23], "rememb": [], "remind": [], "reminisc": 6, "remov": [6, 7, 9, 12, 20, 21, 22], "ren": 1, "renji": 6, "repeat": [1, 13, 23], "repeatedli": 22, "repetit": 13, "replac": [1, 6, 7, 9, 16], "report": [1, 7], "repres": [0, 1, 6, 7, 8, 10, 11, 12, 16, 19, 20, 21, 22, 23], "represent": [1, 5, 6, 8, 9, 10, 11, 12, 20], "representationss": 11, "reproduc": [], "request": 20, "requir": [1, 5, 6, 7, 8, 10, 11, 13, 16, 17, 19, 21, 22, 23], "rescal": 13, "research": [0, 1, 6, 8, 9, 10, 11, 12, 19, 20, 23], "researchcov": [5, 7, 10], "resembl": 6, "reserv": 20, "reset": 6, "reshap": 0, "resid": 12, "residu": [1, 10, 20], "resolut": [], "resourc": [0, 6, 20, 22], "respect": [1, 6, 10, 11, 12, 20, 21, 22], "respond": 17, "respons": [13, 17, 19, 23], "rest": [7, 9, 12], "restera": 5, "restor": 6, "restrict": [1, 10, 17], "result": [1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 22, 23], "retain": [7, 10, 20, 22], "retrain": [6, 12, 17, 19, 22], "retriev": [0, 5, 6, 16, 19], "return": [0, 1, 17, 19, 20], "reveal": [7, 10, 11, 12], "review": [1, 6], "revolut": 0, "revolution": [0, 19], "revolutionari": 0, "reward": [13, 23], "rewon": [5, 7, 9, 10], "rho": [1, 23], "rho_1": 23, "rho_2": 23, "rho_i": 23, "rial": 11, "rich": [6, 10, 13], "richard": [9, 16], "rico": 1, "ride": 5, "right": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 23], "rightarrow": [7, 21], "ring": 20, "ringallreduc": 20, "ringreducescatt": 20, "rio": 11, "rise": [], "risk": [12, 20, 22], "river": 11, "rl": 23, "rl4lm": 21, "rlhf": 17, "rm": 21, "rmsnorm": 1, "rnn": [8, 10], "rnss18": [5, 7, 10], "ro": [5, 22], "robert": [9, 22], "roberta": [6, 10], "robinson": 22, "robust": [1, 9, 16], "robustli": [6, 10], "rocess": [5, 7, 10], "role": [0, 6, 10], "romanc": 5, "rome": 11, "rong": 1, "room": 8, "root": [6, 11], "rope": 1, "ross": 23, "rossum": [], "rotat": [1, 6, 9, 10], "roughli": [7, 23], "round": [12, 20], "rout": 1, "routin": [], "row": [10, 11, 12], "rrrh20": 20, "rrs20": [], "rsm": 21, "rsr": 9, "rte": 12, "rtn": 12, "ru": 1, "ruben": 7, "ruder": 6, "rudolph": 7, "rui": 1, "ruibin": [1, 10], "ruiyang": 1, "ruiz": 1, "rule": [1, 6, 7, 8, 11, 13, 20, 23], "rumelhart": [], "rumor": 7, "run": [8, 11, 12, 16, 17, 20, 22], "run_line_mag": [], "runji": 1, "runtim": [7, 11, 12], "ruwas": 20, "rwc": [5, 7, 9, 10], "ryan": 21, "ryder": [5, 7, 10], "s3": [5, 7, 10], "s_": [6, 8, 12, 21], "s_0": 21, "s_i": [6, 21], "s_j": 21, "s_t": 21, "s_w": 12, "sai": [5, 6, 7, 11, 17, 21, 23], "saksham": 6, "salienc": 12, "saliman": [5, 7, 10], "same": [1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 19, 20, 22], "sampl": [7, 9, 16, 17, 21, 23], "samyam": 20, "san": 5, "sandhini": 21, "sanghai": 1, "sanh": 6, "sanh2019distilbert": [], "sanjeev": 8, "sara": 12, "sargent": [], "sastri": [5, 7, 10], "satisfactori": [5, 6, 10], "satisfi": [1, 7, 20, 21], "satisifi": 21, "satoshi": 8, "satur": 10, "saurabh": 6, "save": [10, 11, 12, 20, 22], "saw": [], "sbh": 20, "scalabl": [11, 12], "scalar": [13, 21], "scale": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 20, 21, 23], "scale_g1": 12, "scale_g2": 12, "scatter": 20, "scenario": [1, 6, 11], "sch": 7, "schedul": 23, "schemat": 12, "scheme": [1, 5, 9, 10, 12, 16], "schulman": 21, "schuster": 6, "schuurman": [16, 17], "scienc": 0, "scientif": [5, 6], "score": [1, 5, 7, 11, 13, 21], "scratch": [1, 10], "scriptsiz": [], "sdcw19": 6, "search": [0, 11, 12, 19], "seat": 17, "sebastian": [6, 10], "sebastianraschka": [], "sec": [], "second": [1, 5, 6, 9, 10, 11, 12, 20], "secondli": 10, "secretli": 21, "section": [0, 6, 7, 10, 11, 12, 20, 21], "secur": [], "see": [1, 10, 11, 12, 17, 20, 21, 23], "seed": [], "seen": [6, 7, 10, 11, 20, 22, 23], "seg": 6, "segmenet": 6, "segment": [6, 9, 10], "select": [5, 6, 9, 11, 12, 13, 16, 17, 22], "self": [6, 9, 10, 12, 23], "selfattent": 10, "seltzer": 6, "semant": [5, 6, 7, 8, 9], "send": 20, "sennrich": 1, "sens": 7, "sensibl": 7, "sensit": [16, 20, 22], "sent": 20, "sentenc": [5, 7, 9, 10, 11, 12, 13, 17, 21], "sentiment": [6, 11], "sep": 6, "separ": [1, 5, 6, 10, 12, 22], "seq2seq": [10, 25], "seq_len": [1, 20], "seqlength": 12, "seqmask": 10, "seqmask_i": 10, "sequenc": [1, 5, 6, 7, 8, 9, 11, 12, 13, 17, 20], "sequencen": 8, "sequenti": [0, 6, 7, 10, 20], "sequitur": [], "sergei": 1, "seri": [1, 10, 25], "serial": [], "serv": [6, 16], "servic": [], "set": [1, 5, 7, 9, 10, 11, 12, 13, 16, 17, 19, 22, 23], "setalgolin": [], "seven": [5, 10], "sever": [0, 6, 7, 8, 10, 11, 12, 17, 19, 22], "sexual": 21, "sft": [], "sgd": 23, "sgdmomentum": [], "sha19": 1, "shall": [], "shallow": [1, 12], "shane": [17, 22], "shang": 6, "shaohan": 6, "shape": [0, 1, 12, 13], "sharan": [9, 16, 20, 22], "share": [1, 5, 6, 9, 10, 11, 12, 20], "sharma": [6, 10, 21], "shayn": 22, "shazeer": [1, 9, 10], "shean": 22, "shelf": 16, "shell": [], "shen": 22, "sheng": 16, "shift": [0, 1, 9, 10, 12], "shiji": [1, 10], "ship": 11, "shirish": 9, "shixiang": [17, 22], "shock": [], "short": [1, 10, 11], "shortag": 10, "shortcom": 11, "shorten": 20, "shorter": [], "shorthand": [7, 13, 21], "shortli": 10, "shot": [1, 5, 6, 7, 10, 16, 22], "should": [1, 5, 6, 7, 9, 10, 12, 17, 20, 22], "show": [1, 5, 6, 7, 11, 12, 21, 22, 23], "shown": [1, 5, 6, 7, 10, 11, 13, 17, 21, 22], "shrink": 23, "shuai": 1, "shuffl": [7, 9], "shume": 6, "shuxin": [1, 10], "shyam": [5, 7, 10], "siddhant": 6, "siddhartha": 22, "side": [5, 6, 10], "sigma": [1, 11, 21], "sigma_1": 1, "sigma_2": 1, "sigma_i": 20, "sigmoid": [1, 6, 8], "sign": 20, "signal": [7, 11], "signific": [0, 1, 5, 6, 7, 10, 12, 16, 19, 20, 22], "significantli": [0, 1, 5, 6, 10, 11, 12, 13, 16, 17, 19, 21, 22], "sim": [7, 11, 12, 21], "sim3": 20, "simen": 21, "simiarl": 16, "similar": [1, 5, 6, 7, 8, 9, 11, 16, 20, 21, 23], "similarli": [1, 7, 10], "simpl": [1, 5, 10, 11, 12, 17, 20, 22, 23], "simpler": [7, 16, 17, 21], "simplesgd": [], "simplest": 13, "simpli": [5, 6, 7, 9, 13, 19, 21, 23], "simplic": [1, 6, 10, 22], "simplif": 17, "simplifi": [1, 12, 19, 21], "simpo": 21, "simul": [], "simultan": [6, 12], "sin": [1, 10], "sinan": 1, "sinc": [5, 6, 7, 9, 10, 11, 12, 13, 20, 21, 23], "sine": 10, "singer": 23, "singhal": 6, "singl": [1, 5, 6, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22], "singular": 11, "sink": [], "sister": 11, "site": [], "situat": [], "six": [6, 20], "sizabl": 1, "size": [0, 5, 6, 7, 8, 10, 11, 12, 13, 19, 22], "skew": 5, "skill": [0, 5], "skip": [], "skip_gram_cbow": [], "skipgramcbow": [], "skipgramoptim": [], "slama": 21, "slav": 22, "slice": [], "slide": [], "slightli": 9, "slow": [5, 6, 23], "slower": [1, 20], "slw": 10, "small": [1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 20, 21, 22, 23], "smaller": [0, 1, 6, 7, 8, 10, 11, 12, 20, 22, 23], "smallest": [11, 12], "smdh13": 23, "smooth": [1, 5, 8, 13], "smoother": 1, "smoothli": [5, 22], "snack": 7, "snippet": 17, "so": [1, 6, 7, 9, 10, 11, 12, 17, 20, 23], "socher": 9, "social": [], "soft": [6, 13], "softmax": [1, 5, 6, 8, 10, 11, 12, 13], "softwar": [], "soheil": 5, "sole": 17, "solid": 11, "solla": 12, "solut": [6, 19, 21, 22], "solv": [1, 6, 9, 11, 12, 17, 20], "some": [1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 20, 21, 22], "some_valu": [], "someth": [5, 17], "sometim": 1, "somewhat": 5, "somewher": [], "song": 6, "soon": [], "sop": [6, 10], "sophist": 0, "soricut": [6, 10], "sorri": [], "sort": [7, 10, 11, 13], "sota": [], "sound": [1, 5, 19], "sourc": [1, 6, 9, 19, 23], "space": [1, 6, 8, 9, 10, 11, 12, 13, 20, 21, 23], "span": [6, 9], "spark": [], "spars": [0, 11, 25], "sparsiti": [1, 8], "speak": 11, "special": [0, 1, 5, 6, 7, 8, 9, 12, 13, 16, 17, 19], "specialist": 16, "specif": [0, 1, 5, 6, 7, 9, 10, 12, 16, 17, 19, 20, 21, 22, 23], "specifi": [5, 6, 7, 9, 10, 11, 13, 17, 20, 23], "specifici": 12, "specificlli": 21, "specul": [0, 7], "sped": 6, "speech": [7, 20], "speed": [1, 5, 6, 20, 23], "spell": 6, "spend": 12, "spent": 20, "sphinx": [], "spike": [], "split": 10, "spur": 0, "sqrt": [1, 6, 10, 11, 23], "squad": 9, "squad2": [], "squar": [6, 11], "ssangyong": 7, "sst": 12, "st": 12, "stabil": 1, "stabl": [1, 20, 21], "stabli": 23, "stabliz": 1, "stachurski": [], "stack": [6, 10], "stack_depth": [], "stage": [1, 5, 6, 7, 9, 10, 11, 12], "stage1": 20, "stai": 11, "staliz": 1, "stand": [0, 6, 10, 11, 20], "standard": [1, 6, 11, 20], "stanford": [], "stanislaw": 22, "star": [], "start": [1, 5, 6, 7, 9, 10, 12, 13, 21], "stat": [], "state": [5, 6, 7, 9, 10, 11, 21, 22, 23], "statement": [], "static": [6, 11], "static_vs_contextualembed": [], "staticvscontextualembed": [], "statist": [11, 22], "statisticallearn": [], "steadili": [], "steam": 11, "steep": 5, "stefano": 21, "stem": [11, 22], "step": [1, 6, 9, 10, 11, 12, 13, 17, 19, 20, 21, 23], "stick": 20, "stiennon": 21, "still": [1, 5, 8, 10, 12, 19], "stochast": 13, "stockton": 11, "stop": [6, 9, 12, 23], "storag": [12, 22], "store": [6, 7, 8, 10, 12, 16, 19, 20, 22], "stori": [13, 17], "stork": 12, "stoyanov": [6, 9, 10], "str": [], "straight": [6, 17], "straightforward": [], "strategi": [6, 7, 8, 9, 10, 12, 16], "stream": [6, 12], "street": 7, "strength": [1, 6, 19, 21, 23], "stretch": 5, "strict": 1, "strictli": [], "string": 21, "strip": 7, "strong": [5, 9, 12, 23], "stronger": [], "strongli": 23, "structur": [0, 1, 5, 6, 7, 10, 11, 16], "struggl": [5, 12], "student": [0, 6], "studi": [0, 5, 6, 10, 11, 16, 22], "stun": 17, "style": [6, 9, 17, 20, 21], "stylist": 21, "sub": [5, 6, 10, 11, 12], "subbiah": [5, 7, 10], "subdirectori": [], "subgradi": 23, "subject": 7, "sublay": 1, "subplot": [], "subscript": 10, "subsect": [], "subsequ": [0, 5, 12, 13], "subset": [6, 10, 11, 12], "subspac": [1, 10], "substanti": [12, 22], "substitut": [], "subsubsect": 7, "subtabl": [], "subtitl": 5, "subtl": 10, "subtract": [1, 20, 21, 22], "subunit": 11, "subword": [1, 6], "subwordwordembeddingmodel": [], "succ": 21, "success": [5, 6, 10, 20], "successfulli": 22, "successor": 5, "suffer": [6, 7, 10, 22], "suffic": 17, "suffici": [12, 20], "suffix": 11, "suggest": [0, 5, 6, 23], "sui": 5, "suit": [6, 7, 10], "suitabl": [1, 9, 12], "sum": [5, 10, 11, 12, 13, 20, 21, 22], "sum_": [1, 5, 6, 7, 8, 10, 11, 12, 13, 20, 22, 23], "sum_i": [7, 12, 13], "sum_j": [13, 20], "sumit": 1, "summar": [1, 5, 6, 7, 8, 9, 10, 12, 13, 17, 21], "summari": 12, "summat": [6, 11, 12, 13, 20], "summer": 11, "sun": [6, 10], "sun2020mobilebert": [], "superfici": 7, "superflu": [], "superglu": 10, "superglue_benchmark_gpt3": [], "supergluebenchmarkgpt3": [], "superior": [19, 23], "superl": 11, "supervis": [1, 6, 10, 21, 22, 23], "supplement": 19, "supplementari": 6, "suppli": [], "support": [1, 19, 20], "suppos": [5, 6, 7, 13], "surfac": 23, "surgeon": 12, "surpris": 13, "surprisingli": 6, "surround": [6, 11], "survei": [1, 6, 10], "susana": 6, "sustain": 22, "sutskev": [5, 7, 9, 10, 11, 23], "suzgun": 22, "svd": [], "svdcooccurencematrix": [], "svdwordembed": [], "swam": 11, "swap": 6, "swapo": 7, "swiglu": 1, "swim": 11, "swish": 1, "swiss": 11, "switch": [6, 22], "switzerland": 11, "sy": 6, "sylvain": [10, 22], "symbol": [1, 5, 6, 7, 9, 10, 11], "sympi": [], "synact": 7, "syntact": 6, "syntat": 7, "syntax": 6, "synthesi": [], "system": [0, 1, 5, 6, 7, 10, 11, 12, 19], "systemat": [12, 16], "szegedi": 1, "t": [1, 5, 6, 7, 8, 10, 11, 12, 13, 16, 20, 21, 22], "t5": [10, 20, 25], "t_": 6, "t_1": 10, "t_2": 10, "t_i": [6, 10, 13], "t_j": 10, "t_m": 10, "t_p": 10, "tab": [], "tabl": [7, 9, 10, 11, 12, 20], "tabular": 11, "tackl": [6, 10, 17, 22], "tag": 6, "tai": 22, "tail": [7, 13], "takao": 8, "take": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 21], "taken": [6, 7, 10], "takeshi": 17, "tan": 1, "tang": 1, "tanh": [1, 8], "target": [5, 6, 9, 10, 11, 20, 21, 22], "task": [0, 1, 7, 10, 11, 13, 16, 19, 21, 22, 23], "tat": 16, "tau": 6, "taylor": 12, "tb": 22, "teach": 6, "teacher": [6, 23], "team": 21, "technic": 1, "techniqu": [0, 1, 6, 9, 10, 11, 17, 19, 22, 25], "technologi": [0, 10, 19], "tell": 19, "temperatur": [6, 16], "templat": [], "temporari": 20, "ten": [5, 6], "tend": [7, 9, 11, 13, 21, 23], "tens": 11, "tensor": [], "tensorfloat": 20, "tensorflow": 11, "term": [6, 7, 10, 11, 12, 13, 17, 21, 22, 23], "termin": [], "terri": 21, "terribl": 17, "test": [5, 6, 7, 11, 16], "text": [0, 1, 6, 7, 8, 10, 11, 12, 13, 16, 19, 20, 21, 22], "textbf": 7, "textbook": [], "textit": [7, 8, 10, 11], "textual": [5, 9], "tf": 11, "tf32": 20, "th": [6, 10, 12], "than": [1, 5, 6, 7, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "thang": 6, "thank": [7, 9], "theater": 5, "thei": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 19, 20, 21, 22, 23], "them": [1, 7, 9, 10, 11, 12, 20], "themselv": [], "theoret": [8, 20, 21], "theori": 10, "therebi": [1, 16], "therefor": [1, 5, 6, 7, 9, 10, 11, 12, 20, 22], "theta": [1, 5, 6, 7, 11, 13, 21, 22, 23], "theta_": [6, 7, 23], "theta_1": 6, "theta_2": 6, "theta_i": 1, "theta_k": [1, 23], "theta_q": 1, "theta_t": [], "theta_x": 1, "thi": [1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "thin": 17, "thing": 11, "think": [11, 16, 17], "third": 6, "thirti": 6, "thoma": [6, 10], "thoppilan": [16, 21], "thorough": [], "thorp": 1, "those": [1, 6, 7, 11, 12, 21, 22, 23], "though": [7, 9], "thought": [0, 6, 7], "thousand": 5, "three": [1, 5, 6, 10, 11, 19, 20, 21], "threshold": [7, 11, 13], "through": [0, 1, 5, 6, 9, 10, 11, 16, 19, 20, 21, 22], "throughout": [5, 6], "throughput": 12, "thu": [1, 6, 7, 8, 10, 11, 12, 13, 20, 22, 23], "thumbnail": [], "ti": 1, "tianhang": 1, "tianhao": 1, "tianyi": 1, "tianyu": 1, "tieyan": [1, 10], "tijmen": 12, "tild": [10, 11, 23], "tim": [5, 7, 10, 12], "time": [1, 5, 6, 7, 10, 11, 12, 13, 16, 20, 21, 22], "timelin": 1, "times1038": 20, "tini": [1, 6], "tinybert": 10, "tip": [], "titl": [5, 17], "tiwari": 6, "tlm": 6, "todai": 5, "togeth": [5, 8, 10, 11, 12], "tok": 6, "token": [5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 19, 21, 23], "tom": [5, 7, 10], "toma": [8, 11], "tomorrow": 7, "tong": 10, "too": [6, 7, 12, 23], "tool": [0, 1], "top": [1, 6, 7, 9, 10, 11, 16, 19, 20], "topic": [6, 11, 13], "tori": 5, "toronto": 23, "total": [6, 7, 10, 11, 23], "totoal": 20, "tough": 11, "tougher": 11, "toujour": 5, "toutanova": [6, 10], "toward": [0, 6, 9, 20, 23], "traceback": [], "track": 13, "trade": [], "tradeoff": [], "tradit": [1, 5, 8, 12, 19, 20, 22], "tradition": 10, "train": [0, 5, 7, 10, 11, 12, 13, 16, 17, 19, 21], "trainabl": [1, 22], "training_data": 23, "training_data_distribution_summari": 23, "training_fundament": [], "trainingdatadistributionsummari": 23, "trane": 1, "transact": 11, "transfer": [1, 5, 6, 9, 22], "transform": [0, 5, 6, 9, 12, 19, 20, 22, 25], "transformer_encod": [], "transformerencod": [], "transformerlay": 5, "transit": [7, 21], "translanguag": 6, "translat": [0, 1, 6, 7, 9, 10, 13, 20], "transpar": 17, "transpos": 1, "treat": [1, 7, 11], "treatment": 1, "tree": [5, 7], "treebank": [5, 7], "trend": [1, 5], "triangl": 10, "trick": [7, 11], "trier": 8, "trigram": 7, "trillion": [0, 20], "tripl": [6, 19], "tripleloss": 6, "trivial": 13, "trivialqa_benchmark_gpt3": [], "trivialqabenchmarkgpt3": [], "triviaqa": 5, "true": [1, 7, 13, 21], "truncat": [6, 7, 11, 16], "trust": [16, 19], "trustworthi": 19, "truth": [16, 17], "try": [17, 19, 20], "ts_length": [], "tt": 20, "tu": [1, 5, 10], "tulloch": 23, "tun": 22, "tune": [0, 1, 9, 10, 12, 13, 16, 17, 20, 21], "tupl": 17, "ture": [], "turn": [11, 20, 21], "twice": [13, 20], "two": [1, 5, 7, 9, 10, 11, 12, 13, 20, 21], "ty": 11, "type": [1, 6, 9, 10, 12, 16, 22, 23], "typic": [1, 5, 6, 7, 10, 11, 12, 13, 16, 17, 20, 22, 23], "typolog": 6, "tze": 7, "u": [0, 1, 5, 7, 8, 10, 11, 12, 13, 20, 22], "u_": [], "u_1": [], "u_n": [], "u_q": 12, "ukasz": 10, "ul2": 16, "ulrv2": [], "ultim": [5, 6, 16], "un": [5, 6, 10, 21], "unabl": [], "unattain": 0, "unbias": [7, 23], "unbound": 1, "unchang": [6, 16], "unclear": 19, "uncommon": [11, 13], "unconvent": 1, "uncorrupt": 10, "under": [5, 6, 7, 21], "underbrac": [6, 11, 21], "underflow": 20, "undergo": 10, "underli": [0, 9], "underlin": [], "underperform": 5, "underpin": [], "underset": 13, "understand": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 17, 19, 20, 22], "understood": [6, 7], "undesir": 22, "undoubtedli": 12, "unembed": 21, "uneth": 11, "unfairli": 5, "unfortun": [], "uni": [8, 9, 11], "unicod": 1, "unidirection": 10, "unifi": [1, 6, 9, 10], "uniform": [7, 11, 23], "uniformli": [1, 12, 13], "unigram": 7, "unintend": 21, "unintention": 6, "uniqu": 16, "unit": [1, 6, 10, 11, 12, 20], "univers": [5, 6, 7, 9, 10, 13, 23], "unk": 7, "unknown": 7, "unlabel": [1, 5, 6], "unlik": [0, 1, 19], "unlimit": 8, "unlock": [5, 22], "unnatur": 1, "unnorm": [1, 6], "unobserv": 7, "unpreced": 0, "unrealist": 7, "unrel": [], "unseen": [1, 7, 8, 17, 22], "unsmooth": 7, "unstabl": [1, 12], "unsuperivsedlearn": [], "unsupervis": [6, 7, 9, 10, 16], "unsupervisedlearn": [], "unterthin": 10, "until": [13, 21, 23], "untrac": 19, "unus": [12, 20], "unveil": [], "up": [0, 1, 5, 6, 7, 9, 10, 11, 13, 19, 20, 22, 23], "updat": [1, 5, 10, 11, 12, 13, 19, 20, 22, 23], "upgrad": [], "upon": 19, "upper": 10, "uptak": [], "upward": 5, "upweight": 21, "url": [1, 5, 6, 7, 8, 10, 12, 20, 21, 22], "urvashi": 6, "us": [1, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 21, 22, 23], "usag": [1, 6, 12, 17, 20, 22], "user": [13, 17, 19, 20, 22], "usual": [1, 5, 6, 11, 12, 20, 22, 23], "uszkoreit": 10, "utf": 1, "util": [1, 6, 9, 10, 11, 12, 16], "utm_medium": [], "utm_oi": [], "utm_psn": [], "utm_sourc": [], "uv": 11, "v": [1, 6, 7, 8, 10, 11, 12, 13, 22], "v2": [], "v_": [1, 11, 23], "v_c": 11, "v_i": [1, 11, 20], "v_j": [11, 20], "v_k": 23, "v_t": 11, "v_w": 11, "vald": 6, "valid": [0, 7, 21], "vallei": 23, "valter": 22, "valu": [1, 6, 7, 10, 11, 12, 13, 20, 21, 22], "valuabl": [], "van": 10, "vanilla": [19, 20], "vanish": 1, "var": 1, "vari": [9, 12, 17], "variabl": [1, 7, 17], "variable_nam": [], "varianc": [1, 20, 23], "variant": [6, 7, 9, 10], "variat": [1, 7, 11], "varieti": 12, "variou": [0, 1, 7, 10, 13, 21, 22, 23], "vast": [0, 1, 6, 11], "vastli": [6, 13], "vaswani": 10, "vdot": 10, "ve": [6, 9], "vecotr": 10, "vector": [1, 5, 6, 8, 9, 10, 11, 12, 16, 19], "vehicl": 22, "veloc": 23, "venkatesh": 20, "verb": [7, 11], "veri": [1, 5, 11, 13, 20, 22], "verifi": [16, 19], "versa": 13, "versatil": [0, 1, 22], "version": [6, 7, 10, 11, 22], "vertic": [], "veselin": [6, 10], "via": [1, 5, 6, 7, 8, 9, 10, 11, 12, 16, 23], "vice": 13, "victor": 6, "video": 22, "view": [5, 6, 11, 19, 21], "vijayakumar2016divers": 13, "vincent": [8, 22], "vinyal": 6, "viridi": [], "vishrav": 6, "vision": [0, 10], "vision_transform": [], "visit": 21, "visual": [17, 21], "vocab": [1, 6], "vocabulari": [5, 6, 8, 9, 10, 11, 13, 21], "vocabulary_s": 1, "volum": 20, "vote": 16, "vr": 6, "vram": 20, "vsp": 10, "vw": [1, 10], "vw_i": 10, "w": [1, 6, 7, 8, 9, 10, 11, 12, 22], "w32a8": 12, "w8a32": 12, "w8a8": 12, "w_": [5, 6, 7, 8, 10, 11, 12, 22], "w_0": [7, 22], "w_1": [1, 6, 7, 10, 11], "w_2": [1, 6, 7, 10, 11], "w_c": 11, "w_i": [7, 11, 12, 13], "w_j": [7, 11, 12], "w_k": 11, "w_l": 21, "w_m": 11, "w_n": 7, "w_q": 12, "w_quant": 12, "w_t": [8, 11], "w_xx_t": 8, "w_y": 8, "wa": [1, 5, 6, 7, 10, 16, 17, 20, 22], "wachter": 7, "wai": [0, 1, 5, 6, 7, 8, 10, 11, 16, 20, 23], "wainwright": 21, "walk": [8, 11], "wall": 7, "walli": 22, "wan": 1, "wang": [1, 6, 10, 16, 17, 22], "wang2020minilm": [], "wang2022self": [], "want": [10, 12, 13, 17, 20, 21], "warm": 1, "warranti": 5, "wasn": [], "wasser": 10, "wast": 20, "watch": 6, "water": [10, 11], "wave": 10, "wavelength": 10, "wayn": 1, "wbz": 22, "we": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "weak": [], "weapon": [], "web": 5, "webpag": 21, "webquest": 5, "websit": [5, 10], "webson": 22, "webtext": [5, 10], "webtext2": 5, "wechat_sess": [], "week": 9, "wei": [1, 6, 9, 10, 16, 17, 22], "wei2021finetun": [], "wei2022chain": [], "weight": [5, 6, 7, 8, 10, 11, 12, 20, 21, 22], "weiglit": 12, "weishung": 16, "weissenborn": 10, "weizhu": 22, "welind": 21, "well": [1, 5, 6, 7, 8, 9, 10, 11, 12, 17, 20, 21, 22], "wen": 1, "wenbin": 1, "wenhui": 6, "went": [6, 11], "wenwu": 10, "wenzek": 6, "were": [0, 1, 7, 9, 10, 17, 20, 21, 22], "weren": 1, "wesolowski": 23, "west": [5, 7, 10], "wh": 11, "what": [0, 5, 6, 17, 20, 21, 23], "whatev": [], "whe": 11, "when": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "whenev": 21, "where": [0, 1, 5, 6, 7, 8, 9, 10, 11, 13, 17, 19, 20, 21, 22, 23], "wherea": [1, 5, 12], "whether": [0, 6, 9], "which": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23], "while": [0, 1, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 21, 22, 23], "whitespac": [], "who": 21, "whole": [6, 10, 20, 22, 23], "whose": [7, 10, 11, 20, 22], "why": [1, 6, 17, 22], "wic": [], "wide": [0, 1, 5, 6, 7, 10, 16, 17, 19, 20, 22], "wider": [6, 12], "widespread": 1, "width": [1, 12, 13, 23], "wiggin": [], "wikipedia": [5, 6, 7, 10], "wikipidia": 6, "wikitext": 7, "william": [9, 22], "win": [], "window": [5, 8, 11], "wine": 11, "winner": 5, "winter2022": [], "wise": [1, 5, 6, 10, 12, 22], "wish": [], "wit": 0, "withdraw": [], "within": [0, 1, 5, 6, 9, 10, 11, 12, 20], "without": [1, 5, 6, 8, 10, 12, 13, 16, 17, 20, 22, 23], "wolf": 6, "wolff": 12, "wolfgang": 6, "woman": 11, "won": 22, "word": [1, 6, 8, 9, 10, 12, 13, 17, 19, 25], "word2vec": 6, "word2vec_visu": [], "word2vecvisu": [], "word_embedding_demo": [], "wordembed": [], "wordpiec": 6, "work": [1, 5, 9, 11, 12, 16, 20], "world": [0, 1, 5, 7, 17, 22], "worldthi": [], "worldwid": [], "worri": [], "wors": 20, "worth": 10, "would": [0, 6, 7, 8, 9, 10, 11, 12, 13, 20], "wrap": [], "write": [0, 1, 7, 11, 12, 13, 17, 20, 23], "writer": 7, "written": [6, 7, 11], "wrong": [9, 16], "wrote": 5, "wsc": 6, "wu": [5, 6, 7, 9, 10, 21], "wu2016googl": [], "ww": [16, 17], "wwd": 6, "www": 21, "x": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20, 21, 22, 23], "x_": [5, 6, 11, 12], "x_0": 21, "x_1": [5, 6, 10, 20], "x_2": 10, "x_i": [1, 10, 20], "x_j": 20, "x_m": 21, "x_n": [10, 20], "x_p": 10, "x_t": [5, 6, 8], "xia": [6, 10, 21], "xiao": [6, 10], "xiaodan": 6, "xiaodong": 1, "xiaohua": 10, "xiaohuan": 1, "xiaolei": 1, "xiaoqi": 6, "xin": [1, 6], "xing": [1, 10], "xingzhang": 1, "xinyu": 1, "xinyun": 22, "xiong": [1, 9, 10], "xipin": 1, "xl": [], "xlarg": [], "xlco": [], "xlm": 5, "xlm_demo": [], "xlm_e_demo": [], "xlmdemo": [], "xlmedemo": [], "xsum": 9, "xtreme": 6, "xu": [1, 21], "xuancheng": 1, "xue": 1, "xuej": 1, "xuezhi": [16, 17, 22], "xv": 1, "xw": 1, "xw_1": 1, "xwvd20": 10, "xxlarg": [], "xyh": [1, 10], "y": [1, 5, 7, 8, 9, 10, 11, 13, 21, 22, 23], "y_": [8, 13, 22], "y_1": [10, 13, 21], "y_2": [10, 21], "y_i": 10, "y_l": 21, "y_m": 10, "y_n": 13, "y_p": 10, "y_t": [6, 13, 22], "y_w": 21, "yafu": 22, "yang": [1, 6, 10, 22], "yangq": 23, "yann": 12, "yanp": 22, "yanqi": 9, "yanyan": [1, 10], "yao": 1, "ye": [], "year": [0, 1, 7, 10], "yellow": 1, "yelong": 22, "yelysei": 12, "yet": 13, "yi": 22, "yichang": 1, "yichun": 6, "yield": [0, 10, 12, 17, 23], "yifan": 1, "yime": 6, "yin": [6, 16], "yingqian": 1, "yinhan": [6, 9, 10], "yonghui": 6, "yoram": 23, "york": 6, "yoshua": 8, "you": [0, 1, 5, 6, 9, 10, 12, 17, 19, 20, 22], "youn": 12, "your": [9, 19, 20, 21, 22], "yourself": 19, "ystem": [5, 7, 10], "yu": [1, 6, 21, 22], "yuan": 6, "yuanzhi": [16, 22], "yue": 22, "yun": [1, 22], "yunchang": [1, 10], "yunfei": 1, "yunxuan": 22, "yupeng": 1, "yuqiong": 1, "yuri": 1, "yushuo": 1, "yusuk": 17, "yutaka": 17, "yuxiong": 20, "yyh": 1, "z": [5, 6, 9, 11, 12, 21, 22], "z_": 13, "z_g": 11, "z_i": [6, 13], "z_j": [6, 13], "zei12": [], "zeiler": [], "zemlyanskii": 1, "zero": [1, 5, 6, 7, 8, 9, 10, 12, 16, 21, 22, 23], "zero_point": 12, "zero_point_g1": 12, "zero_point_g2": 12, "zeropoint": 12, "zeroshot": 12, "zettlemoy": [6, 9, 10, 12], "zewen": 6, "zeyu": 1, "zeyuan": 22, "zhai": 10, "zhang": [1, 10, 16, 21, 22], "zhao": [1, 22], "zhao2023survei": 23, "zhaopeng": 10, "zhen": 22, "zheng": [1, 10], "zhenru": 1, "zhenzhong": [6, 10], "zhifang": 1, "zhifeng": 6, "zhihao": 1, "zhihu": [], "zhipeng": 1, "zhiqe": 6, "zhou": [1, 6, 9, 16, 17, 22], "zhu": [1, 22], "zhuanlan": [], "zhuyun": 22, "zican": 1, "ziegler": 21, "zikang": 1, "zimbabw": 11, "ziya": 21, "zoph": 22, "zs19": 1, "zzl": 1, "\u00e1": [6, 23], "\u00e9": [6, 8], "\u00ed": 6, "\u00fc": 7, "\u0142": 10, "\u03b1": [], "\u03b1_valu": [], "\u03b8": [], "\u03bb": [], "\u03c0": [], "\u03d5": [], "\u03f5_valu": [], "\u4e2a\u5143\u7d20": 1, "\u4e5f\u5c31\u662f\u8bf4\u8f93\u51fa\u77e9\u9635": 1, "\u4ee5\u77e9\u9635\u4e58\u4e3a\u4f8b": 1, "\u4f5c\u4e3a\u6240\u6709\u8f93\u5165token\u7684\u6253\u5206\u7ed3\u679c": 21, "\u5176\u5b9e\u4e5f\u53ef\u4ee5\u53d6\u6240\u6709token\u751f\u6210\u7684score\u8fdb\u884c\u5e73\u5747": 21, "\u53c2\u6570\u540d": [], "\u53c2\u6570\u91cf": [], "\u548c": 1, "\u56e0\u6b64\u589e\u52a0\u4e86\u548c\u539f\u59cb\u6a21\u578b\u8f93\u51fa\u7684kl\u635f\u5931": 21, "\u5982\u679c\u4ec5\u4ec5\u4f7f\u7528reward": 21, "\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u5728\u504f\u597d\u6570\u636e\u4e0a\u8fc7\u62df\u5408": 21, "\u5bf9\u4e8ellm\u6765\u8bf4": 21, "\u603b\u8ba1": [], "\u635f\u5931\u539f\u672c\u7684\u80fd\u529b": 21, "\u64cd\u4f5c": [], "\u6620\u5c04": 1, "\u6700\u540e\u4e00\u4e2a\u8f93\u5165token\u7684\u5904\u7406\u7ed3\u679c\u4f1a\u91c7\u6837\u53d8\u6210next_token": 21, "\u6a21\u5757": [], "\u6bcf\u4e00\u4e2a\u8f93\u5165token\u6700\u7ec8\u90fd\u80fd\u591f\u751f\u6210\u4e00\u4e2a\u6807\u91cf\u503c": 21, "\u6bcf\u4e2a\u5143\u7d20\u7ecf\u8fc7\u4e00\u6b21\u4e58\u6cd5\u548c\u4e00\u6b21\u52a0\u6cd5\u8fd0\u7b97": 1, "\u73b0\u5728\u53d8\u6210\u4e86score": 21, "\u77e9\u9635\u4e58\u6cd5": [], "\u8ba1\u7b97\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a": 1, "\u8bad\u7ec3\u7684\u6548\u679c\u66f4\u597d\u4e00\u4e9b": 21, "\u8f93\u5165": 1, "\u901a\u5e38\u662f\u76f4\u63a5\u53d6\u6700\u540e\u4e00\u4e2ascore": 21, "\u9884\u8bad\u7ec3\u597d\u7684reward\u6a21\u578b\u53ef\u4ee5\u53c2\u8003": 21}, "titles": ["<span class=\"section-number\">1. </span>Introduction: LLM in the Age of AI", "<span class=\"section-number\">9. </span>LLM Architectures Fundamentals", "<span class=\"section-number\">10. </span>MOE sparse models", "<span class=\"section-number\">24. </span>Application of LLM in IR", "<span class=\"section-number\">23. </span>Information Retrieval Fundamentals", "<span class=\"section-number\">8. </span>GPT Series", "<span class=\"section-number\">6. </span>BERT", "<span class=\"section-number\">2. </span>Language Models", "<span class=\"section-number\">3. </span>Early Neural Language Models", "<span class=\"section-number\">7. </span>Seq2Seq: T5 and BART", "<span class=\"section-number\">5. </span>Transformers", "<span class=\"section-number\">4. </span>Word Embeddings", "<span class=\"section-number\">17. </span>Inference acceleration", "<span class=\"section-number\">16. </span>LLM Decoding", "Multimodality fundamentals", "Vision transformers", "<span class=\"section-number\">21. </span>Advanced prompt techniques", "<span class=\"section-number\">20. </span>Basic prompt", "<span class=\"section-number\">23. </span>Advanced rag techniques", "<span class=\"section-number\">22. </span>Basic RAG", "<span class=\"section-number\">14. </span>LLM Training Acceleration", "<span class=\"section-number\">13. </span>LLM Alignement and Preference learning", "<span class=\"section-number\">12. </span>LLM Finetuning", "<span class=\"section-number\">11. </span>LLM Training Fundamentals", "&lt;no title&gt;", "Table of Contents"], "titleterms": {"": 7, "1": 5, "2": 5, "200": 5, "3": 5, "4": [], "5": [], "50th": [], "A": 19, "And": [6, 7], "For": 20, "In": 10, "It": 6, "Of": [7, 10], "On": 7, "One": 20, "The": [0, 1, 6, 7, 10, 11, 12, 13, 20, 21, 22], "To": 20, "With": [6, 10], "about": 0, "absolut": 1, "acceler": [12, 20], "accuraci": 5, "activ": [1, 20], "adadelta": [], "adagrad": 23, "adam": [20, 23], "adamw": 23, "adapt": [22, 23], "add": 7, "addit": 21, "advanc": [12, 16, 18], "advantag": 19, "ag": 0, "ai": 0, "albert": 6, "algebra": [], "algorithm": [12, 20, 21, 23], "align": 21, "alloc": 20, "alpha": 7, "altern": [], "among": 5, "an": [], "anaconda": [], "analysi": [9, 10, 22], "anatomi": [6, 10], "anoth": [], "answer": 5, "appear": 5, "appendix": 20, "applic": [3, 25], "applicationnlp": [], "approach": 22, "ar": [5, 6], "architectur": [1, 2, 6, 10, 25], "arithmet": 5, "around": 5, "articl": 5, "artifici": [], "assumpt": 12, "attent": [1, 10, 20], "augment": [], "awq": 12, "back": 7, "bart": 9, "base": [11, 17, 22], "basic": [1, 12, 13, 17, 19, 22], "bbpe": 1, "beam": 13, "behavior": 13, "benchmark": [6, 7], "bert": 6, "bertbas": 6, "bertlarg": 6, "between": [], "bia": 7, "bibliographi": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23], "book": [0, 5], "bpe": 1, "branch": 10, "breadown": 1, "breakdown": [1, 10], "byte": 1, "cach": 12, "can": 5, "card": 1, "case": 12, "caveat": 7, "cbow": 11, "cell": [], "ch": [], "chain": [16, 17], "challeng": 12, "channel": 12, "checkpoint": 20, "choic": [1, 7, 16, 23], "classif": 17, "close": 5, "collect": 21, "combin": [12, 16, 23], "comment": [], "common": 5, "commonli": 6, "commun": 20, "compar": 6, "comparis": 22, "comparison": [5, 10, 22], "complet": [], "complex": 13, "compon": 20, "componen": 6, "composit": 1, "comput": [1, 6, 10, 12, 13], "concept": 12, "configur": [1, 6], "consider": [], "consist": 16, "content": 25, "context": [1, 16, 17], "contextu": [], "contrast": 11, "control": 13, "convent": 10, "corpu": 5, "cost": 12, "cot": [16, 17], "cross": 7, "data": [20, 21], "dataset": 7, "decai": 23, "decod": [10, 13], "deep": [], "deepspe": 20, "denot": 1, "dens": 1, "dequant": 12, "deriv": 7, "descent": 23, "design": [], "detail": 1, "develop": 10, "devic": 20, "diagon": 12, "differ": [10, 20], "directli": [], "discount": 7, "distil": 6, "distillbert": 6, "distribut": 20, "dmodel": 1, "doe": 1, "down": 11, "dpo": 21, "draw": [], "drive": 21, "dure": [1, 20], "dynam": 16, "e": 6, "earli": 8, "edit": [], "effici": [6, 22], "electra": 6, "element": [], "elmo": 6, "embed": [1, 6, 11], "encod": [6, 10], "engin": [], "ensembl": 16, "entropi": 7, "environ": [], "error": 12, "estim": [7, 11], "evalu": [6, 7, 21], "exampl": [1, 11, 19], "exercis": [], "expans": 23, "extract": 17, "extrem": 6, "featur": [], "feed": [1, 8], "feedforward": 10, "few": 17, "fibonacci": [], "fine": [5, 6, 22], "finetun": 22, "five": 11, "flash": 20, "float": 20, "ford": [], "forward": [1, 8], "foundat": 25, "fp8": 12, "framework": 12, "frequent": 11, "from": [1, 20], "fulkerson": [], "fundament": [1, 2, 4, 12, 13, 14, 23], "further": [], "g": [], "g_k": 23, "g_t": [], "gener": [5, 9, 12, 16], "glove": 11, "gpt": 5, "gptq": 12, "gpu": 20, "gqa": [1, 12], "gradient": 23, "gram": [7, 11], "granular": 12, "graphic": [], "greedi": 13, "greek": [], "group": 1, "groupwis": 12, "h": 1, "happen": 12, "head": 1, "help": [], "here": 1, "hessian": 12, "hidden": 1, "how": 21, "human": 5, "hyperparamet": 6, "hypothesi": 22, "i": [10, 11, 12, 19], "identifi": 5, "ii": 11, "implement": 1, "import": [], "indent": [], "index": [], "infer": [12, 22, 25], "inform": [4, 25], "initi": 22, "input": [1, 6, 10], "insert": [], "instal": [], "instruct": [17, 22], "int8": 12, "intellig": [], "introduct": [0, 5, 6, 19, 25], "introductori": [], "ir": 3, "jupyt": [], "k": 13, "katz": 7, "kei": [], "kv": 12, "l": 1, "l_2": 23, "label": 21, "languag": [0, 5, 6, 7, 8, 10, 12], "larg": 0, "layer": [1, 6, 10], "learn": [16, 17, 21], "length": 1, "let": 20, "letter": [], "level": 1, "limit": [], "line": [], "lingual": 5, "list": [], "llama": 1, "lll": [], "llm": [0, 1, 2, 3, 12, 13, 17, 20, 21, 22, 23, 25], "lm": 6, "logist": 21, "loop": [], "lora": 22, "loss": 21, "low": 22, "machin": 5, "mani": [], "mask": [6, 10], "matric": 22, "matrix": 12, "maximum": 1, "mbert": 6, "mcl": 1, "mdp": 21, "mean": 1, "mechan": 1, "med": 16, "memori": [12, 20], "method": [22, 23], "methodologi": 21, "metric": 7, "mha": 1, "minibatch": 23, "minilm": 6, "minim": [12, 19], "mistral": 2, "mix": 20, "mle": 7, "mlp": 20, "mobilebert": 6, "modal": [], "model": [0, 1, 2, 5, 6, 7, 8, 10, 11, 12, 20, 21], "modul": [6, 10], "moe": 2, "momentum": 23, "more": 7, "most": 6, "motiv": [7, 8, 19, 20, 21, 22], "movi": 17, "mqa": 1, "multi": [1, 5], "multihead": 10, "multilingu": 6, "multimod": 14, "multipl": 12, "n": [7, 20], "name": [], "natur": 5, "necessari": 10, "neg": 11, "network": 12, "neural": [5, 8, 12], "new": 5, "next": 6, "nine": 11, "nois": 11, "noisecontrastiveestim": [], "norm": 1, "normal": 1, "notebook": [], "nsp": 6, "number": [1, 20], "numpi": [], "ob": 12, "off": [7, 12], "offlin": [], "one": 20, "onlin": 20, "oov": 7, "oper": 20, "optim": [11, 23], "other": 22, "out": 7, "output": [1, 10], "overal": [10, 21], "overview": [1, 5, 9, 10, 11, 12, 19, 20, 23], "p": 13, "packag": [], "pair": 5, "panda": [], "paper": [], "paradigam": 19, "parallel": 20, "paramet": [1, 6, 7, 22], "part": 20, "pass": 1, "pe": 1, "per": 12, "perform": [5, 9, 12], "perplex": 7, "phi": 20, "plot": [], "pointwis": 10, "polici": [], "popular": [], "posit": [1, 10], "post": 23, "postion": 1, "power": [], "ppo": 21, "practic": [2, 7], "practiv": 1, "pre": [6, 9], "precis": 20, "predict": 6, "prefer": 21, "preliminari": [12, 21], "pretrain": [5, 6, 9, 10, 23], "problem": 11, "process": 20, "program": 17, "prompt": [16, 17, 22, 25], "prune": 12, "public": 1, "put": 6, "python": [], "qualiti": 21, "quant": 12, "quantiz": 12, "queri": 1, "quest": [], "question": 5, "quickstart": [], "r": 6, "rag": [18, 19, 25], "random": [], "rank": 22, "rare": 7, "read": [], "reason": 5, "recurr": [8, 10], "refer": 12, "regress": 21, "reinforc": 21, "rel": [], "relationship": [7, 11, 21], "remark": 21, "requir": [12, 20], "respons": [21, 22], "retriev": [4, 25], "review": 17, "reward": 21, "rise": 0, "rl": 21, "rlhf": [21, 23], "rm": 1, "rmsprop": 23, "root": 1, "rotari": 1, "rtn": [], "run": [], "sampl": [6, 11, 13], "scale": 22, "scientif": [], "scipi": [], "search": 13, "sec": [], "select": 1, "self": [1, 16, 20], "semant": 11, "sens": 5, "sentenc": 6, "sentiment": 17, "seq2seq": 9, "sequenc": 10, "seri": 5, "set": 6, "sever": 1, "sft": [21, 23], "share": [], "short": 5, "shot": 17, "shuffl": 16, "simpl": [7, 21], "size": [1, 20, 23], "skip": 11, "slide": 1, "smooth": [7, 12, 21], "so": [], "softmax": 20, "softwar": 12, "solut": [], "solv": [], "sota": 5, "spars": [1, 2], "speed": 12, "speical": 12, "squar": 1, "stage": 20, "standard": 12, "star": 7, "start": [], "state": [1, 20], "statist": 7, "stochast": 23, "storag": 20, "strategi": [], "subpackag": [], "subword": 11, "summari": [1, 10, 20], "superglu": 5, "supervis": 5, "svd": 11, "symbol": [], "syntact": 11, "syntax": [], "system": [], "t": [], "t5": 9, "tab": [], "tabl": 25, "task": [5, 6, 9, 17], "techniqu": [7, 12, 16, 18, 20], "temperatur": 13, "tensor": [12, 20], "test": [], "text": [5, 9, 17], "thi": 0, "thought": [16, 17], "tinybert": 6, "todai": 6, "togeth": [6, 16, 23], "token": [1, 12], "tokenzi": 1, "top": 13, "total": [1, 20], "trade": [7, 12], "train": [1, 6, 9, 20, 22, 23, 25], "transform": [1, 10, 15], "translat": 5, "tune": [5, 6, 22], "two": 6, "ty": 1, "type": [11, 20], "un": [], "understand": [], "unicod": [], "uninstrut": [], "unsupervis": 5, "unveil": [], "up": 12, "updat": [], "url": [], "us": [6, 20], "v": [17, 21, 23], "varianc": 7, "variant": [1, 21], "variou": 6, "version": [], "via": [20, 21], "vision": 15, "visual": 11, "vocabulari": [1, 7], "volumn": 20, "weight": [1, 23], "what": [1, 12, 19], "where": 12, "whether": 5, "while": [], "white": [], "why": [], "window": 1, "word": [5, 7, 11], "word2vec": 11, "work": 21, "xlm": 6, "your": [], "zero": [17, 20]}})