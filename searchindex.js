Search.setIndex({"alltitles": {"": [[1, "example-2"], [1, "example-4"], [1, "remark-6"], [1, "example-7"], [6, "example-1"], [9, "example-0"], [9, "example-1"], [11, "example-0"], [12, "example-0"], [13, "example-0"], [13, "example-1"], [14, "example-0"], [14, "example-2"], [19, "example-3"], [20, "example-1"], [20, "example-2"], [21, "example-3"], [21, "example-6"], [22, "example-0"]], " ((Skip-gram vs CBOW performance))": [[13, "remark-3"]], " (A minimal RAG example)": [[21, "example-0"]], " (A,B initialization and model inference)": [[24, "remark-1"]], " (Adam stochastic gradient descent algorithm with weight decay)": [[26, "Adam_stochastic_gradient_descent_algorithm_with_weight_decay"]], " (Adam stochastic gradient descent algorithm)": [[26, "Adam_stochastic_gradient_descent_algorithm"]], " (BPE)": [[1, "BPE-algorithm"]], " (Caveats)": [[9, "remark-3"]], " (Challenging reasoning queries for dense retriever)": [[21, "example-4"]], " (Combine to RoPE)": [[1, "remark-1"]], " (Comparision of base LLM and instructed LLM in response to a prompt)": [[24, "example-0"]], " (Design considerations for fusing image understanding signals)": [[17, "remark-0"]], " (Dropout on attention weight)": [[12, "remark-1"]], " (Effective implementing PPO is critical)": [[23, "remark-8"]], " (Encoder layer)": [[8, "definition-0"], [12, "chapter_foundation_def_pretrained_LM_transformer_encoder_layer"]], " (Expansion of G_k)": [[26, "remark-2"]], " (FLOPs estimation)": [[1, "remark-8"]], " (Finite state Markov decision process (MDP))": [[25, "definition-0"]], " (How DPO loss work)": [[23, "remark-6"]], " (Imperfections of the masking strategy.)": [[8, "remark-2"]], " (Implicit reward)": [[23, "remark-5"]], " (Importance of adaptive learning rate)": [[26, "remark-3"]], " (Is feedforward layer necessary for Transformer?)": [[12, "remark-3"]], " (Iterative reward model and policy improvement)": [[23, "example-0"]], " (KV-cache pre-fill for prompts)": [[14, "remark-1"]], " (Knowledge graph example)": [[21, "example-1"]], " (LLM prompt to query rewrite)": [[21, "example-2"]], " (Minibatch stochastic gradient descent algorithm)": [[26, "Minibatch_stochastic_gradient_descent_algorithm"]], " (Monitor DPO training process)": [[23, "remark-7"]], " (OBS Neural Network Pruning Algorithm)": [[14, "OBS_network_pruning_algorithm"]], " (Per-channel quantization)": [[14, "example-4"]], " (Per-tensor quantization)": [[14, "example-3"]], " (Practical simple back-off)": [[9, "remark-2"]], " (Relationship to Cross Entropy)": [[9, "remark-4"]], " (Relationship to logistic regression)": [[23, "remark-4"]], " (SFT on positive only data can lead to over-generalization)": [[23, "example-3"]], " (Self-RAG Inference)": [[20, "algorithm-0"]], " (Skip-gram and CBOW optimization problem)": [[13, "chapter_foundation_word_embedding_def_skipGramOptimization"]], " (The importance of accurate reward model)": [[23, "remark-1"]], " (The policy iteration algorithm for MDP)": [[25, "ch:reinforcement-learning:alg:policyIterationMDP"]], " (Translation pairs can appear naturally in pretraining text corpus)": [[7, "example-0"]], " (Value iteration algorithm for a finite state MDP)": [[25, "ch:reinforcement-learning:alg:valueIterationAlg"]], " (Weighting scheme for long queries)": [[6, "remark-2"]], " (What does Byte-level mean?)": [[1, "remark-5"]], " (Why we need \\gamma and \\beta)": [[1, "remark-0"]], " (Why we need a semantic understanding model)": [[6, "remark-0"]], " (Zero shot prompt for movie review sentiment classification)": [[19, "example-0"]], " (Zero shot prompt for programming task)": [[19, "example-2"]], " (Zero shot prompt for text extracting)": [[19, "example-1"]], " (choice of minibatch size)": [[26, "remark-1"]], " (computation in decoder module)": [[12, "definition-5"]], " (computation in encoder module)": [[8, "chapter_foundation_def_pretrained_LM_transformer_bert_encoder_computation"], [12, "chapter_foundation_def_pretrained_LM_transformer_encoder_computation"]], " (connections between MSE loss and KL loss)": [[6, "remark-3"]], " (convergence property of iterative policy evaluation)": [[25, "ch:reinforcement-learning:th:convergenceIterativePolicyEvaluation"]], " (convergence property of value iteration)": [[25, "ch:reinforcement-learning:th:valueIterationConvergence"]], " (error estimation and stopping criterion)": [[25, "remark-8"]], " (examples of reward functions)": [[25, "example-1"]], " (exploitation and exploration aspects from \\gamma)": [[23, "remark-2"]], " (policy improvement theorem)": [[25, "ch:reinforcement-learning:th:policyImprovementT"]], " (recursive relation for value functions)": [[25, "remark-6"]], " (recursive relations of the Q function)": [[25, "lemma-5"]], " (recursive relationship of value functions)": [[25, "ch:reinforcement-learning:th:recursiveRelationshipValueFunctionMDP"]], " (shared product quantizer for residuals)": [[6, "remark-4"]], " (sparse retrieval vs dense retrieval for legal documents)": [[21, "example-5"]], " (state-action value function - Q function)": [[25, "definition-4"]], " (value functions)": [[25, "definition-2"]], " (value iteration vs. policy iteration; model-based vs. model-free)": [[25, "remark-13"]], "*Annotated LLama": [[31, null]], "*Lab: DPO Training": [[35, null]], "*Lab: Decoding": [[33, null]], "*Lab: Finetuning": [[36, null]], "*Lab: Instruction Finetuning": [[34, null]], "*Lab: LLM Pretraining": [[37, null], [38, null], [39, null]], "*Lab: Minimal LLama": [[32, null]], "*Reinforcement Learning Essentials": [[25, null]], "A unified perspective from matching": [[5, "a-unified-perspective-from-matching"]], "ALBERT": [[8, "albert"]], "ALiBi": [[1, "alibi"]], "AWQ": [[14, "awq"]], "About This Book": [[0, "about-this-book"]], "Absolute Position Encoding": [[1, "absolute-position-encoding"]], "Activation Checkpointing Techniques": [[22, "activation-checkpointing-techniques"]], "Activations": [[22, "activations"]], "Ad-hoc Retrieval": [[6, "ad-hoc-retrieval"]], "Ad-hoc retrieval": [[5, "ad-hoc-retrieval"]], "Adam": [[26, "adam"]], "Adapter Tuning": [[24, "adapter-tuning"]], "Adaptive Gradient (AdaGrad)": [[26, "adaptive-gradient-adagrad"]], "Adaptive Gradient Method": [[26, "adaptive-gradient-method"]], "Add \\alpha Smoothing and Discounting": [[9, "add-alpha-smoothing-and-discounting"]], "Advanced Architectures": [[6, "advanced-architectures"]], "Advanced Prompting Techniques": [[18, null]], "Advanced Query Categorization": [[21, "advanced-query-categorization"]], "Advanced RAG (WIP)": [[20, null]], "Advanced quantization techniques": [[14, "advanced-quantization-techniques"]], "Agentic RAG": [[20, "agentic-rag"]], "Alignment Using RLHF": [[23, "alignment-using-rlhf"]], "Analysis of Documents": [[28, "analysis-of-documents"]], "Analysis of Queries": [[28, null]], "Appendix": [[22, "appendix"]], "Application in Information Retrieval": [[30, null]], "Application in RAG": [[4, "application-in-rag"]], "Application of LLM in IR (WIP)": [[4, null]], "Approach to Complex Multi-Concept Queries": [[21, "approach-to-complex-multi-concept-queries"]], "Approach to Multi-Turn Conversations": [[21, "approach-to-multi-turn-conversations"]], "Approach to Vocalbulary Mismatch": [[21, "approach-to-vocalbulary-mismatch"]], "Approximate Nearest Neighbor Search": [[6, "approximate-nearest-neighbor-search"]], "Approximate Non-exhaustive Nearest Neighbor Search": [[6, "approximate-non-exhaustive-nearest-neighbor-search"]], "Approximate Representation And Storage": [[6, "approximate-representation-and-storage"]], "Approximate nearest neighbor search": [[5, "approximate-nearest-neighbor-search"]], "Approximate non-exhaustive nearest neighbor search": [[5, "approximate-non-exhaustive-nearest-neighbor-search"]], "Approximate representation and storage": [[5, "approximate-representation-and-storage"]], "Approximating Distances Using Quantized Codes": [[6, "approximating-distances-using-quantized-codes"], [6, "id66"]], "Approximating distances using quantized codes": [[5, "approximating-distances-using-quantized-codes"], [5, "id80"]], "Architecture": [[2, "architecture"], [5, "architecture"], [5, "id88"]], "Arithmetic tasks": [[7, "arithmetic-tasks"]], "Attention Layer": [[31, "attention-layer"], [32, "attention-layer"], [40, "attention-layer"]], "Attention and FFN": [[34, "attention-and-ffn"]], "BART": [[11, "bart"]], "BERT": [[8, null]], "BERT Architecture Componenents": [[8, "bert-architecture-componenents"]], "BERT bi-encoder and BM25": [[5, "bert-bi-encoder-and-bm25"]], "BERT model parameters": [[8, "id1598"]], "BLIP": [[17, "blip"]], "BLIP-2": [[17, "blip-2"]], "BM25": [[5, "bm25"], [6, "bm25"]], "BM25 Implementation": [[6, "bm25-implementation"]], "BPE Tokenization": [[1, "bpe-tokenization"]], "Base LLM vs Instructed LLM": [[19, "base-llm-vs-instructed-llm"]], "Basic Concepts": [[14, "basic-concepts"]], "Basic Prompting": [[19, null]], "Basic RAG": [[21, "basic-rag"]], "Basics": [[5, "basics"], [14, "basics"], [15, "basics"], [24, "basics"]], "Beam Decoding": [[33, "beam-decoding"]], "Beam search decoding": [[15, "beam-search-decoding"]], "Benchmark Datasets": [[6, "benchmark-datasets"]], "Benchmark datasets": [[5, "benchmark-datasets"]], "Benchmarking": [[9, "benchmarking"]], "Bi-encoder Teacher Distillation": [[6, "bi-encoder-teacher-distillation"]], "Bibliography": [[1, "bibliography"], [2, "bibliography"], [3, "bibliography"], [4, "bibliography"], [5, "bibliography"], [6, "bibliography"], [7, "bibliography"], [8, "bibliography"], [9, "bibliography"], [10, "bibliography"], [11, "bibliography"], [12, "bibliography"], [13, "bibliography"], [14, "bibliography"], [15, "bibliography"], [17, "bibliography"], [18, "bibliography"], [19, "bibliography"], [20, "bibliography"], [21, "bibliography"], [22, "bibliography"], [23, "bibliography"], [24, "bibliography"], [26, "bibliography"]], "Blender": [[5, "blender"]], "Blocked KV Caching via Paged Attention": [[14, "blocked-kv-caching-via-paged-attention"]], "Bootstraping Instruction Finetuning": [[24, "bootstraping-instruction-finetuning"]], "Building a language model": [[5, "building-a-language-model"]], "Building an Error Model": [[5, "building-an-error-model"]], "Building models": [[5, "building-models"]], "CLEAR": [[5, "clear"]], "CLIP": [[17, "clip"]], "CNN-DSSM": [[5, "cnn-dssm"], [6, "cnn-dssm"]], "COIL": [[5, "coil"]], "COIL-token and uni-COIL": [[5, "coil-token-and-uni-coil"]], "Candidate generation": [[5, "candidate-generation"], [5, "id89"]], "Chain-of-Thought (CoT) Prompting": [[19, "chain-of-thought-cot-prompting"]], "Challenges": [[21, "challenges"]], "Challenges And Opportunities In IR Systems": [[6, "challenges-and-opportunities-in-ir-systems"]], "Challenges and approaches": [[5, "challenges-and-approaches"]], "Challenges and opportunities in IR systems": [[5, "challenges-and-opportunities-in-ir-systems"]], "Char-level N grams": [[5, "char-level-n-grams"]], "Choice Shuffling Ensembling": [[18, "choice-shuffling-ensembling"]], "Choices Of n and Bias-variance Trade-off": [[9, "choices-of-n-and-bias-variance-trade-off"]], "Classic Representation-based Learning": [[6, "classic-representation-based-learning"]], "Classic interaction-based matching": [[5, "classic-interaction-based-matching"]], "Classic representation-based learning": [[5, "classic-representation-based-learning"]], "Classic semantic dense retrieval models": [[5, "classic-semantic-dense-retrieval-models"]], "Closed-book question answering": [[7, "closed-book-question-answering"]], "CoRT": [[5, "cort"]], "CoT with Self-Consistency": [[18, "cot-with-self-consistency"]], "ColBERT": [[5, "colbert"], [6, "colbert"]], "Collections": [[4, "collections"]], "Combined Together: Adam and AdamW": [[26, "combined-together-adam-and-adamw"]], "Combined with GQA": [[14, "combined-with-gqa"]], "Combining Together Example: Med Prompt": [[18, "combining-together-example-med-prompt"]], "Common Sense Reasoning": [[7, "common-sense-reasoning"]], "Common-sense reasoning": [[3, "common-sense-reasoning"]], "Communication volumne summary for different operations. Let \\Phi be the total data size in one device and N be the total number of devices.": [[22, "id1576"]], "Compared with ELMO": [[8, "compared-with-elmo"]], "Comparison of pre-training objectives. Performance varies considerably across tasks, but the BART models with text infilling demonstrate the most consistently strong performance. .": [[11, "id1577"]], "Comparison with Recurrent Layer in Sequence Modeling": [[12, "comparison-with-recurrent-layer-in-sequence-modeling"]], "Comparison with other approaches": [[24, "comparison-with-other-approaches"]], "Comparison with recommender system": [[5, "comparison-with-recommender-system"]], "Composite benchmarks": [[3, "composite-benchmarks"]], "Computation breakdown": [[1, "id1601"], [14, "id1582"]], "Computational Breakdown Analysis": [[12, "computational-breakdown-analysis"]], "Computational Efficiency": [[6, "computational-efficiency"]], "Computational complexity": [[15, "computational-complexity"]], "Computational cost with KV Cache": [[14, "computational-cost-with-kv-cache"]], "Computational efficiency": [[5, "computational-efficiency"]], "Context specific features": [[5, "context-specific-features"]], "Context-aware Term Importance: Deep-CT": [[6, "context-aware-term-importance-deep-ct"]], "Context-aware term importance: Deep-CT": [[5, "context-aware-term-importance-deep-ct"]], "Context-dependent and personalized search": [[5, "context-dependent-and-personalized-search"]], "Contextual Embedding": [[8, "contextual-embedding"]], "Contextualized Term Importance": [[6, "contextualized-term-importance"]], "Contextualized sparse representation": [[5, "contextualized-sparse-representation"]], "Contextualized term importance": [[5, "contextualized-term-importance"]], "Continued Pretraining": [[26, "continued-pretraining"]], "Controling beam search behavior": [[15, "controling-beam-search-behavior"]], "Corrective RAG (CRAG)": [[20, "corrective-rag-crag"]], "Cross-Encoder Embedding Similarity Distillation": [[6, "cross-encoder-embedding-similarity-distillation"]], "DC-BERT": [[5, "dc-bert"], [6, "dc-bert"]], "DPO": [[23, "dpo"]], "DPO Variants": [[23, "dpo-variants"]], "DPO-Positive": [[23, "dpo-positive"]], "DRMM": [[5, "drmm"]], "DSSM": [[5, "dssm"], [6, "dssm"]], "Data": [[34, "data"], [35, "data"], [36, "data"], [37, "data"], [38, "data"], [39, "data"]], "Data Source Augmentation": [[21, "data-source-augmentation"]], "Data mixture and schedule": [[26, "data-mixture-and-schedule"]], "Data sources and cleaning": [[26, "data-sources-and-cleaning"]], "Datasets": [[9, "datasets"]], "Decoder Anatomy": [[12, "decoder-anatomy"]], "Decoder for language modeling": [[31, "decoder-for-language-modeling"], [32, "decoder-for-language-modeling"], [36, "decoder-for-language-modeling"], [40, "decoder-for-language-modeling"]], "Decoding": [[15, null]], "Decoding Fundamentals": [[15, "decoding-fundamentals"]], "DeepSeek MoE": [[2, "deepseek-moe"]], "DeepSeek V3": [[2, "deepseek-v3"]], "Dense Architecture Examples": [[1, "dense-architecture-examples"]], "Detailed Implementations": [[17, "detailed-implementations"]], "Different Branches Of Developments": [[12, "different-branches-of-developments"]], "Different factors to consider when choosing among prompting, fine-tuning, and RAG.": [[21, "id1586"]], "Discussion": [[5, "discussion"]], "Discussion: DPO vs RL": [[23, "discussion-dpo-vs-rl"]], "Discussion: Reward Model Criticality": [[23, "discussion-reward-model-criticality"]], "Discussion: SFT vs RLHF": [[23, "discussion-sft-vs-rlhf"]], "DistillBERT": [[8, "distillbert"]], "Distributed Parallel Training": [[22, "distributed-parallel-training"]], "Diversity Optimization": [[21, "diversity-optimization"]], "Doc-Doc N-pair Loss": [[6, "doc-doc-n-pair-loss"]], "Document Chunk Relationship": [[21, "document-chunk-relationship"]], "Document Expansion Via Query Prediction": [[6, "document-expansion-via-query-prediction"]], "Document Parsing": [[21, "document-parsing"]], "Document Ranking Task": [[5, "document-ranking-task"], [6, "document-ranking-task"]], "Document Splitting and Granularity": [[21, "document-splitting-and-granularity"]], "Document expansion via query prediction": [[5, "document-expansion-via-query-prediction"]], "Document offline ranking": [[5, "document-offline-ranking"]], "Document selection": [[5, "document-selection"], [5, "id76"]], "Document selection overview": [[5, "document-selection-overview"]], "Document specific features": [[5, "document-specific-features"]], "Document term generation": [[5, "document-term-generation"]], "Downstream Application": [[17, "downstream-application"]], "Driving the DPO": [[23, "driving-the-dpo"]], "Dual Chunk Attention": [[1, "dual-chunk-attention"]], "Duet": [[5, "duet"]], "Duo-BERT For Pairwise Ranking": [[6, "duo-bert-for-pairwise-ranking"]], "Duo-BERT for pairwise ranking": [[5, "duo-bert-for-pairwise-ranking"]], "Dynamic Hard Negative Examples": [[6, "dynamic-hard-negative-examples"]], "Dynamic In-Context Learning": [[18, "dynamic-in-context-learning"]], "Dynamic hard negative examples": [[5, "dynamic-hard-negative-examples"]], "Early Neural Language Models": [[10, null]], "Efficient BERT Models": [[8, "efficient-bert-models"]], "Embedding-based approach": [[5, "embedding-based-approach"]], "Encoder Computation Summary": [[12, "encoder-computation-summary"]], "Enhancing sparse IR via dense methods": [[5, "enhancing-sparse-ir-via-dense-methods"]], "Enriching document representations": [[5, "enriching-document-representations"]], "Enriching query representations": [[5, "enriching-query-representations"]], "Ensemble Teacher Distillation": [[6, "ensemble-teacher-distillation"]], "Ensemble teacher distillation": [[5, "ensemble-teacher-distillation"]], "Evaluation Metrics": [[9, "evaluation-metrics"]], "Exact Match And Semantic Match": [[6, "exact-match-and-semantic-match"]], "Exact Match Framework": [[6, "exact-match-framework"]], "Exact match and semantic match": [[5, "exact-match-and-semantic-match"]], "Example Distillation Strategies": [[6, "example-distillation-strategies"]], "Example distillation strategies": [[5, "example-distillation-strategies"]], "Examples of five types of semantic relationships.": [[13, "id1580"]], "Examples of nine types of syntactic relationships.": [[13, "id1581"]], "Extending Context Windows via RoPE": [[1, "extending-context-windows-via-rope"]], "FFN Layer": [[31, "ffn-layer"], [32, "ffn-layer"], [40, "ffn-layer"]], "FP8": [[14, "fp8"]], "False Negatives": [[6, "false-negatives"]], "False Positives": [[6, "false-positives"]], "False negatives": [[5, "false-negatives"]], "False positives": [[5, "false-positives"]], "Feature engineering": [[5, "feature-engineering"]], "Feed-forward Neural Language Model": [[10, "feed-forward-neural-language-model"]], "Few-shot and in-context learning": [[19, "few-shot-and-in-context-learning"]], "Fine-tuning and Evaluation": [[8, "fine-tuning-and-evaluation"]], "Finite-state MDP": [[25, "finite-state-mdp"]], "Floating Data Types": [[22, "floating-data-types"]], "Forward Pass Computation Breadown": [[1, "forward-pass-computation-breadown"]], "Framework": [[5, "framework"]], "From BPE to BBPE": [[1, "from-bpe-to-bbpe"]], "From Vector Quantization To Product Quantization": [[6, "from-vector-quantization-to-product-quantization"]], "From vector quantization to product quantization": [[5, "from-vector-quantization-to-product-quantization"]], "Fundamentals": [[21, "fundamentals"], [26, "fundamentals"]], "Further RAG Discussion": [[21, "further-rag-discussion"]], "GEFEED (Retrieval Feedback)": [[4, "gefeed-retrieval-feedback"]], "GPT Series": [[7, null]], "GPT-1": [[7, "gpt-1"]], "GPT-1 Fine Tuning": [[7, "gpt-1-fine-tuning"]], "GPT-2": [[7, "gpt-2"]], "GPT-3": [[7, "gpt-3"]], "GPT-3-175B with different adaptation methods on the language understanding benchmark.": [[24, "id1592"]], "GPTQ": [[14, "gptq"]], "GPU Memory Allocation": [[22, "gpu-memory-allocation"]], "GPU Parallel Operations": [[22, "gpu-parallel-operations"]], "General Case": [[14, "general-case"]], "Generative SERP": [[4, "generative-serp"]], "GloVe": [[13, "glove"]], "Graph-based Retrieval": [[20, "graph-based-retrieval"]], "GraphRAG": [[20, "graphrag"]], "Greedy Decoding": [[33, "greedy-decoding"]], "Greedy decoding": [[15, "greedy-decoding"]], "Grouped Query Attention (GQA)": [[1, "grouped-query-attention-gqa"]], "Groupwise quantization": [[14, "groupwise-quantization"]], "Hard Positives": [[6, "hard-positives"]], "Hierarchical Quantization And Inverted File Indexing": [[6, "hierarchical-quantization-and-inverted-file-indexing"]], "Hierarchical quantization and inverted file indexing": [[5, "hierarchical-quantization-and-inverted-file-indexing"]], "How labeler evaluates the response quality": [[23, "id1591"]], "Human accuracy in identifying whether short (around 200 word) news articles are model generated.": [[7, "id1575"]], "Hybrid retrieval models": [[5, "hybrid-retrieval-models"]], "Indexing Data Sources": [[21, "indexing-data-sources"]], "Indexing and serving": [[5, "indexing-and-serving"]], "Indexing tokens": [[5, "indexing-tokens"]], "Inference Acceleration (WIP)": [[14, null]], "Inference Memory Requirement with KV Cache": [[14, "inference-memory-requirement-with-kv-cache"]], "Information Retrieval and Text Ranking": [[6, null]], "Information retrieval and neural matching": [[5, "information-retrieval-and-neural-matching"]], "Input Embeddings": [[8, "input-embeddings"]], "Input Output Conventions": [[12, "input-output-conventions"]], "Instruct BLIP": [[17, "instruct-blip"]], "Instruction Finetuning": [[24, "instruction-finetuning"]], "Insturction Finetuning Loss Functions": [[24, "insturction-finetuning-loss-functions"]], "Introduction": [[5, "introduction"], [5, "id43"], [5, "id59"], [5, "id83"], [5, "id85"], [5, "id90"], [6, "introduction"], [6, "id53"], [7, "introduction"], [7, "id4"], [8, "introduction"], [8, "id19"], [17, "introduction"], [30, null]], "Introduction: LLM in the Age of AI": [[0, null]], "Inverted file indexing and non exhaustive search": [[5, "inverted-file-indexing-and-non-exhaustive-search"]], "Inverted index": [[5, "inverted-index"]], "Inverted indexing": [[5, "inverted-indexing"]], "Inverted indexing construction": [[5, "inverted-indexing-construction"]], "Iterative Alignment": [[23, "iterative-alignment"]], "KNRM": [[5, "knrm"]], "KV Cache": [[14, "kv-cache"]], "Katz\u2019s Back-off": [[9, "katz-s-back-off"]], "Key Componenents": [[2, "key-componenents"]], "Key Design": [[20, "key-design"]], "Knowledge Distillation": [[6, "knowledge-distillation"]], "Knowledge Distillation Training Framework": [[6, "knowledge-distillation-training-framework"]], "Knowledge Extraction": [[20, "knowledge-extraction"]], "Knowledge distillation": [[5, "knowledge-distillation"]], "Knowledge distillation training framework": [[5, "knowledge-distillation-training-framework"]], "LLM Alignement and Preference Learning": [[23, null]], "LLM Architectures": [[30, null]], "LLM Architectures Fundamentals": [[1, null]], "LLM Embedding Model": [[4, "llm-embedding-model"]], "LLM Evaluation": [[3, null]], "LLM Finetuning": [[24, null]], "LLM Foundations": [[30, null]], "LLM Inference": [[30, null]], "LLM Model": [[34, "llm-model"]], "LLM Training": [[30, null]], "LLM Training Acceleration (WIP)": [[22, null]], "LLM Training Fundamentals": [[26, null]], "LLM.int8()": [[14, "llm-int8"]], "LLama Decoder Layer": [[31, "llama-decoder-layer"], [32, "llama-decoder-layer"], [40, "llama-decoder-layer"]], "LLama-2 Alignment in Practice": [[23, "llama-2-alignment-in-practice"]], "L_2 Weight Decay and AdamW": [[26, "l-2-weight-decay-and-adamw"]], "Label Denoising": [[6, "label-denoising"]], "Label denoising": [[5, "label-denoising"]], "LambdaNet": [[5, "lambdanet"]], "Language Models": [[9, null]], "Language Understanding Tasks": [[11, "language-understanding-tasks"]], "Language modeling": [[7, "language-modeling"]], "Language models for speller": [[5, "language-models-for-speller"]], "Language-model based approach": [[5, "language-model-based-approach"]], "Large-Scale Negatives": [[6, "large-scale-negatives"]], "Layer Normalization": [[1, "layer-normalization"]], "Layer normalization basics": [[1, "layer-normalization-basics"]], "Layer normalization example choices": [[1, "layer-normalization-example-choices"]], "Layer normalization position": [[1, "layer-normalization-position"]], "Learnable context-aware term importance: Deep-Impact": [[5, "learnable-context-aware-term-importance-deep-impact"]], "Learning to rank candidates": [[5, "learning-to-rank-candidates"]], "Learning-to-rank objective": [[5, "learning-to-rank-objective"]], "Limitations and Challenges": [[13, "limitations-and-challenges"]], "Links": [[29, "links"]], "LoRA (Low-Rank Adaptation)": [[24, "lora-low-rank-adaptation"]], "Load Balance Consideration": [[2, "load-balance-consideration"]], "Load Balancing": [[2, "load-balancing"]], "Load Balancing Loss": [[2, "load-balancing-loss"]], "Loss-Free Load Balanace": [[2, "loss-free-load-balanace"]], "ME-BERT": [[5, "me-bert"]], "MS MARCO": [[5, "ms-marco"], [6, "ms-marco"]], "MTP": [[2, "mtp"]], "Machine Translation": [[7, "machine-translation"]], "Markov Decision Process (MDP) and Reinforcement learning": [[23, "markov-decision-process-mdp-and-reinforcement-learning"]], "Masked Language Modeling (Masked LM)": [[8, "masked-language-modeling-masked-lm"]], "Mathematical reasoning": [[3, "mathematical-reasoning"]], "Mean Average Precision": [[5, "id9"]], "Mean average precision": [[5, "mean-average-precision"]], "Mean reciprocal rank (MRR)": [[5, "mean-reciprocal-rank-mrr"]], "Memory Requirement Breakdown": [[14, "memory-requirement-breakdown"]], "Memory requirement breakdown": [[14, "id1581"]], "Metrics": [[5, "metrics"]], "MiniLM": [[8, "minilm"]], "Minibatch Stochastic Gradient Descent": [[26, "minibatch-stochastic-gradient-descent"]], "Mixed Precision Training": [[22, "mixed-precision-training"]], "MoE Sparse Architectures (WIP)": [[2, null]], "MoE architecture fundamentals": [[2, "moe-architecture-fundamentals"]], "MoE vs Dense Model": [[2, "moe-vs-dense-model"]], "MobileBERT": [[8, "mobilebert"]], "Model": [[37, "model"], [39, "model"]], "Model Architecture": [[17, "model-architecture"], [17, "id6"], [34, "model-architecture"]], "Model Distillation": [[8, "model-distillation"]], "Model Evaluation": [[9, "model-evaluation"]], "Model Fine Tuning": [[11, "model-fine-tuning"]], "Model Finetuning": [[21, "model-finetuning"]], "Model Parameter Estimation": [[9, "model-parameter-estimation"]], "Model Training Objective Functions": [[6, "model-training-objective-functions"]], "Model and Optimizer States": [[22, "model-and-optimizer-states"]], "Model architecture and training": [[5, "model-architecture-and-training"]], "Model configuration of Qwen2 and Mistral, which uses GQA (# KV heads is number of groups )": [[1, "id1599"]], "Model parallelism (tensor parallelism)": [[22, "model-parallelism-tensor-parallelism"]], "Model training objective functions": [[5, "model-training-objective-functions"]], "Modern IR Systems": [[5, "modern-ir-systems"], [6, "modern-ir-systems"]], "Momentum Method": [[26, "momentum-method"]], "Mono T5": [[5, "mono-t5"]], "Mono-BERT (Cross-Encoder) For Point-wise Ranking": [[6, "mono-bert-cross-encoder-for-point-wise-ranking"]], "Mono-BERT And Duo-BERT": [[6, "mono-bert-and-duo-bert"]], "Mono-BERT for point-wise ranking": [[5, "mono-bert-for-point-wise-ranking"]], "More On Perplexity": [[9, "more-on-perplexity"]], "Motivation": [[1, "motivation"], [2, "motivation"], [5, "motivation"], [5, "id58"], [5, "id67"], [5, "id69"], [6, "motivation"], [9, "motivation"], [10, "motivation"], [20, "motivation"], [21, "motivation"], [21, "id8"], [24, "motivation"]], "Motivation and Objective": [[21, "motivation-and-objective"]], "Motivation and Overview": [[23, "motivation-and-overview"], [24, "motivation-and-overview"]], "Motivations": [[5, "motivations"]], "Multi Query Attention (MQA)": [[1, "multi-query-attention-mqa"]], "Multi-Attribute and Multi-task Modeling": [[6, "multi-attribute-and-multi-task-modeling"]], "Multi-Head Attention (MHA)": [[1, "multi-head-attention-mha"]], "Multi-Head Latent Attention (MLA)": [[1, "multi-head-latent-attention-mla"]], "Multi-step Decoding": [[15, "multi-step-decoding"]], "Multi-teacher distillation": [[5, "multi-teacher-distillation"]], "Multi-vector Representations": [[6, "multi-vector-representations"]], "Multi-vector representations": [[5, "multi-vector-representations"]], "Multihead Attention with Masks": [[12, "multihead-attention-with-masks"]], "Multihead Decoding (Medusa)": [[15, "multihead-decoding-medusa"]], "Multilingual Models": [[8, "multilingual-models"]], "Multilingual-BERT (mBERT)": [[8, "multilingual-bert-mbert"]], "Multimodality fundamentals": [[16, null]], "Multiple Token Prediction": [[26, "multiple-token-prediction"]], "Multiple streams and BM25F": [[5, "multiple-streams-and-bm25f"]], "Multistage Retrieval And Ranking Pipeline": [[6, "multistage-retrieval-and-ranking-pipeline"]], "Multistage retrieval and ranking pipeline": [[5, "multistage-retrieval-and-ranking-pipeline"]], "N-pair Dual Loss": [[6, "n-pair-dual-loss"]], "N-pair Loss": [[6, "n-pair-loss"]], "N-pair dual loss": [[5, "n-pair-dual-loss"]], "N-pair loss": [[5, "n-pair-loss"]], "NTK-Aware RoPE": [[1, "ntk-aware-rope"]], "NTK-by-parts and YaRN": [[1, "ntk-by-parts-and-yarn"]], "NV-Embed": [[4, "nv-embed"]], "Natural Language Queries": [[4, "natural-language-queries"]], "Natural Question (NQ)": [[5, "natural-question-nq"], [6, "natural-question-nq"]], "Negative Sampling Methods I: Heuristic Methods": [[6, "negative-sampling-methods-i-heuristic-methods"]], "Negative Sampling Methods II: Model-based Methods": [[6, "negative-sampling-methods-ii-model-based-methods"]], "Negative sampling methods I: heuristic methods": [[5, "negative-sampling-methods-i-heuristic-methods"]], "Negative sampling methods II: model-based methods": [[5, "negative-sampling-methods-ii-model-based-methods"]], "Neural pseudo relevance feedback (NPRF)": [[5, "neural-pseudo-relevance-feedback-nprf"]], "Neural sparse representation learning model": [[5, "neural-sparse-representation-learning-model"]], "Neural text ranking and information retrieval": [[5, null]], "News article generation": [[7, "news-article-generation"]], "Next Sentence Prediction (NSP)": [[8, "next-sentence-prediction-nsp"]], "Noise Contrastive Estimation": [[13, "noise-contrastive-estimation"]], "Nonlinearity in FFN": [[1, "nonlinearity-in-ffn"]], "Normalized Discounted Cumulative Gain (NDCG)": [[6, "normalized-discounted-cumulative-gain-ndcg"]], "Normalized discounted cumulative gain (NDCG)": [[5, "normalized-discounted-cumulative-gain-ndcg"]], "Notations": [[25, "notations"]], "Note On Bibliography And Software": [[6, "note-on-bibliography-and-software"]], "Note on bibliography and software": [[5, "note-on-bibliography-and-software"]], "Offline computation and indexing for re-ranking and retrieval": [[5, "offline-computation-and-indexing-for-re-ranking-and-retrieval"]], "Online Metrics": [[6, "online-metrics"]], "Online metrics": [[5, "online-metrics"]], "Online query processing": [[5, "online-query-processing"]], "Open-domain Question Answering": [[6, "open-domain-question-answering"]], "Open-domain question answering": [[5, "open-domain-question-answering"]], "Optimization Algorithms": [[26, "optimization-algorithms"]], "Optimization I: negative sampling": [[13, "optimization-i-negative-sampling"]], "Optimization II: down-sampling of frequent words": [[13, "optimization-ii-down-sampling-of-frequent-words"]], "Out Of Vocabulary (OOV) Words and Rare Words": [[9, "out-of-vocabulary-oov-words-and-rare-words"]], "Overall Architecture": [[12, "overall-architecture"]], "Overall architecture": [[5, "overall-architecture"]], "Overall methodology": [[23, "overall-methodology"]], "Overview": [[1, "overview"], [2, "overview"], [5, "overview"], [5, "id20"], [5, "id25"], [5, "id47"], [5, "id74"], [5, "id77"], [5, "id78"], [5, "id92"], [6, "overview"], [6, "id56"], [6, "id64"], [11, "overview"], [11, "id3"], [12, "overview"], [13, "overview"], [14, "overview"], [17, "overview"], [22, "overview"], [23, "overview"], [23, "id19"], [25, "overview"]], "Overview of Information Retrieval": [[6, "overview-of-information-retrieval"]], "Overview of evaluation metrics": [[3, "overview-of-evaluation-metrics"]], "Overview of information retrieval": [[5, "overview-of-information-retrieval"]], "Overview of parallel training techniques": [[22, "overview-of-parallel-training-techniques"]], "Pairwise Ranking via Triplet Loss": [[6, "pairwise-ranking-via-triplet-loss"]], "Pairwise ranking objective": [[5, "pairwise-ranking-objective"]], "Pairwise ranking via triplet loss": [[5, "pairwise-ranking-via-triplet-loss"]], "Parameter composition in Transformer models": [[1, "parameter-composition-in-transformer-models"]], "Parameter-Efficient Fine Tuning (PEFT)": [[24, "parameter-efficient-fine-tuning-peft"]], "Parameters in a Transformer": [[1, "id1600"]], "Passage Ranking Task": [[5, "passage-ranking-task"], [6, "passage-ranking-task"]], "Performance Overview": [[7, "performance-overview"]], "Performance comparison among  supervised SOTA neural machine translation models, unsupervised multi-lingual pretrained language models, and GPT-3.": [[7, "id1576"]], "Performance of Step-Back prompting on MMLU tasks.": [[18, "id1575"]], "Phrase representation": [[5, "phrase-representation"]], "Pointwise FeedForward Layer": [[12, "pointwise-feedforward-layer"]], "Pointwise Ranking Objective": [[6, "pointwise-ranking-objective"]], "Pointwise Regression Objective": [[6, "pointwise-regression-objective"]], "Pointwise ranking objective": [[5, "pointwise-ranking-objective"]], "Pointwise regression objective": [[5, "pointwise-regression-objective"]], "Policy iteration": [[25, "policy-iteration"]], "Policy iteration and Value iteration": [[25, "policy-iteration-and-value-iteration"]], "Polyencoder": [[5, "polyencoder"]], "Popularity-based Negative Sampling": [[6, "popularity-based-negative-sampling"]], "Popularity-based negative sampling": [[5, "popularity-based-negative-sampling"]], "Position Encoding and Long Context": [[1, "position-encoding-and-long-context"]], "Position Encodings": [[12, "position-encodings"]], "Position Interpolation for RoPE": [[1, "position-interpolation-for-rope"]], "Practical searching and ranking": [[5, "practical-searching-and-ranking"]], "Pre-trained language models": [[5, "pre-trained-language-models"]], "Pre-training": [[11, "pre-training"]], "Pre-training Tasks": [[8, "pre-training-tasks"]], "Precision And Recall": [[6, "precision-and-recall"]], "Precision and recall": [[5, "precision-and-recall"]], "Preference Data Collection": [[23, "preference-data-collection"]], "Preference Data and Reward Modeling": [[23, "preference-data-and-reward-modeling"]], "Preference Learning": [[35, "preference-learning"]], "Prefix-tuning": [[24, "prefix-tuning"]], "Preliminary: Preference modeling": [[23, "preliminary-preference-modeling"]], "Pretrained Language Models": [[12, "pretrained-language-models"]], "Pretraining": [[7, "pretraining"], [11, "pretraining"], [26, "pretraining"]], "Pretraining performance analysis": [[11, "pretraining-performance-analysis"]], "Principles": [[5, "principles"], [6, "principles"]], "Probabilistic Naive Bayes retrieval": [[5, "probabilistic-naive-bayes-retrieval"]], "Problem statement": [[5, "problem-statement"]], "Product Quantization": [[6, "product-quantization"]], "Product quantization": [[5, "product-quantization"]], "Prompt Compression": [[14, "prompt-compression"]], "Prompt Tuning": [[24, "prompt-tuning"]], "Prompting": [[21, "prompting"], [30, null]], "Prompting Lab": [[40, null]], "Properties of RoPE": [[1, "properties-of-rope"]], "Pseudo relevance feedback": [[5, "pseudo-relevance-feedback"]], "Put It Together": [[8, "put-it-together"]], "QW papers": [[5, "qw-papers"]], "Quantization Fundamentals": [[14, "quantization-fundamentals"]], "Quantization granularities": [[14, "quantization-granularities"]], "Quantization-performance trade-off in language models": [[14, "quantization-performance-trade-off-in-language-models"]], "Quantized matrix multiplication": [[14, "quantized-matrix-multiplication"]], "Query Categorization": [[4, "query-categorization"]], "Query Optimization Overview": [[4, "query-optimization-overview"]], "Query Rewriting": [[5, "id82"]], "Query Understanding & Optimization": [[4, "query-understanding-optimization"]], "Query Understanding And Rewriting": [[6, "query-understanding-and-rewriting"]], "Query and Document Expansion": [[6, "query-and-document-expansion"]], "Query and document expansion": [[5, "query-and-document-expansion"]], "Query expansion": [[5, "query-expansion"]], "Query preprocessing": [[5, "query-preprocessing"]], "Query relaxation": [[5, "query-relaxation"]], "Query rewriting": [[5, "query-rewriting"], [5, "id91"]], "Query scoping": [[5, "query-scoping"]], "Query segmentation": [[5, "query-segmentation"]], "Query similarity from Query-URL bipartite graph method": [[5, "query-similarity-from-query-url-bipartite-graph-method"]], "Query suggestion": [[5, "query-suggestion"]], "Query understanding": [[5, "query-understanding"], [5, "id81"]], "Query understanding and rewriting": [[5, "query-understanding-and-rewriting"], [5, "id75"]], "Query-Doc Ranking": [[4, "query-doc-ranking"]], "Query-document feature": [[5, "query-document-feature"]], "RAFT: Retrieval Augmented Fine Tuning": [[21, "raft-retrieval-augmented-fine-tuning"]], "RAG": [[21, null]], "RAG Challenges in Practice": [[21, "rag-challenges-in-practice"]], "RAG Evaluation": [[21, "rag-evaluation"]], "RAG Frameworks": [[21, "rag-frameworks"]], "RAG Optimization: Document Understanding": [[21, "rag-optimization-document-understanding"]], "RAG Optimization: LLM Understanding & Generation": [[21, "rag-optimization-llm-understanding-generation"]], "RAG Optimization: Query Understanding and Rewriting": [[21, "rag-optimization-query-understanding-and-rewriting"]], "RAG Optimization: Retriever and ReRanker": [[21, "rag-optimization-retriever-and-reranker"]], "RAG Optimizations": [[21, "rag-optimizations"]], "RAG and Agents": [[30, null]], "RAG vs Long Context LLM": [[21, "rag-vs-long-context-llm"]], "RAG vs Prompting and Fine Tuning": [[21, "rag-vs-prompting-and-fine-tuning"]], "RM3": [[5, "rm3"]], "RMS Norm": [[31, "rms-norm"], [32, "rms-norm"], [40, "rms-norm"]], "RMS Norm (Root Mean Square Norm)": [[1, "rms-norm-root-mean-square-norm"]], "RMSProp": [[26, "rmsprop"]], "Random Negatives and In-batch Negatives": [[6, "random-negatives-and-in-batch-negatives"]], "Random negatives and in-batch negatives": [[5, "random-negatives-and-in-batch-negatives"]], "Rank List Generation": [[4, "rank-list-generation"]], "RankNet": [[5, "ranknet"]], "Ranker": [[5, "ranker"]], "Ranker Distillation": [[4, "ranker-distillation"]], "Ranker Training": [[6, "ranker-training"]], "Ranking features": [[5, "ranking-features"]], "Ranking model training": [[5, "ranking-model-training"]], "Reading comprehension": [[3, "reading-comprehension"]], "Recurrent Neural Language Model": [[10, "recurrent-neural-language-model"]], "Reinforcement learning framework": [[25, "reinforcement-learning-framework"]], "Relevance scoring scheme": [[5, "relevance-scoring-scheme"]], "Retrieval Data Sources": [[21, "id1584"], [21, "id1585"]], "Retrieval Model Enhancement": [[21, "retrieval-model-enhancement"]], "Retrieval Result Quality Control": [[21, "retrieval-result-quality-control"]], "Retrieval results based on exact matching methods and semantic matching methods.": [[6, "id1643"]], "Reward Modeling": [[23, "reward-modeling"]], "RoBERT with different adaptation methods on the language understanding GLUE benchmark.": [[24, "id1591"]], "Robustness To Document Variations": [[6, "robustness-to-document-variations"]], "Robustness to document variations": [[5, "robustness-to-document-variations"]], "Rotary Postion Embedding": [[1, "rotary-postion-embedding"]], "Rotory Embedding": [[31, "rotory-embedding"], [32, "rotory-embedding"], [40, "rotory-embedding"]], "SNRM": [[5, "snrm"]], "SVD based word embeddings": [[13, "svd-based-word-embeddings"]], "Safety evaluation": [[3, "safety-evaluation"]], "Sample Efficient: ELECTRA": [[8, "sample-efficient-electra"]], "Scaling Instruction Finetuning": [[24, "scaling-instruction-finetuning"]], "Scaling Law for Fine Tuning": [[24, "scaling-law-for-fine-tuning"]], "Score fusion": [[5, "score-fusion"]], "Scoring": [[5, "scoring"]], "Searcher-document features": [[5, "searcher-document-features"]], "Self-Generated CoT": [[18, "self-generated-cot"]], "Self-Reflective RAG (SELF-RAG)": [[20, "self-reflective-rag-self-rag"]], "Self-attention Variants": [[1, "self-attention-variants"]], "Semantic Clusters As Pseudo Query Embeddings": [[6, "semantic-clusters-as-pseudo-query-embeddings"]], "Semantic Dense Models": [[6, "semantic-dense-models"]], "Semantic clusters as pseudo query embeddings": [[5, "semantic-clusters-as-pseudo-query-embeddings"]], "Semantic match": [[5, "semantic-match"]], "Seq2Seq: T5 and BART": [[11, null]], "Sequence-to-sequence learning": [[5, "sequence-to-sequence-learning"]], "Simple DPO": [[23, "simple-dpo"]], "Simple score interpolation": [[5, "simple-score-interpolation"]], "Single bi-encoder teacher distillation": [[5, "single-bi-encoder-teacher-distillation"]], "Single cross-encoder teacher distillation": [[5, "single-cross-encoder-teacher-distillation"]], "Sites": [[29, "sites"]], "Sliding Window Attention": [[1, "sliding-window-attention"]], "Smooth Quant": [[14, "smooth-quant"]], "Smoothing and Discounting Techniques": [[9, "smoothing-and-discounting-techniques"]], "Smoothing preference label": [[23, "smoothing-preference-label"]], "Software": [[5, "software"], [6, "software"]], "SparTerm": [[5, "sparterm"]], "Sparse IR serving": [[5, "sparse-ir-serving"]], "Special case: unigram language model": [[9, "special-case-unigram-language-model"]], "Speculative Decoding": [[15, "speculative-decoding"]], "Speed-Up Hessian Computation": [[14, "speed-up-hessian-computation"]], "Speical Case: Diagonal Hessian Assumption": [[14, "speical-case-diagonal-hessian-assumption"]], "Speller": [[5, "speller"]], "Speller error type": [[5, "speller-error-type"]], "Spelling correction": [[5, "spelling-correction"], [5, "id84"]], "Stacked Decoder layers": [[31, "stacked-decoder-layers"], [32, "stacked-decoder-layers"], [40, "stacked-decoder-layers"]], "Standard quantization techniques": [[14, "standard-quantization-techniques"]], "State-action Value function (Q function)": [[25, "state-action-value-function-q-function"]], "Static Hard Negative Examples": [[6, "static-hard-negative-examples"]], "Static hard negative examples": [[5, "static-hard-negative-examples"]], "Statistical Language Models": [[9, "statistical-language-models"]], "Step Back Prompting": [[18, "step-back-prompting"]], "Storage requirement for different components during LLM training using Adam.": [[22, "id1575"]], "Study Results": [[24, "study-results"]], "Subword model": [[13, "subword-model"]], "SuperGLUE": [[7, "superglue"]], "Switch Transformer": [[2, "switch-transformer"]], "T5": [[11, "t5"]], "TERC": [[5, "terc"], [6, "terc"]], "TERC-COVID": [[5, "terc-covid"]], "TF-IDF Vector Space Model": [[6, "tf-idf-vector-space-model"]], "TREC-CAR": [[5, "trec-car"], [6, "trec-car"]], "TREC-deep Learning Track": [[6, "trec-deep-learning-track"]], "TREC-deep learning track": [[5, "trec-deep-learning-track"]], "Table of Contents": [[30, null]], "Task-specific evaluation": [[3, "task-specific-evaluation"]], "Techniques to increasing Precision": [[5, "techniques-to-increasing-precision"]], "Techniques to increasing Recall": [[5, "techniques-to-increasing-recall"]], "Temperature-controlled sampling": [[15, "temperature-controlled-sampling"]], "Test Model": [[34, "test-model"]], "Test model": [[32, "test-model"]], "Text Generation Tasks": [[11, "text-generation-tasks"]], "Text Ranking Evaluation Metrics": [[6, "text-ranking-evaluation-metrics"]], "Text ranking evaluation metrics": [[5, "text-ranking-evaluation-metrics"]], "The Decoder Branch": [[12, "the-decoder-branch"]], "The EXTREME Benchmark": [[8, "the-extreme-benchmark"]], "The Encoder Anatomy": [[8, "the-encoder-anatomy"]], "The Encoder Branch": [[12, "the-encoder-branch"]], "The Encoder-decoder Branch": [[12, "the-encoder-decoder-branch"]], "The Error Minimization Framework": [[14, "the-error-minimization-framework"]], "The Memory Requirement For Training LLM": [[22, "the-memory-requirement-for-training-llm"]], "The PPO Algorithm": [[23, "the-ppo-algorithm"]], "The Rise of Large Language Models": [[0, "the-rise-of-large-language-models"]], "The basics": [[15, "the-basics"]], "The exact match framework": [[5, "the-exact-match-framework"]], "The fundamental challenge of LLM inference": [[14, "the-fundamental-challenge-of-llm-inference"]], "The hyperparameter settings of various pretrained BERT configurations.  BERTBase and BERTLarge are the two most commonly used configurations today;": [[8, "id1597"]], "The hypothesis and method": [[24, "the-hypothesis-and-method"]], "The mechanism": [[1, "the-mechanism"]], "The model": [[5, "the-model"], [13, "the-model"]], "TinyBERT": [[8, "tinybert"]], "Token-level Multi-vector Representation": [[6, "token-level-multi-vector-representation"]], "Token-level multi-vector representation": [[5, "token-level-multi-vector-representation"]], "Tokenziation, vocabulary, and weight tying": [[1, "tokenziation-vocabulary-and-weight-tying"]], "Top-k and top-p sampling": [[15, "top-k-and-top-p-sampling"]], "Topic-aware Negative Sampling": [[6, "topic-aware-negative-sampling"]], "Topic-aware negative sampling": [[5, "topic-aware-negative-sampling"]], "Toxicity and harmful content": [[3, "toxicity-and-harmful-content"]], "Traditional Sparse IR Fundamentals": [[6, "traditional-sparse-ir-fundamentals"]], "Traditional evaluation": [[3, "traditional-evaluation"]], "Traditional query rewriting": [[5, "traditional-query-rewriting"]], "Traditional sparse IR fundamentals": [[5, "traditional-sparse-ir-fundamentals"]], "Training": [[34, "training"], [35, "training"], [36, "training"], [37, "training"], [38, "training"], [39, "training"]], "Training Data": [[6, "training-data"]], "Training Data Sampling Strategies": [[6, "training-data-sampling-strategies"]], "Training Entry": [[34, "training-entry"], [37, "training-entry"], [38, "training-entry"], [39, "training-entry"]], "Training Overview": [[26, "training-overview"]], "Training Process": [[22, "training-process"]], "Training Strategy": [[17, "training-strategy"], [17, "id10"]], "Training data": [[5, "training-data"]], "Training data sampling strategies": [[5, "training-data-sampling-strategies"]], "Transformer Layer": [[34, "transformer-layer"]], "Transformer architectures for retrieval and ranking": [[5, "transformer-architectures-for-retrieval-and-ranking"]], "Transformers": [[5, "transformers"], [12, null]], "Transformers Anatomy": [[12, "transformers-anatomy"]], "Tutorial": [[5, "tutorial"]], "Two Architecture Paradigms": [[6, "two-architecture-paradigms"]], "Two architecture paradigms": [[5, "two-architecture-paradigms"]], "Ultra-high dimensional BERT representation (UHD-BERT)": [[5, "ultra-high-dimensional-bert-representation-uhd-bert"]], "Unigram language model": [[5, "unigram-language-model"]], "Utilizing Knowledge Graph": [[21, "utilizing-knowledge-graph"]], "Validation accuracy on WikiSQL and MultiNLI with different rank r.": [[24, "id1593"]], "Value iteration": [[25, "value-iteration"]], "Vector Quantization": [[6, "vector-quantization"]], "Vector quantization": [[5, "vector-quantization"]], "Vector space model": [[5, "vector-space-model"]], "Vision LLM": [[30, null]], "Vision Language Pretraining": [[17, null]], "Visualization": [[13, "visualization"]], "Where quantization and dequant happen? What is the trade off": [[14, "where-quantization-and-dequant-happen-what-is-the-trade-off"]], "Why Transformers?": [[5, "why-transformers"], [6, "why-transformers"]], "Word Embeddings": [[13, null]], "Word hashing token size and collision numbers as a function of the vocabulary size and the type of letter ngrams.": [[6, "id1644"]], "Word level N grams": [[5, "word-level-n-grams"]], "Word-Embedding based model": [[5, "word-embedding-based-model"]], "Word2Vec": [[13, "word2vec"]], "World knowledge": [[3, "world-knowledge"]], "XLM, XLM-R, And XLM-E": [[8, "xlm-xlm-r-and-xlm-e"]], "ZeRO Via DeepSpeed": [[22, "zero-via-deepspeed"]], "ZeRO-Stage-One": [[22, "zero-stage-one"]], "Zero-shot prompt": [[19, "zero-shot-prompt"]], "\\begin{example} Consider two queries and their retrieved document lists:\n$\n\t\\begin{aligned}\n\t\t&q_{1} \\rightarrow d_{1}, d_{2} \\\\\n\t\t&q_{2} \\rightarrow d_{3}, d_{4}, d_{5}\n\t\\end{aligned}\n\t\n\tAssuming only d_{2}, d_{3}, d_{5} are relevant document given their corresponding query. We have\n\t- \\mathrm{AP} of query 1: \\frac{1}{1} \\times\\left(\\frac{0}{1} \\times 0+\\frac{1}{2} \\times 1\\right)=\\frac{1}{2}$": [[5, "begin-example-consider-two-queries-and-their-retrieved-document-lists-begin-aligned-q-1-rightarrow-d-1-d-2-q-2-rightarrow-d-3-d-4-d-5-end-aligned-assuming-only-d-2-d-3-d-5-are-relevant-document-given-their-corresponding-query-we-have-mathrm-ap-of-query-1-frac-1-1-times-left-frac-0-1-times-0-frac-1-2-times-1-right-frac-1-2"]], "\\star Deriving The MLE": [[9, "star-deriving-the-mle"]], "markmap": [[29, null]], "n-gram Language Model": [[9, "n-gram-language-model"]]}, "docnames": ["docs/Introduction", "docs/chapter_LLM_arch/LLM_dense_architectures", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures", "docs/chapter_LLM_eval/LLM_eval", "docs/chapter_application_IR/application_LLM_in_IR", "docs/chapter_application_IR/conversion/neuralNetworkApplicationNLP_IRSearch", "docs/chapter_application_IR/information_retrieval_fundamentals", "docs/chapter_foundation/GPT_series", "docs/chapter_foundation/bert", "docs/chapter_foundation/language_models", "docs/chapter_foundation/neural_language_models", "docs/chapter_foundation/t5", "docs/chapter_foundation/transformers", "docs/chapter_foundation/word_embeddings", "docs/chapter_inference/inference_acceleration", "docs/chapter_inference/inference_fundamentals", "docs/chapter_multimodality/multimodality_fundamentals", "docs/chapter_multimodality/vision_transformers", "docs/chapter_prompt/advanced_prompt", "docs/chapter_prompt/basic_prompt", "docs/chapter_rag/advanced_rag", "docs/chapter_rag/basic_rag", "docs/chapter_training/accelerated_training", "docs/chapter_training/alignment", "docs/chapter_training/finetuning", "docs/chapter_training/reinforcement_learning", "docs/chapter_training/training_fundamentals", "docs/chapter_training/training_lab", "docs/img/chapter_application_IR/ApplicationIRSearch/DataExploration/data_explorer", "docs/img/chapter_application_IR/ApplicationIRSearch/DeepRetrievalModels/KNRM/test", "docs/index", "docs/notebooks/chapter_LLM_arch/annotated_llama", "docs/notebooks/chapter_LLM_arch/annotated_llama_custom", "docs/notebooks/chapter_LLM_inference/annotated_decoding", "docs/notebooks/chapter_LLM_training/annotated_instruction_tuning", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_DPO", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_finetuning", "docs/notebooks/chapter_LLM_training/annotated_pretraining", "docs/notebooks/chapter_LLM_training/annotated_pretraining_old", "docs/notebooks/chapter_LLM_training/annotated_pretraining_rotary_decoder", "docs/notebooks/chapter_prompt/prompting_lab", "docs/notebooks/chapter_rag/Graph_Rag", "docs/notebooks/chapter_rag/llamaIndexLearning/test"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["docs/Introduction.md", "docs/chapter_LLM_arch/LLM_dense_architectures.md", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures.md", "docs/chapter_LLM_eval/LLM_eval.md", "docs/chapter_application_IR/application_LLM_in_IR.md", "docs/chapter_application_IR/conversion/neuralNetworkApplicationNLP_IRSearch.md", "docs/chapter_application_IR/information_retrieval_fundamentals.md", "docs/chapter_foundation/GPT_series.md", "docs/chapter_foundation/bert.md", "docs/chapter_foundation/language_models.md", "docs/chapter_foundation/neural_language_models.md", "docs/chapter_foundation/t5.md", "docs/chapter_foundation/transformers.md", "docs/chapter_foundation/word_embeddings.md", "docs/chapter_inference/inference_acceleration.md", "docs/chapter_inference/inference_fundamentals.md", "docs/chapter_multimodality/multimodality_fundamentals.md", "docs/chapter_multimodality/vision_transformers.md", "docs/chapter_prompt/advanced_prompt.md", "docs/chapter_prompt/basic_prompt.md", "docs/chapter_rag/advanced_rag.md", "docs/chapter_rag/basic_rag.md", "docs/chapter_training/accelerated_training.md", "docs/chapter_training/alignment.md", "docs/chapter_training/finetuning.md", "docs/chapter_training/reinforcement_learning.md", "docs/chapter_training/training_fundamentals.md", "docs/chapter_training/training_lab.md", "docs/img/chapter_application_IR/ApplicationIRSearch/DataExploration/data_explorer.ipynb", "docs/img/chapter_application_IR/ApplicationIRSearch/DeepRetrievalModels/KNRM/test.md", "docs/index.md", "docs/notebooks/chapter_LLM_arch/annotated_llama.ipynb", "docs/notebooks/chapter_LLM_arch/annotated_llama_custom.ipynb", "docs/notebooks/chapter_LLM_inference/annotated_decoding.ipynb", "docs/notebooks/chapter_LLM_training/annotated_instruction_tuning.ipynb", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_DPO.ipynb", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_finetuning.ipynb", "docs/notebooks/chapter_LLM_training/annotated_pretraining.ipynb", "docs/notebooks/chapter_LLM_training/annotated_pretraining_old.ipynb", "docs/notebooks/chapter_LLM_training/annotated_pretraining_rotary_decoder.ipynb", "docs/notebooks/chapter_prompt/prompting_lab.ipynb", "docs/notebooks/chapter_rag/Graph_Rag.ipynb", "docs/notebooks/chapter_rag/llamaIndexLearning/test.ipynb"], "indexentries": {"information retrieval": [[5, "index-0", false], [6, "index-0", false]], "inverted index": [[5, "index-1", false]], "ir": [[5, "index-0", false], [6, "index-0", false]], "neural ir": [[5, "index-0", false], [6, "index-0", false]]}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 40, 41, 42], "0": [1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "00": [5, 11, 41, 42], "000": [1, 3, 4, 5, 6, 8, 9, 13, 17, 24, 41, 42], "000095367431641": 36, "00051": 6, "000537395477295": 36, "000862121582031": 36, "001": [5, 26], "001102447509766": 36, "00111198425293": 36, "001513957977295": 36, "001770973205566": 36, "00190": 24, "0024333000183105": 36, "002604961395264": 36, "0030306577682495": [34, 38], "003237247467041": 36, "0032548904418945": 36, "0041": 1, "00510": 14, "00555": 1, "005776882171631": 36, "005826950073242": 36, "005913734436035": 36, "006173133850098": 36, "0064697265625": 36, "00651741027832": 36, "006951332092285": 36, "007287502288818": 36, "007312297821045": 36, "00751": 24, "0077738761901855": 36, "007800598628818989": [34, 38], "008021831512451": 36, "00808": 6, "00854": 12, "008838176727295": 36, "009037494659424": 36, "009293556213379": 36, "00df903954ac": [41, 42], "01": [5, 14, 24, 41, 42], "01000001": 1, "01020304050607gener": 5, "010351657867432": 36, "01047420501709": 36, "010768338106572628": 39, "0109546184539795": 36, "011043071746826": 36, "01108": 8, "01137": 6, "012027263641357": 36, "012099266052246": 36, "012349644675850868": 39, "013116082176566124": [34, 38], "01318": 15, "013998031616211": 36, "014437675476074": 36, "014496803283691": 36, "014517992734909058": [34, 38], "014609336853027": 36, "01462": 13, "014990329742432": 36, "01567663997411728": [34, 38], "016483306884766": 36, "01652": 24, "016759872436523": 36, "017136573791504": 36, "01759": 13, "0175909996032715": 36, "0180": [41, 42], "0184197425842285": 36, "018761157989502": 36, "0189290046691895": 36, "019": [41, 42], "019296646118164": 36, "019469738006592": 36, "019588947296143": 36, "01969": 6, "01_main": [34, 38], "02": [14, 32, 35, 36], "020229710955313": 39, "02054": 22, "020560264587402": 36, "020669937133789": 36, "020719528198242": 36, "0208258628845215": 36, "020852088928223": 36, "021": 9, "02116": 8, "021180152893066": 36, "02150": 1, "02155": 23, "021723747253418": 36, "021773338317871": 36, "022000789642334": 36, "022898197174072": 36, "023150444030762": 36, "023197127506136894": [34, 38], "02336311340332": 36, "023693561553955": 36, "023902416229248": 36, "02424": 15, "02440521866083145": [34, 38], "025": 19, "02531": [6, 8], "0253249f": 42, "025507673621177673": 39, "025716781616211": 36, "02600269578397274": [34, 38], "026512518525123596": [34, 38], "02677": 26, "026836492121219635": [34, 38], "026931755244731903": 39, "026de08c": [41, 42], "027651309967041": 36, "027662754058838": 36, "0278215408325195": 36, "02880910411477089": [34, 38], "02886047028005123": [34, 38], "0293": [41, 42], "029511943459510803": 39, "029530048370361": 36, "02984": 8, "03": 14, "03167": 1, "032745361328125": 36, "033027324825525284": [34, 38], "033673286437988": 36, "03374": 26, "0339795351028442": 39, "03422737121582": 36, "03439474105835": 36, "03444734588265419": [34, 38], "035079002380371": 36, "03599": 6, "036285400390625": 36, "036287613213062286": [34, 38], "036416053771973": [34, 38], "0366": [5, 6], "0369696617126465": 36, "037397384643555": 36, "03740": 22, "037643432617188": 36, "03766665980219841": [34, 38], "037725448608398": 36, "03789590671658516": [34, 38], "038": 7, "03828873857855797": [34, 38], "038869857788086": 36, "04": [5, 9, 41, 42], "040163993835449": 36, "04039938002824783": [34, 38], "04059940576553345": [34, 38], "04085": 6, "041125692427158356": [34, 38], "041174411773682": 36, "0411882400512695": 36, "041816234588623": 36, "042531490325928": 36, "04279662296175957": 39, "04297": 6, "043063640594482": 36, "04341": 8, "04371192306280136": [34, 38], "0443267822265625": 36, "044668205082416534": [34, 38], "04478645324707": 36, "04554": 6, "04636172950267792": [34, 38], "047027587890625": 36, "04754674434661865": 39, "047771453857422": 36, "047902584075928": 36, "048016272485256195": [34, 38], "04805": [6, 8, 12], "048269271850586": 36, "0483412505480632": 39, "04857831075787544": 39, "04906": 6, "05": [5, 6, 9, 11, 14], "050281047821045": 36, "050431728363037": 36, "05101": 26, "051425457000732": 36, "051654815673828": 36, "05197812244296074": [34, 38], "05202": 1, "052042007446289": 36, "052127838134766": 36, "052281379699707": 36, "0523810386657715": 36, "052631378173828": 36, "052845001220703": 36, "0529069900512695": 36, "05365": 8, "05378653109073639": [34, 38], "054011344909668": [34, 38], "054613832384347916": [34, 38], "05462772026658058": [34, 38], "055233478546143": 36, "055540084838867": 36, "055841445922852": 36, "0558529794216156": [34, 38], "05649694427847862": 39, "056744575500488": 36, "05726563185453415": [34, 38], "05736": 14, "0578880310058594": 36, "05852453410625458": [34, 38], "05859": 13, "0587334632873535": 36, "0588991753757": [34, 38], "059050846844911575": [34, 38], "059132099151611": 36, "059300899505615": 36, "059329509735107": 36, "05941": 1, "06": [14, 32, 35, 36], "06037088483572006": [34, 38], "06066": 2, "06080": 23, "06099998578429222": 39, "06117": 18, "061482429504395": 36, "061509609222412": 36, "06174": 22, "061813831329346": 36, "061917304992676": 36, "062714576721191": 36, "062737226486206": 36, "06275": 6, "06347": 23, "06445721536874771": [34, 38], "06446892023086548": [34, 38], "065298080444336": 36, "065533638000488": 36, "066253662109375": 36, "0672410720783017": 39, "067604064941406": 36, "067690849304199": 36, "067878723144531": 36, "068182945251465": 36, "06825": 1, "068316698074341": 36, "0693352222442627": 39, "06971258670091629": [34, 38], "06983757019043": 36, "06af60db": 42, "07": [6, 9, 14, 41, 42], "070650100708008": 36, "07119077444076538": 39, "071258068084717": 36, "071336269378662": 36, "071442127227783": 36, "0717201232910156": [34, 38], "071742057800293": 36, "07186": 6, "07278": 8, "07291": 8, "07328592240810394": 39, "07339": 14, "073481559753418": 36, "0735877752304077": [34, 38], "074522972106934": 36, "07467": 1, "074995517730713": 36, "07514037191867828": [34, 38], "075766086578369": 36, "076148509979248": 36, "07633408159017563": 39, "07640326768159866": [34, 38], "076551914215088": 36, "076613426208496": 36, "07666": 6, "07678": 4, "0769914910197258": [34, 38], "07708": 6, "07765556126832962": 39, "078139781951904": 36, "07820": 6, "07834529876709": 36, "078483581542969": 36, "078586578369141": 36, "07909": 1, "079100608825684": 36, "079553604125977": 36, "079935073852539": 36, "08": [5, 11], "08067": 21, "08073": 23, "081141948699951": 36, "081357955932617": 36, "08144": 8, "081643104553223": 36, "081788539886475": 36, "081859588623047": 36, "08191": 6, "082344055175781": 36, "08261846750974655": 39, "082972049713135": 36, "0829901695251465": 36, "083053112030029": 36, "08328281342983246": [34, 38], "08338280767202377": 39, "08361": 26, "08375": [6, 21], "084001064300537": 36, "08412479609251022": [34, 38], "084579467773438": 36, "08510": 8, "085297107696533": 36, "085419178009033": 36, "08564770221710205": [34, 38], "0857086181640625": 36, "086000442504883": 36, "08691": [17, 24], "0870": 34, "08730": 11, "08739487081766129": [34, 38], "08747": 24, "08758139610290527": [34, 38], "087961673736572": 36, "088": 9, "0880608558654785": [34, 38], "088583946228027": 36, "08875849843025208": [34, 38], "088858127593994": [34, 38], "08958636224269867": 39, "09": [14, 23, 42], "09015399217605591": 39, "09018289297819138": 39, "09021760523319244": [34, 38], "090518951416016": 36, "091506481170654": 36, "091830253601074": 36, "091935157775879": 36, "091977119445801": 36, "092382431030273": 36, "093469619750977": 36, "093663692474365": 36, "093731641769409": 36, "093860149383545": 36, "093935012817383": 36, "09413014352321625": [34, 38], "094305515289307": 36, "094555854797363": 36, "09466552734375": 36, "094918251037598": 36, "095365524291992": 36, "09542": 4, "0959155055818307": 39, "0959885120391846": 36, "09600830078125": 36, "09685": 24, "09697091216987117": 39, "09702205657959": 36, "097576804459095": 39, "09781": 15, "098": [41, 42], "0980504394975618": 39, "098481178283691": 36, "09864": [1, 31, 32, 40], "098686695098877": 36, "098811626434326": 36, "0994": 34, "09992072919463102": 39, "099956512451172": [34, 38], "0b": 1, "0m": [24, 41, 42], "0x": [5, 6], "0x0000023000156e50": [41, 42], "1": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "10": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 22, 24, 26, 28, 33, 34, 35, 36, 38, 41, 42], "100": [3, 5, 6, 7, 12, 14, 26, 28, 31, 34, 35, 36, 39, 40], "1000": [1, 5, 6, 39, 42], "10000": [1, 5, 6, 12, 31, 32, 40], "1000000": [32, 35, 36], "10000010": 1, "10001010": 1, "10011000": 1, "10011111": 1, "10063": 4, "1007": [41, 42], "1008782386779785": 36, "100k": [1, 5], "100m": 22, "101": [5, 6, 17], "10101100": 1, "101051330566406": 36, "1012": [35, 36], "101280689239502": 36, "1013": 34, "10131": 21, "1014628410339355": 39, "1016": [41, 42], "10175716297866659": 39, "10183": 12, "101871013641357": 36, "102": [41, 42], "102067": 6, "102071762084961": 36, "10208554565906525": [34, 38], "10221000760793686": 39, "1024": [1, 8, 14, 34, 37, 38, 39], "102511882781982": 36, "1027": 28, "10295": [35, 36], "103": [1, 9], "10306": [5, 6], "103277206420898": 36, "10345983505249": 36, "10351": 8, "104": [8, 41, 42], "1040421724319458": 39, "1045": 10, "10455": [35, 36], "104673862457275": 36, "10472672432661057": 39, "1048": 10, "104902744293213": 36, "1050": 39, "105184078216553": 36, "10520": 34, "10524": [1, 12], "10533": [1, 12], "1054": 28, "10555": 8, "1056838035583496": 36, "105834007263184": 36, "10671": [1, 22], "106788948743525": 39, "106828689575195": 36, "10683": 6, "10687": 6, "106971740722656": 36, "10719": 23, "107256889343262": 36, "107507228851318": 36, "107565879821777": 36, "10774": 15, "10786582617982032": 39, "1079": [34, 35, 36], "108": 8, "1081318855285645": 36, "108236312866211": 36, "1082444190979": [34, 38], "10835": 23, "10854959487915": 36, "10866": 23, "10886287689209": 36, "10899": 38, "108m": 8, "109013557434082": 36, "10905103474105166": 39, "109280109405518": 36, "10985501110553741": [34, 38], "10997": 21, "109997272491455": 36, "10_getting_start": 42, "10a6": 42, "10b": [1, 24], "10k": [5, 9, 22, 42], "10k_sub_quest": 42, "10q": 42, "10q_sub_quest": 42, "10x": [5, 6], "11": [1, 5, 6, 7, 8, 9, 11, 12, 21, 34, 35, 36, 38, 41, 42], "110": [6, 8, 9], "1100": 39, "110368728637695": 36, "1104": [37, 39], "110491991043091": 36, "1107": [5, 6], "110700607299805": 36, "110k": 8, "110m": 8, "11100010": 1, "11110000": 1, "1113": 28, "11171": [18, 24], "11179701238870621": [34, 38], "112": 22, "1120": 22, "112430095672607": 36, "112819671630859": 36, "112850666046143": 36, "113": 6, "11344993114471436": 39, "1137": 10, "1139": 26, "113960266113281": 36, "11416": 24, "114251136779785": 36, "1144712045788765": [34, 38], "1147": 26, "11484288345580376": 39, "114983558654785": [35, 36], "1150": 39, "11511": 20, "115427494049072": 36, "1155": 10, "116": 28, "11652": 34, "11692": [8, 12], "117002010345459": 36, "11717287451028824": 39, "117216110229492": 36, "11755": 21, "11761": 21, "11771243065595627": [34, 38], "11799028416805349": 39, "1186": [41, 42], "11903": 19, "11916": 19, "1192": [5, 6], "11929": 12, "11942": [8, 12], "11945632100105286": 39, "11b": 22, "11v2h12l": 42, "11z": 42, "12": [1, 3, 5, 6, 7, 8, 11, 12, 14, 17, 19, 21, 22, 24, 26, 28, 34, 35, 36, 38, 41, 42], "120": [2, 9, 22], "1200": 39, "12039041519165": 36, "120830535888672": 36, "120845317840576": 36, "12120829767329572": 39, "12136": 6, "121431827545166": 36, "12148": 24, "121613502502441": 36, "122": 6, "122198581695557": 36, "122265338897705": 36, "122282028198242": 36, "122321128845215": 36, "1223673820495605": 36, "12254524230957": 36, "1228": 28, "12288": 1, "123": 34, "123189926147461": 36, "1232042983174324": 39, "123317718505859": 36, "123326778411865": 36, "12373088300228119": 39, "123955249786377": 36, "12409": 1, "124289035797119": 36, "1246867179870605": 36, "12477972358465195": [34, 38], "1248273029923439": 39, "125": 24, "1250": 39, "1252295247635492": 39, "125601768493652": 36, "12577679825099244": 39, "125786542892456": 36, "1258463859558105": 36, "125m": 7, "126089096069336": 36, "1268": 28, "126978397369385": 36, "127": [14, 22, 41, 42], "127451419830322": 36, "128": [1, 5, 8, 22, 34, 35, 36, 38], "1281": [35, 36], "128173351287842": [34, 38], "1285733113386835": 39, "12888": 17, "129": 6, "12900": 17, "1291": 6, "1291351318359375": 36, "12927584716122092": 39, "1294450759887695": 36, "12948": 14, "12956428527832": 36, "129610061645508": 36, "1299": 6, "12b": 42, "12df1a233612": [41, 42], "12l": 42, "12z": 42, "12zm": 42, "13": [1, 3, 5, 6, 9, 13, 14, 21, 24, 28, 34, 35, 36, 38, 41, 42], "130": [41, 42], "1300": 39, "1301": 13, "130191326141357": 36, "131": 6, "1315": 28, "131k": 1, "132": [5, 28], "13228": 23, "132312455478721": 39, "13245": 1, "132767200469971": 36, "132808685302734": 36, "132901668548584": 36, "1329402860087926": 39, "133650779724121": 36, "1343431919813156": 39, "134390830993652": 36, "13461": 11, "135": 13, "1350": 39, "13514639128325923": 39, "1355173505273704": 39, "13567930459976196": [34, 38], "1359076499938965": 36, "136": [6, 41, 42], "13653340935707092": [34, 38], "13719": 34, "137276649475098": 36, "1374053955078125": 36, "1376": [35, 36], "137b": 18, "138185024261475": 36, "138240814208984": 36, "1385064125061035": 36, "13889189064502716": 39, "13895043907426818": 39, "139": [41, 42], "1396494358778": 39, "13971": 23, "139718532562256": 36, "139926910400391": 36, "13b": [1, 7, 42], "14": [1, 5, 6, 7, 11, 17, 22, 23, 32, 35, 36, 41, 42], "140": [5, 11], "1400": 39, "14002": 4, "1401": [35, 36], "1402": 13, "14093": 34, "1412": 26, "14168298818636121": 39, "141721725463867": 36, "141951084136963": 36, "142255783081055": 36, "1424946784973145": 36, "142984390258789": 36, "143166542053223": 36, "143261909484863": 36, "1433515040811": 39, "1435980796813965": 36, "14374": [34, 35, 36], "14394": 24, "144": 5, "1441": 12, "14416790008545": [34, 38], "144201278686523": 36, "14424": 6, "144306182861328": 36, "14432775974273682": 39, "14454984664917": 36, "144584655761719": 36, "1450": [12, 39], "145068168640137": 36, "1457": 28, "14589": [35, 36], "14591908454895": 36, "146": 13, "146424770355225": 36, "146705389022827": 39, "14686393737793": 36, "147": [41, 42], "14701": 26, "14715632141067736": 39, "14734": 23, "1475": 28, "148385047912598": 36, "14847814030488105": 39, "1493": [35, 36], "149815051465409": 39, "15": [1, 4, 5, 6, 8, 11, 13, 19, 25, 28, 41, 42], "150": 39, "1500": 39, "1501040756702423": [34, 38], "150128364562988": 36, "1502": 1, "1503": [6, 8], "150716781616211": 36, "1508": 1, "1509199142456055": 36, "151": 28, "151343822479248": 36, "151587963104248": 36, "151601791381836": 36, "151643": [32, 34, 35, 36], "151936": [32, 35, 36], "152644634246826": 36, "152826309204102": 36, "154": [5, 28], "1541220098733902": [34, 38], "154237747192383": 36, "154354572296143": 36, "15440": [35, 36], "154609680175781": 36, "1549": [35, 36], "1550": 39, "15538781881332397": [34, 38], "155660629272461": 36, "1558": [35, 36], "15595": 1, "1566009521484375": [34, 38], "15684756636619568": 39, "15696": 4, "15707": 4, "158": 28, "158417224884033": 36, "15845389405402713": 39, "158575057983398": 36, "15884": 20, "1590": 28, "15908": [34, 35, 36], "16": [4, 5, 6, 7, 8, 11, 13, 14, 15, 22, 35, 36, 41, 42], "160": [13, 28], "1600": 39, "16008293923810207": 39, "1602": 6, "160398006439209": 36, "1604": 22, "16051721572876": 36, "1607": [5, 6, 13, 34], "1607208251953125": 36, "1608": 13, "1609": 8, "161": 28, "1610": 15, "1611": 13, "16128183901309967": 39, "16130": 20, "16138": 8, "162": [28, 41, 42], "162322044372559": 36, "162805080413818": 36, "163": 6, "163131713867188": 36, "16319": [35, 36], "1632": 34, "163222789764404": 36, "1635": [35, 36], "163662910461426": 36, "16411": 34, "16452": 18, "1647": 34, "165": [41, 42], "1650": 39, "16555": [34, 35, 36], "1656084060668945": 36, "165675401687622": [34, 38], "1658274382352829": [34, 38], "16613245010376": 36, "16630381678691808": 39, "16657713055610657": 39, "1667": 34, "167": [13, 28], "167695999145508": 36, "168": 36, "1681": [34, 35, 36], "16864658892154694": [34, 38], "169183731079102": 36, "169384956359863": 36, "16980576515197754": [34, 38], "16b": 24, "16l7": 42, "16x16": 12, "17": [5, 6, 11, 12, 19, 22, 23, 26, 35, 36, 41, 42], "170": 36, "1700": 39, "17016740589497703": 39, "1704": 6, "1706": 26, "1707": 23, "171": 36, "1710": [1, 22], "1711": 26, "17119836807251": 36, "17193": 24, "172": 36, "172737121582031": 36, "172832489013672": 36, "1729037596728389": 39, "173": [6, 36], "173192501068115": 36, "173440456390381": 36, "174": 36, "1741": [35, 36], "17428": 4, "17463": 1, "1747": 28, "174975395202637": 36, "175": [0, 1, 7, 24, 36], "1750": 39, "175256252288818": 36, "17539710472750406": 39, "1755": 34, "175565719604492": 36, "17556619644165": 36, "17576": 13, "175b": [1, 7, 23], "176": [41, 42], "176111221313477": 36, "176688194274902": 36, "176878452301025": 36, "1769914627075195": 36, "17788": 34, "17809009552002": 36, "17817610502243042": 39, "178514003753662": 36, "179": [41, 42], "1795573234558105": 36, "179817199707031": 36, "179b": 1, "17bsdp": 22, "18": [5, 6, 7, 8, 12, 26, 35, 36, 41, 42], "180": 3, "1800": 39, "1802": 8, "180410385131836": 36, "1806": 11, "180679798126221": 36, "18074893951416": 36, "1809": 8, "18098746515097255": 39, "1810": [6, 8, 12], "1818265914917": 36, "18223": [1, 26], "182458877563477": 36, "1829": 6, "18290": 23, "183032512664795": 36, "183049201965332": 36, "18310590088367462": 39, "183134078979492": 36, "1832": 6, "18330155313014984": 39, "18332052230835": 36, "183322906494141": 36, "183326244354248": 36, "183656692504883": 36, "183904647827148": 36, "183990478515625": [35, 36], "184": 5, "184030055999756": 36, "184084415435791": 36, "18418020009994507": 39, "1843748092651367": 36, "184566020965576": 36, "18459": 38, "1848344802856445": 36, "184986114501953": 36, "1850": [35, 36, 39], "18514": 34, "185161113739014": 36, "18527889251709": 36, "186308860778809": 36, "1863226890563965": 36, "18638801574707": [34, 38], "186612129211426": 36, "186622142791748": 36, "18667520582675934": 39, "1872": [41, 42], "18759298324585": 36, "187629699707031": 36, "1877": [1, 7, 9, 12], "188": 13, "188701629638672": 36, "18892765045166": 36, "188948154449463": 36, "1896": [35, 36], "189830780029297": 36, "189905166625977": 36, "18c": 42, "19": [5, 6, 7, 8, 9, 11, 12, 22, 24, 35, 36, 41, 42], "190": 5, "1900": 39, "1901": [1, 6, 7, 8, 9, 12], "1902": 24, "1902608141362801": 39, "1903": 6, "1904": [6, 21], "1905": 6, "1906": 8, "1907": [8, 12], "190706729888916": 36, "1909": [8, 12], "1910": [1, 6, 8, 11, 22], "1911": [1, 8], "191983222961426": 39, "192": 1, "192046165466309": 36, "19274": 15, "19286": 15, "1930": 5, "1931455284357071": [34, 38], "1939": [35, 36], "19411039352417": 36, "19437": 2, "194373607635498": 36, "1946": [41, 42], "1950": 39, "1952": 23, "1956353187561035": 36, "195936679840088": 36, "196": 5, "1961": [41, 42], "196247100830078": 36, "1963": 4, "19633081555366516": [34, 38], "19641": [35, 36], "196491241455078": 36, "1966233253479": 36, "1968": 5, "1971": [5, 6], "19717825949192047": 39, "1972": 5, "19730": 17, "19737": 26, "197397232055664": 36, "19742": 17, "197486877441406": 36, "1975": 5, "1976": 5, "1976093819610651": 39, "1976746320724487": [34, 38], "1977": 6, "1979": 5, "198": 38, "1980": [5, 28], "1982": 20, "198347806930542": 36, "1984": 21, "198479652404785": 36, "1986": [41, 42], "1986823081970215": 36, "1987": 5, "1988": [], "1988b": 5, "1989": 14, "199": 28, "1990": 5, "199103832244873": 36, "199112892150879": 36, "1992": 5, "1993": [5, 14, 41, 42], "199366569519043": 36, "1994": [5, 9], "199484825134277": 36, "1995": 5, "1998": [5, 21], "1999": [5, 9], "1a": 5, "1b": [5, 20, 24], "1bcf": [41, 42], "1d": 8, "1d5fe2e2902": [41, 42], "1e": [26, 31, 32, 34, 35, 36, 39, 40], "1f60a": 1, "1g": [7, 14], "1i": 7, "1j": 12, "1m": 12, "1mb": 14, "1x": [5, 6], "2": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 24, 25, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "20": [1, 5, 6, 7, 8, 9, 11, 12, 13, 17, 23, 26, 28, 41, 42], "200": [5, 9, 21, 39, 42], "2000": [5, 39, 41, 42], "2001": [5, 26], "2002": [1, 6], "2003": [5, 6, 8, 10], "2004": [5, 6, 8, 13], "2006": 5, "2007": [4, 5, 6, 12], "2008": [4, 6, 13], "20080718121858aamfk0v": 5, "2009": [4, 6], "2010": [5, 6, 10, 12, 26], "2011": [5, 26, 41, 42], "2012": [5, 26], "2013": [6, 13, 26, 41, 42], "2014": [5, 6, 13, 26], "2015": [1, 5, 6, 8], "2016": [6, 8, 13, 15, 22, 41, 42], "2017": [1, 5, 6, 8, 9, 12, 13, 22, 23, 26, 41, 42], "2017765045166016": 36, "2018": [5, 6, 7, 8, 9, 11, 12, 41, 42], "20189234614372253": 39, "2019": [1, 5, 6, 7, 8, 9, 11, 12, 21, 24, 41, 42], "202": [41, 42], "2020": [1, 5, 6, 7, 8, 9, 11, 12, 21, 22, 23, 26, 41, 42], "202093124389648": 36, "2021": [5, 6, 8, 14, 17, 24, 26, 41, 42], "2021a": 5, "2022": [1, 2, 4, 14, 17, 18, 19, 21, 23, 24, 41, 42], "2023": [1, 4, 14, 15, 17, 18, 20, 21, 23, 24, 26, 41, 42], "2023a": 23, "2024": [1, 2, 4, 15, 17, 20, 21, 22, 23, 24, 26, 41, 42], "2024a": 2, "202847957611084": 36, "203221321105957": 36, "2032294273376465": 36, "2033": [34, 35, 36], "2039031982421875": 36, "203961372375488": 36, "204647064208984": 36, "2048": [1, 8, 12, 14, 31, 32, 40], "2050": 39, "205238342285156": [35, 36], "205798625946045": 36, "205985069274902": 36, "206247806549072": 36, "20643": [35, 36], "20675155868711184": 39, "2069501876831055": 36, "2076023817062378": [34, 38], "208010673522949": 36, "2081": 6, "208345413208008": 36, "2084": 6, "208878993988037": 36, "209": 6, "209777355194092": 36, "20_core_compon": 42, "20ac": 1, "20h": 42, "20h20v": 42, "21": [1, 5, 6, 7, 8, 11, 12, 14, 17, 24, 26, 35, 36, 41, 42], "2100": 39, "2101": 24, "210110664367676": 36, "2104": [1, 6, 17, 24, 31, 32, 40], "210432529449463": 39, "2105": 6, "2106": [6, 8, 24], "21068000793457": 36, "2107": 26, "2108": 1, "2109": [14, 24], "2112": 6, "211876392364502": 36, "2121": 26, "21279782056808472": [34, 38], "2128376960754395": 36, "213296890258789": 36, "213634490966797": 36, "21381": 28, "213995456695557": 36, "215": 7, "2150": 39, "21507889968048": 39, "2159": 26, "2165975123643875": [34, 38], "217": 9, "217145919799805": 36, "2175068855285645": 36, "217704772949219": 36, "21783": 1, "2180812220598306": 39, "219": 28, "219264030456543": 36, "219285011291504": 36, "219350337982178": 36, "219789028167725": 36, "21st": 21, "22": [1, 4, 5, 6, 9, 12, 18, 19, 21, 23, 24, 36, 41, 42], "220": [35, 36], "2200": 39, "220089912414551": 36, "2201": 19, "2201690673828125": 36, "2203": [1, 18, 23, 24], "220418930053711": 36, "2204294204711914": [34, 38], "2205": 19, "220532178878784": 36, "220538929104805": 39, "220764636993408": 36, "220792770385742": 36, "2208": 14, "2209": [4, 21], "2210": 24, "2212": 23, "2213757038116455": 36, "221405029296875": 36, "2214741706848145": [34, 38], "221652030944824": 36, "221750259399414": 36, "221808910369873": 36, "22231": [35, 36], "223": [5, 6, 28], "2233043611049652": [34, 38], "223731994628906": 36, "223905086517334": 36, "22411604225635529": 39, "22432074770765273": 39, "2250": [39, 41, 42], "2250871658325195": 36, "22550": [35, 36], "225741386413574": 36, "226": 6, "226304531097412": 36, "226582050323486": 36, "227": 9, "227993965148926": 36, "228": 28, "229344367980957": 36, "229555606842041": 36, "22967249155044556": 39, "22996433079242706": [34, 38], "22nd": 6, "23": [1, 2, 3, 4, 5, 6, 14, 15, 18, 20, 21, 22, 24, 26, 35, 36, 41, 42], "230": [13, 28], "2300": 39, "2302": [15, 23], "2302520275115967": 36, "2303": [1, 4, 26], "2304": 4, "2305": [1, 4, 15, 23], "2306": 1, "230792760848999": 36, "2308": [21, 24], "2310": [1, 14, 18, 20, 35, 36], "2311": 18, "2312": [21, 24], "231400489807129": 36, "23192028569184286": 39, "23215913772583": 36, "232213497161865": 36, "2322254180908203": [34, 38], "2326": [35, 36], "2333": [5, 6], "2334029": 23, "2338": 6, "233859062194824": 36, "234": 5, "234323978424072": 36, "234857439994812": [34, 38], "2350": 39, "235097408294678": 36, "235403537750244": 36, "23635927794352224": 39, "236362934112549": 36, "236627101898193": 36, "23663": 28, "236884117126465": 36, "23775900081025814": 39, "238": [41, 42], "238468647003174": 36, "238506317138672": 36, "23895448446273804": [34, 38], "23905086517334": 36, "239485263824463": 36, "23l": 42, "23rd": 6, "24": [1, 2, 4, 5, 6, 7, 8, 11, 14, 15, 20, 21, 22, 23, 24, 26, 28, 32, 35, 36, 41, 42], "2400": 39, "2401": [2, 15, 20, 23], "2402": [1, 23, 24], "2403": [21, 23], "2404": [20, 23, 26], "2405": [4, 23, 24], "2407": [1, 22], "2408": 21, "2412": 2, "241434097290039": 36, "242073059082031": 36, "242163181304932": 36, "243": 5, "243106842041016": 36, "24321489036083221": [34, 38], "24347": [35, 36], "2435624335909632": 39, "243719577789307": 36, "244636058807373": 36, "244905471801758": 36, "245": 9, "2450": 39, "24505090713501": 36, "2450714111328125": 36, "245612621307373": 36, "246973991394043": 36, "24772822535568678": 39, "247925281524658": 36, "2480": [35, 36], "249174118041992": 36, "2493443142": 28, "24th": 6, "25": [1, 5, 7, 9, 11, 13, 14, 20, 34, 36, 41, 42], "250": [5, 6, 39], "2500": [26, 39], "250100136061844": 39, "250267744064331": 39, "250294208526611": 36, "250489711761475": 36, "2514617443084717": 36, "251805305480957": 36, "252415657043457": 36, "252851486206055": 36, "253942489624023": 36, "254053115844727": 36, "254146099090576": 36, "254385948181152": 36, "254650115966797": 36, "254941940307617": 36, "255": [14, 22, 24], "2550": 39, "2551": 34, "255387783050537": 36, "255984306335449": 36, "256": [1, 5, 6, 8, 12, 28, 34, 35, 36, 37, 38, 39], "256246566772461": 36, "256918340921402": [34, 38], "257": 1, "257620811462402": 36, "258242607116699": 36, "2589764347443116": 39, "259": 28, "259034156799316": 36, "259069442749023": 36, "2595366069104909": 39, "25th": 13, "26": [5, 6, 7, 11, 13, 17, 36, 38, 41, 42], "2600": 39, "26035213470459": 36, "260522842407227": 36, "260662078857422": 36, "26072883605957": 36, "261": 28, "262": 38, "262142658233643": 36, "262190818786621": 36, "26226806640625": 36, "262915134429932": 36, "263815879821777": 36, "263994216918945": 36, "264": [34, 35, 36], "264045238494873": 36, "264111042022705": 36, "2643789052963257": 39, "264615058898926": 36, "2650": 39, "266002655029297": 36, "26678991317749": 36, "267": 9, "267117977142334": 36, "267175197601318": 36, "2679": 34, "268042087554932": 36, "268439769744873": 36, "2689290046691895": 36, "269": [19, 28], "269332408905029": 36, "269647121429443": 36, "269782066345215": 36, "2698668811876248": 39, "26th": [4, 6], "27": [5, 6, 7, 14, 18, 28, 36, 41, 42], "270": 28, "2700": 39, "2701": 34, "2702107429504395": 36, "270448684692383": 36, "271": [35, 36, 38], "271264553070068": 36, "271533966064453": 36, "272322654724121": 36, "2724": 28, "272527694702148": 36, "272828102111816": 36, "273": 38, "273373603820801": 36, "273721694946289": 36, "27378": [35, 36], "273829936981201": 36, "27407965064048767": 39, "27408504486084": 36, "2743229269981384": 39, "2745": 38, "2747355103492737": [34, 38], "2748712301254272": [34, 38], "2750": 39, "275448322296143": 36, "275712490081787": 36, "275812149047852": 36, "276309013366699": 36, "277": 5, "277144908905029": 36, "277264356613159": 36, "2779080867767334": 36, "278": [9, 28], "278239727020264": 36, "279": [34, 35, 36], "279453992843628": 36, "279878616333008": 36, "2799654006958": [35, 36], "27a6": 42, "27h": 42, "28": [1, 4, 5, 6, 7, 9, 22, 24, 36, 41, 42], "2800": 39, "280029296875": 36, "280559539794922": 36, "2807860374450684": 39, "2813216200457986": 39, "281369686126709": 36, "281500816345215": 36, "28344289717003707": 39, "284355640411377": 36, "284381866455078": 36, "284786701202393": 36, "2848913073539734": [34, 38], "2850": 39, "28593635559082": 36, "286657810211182": 36, "286722183227539": 36, "286881446838379": 36, "28696480": [41, 42], "287": [6, 38], "2870": 28, "287336826324463": 36, "288": 7, "28824520111084": 36, "288344383239746": 36, "2884441027276625": 39, "288504600524902": 36, "288642406463623": 36, "289": 28, "289977550506592": 36, "28th": 12, "29": [5, 6, 7, 8, 24], "2900": 39, "290078163146973": 36, "290414333343506": 36, "29051": [34, 35, 36], "29083251953125": 36, "29171895980835": 36, "292008399963379": 36, "292236328125": 36, "292308330535889": 36, "292393684387207": 36, "293": 14, "29322": [41, 42], "29323148727417": 36, "29353666305542": 36, "2936": 38, "293612957000732": 36, "294384956359863": 36, "29457289319999": 39, "294795036315918": 36, "294926166534424": 36, "295": [41, 42], "2950": 39, "29543": 38, "29562": 34, "295699119567871": 36, "296": 6, "296192169189453": 36, "297027826309204": 36, "297110557556152": 36, "2976996898651123": 36, "298": [5, 6, 41, 42], "2980282306671143": 36, "298332691192627": 36, "298480033874512": 36, "299": 14, "29th": 14, "2_": 12, "2a": 5, "2b": [5, 22], "2b5669c2": 42, "2bsd": 22, "2bsdp": 22, "2bypt": 22, "2c": 5, "2c7": 42, "2d": [1, 5, 13, 31, 40], "2d_": 12, "2e": 5, "2f": 5, "2fc7077e": [41, 42], "2g": 5, "2gd_": 1, "2h": [22, 42], "2h7": 42, "2hp": 22, "2i": 1, "2j": 12, "2l": 42, "2m": 12, "2v8l": 42, "2x": 6, "3": [0, 1, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 18, 20, 21, 22, 23, 25, 26, 27, 28, 31, 32, 34, 36, 38, 39, 40, 41, 42], "30": [5, 6, 7, 8, 12, 36, 42], "300": [5, 6, 28, 39, 42], "3000": 39, "30039644241333": 36, "300551414489746": 36, "3006774187088013": [34, 38], "300681114196777": 36, "3008": 23, "300i": 42, "301": [41, 42], "301499366760254": 36, "30162525177002": 36, "302": [28, 41, 42], "3021": 23, "302224636077881": 36, "302529811859131": 36, "302533149719238": 36, "3028809143600657": 39, "303577899932861": 36, "303918361663818": 36, "304": [34, 35, 36], "304293155670166": 36, "30477046966552734": 39, "3050": 39, "305261135101318": 36, "3055548667907715": 36, "30568265914917": 36, "305816173553467": 36, "305967330932617": 36, "30621": [5, 6], "30665": [34, 35, 36], "306757926940918": 36, "307093143463135": 36, "3072": 1, "308": [5, 6], "3082857131958": [35, 36], "30828776955604553": [34, 38], "30832594633102417": [34, 38], "308478832244873": 36, "309": 9, "30929644": [41, 42], "309408664703369": 36, "309920787811279": 36, "30_manual_orchestr": 42, "30k": [5, 6], "31": [5, 6, 7, 14, 22, 36, 41, 42], "3100": 39, "3102": 28, "310380458831787": 36, "310995578765869": 39, "311": [34, 35, 36], "3110": 34, "3111": [6, 13], "31115": [34, 35, 36], "311150074005127": 36, "31174373626709": 36, "311887741088867": 36, "3119": [6, 13], "311979293823242": [34, 38], "312523365020752": 36, "312560081481934": 36, "313": [6, 28], "31392": [35, 36], "3139857236895701": 39, "314": 38, "3146632623914765": 39, "315": [5, 34, 35, 36], "3150": 39, "315019607543945": 36, "315254211425781": 36, "3153": [41, 42], "315401077270508": 36, "315445423126221": 36, "31577205657959": [35, 36], "316": 28, "316316604614258": 36, "317086696624756": 36, "317536354064941": 36, "3179033994674683": [34, 38], "3184404373168945": 36, "319": [5, 6, 28], "3196fd91": [41, 42], "31v20h4": 42, "31v4h": 42, "32": [1, 5, 6, 7, 14, 22, 36, 41, 42], "3200": 39, "320345878601074": 36, "3208198547363281": 39, "3208274245262146": [34, 38], "3208323121070862": [34, 38], "3213835": 28, "321924686431885": 36, "3219523429870605": 36, "3223795890808105": 36, "322475433349609": 36, "323": [6, 35, 36], "3230046033859253": [34, 38], "323247909545898": 36, "324": 23, "324112892150879": 36, "324169851526482": 39, "324937343597412": 36, "325": 6, "3250": 39, "325492858886719": 36, "325699806213379": 36, "326": [5, 38], "326104164123535": 36, "326220512390137": 36, "326286792755127": 36, "3267621994018555": 36, "326879024505615": 36, "326934814453125": 36, "327077388763428": 36, "327323913574219": 36, "3274566013152589": 39, "327679634094238": 36, "32768": [1, 32, 35, 36], "328179359436035": 36, "329": 6, "3295214429391804": 39, "32k": 1, "32mextract": [41, 42], "33": [1, 5, 6, 7, 8, 9, 12, 19, 23, 36, 41, 42], "330": 28, "3300": 39, "3309": [35, 36], "330907344818115": 36, "33094": [35, 36], "331": 28, "3313188552856445": 36, "331404447555542": 36, "331404685974121": 36, "331676006317139": 36, "33185669779777527": [34, 38], "332029819488525": 36, "332251071929932": 36, "332863807678223": 36, "333367824554443": 36, "333590984344482": 36, "333754062652588": 36, "333774089813232": 36, "333951950073242": 36, "334": 8, "33411979675293": 36, "334537982940674": 36, "334575653076172": 36, "3347": 38, "335": [21, 28], "3350": 39, "335203170776367": 36, "3354811668396": 36, "335762023925781": 36, "336": 21, "336148262023926": 36, "336493492126465": 36, "336531639099121": 36, "337": 28, "337359428405762": 36, "3376": 28, "337612152099609": 36, "338": 28, "3380939960479736": 36, "3383": [34, 35, 36], "34": [5, 6, 7, 36, 41, 42], "340": [5, 8], "3400": 39, "340113162994385": 36, "340m": 8, "341": 5, "341320037841797": 36, "341635704040527": [35, 36], "342": 34, "342676162719727": 39, "342960357666016": 36, "343040943145752": 36, "3431472182273865": [34, 38], "3432": [35, 36], "343332290649414": 36, "343361854553223": 36, "3435": 34, "3436481123064947": 39, "34458065032959": 39, "345": [6, 23, 35, 36], "3450": 39, "34599336981773376": 39, "3463053703308105": 36, "3467597127653406": 39, "347463607788086": 36, "347705364227295": 39, "3481526374816895": 36, "34901": [34, 35, 36], "349497318267822": 36, "3495795726776123": 36, "3496479988098145": 36, "34bsd": 22, "35": [5, 6, 7], "350": 39, "3500": 39, "350389710870076": 39, "3511956036090851": [34, 38], "3517656326293945": 36, "3518853187561035": 36, "352": [5, 6], "3524281978607178": 36, "3531911373138428": 39, "35325485467910767": 39, "3535": [35, 36], "3537": [35, 36], "353724956512451": 36, "3540425300598145": 36, "3543524742126465": 36, "3550": 39, "355349540710449": 36, "3554": 34, "356051445007324": 36, "357344627380371": 36, "357487678527832": 36, "3576202392578125": 36, "358": [34, 35, 36], "3584": 22, "359": 9, "359533786773682": 36, "35969877243042": 36, "36": [5, 6, 13, 14, 36, 41, 42], "360": 28, "3600": 39, "360662937164307": 36, "3607293127420803": 39, "361": [5, 28], "362": [5, 6], "362468719482422": 36, "3626762628555298": 39, "362699031829834": 36, "362935543060303": 36, "3634558618068695": 39, "363485336303711": 36, "363903999328613": 36, "364670753479004": 36, "3650": 39, "365195274353027": 36, "366": 38, "366093635559082": 36, "366409778594971": 36, "366528511047363": 36, "366771697998047": 36, "367": [5, 6], "367013": 28, "367886066436768": 36, "368297576904297": 36, "36879": [35, 36], "369": [28, 35, 36], "3691011965274811": 39, "369438171386719": 36, "37": [2, 5, 6, 7, 24, 41, 42], "370": 28, "3700": 39, "370241641998291": 36, "370524883270264": 36, "370950222015381": 36, "371190547943115": 36, "37131962180137634": [34, 38], "371455669403076": 36, "371676445007324": 36, "371853351593018": 36, "371891021728516": 36, "37199068069458": 36, "372": [5, 6], "372015953063965": 36, "3722": 13, "3724923133850098": 36, "372688293457031": 36, "372903347015381": 36, "373": [5, 6], "3731765747070312": 36, "373385906219482": 36, "373404502868652": 36, "374": [34, 35, 36], "374007225036621": 36, "37417459487915": 36, "374730110168457": 36, "3750": 39, "375204563140869": 36, "3765709400177": 36, "37682580947876": 36, "377189636230469": 36, "37800800800323486": 39, "3781": 13, "378183364868164": 36, "378776550292969": 36, "3796772956848145": 36, "379730224609375": 36, "38": [5, 6, 7, 13, 41, 42], "380": 28, "3800": 39, "380285739898682": 36, "380952835083008": 36, "381": [41, 42], "38142": [35, 36], "3818368911743164": 36, "382": [5, 6, 34, 35, 36], "3821120262146": 36, "38214": [34, 35, 36], "38234950190919664": 39, "383841037750244": 36, "384125709533691": 36, "385": 13, "3850": [37, 39], "38566": 34, "385810375213623": 36, "3863539695739746": 36, "386f": [41, 42], "387": [36, 41, 42], "387298583984375": 36, "387340068817139": 36, "388": 36, "3882494270801544": 39, "3883811235427856": [34, 38], "3887": 6, "389": [35, 36], "3895280361175537": 39, "3896": 6, "38f": [5, 6], "39": [2, 3, 5, 6, 7, 23, 24], "390": [9, 36], "3900": [34, 37, 39, 41, 42], "390007495880127": 36, "39061975479126": 36, "390718460083008": [34, 38], "391116142272949": 36, "391934394836426": 36, "392": 28, "392367839813232": 36, "392545": [41, 42], "393157005310059": 36, "393226623535156": 36, "3936262130737305": 36, "393649101257324": 36, "393858432769775": 36, "393913745880127": 36, "394": [9, 28, 36], "394032826321432": 39, "3943068981170654": 36, "394356727600098": [35, 36], "394460201263428": 36, "394472318179944": 39, "394814491271973": 36, "395": 36, "3950": [37, 39], "39547872543335": 36, "395797729492188": 36, "396": 36, "396156311035156": 36, "396198272705078": 36, "396443367004395": 36, "3968892097473145": 36, "3981733322143555": 36, "398224353790283": 36, "398374557495117": 36, "398658752441406": 36, "3988": [35, 36], "399": 13, "399399518966675": 36, "399779796600342": 36, "399806499481201": 36, "3a": 23, "3a6": 42, "3b": 22, "3bsdp": 22, "3d": 1, "3l12": 42, "3m": [5, 6, 24], "3m0": 42, "3rd": 9, "3x": [5, 6], "4": [0, 1, 4, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "40": [1, 3, 5, 7, 8, 14, 19, 24, 28, 34, 35, 36, 41, 42], "400": [5, 39, 42], "4000": [37, 39], "40000": 5, "400i": 42, "400m": 17, "401310443878174": 36, "40156105160713196": [34, 38], "40158": [35, 36], "402266025543213": 36, "40275764465332": 36, "403815269470215": 36, "4044294357299805": 36, "4050": [37, 39], "405b": 1, "406094074249268": 36, "4070963859558105": 36, "407286643981934": 36, "407567024230957": 36, "408": [41, 42], "408968448638916": 36, "4092": [35, 36], "4092062050130844": 39, "4096": [1, 14, 22], "409931182861328": 36, "40_python_sdk": 42, "40bd": [41, 42], "40k": [5, 6], "40th": 6, "41": [3, 7, 11], "410": 7, "4100": [37, 39], "4107441902160645": 36, "411169052124023": 36, "41145658493042": 36, "41212919295760314": 39, "412205457687378": 36, "413370132446289": 36, "413440227508545": 36, "4138765335083": 36, "41429328918457": 36, "4145": 34, "4150": [37, 39], "415234088897705": 36, "41815683245658875": [34, 38], "418431282043457": 39, "418442249298096": 36, "418704986572266": 36, "419": 34, "41a7": [41, 42], "41st": 6, "42": [3, 5, 6, 8, 42], "4200": 39, "4208574295043945": 36, "421682357788086": 36, "42185115814209": 36, "4221187233924866": [34, 38], "422640323638916": 36, "423": 38, "423009395599365": 36, "423011779785156": 36, "423229217529297": 36, "423436641693115": 36, "4235": [41, 42], "424270153045654": 36, "424302339553833": 36, "4244": 34, "425": [5, 6], "4250": 39, "425178527832031": 36, "425512790679932": 36, "426880836486816": 36, "427": 28, "42734432220459": 36, "427750110626221": 36, "42807": [35, 36], "428111553192139": 36, "428226947784424": 36, "428523063659668": 36, "4287636280059814": 36, "429": [28, 34, 35, 36, 41, 42], "429275512695312": 36, "429739475250244": 36, "429806232452393": 36, "42l12": 42, "42l13": 42, "42l19": 42, "42nd": 6, "43": [3, 5, 6, 14], "430": [41, 42], "4300": 39, "431": [41, 42], "431405067443848": 36, "431438446044922": 36, "4315948486328125": 36, "432": [35, 36, 41, 42], "432180404663086": 36, "4324140548706055": 36, "432761192321777": 36, "432821750640869": 36, "433": [41, 42], "4338": [41, 42], "434": [41, 42], "4340": [35, 36], "434049606323242": 36, "4341": [41, 42], "434146881103516": 36, "434628486633301": 36, "435": [41, 42], "4350": 39, "43510968697448005": 39, "4353928565979": 36, "436": [41, 42], "43606948852539": 36, "436637878417969": 36, "436718463897705": 36, "437": [41, 42], "437107086181641": 36, "437134265899658": 36, "4378": 34, "438": [38, 41, 42], "438089370727539": 36, "438453674316406": 36, "438752174377441": 36, "439": [28, 41, 42], "43989896774292": 36, "439957618713379": 36, "43rd": 6, "44": [3, 5, 9, 14, 24, 36, 42], "440": [41, 42], "4400": 39, "4402653791785611": 39, "440547466278076": 36, "4411": 8, "441150665283203": 36, "441350936889648": 36, "4415": [41, 42], "4421": 8, "442394733428955": 36, "44239616394043": 39, "4426798820495605": [34, 38], "442732810974121": 36, "4431843757629395": 36, "443197250366211": 36, "443287372589111": 36, "444087982177734": 36, "4450": 39, "445369243621826": 36, "44551944732666": 36, "44568920135498": [35, 36], "445786476135254": 36, "44595": [34, 35, 36], "44614315032959": 36, "446750640869141": 36, "4469170570373535": 36, "4486": 34, "4496119022369385": 36, "4497267007827759": 39, "44975471496582": 36, "44th": 6, "45": [3, 5, 7, 21, 24, 41, 42], "450": [28, 39], "4500": 39, "451141357421875": 36, "4517886638641357": 36, "452328205108643": 36, "452475070953369": 36, "452916622161865": 36, "453": 6, "453352451324463": 36, "453845024108887": 36, "455": [5, 6], "4550": 39, "455920219421387": [35, 36], "456425189971924": 36, "456601619720459": 36, "45728063583374": 36, "458": [5, 6, 34, 35, 36], "458085536956787": 36, "458860397338867": 36, "459051609039307": 36, "459372520446777": 36, "459793090820312": 36, "459e": [41, 42], "45c10": 42, "46": [3, 11, 36], "4600": 39, "460000": 5, "461446285247803": 36, "4618144035339355": 36, "462": [5, 6], "4624552726745605": 36, "4628005027770996": 36, "4628641605377197": 36, "462956428527832": 36, "4637": [35, 36], "4641529619693756": 39, "46475347876548767": [34, 38], "4650": 39, "465144634246826": 36, "4653306007385254": 36, "4658331871032715": 36, "466": 6, "466038227081299": 36, "4663128215367203": 39, "466475486755371": 36, "466663837432861": 36, "468654155731201": 36, "46910417079925537": [34, 38], "46e4": [41, 42], "47": [3, 32, 35, 36], "4701": [41, 42], "470743179321289": 36, "471054553985596": 36, "471277713775635": 36, "471698522567749": 36, "4721360206604": 36, "472388744354248": 36, "472402095794678": 36, "472513198852539": 36, "4728546142578125": 36, "473038673400879": 36, "4736328125": 36, "4738071170653555": 39, "474020481109619": 36, "474560022354126": 36, "475": [9, 38], "4750": 38, "4750823974609375": 36, "4755": 34, "475765228271484": 36, "475982666015625": 36, "476": 34, "4765475988388062": 39, "476668834686279": 36, "476725101470947": 36, "476774215698242": [35, 36], "477248191833496": 36, "477256774902344": 36, "477426528930664": 36, "4774370193481445": 36, "47752046585083": 36, "477724552154541": 36, "4789605140686035": 36, "479019641876221": 36, "479202747344971": 36, "4797074794769287": 36, "4797680377960205": 36, "479838848114014": 36, "48": [3, 5, 6, 9, 19, 22, 36, 41, 42], "480766296386719": 36, "480937957763672": 36, "481202602386475": 36, "481714248657227": 36, "481831073760986": 36, "481995105743408": 36, "483189582824707": 36, "483315467834473": 36, "483484745025635": 36, "483814716339111": 36, "483890056610107": 36, "484647274017334": 36, "485343933105469": 36, "485445499420166": 36, "485818862915039": 36, "4858431711281295": 39, "4864": [32, 35, 36], "486827850341797": 36, "487637042999268": 36, "487700462341309": 36, "487936019897461": 36, "488248825073242": 36, "488309383392334": 36, "488674640655518": 36, "489042282104492": 36, "489135265350342": 36, "489388465881348": 36, "489965438842773": 36, "48e3": [41, 42], "49": [3, 7, 41, 42], "490474700927734": 36, "49088": [34, 35, 36], "49103": [35, 36], "491201877593994": 36, "491785049438477": 36, "492624759674072": 36, "4930685758590698": 39, "493218898773193": 36, "4936649799346924": 36, "493767261505127": 36, "494001865386963": 36, "4940517842769623": 39, "495570659637451": 36, "495635032653809": 36, "495880603790283": 36, "4959029606489849": 39, "496494293212891": 36, "496853351593018": 36, "497350692749023": 36, "497448921203613": 36, "4975152611732483": [34, 38], "498": [5, 6, 34], "4981274604797363": [34, 38], "498323440551758": 36, "498516082763672": 36, "498530387878418": 36, "499092102050781": 36, "499148368835449": 36, "499700": 5, "4997334480285645": 36, "49c0": [41, 42], "49d2": [41, 42], "49f6": [41, 42], "4b92": [41, 42], "4bsdp": 22, "4d": [12, 31, 40], "4d0a": 42, "4e43": [41, 42], "4h": 22, "4h4v4": 42, "4m": 23, "4m0": 42, "4o": [40, 42], "4v": 42, "4x": 14, "5": [3, 6, 7, 9, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42], "50": [1, 3, 5, 6, 8, 14, 17, 19, 34, 35, 36, 37, 39, 41, 42], "500": [1, 5, 8, 13, 17, 24, 39], "500000": 5, "500061988830566": 36, "500189781188965": 36, "500211113480706": 39, "500576972961426": 36, "500579357147217": 36, "5009": 34, "500k": [5, 6, 26], "500m": 21, "5017807483673096": 36, "501925468444824": 36, "502203643321991": [34, 38], "5025153160095215": 39, "50257": [34, 37, 38, 39], "502859115600586": 36, "503": [5, 6], "503620147705078": 36, "50405740737915": 36, "504574775695801": 36, "5048041343688965": 36, "504852771759033": 36, "505090713500977": 36, "505105972290039": 36, "507336616516113": 36, "507905960083008": 36, "508": [34, 35, 36, 38], "508111953735352": 36, "508213996887207": 36, "509119033813477": 36, "509369850158691": 36, "509552001953125": 36, "50_llamactl": 42, "50b": 26, "50m": 23, "50th": 19, "51": [3, 7, 11, 19, 28], "510": [34, 35, 36], "510037422180176": 36, "510807991027832": 36, "510921478271484": 36, "512": [1, 4, 5, 6, 8, 12, 41, 42], "5129594802856445": 36, "512974739074707": 36, "5140": 1, "515994071960449": 36, "516447067260742": 36, "516720771789551": 36, "51699161529541": [35, 36], "51749": [35, 36], "517505168914795": 36, "517650604248047": 36, "517978191375732": 36, "518763065338135": 36, "518989562988281": 36, "519045352935791": 36, "51907205581665": 36, "519378185272217": 36, "5197012424468994": 36, "52": [3, 5, 7, 14, 24, 42], "520": 6, "52064323425293": 36, "5206479844022962": 39, "521": [9, 28], "5211755128874394": 39, "5216474533081055": 36, "521772861480713": [34, 38], "522157669067383": 36, "5231332778930664": 36, "523230075836182": 36, "523402214050293": 36, "524458408355713": 36, "5248": [41, 42], "525": [35, 36], "525822639465332": 36, "526": 38, "526586055755615": 36, "5270466804504395": 36, "528031826019287": 36, "528431415557861": 36, "528918743133545": 36, "529": 28, "529574394226074": 36, "529670000076294": 36, "529696226119995": 36, "5297532081604": 36, "529804706573486": 36, "53": [3, 7, 11, 14, 24, 41, 42], "530": [5, 6], "530302047729492": 36, "5303852558135986": 36, "531440258026123": 36, "531777381896973": 36, "531828880310059": [34, 38], "532500267028809": 36, "532714605331421": 36, "533547401428223": 36, "535": 6, "535629749298096": 36, "535632133483887": 36, "5358526110649109": [34, 38], "53585433959961": 36, "535881042480469": 36, "536": 1, "536715030670166": 36, "53681755065918": 36, "537": [28, 34, 35, 36], "537608623504639": 36, "537712097167969": 36, "538330078125": 36, "538795471191406": [35, 36], "539457321166992": 36, "539644241333008": 36, "539986610412598": 36, "54": [3, 7, 14, 41, 42], "540": 0, "5420756340026855": 36, "543970584869385": 36, "544000625610352": 36, "544711589813232": 36, "54485559463501": 36, "545587062835693": 36, "545934677124023": [34, 38], "546802282333374": 36, "547": 6, "5471502542495728": [34, 38], "549046039581299": 36, "5498576164245605": 36, "549989223480225": 36, "54cbf61d": [41, 42], "55": [3, 5, 7, 14], "550": [5, 38, 39], "550424575805664": 36, "550425052642822": 36, "5504891872406006": 36, "5507609844207764": [34, 38], "5514726638793945": 36, "551836967468262": 36, "552192687988281": 36, "552657604217529": 36, "552811145782471": 36, "5529890060424805": 36, "553": [35, 36], "5534721612930298": [34, 38], "554015159606934": 36, "5544586181640625": 36, "5545": 34, "554964065551758": 36, "5555013418197632": [34, 38], "555557148217498": 39, "55605697631836": [34, 38], "556525230407715": 36, "5571": [35, 36], "557234048843384": 36, "557378768920898": [35, 36], "558029651641846": 36, "559053421020508": 36, "559063911437988": 36, "5597606897354126": [34, 38], "55c11": 42, "56": [3, 5, 6, 7, 11, 14, 42], "56008243560791": 36, "5603532791137695": 36, "5610265731811523": [34, 38], "56149673461914": 36, "56154203414917": 36, "562791347503662": 36, "5628833770751953": 36, "5643": [35, 36], "565061569213867": [35, 36], "56566047668457": 36, "566010475158691": 36, "566425323486328": 36, "566890716552734": 36, "568009376525879": 36, "568994998931885": 36, "569": 9, "569152355194092": 36, "56923770904541": 36, "5693602561950684": 36, "569487571716309": 36, "569583892822266": 36, "569966316223145": 36, "57": [3, 5, 6, 7, 14], "5711305141448975": 39, "571550369262695": 36, "571666240692139": 36, "572741508483887": 36, "573783874511719": 36, "574258804321289": 36, "574467658996582": 36, "57578182220459": 36, "576030731201172": 36, "57619571685791": 36, "576348304748535": 36, "576384544372559": 36, "577573776245117": 36, "5776": 8, "57779598236084": 36, "5788": 8, "579033374786377": 36, "579311370849609": 36, "5797553062438965": 36, "58": [3, 7, 14, 34, 35, 36, 41, 42], "580028533935547": 36, "580134868621826": 36, "580226898193359": 36, "580467224121094": 36, "580507755279541": 36, "581": 6, "581442832946777": 36, "581953048706055": 36, "58283": [35, 36], "58307a52": [41, 42], "583113193511963": 36, "583437442779541": 36, "583615779876709": 36, "5837": [35, 36], "584": 1, "584530353546143": 36, "584754943847656": 36, "584958076477051": 36, "584d": [41, 42], "585": 28, "5854703783988953": [34, 38], "585550308227539": 36, "586": 19, "5864": 28, "586897850036621": 36, "5871": [35, 36], "587782382965088": 36, "588257312774658": 36, "589232444763184": 36, "59": [5, 6, 11, 42], "590230464935303": 36, "590473175048828": 36, "590849876403809": [34, 38], "5909385681152344": 36, "5911970138549805": 36, "591366767883301": 36, "5918143ce249": [41, 42], "592565059661865": 36, "592731475830078": 36, "593": 28, "594": 28, "5949": [34, 35, 36], "5954437255859375": 36, "5963003635406494": [34, 38], "596868991851807": 36, "597": 28, "597620487213135": 36, "5977479219436646": [34, 38], "5978": [35, 36], "597959041595459": 36, "598532199859619": 36, "598954200744629": 36, "599": 28, "5995545712060928": 39, "5998": [6, 12], "5a21": [41, 42], "5b": [1, 5, 6, 22, 32, 34, 35, 36, 42], "5bsdp": 22, "5c0": 42, "5e": [34, 35, 36, 37, 38, 39], "5h18v2h3z": 42, "5h18v2h3zm0": 42, "5s7": 42, "5v": 42, "5x": 18, "6": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 24, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "60": [3, 5, 6, 7, 9, 34, 35, 36, 41, 42], "600": [5, 9, 39], "60009": [35, 36], "600272178649902": 36, "600544452667236": 36, "60056209564209": 36, "6008": [6, 12], "601119041442871": 36, "601291179656982": 36, "602296352386475": 36, "602899551391602": 36, "60315465927124": 36, "603550434112549": 36, "603623867034912": 36, "604100227355957": 36, "60424": [35, 36], "604459285736084": 36, "6048583984375": 36, "605": 28, "6051": 34, "60521936416626": 36, "6053457260131836": [34, 38], "605682849884033": 36, "605772018432617": 36, "6057915687561035": [34, 38], "6067054271698": 36, "606869220733643": 36, "607332706451416": 36, "6074926472101367": 39, "608583450317383": [35, 36], "608859539031982": 36, "60928201675415": 36, "6098673343658447": 36, "6099380850791931": 37, "609960079193115": 36, "61": [5, 6, 11, 41, 42], "610466957092285": 36, "6105570793151855": 36, "611": 14, "6119120121002197": 36, "613434791564941": 36, "614": 34, "614431858062744": 36, "614804267883301": 36, "6153844594955444": [34, 38], "6168": [35, 36], "616897106170654": 36, "617480754852295": 36, "6194265484809875": [34, 38], "62": [5, 6, 7, 11], "6206157207489014": 36, "621312618255615": 36, "621826648712158": 36, "6219611167907715": 36, "622305870056152": 36, "622346878051758": 36, "622471332550049": 36, "622495174407959": 36, "622593879699707": 36, "622760057449341": [34, 38], "624054431915283": 36, "624549865722656": 36, "625": 28, "625117301940918": 36, "625831127166748": 36, "626": 14, "62721586227417": 36, "628": 9, "628726005554199": 36, "628757476806641": 36, "629382610321045": 36, "629907608032227": 36, "62a38c14ef93": [41, 42], "63": [5, 6, 7, 14], "630148887634277": [35, 36], "630690574645996": 36, "632315635681152": 36, "632775783538818": 36, "633367538452148": 36, "633436679840088": 36, "634267807006836": 36, "634389877319336": 36, "634511470794678": 36, "635364055633545": 36, "6356282234191895": 36, "635852336883545": 36, "636819839477539": 36, "636826515197754": 36, "636929512023926": 36, "6371138095855713": 36, "637344837188721": 36, "6378068923950195": 36, "6382832527160645": 36, "638418674468994": 36, "64": [1, 5, 6, 14, 22, 24, 28, 41, 42], "6400299072265625": 36, "640043258666992": 36, "6411399841308594": 36, "641413688659668": 36, "641853332519531": 36, "64230489730835": 36, "6428487300872803": 36, "642920017242432": 36, "643113613128662": 36, "643775939941406": 36, "6444194316864014": 36, "646": 9, "646106719970703": 36, "6462178230285645": 36, "646474838256836": 36, "64660120010376": 36, "6468448042869568": 37, "647436618804932": 36, "64829683303833": 36, "6485166549682617": 36, "648794651031494": 36, "64k": 22, "65": [5, 6, 7], "650": 39, "650116920471191": 36, "6505937576293945": 36, "65060": [35, 36], "6517698764801025": 36, "65182113647461": 36, "6522207260131836": 36, "6524": [35, 36], "6527": [35, 36], "653": [34, 35, 36], "653111457824707": [34, 38], "6531763765318296": 39, "6534948348999023": 36, "653968811035156": 36, "6552670001983643": 39, "656194686889648": 36, "658": 28, "659289360046387": 36, "66": [5, 41, 42], "66028356552124": 36, "6610188484191895": 39, "661034107208252": [34, 38], "661935806274414": 36, "662009239196777": 36, "6628137826919556": 37, "663405895233154": 36, "6638": [35, 36], "664598226547241": 36, "664869785308838": 36, "6651949882507324": 36, "665449619293213": 36, "666153430938721": 36, "666990756988525": 36, "667112112045288": 36, "667187213897705": 36, "667201995849609": 36, "667232513427734": 36, "667469024658203": [34, 38], "668": 28, "668609619140625": 36, "668902397155762": 36, "669": 9, "67": [5, 9, 11], "6703057885169983": 37, "670968532562256": 36, "671": [2, 28], "671119213104248": 36, "671813488006592": 36, "6721017360687256": 36, "6727049350738525": 36, "673074245452881": 36, "673221111297607": 36, "673618316650391": 36, "673720836639404": 36, "674612998962402": 36, "6747": [35, 36], "675": [34, 35, 36], "675600528717041": 36, "675665378570557": 36, "6758": 34, "675980091094971": 36, "6762202845779502": 37, "676620960235596": 36, "677322864532471": 36, "678": [35, 36], "678136348724365": 36, "6782277143252924": 37, "678229808807373": 36, "678469657897949": 36, "679": 3, "679088592529297": 36, "68": [5, 6, 7, 14, 24], "680325984954834": 36, "680359840393066": 36, "6811306476593018": 36, "681352615356445": 36, "681512355804443": 36, "681833744049072": 36, "681835651397705": 36, "682058334350586": 36, "683": [28, 38], "6833784580230713": 36, "6834278106689453": 36, "683590888977051": 36, "684218883514404": 36, "684447288513184": 36, "684568405151367": 36, "6858339309692383": 36, "685907363891602": 36, "686": [35, 36], "687262058258057": 36, "6873087882995605": 36, "68833065032959": 36, "688720703125": 36, "688923716545105": [34, 38], "689": 4, "6893414855003357": 37, "68g": 14, "69": [5, 6, 11, 18, 24, 42], "69024658203125": 36, "690571196670064": 39, "690933227539062": 36, "690967559814453": 36, "6910786628723145": 36, "6914448738098145": 36, "691554069519043": 36, "692015171051025": 36, "692304611206055": 36, "692431449890137": 36, "692702293395996": 36, "692835807800293": 36, "6931740045547485": 39, "694700717926025": 36, "6950": [35, 36], "6956562995910645": 36, "695700645446777": 36, "6958794593811035": 36, "696": 4, "696816921234131": 36, "696834564208984": [34, 38], "697": [35, 36], "697264671325684": 36, "6973631381988525": 36, "697608232498169": 36, "69783878326416": 36, "6980": 26, "698017597198486": 36, "6988437660309196": 37, "699291229248047": 36, "69l": 42, "69l12": 42, "69l23": 42, "69v4h": 42, "6_45": [41, 42], "6a6": 42, "6b": 23, "6ce7567c": 42, "6h18v2h3zm0": 42, "6m8": 42, "6t": 1, "6th": 6, "6x": [5, 6], "7": [5, 6, 7, 9, 11, 13, 14, 18, 19, 21, 22, 23, 24, 26, 28, 31, 32, 34, 36, 38, 39, 40, 41, 42], "70": [5, 6, 7, 9, 14, 24], "700": [5, 6, 26, 34, 39, 42], "700878530984053": 39, "700i": 42, "700k": [5, 6], "701747894287109": 36, "702801704406738": 36, "7028074264526367": 36, "703210353851318": 36, "7035064101219177": 39, "703780651092529": 36, "704662322998047": 36, "704864501953125": 36, "704891681671143": 36, "7049126117942794": 37, "704917907714844": 36, "704999923706055": 36, "705": [35, 36], "705660820007324": 39, "7060208320617676": 36, "706062316894531": 36, "706840991973877": 36, "707007884979248": 36, "7073099613189697": [34, 38], "7074978351593018": 36, "707741737365723": 36, "707758903503418": [35, 36], "707916498184204": 36, "708553314208984": 36, "709282875061035": 36, "7093892097473145": 36, "70b": 22, "71": [5, 6, 7, 14, 22], "710": [41, 42], "710177421569824": 36, "71079158782959": 36, "711": 28, "7111575603485107": 36, "711648464202881": 36, "712862968444824": 36, "712878227233887": 36, "713091850280762": 36, "713352203369141": 36, "713385581970215": 36, "714572906494141": 36, "715023994445801": 36, "715595006942749": 36, "715723037719727": 36, "7158518082294832": 39, "71601676940918": 36, "716200351715088": 36, "717043399810791": 36, "717501163482666": 36, "718": [41, 42], "718930721282959": 36, "719274520874023": 36, "719524383544922": 36, "72": [5, 7, 14], "720107078552246": 36, "7205791473388672": 37, "7206292152404785": 36, "721": 28, "722000598907471": 36, "722191333770752": 36, "7227935791015625": 36, "7228095072978866": 37, "723069190979004": 36, "723470687866211": [34, 38], "723588466644287": 36, "723733425140381": 36, "723975658416748": 36, "723995208740234": 36, "724527359008789": 36, "725409030914307": 36, "726780652999878": 36, "727088212966919": 36, "727319717407227": 36, "727591514587402": 36, "728212833404541": 36, "728569984436035": 36, "729640483856201": 36, "72987174987793": 36, "72b": [1, 22, 24], "73": [5, 11, 24], "730113983154297": 36, "7304390668869019": [34, 38], "73057746887207": 36, "7306365966796875": 36, "7311224937438965": 36, "73159122467041": 36, "731667518615723": 36, "732223510742188": 36, "732889175415039": 36, "734208822250366": 36, "735": 9, "7354": [35, 36], "73932409286499": 36, "739846706390381": 36, "74": [6, 9, 14, 24, 41, 42], "740163803100586": 36, "74027681350708": 36, "741073131561279": 36, "741084098815918": 36, "741124629974365": 36, "741174697875977": 36, "741250038146973": 36, "741294860839844": 36, "741503715515137": 36, "7415623664855957": [34, 38], "741562366485596": 36, "7417104244232178": 36, "742": 28, "743686199188232": 36, "745245933532715": 36, "7454066276550293": 36, "745575428009033": 36, "747305393218994": 36, "747768878936768": 36, "747809410095215": 36, "748711585998535": 36, "7493696212768555": 36, "74m": 7, "75": [5, 6, 11, 15], "750": 39, "750854969024658": 36, "751248836517334": 36, "75154972076416": 36, "751e9282": [41, 42], "752": [35, 36], "75210428237915": 36, "75229549407959": [35, 36], "752303123474121": 36, "752645969390869": 36, "7526979942824544": 37, "75282621383667": 36, "7530999183654785": 36, "753459453582764": 36, "754215717315674": 36, "754348278045654": 36, "754844903945923": 36, "755044937133789": 36, "755195617675781": 36, "755681991577148": 36, "756224632263184": 36, "7571fd0e": [41, 42], "757355690002441": 36, "7575275960154447": 37, "758039969718746": 39, "7589945793151855": 36, "7592775821685791": [34, 38], "759560585021973": 36, "76": [5, 7, 11, 41, 42], "7600": [34, 35, 36], "760083198547363": 36, "7603330612182617": 36, "7606987953186035": 36, "761293649673462": 36, "761895179748535": 36, "7626": [35, 36], "7630279064178467": 36, "763137340545654": 36, "76379919052124": 36, "763954162597656": 36, "763996601104736": 36, "76458215713501": 36, "764934539794922": 36, "765582084655762": [35, 36], "765937805175781": 36, "766097545623779": 36, "766164302825928": 36, "766860485076904": 36, "7668848037719727": 36, "767918109893799": 36, "767960786819458": 36, "768": [7, 8, 14, 28, 34, 37, 38, 39], "768507957458496": 36, "7687": [41, 42], "7694032192230225": 36, "769754409790039": 36, "77": [5, 11], "7702178955078125": 36, "7712979316711426": 36, "772399663925171": 36, "772454738616943": 36, "7735574245452881": 39, "77386999130249": 36, "774710655212402": 36, "774909019470215": 36, "774920463562012": 36, "775512218475342": 36, "7757829034613258": 39, "7771": [35, 36], "778233051300049": 36, "7789058685302734": 36, "779604434967041": 36, "779975414276123": 36, "78": [7, 9, 18, 19, 36, 41, 42], "7802093029022217": 36, "78045129776001": 36, "7807536125183105": 36, "781039237976074": 36, "78139591217041": 36, "781938552856445": [35, 36], "784018039703369": 36, "784379005432129": 36, "785": [34, 35, 36], "785065174102783": 36, "785312175750732": [34, 38], "785589694976807": 36, "785794258117676": 36, "785893201828003": 36, "7861552238464355": 36, "786230087280273": 36, "7864863872528076": 36, "7880635261535645": 36, "7880818843841553": 36, "78818941116333": 36, "788674831390381": 36, "79": [7, 18, 36], "790492057800293": 36, "79287338256836": 36, "793": 28, "79330587387085": 36, "79390287399292": 36, "793996810913086": [35, 36], "795068740844727": 36, "7956585884094238": [34, 38], "795717716217041": 36, "796220779418945": [34, 38], "796965599060059": 36, "797081470489502": 36, "797332763671875": 36, "79794979095459": 36, "798689842224121": 36, "798949718475342": 36, "799320697784424": 36, "799370288848877": 36, "799619197845459": 36, "79gb": 22, "79l": 42, "79l5": 42, "7b": [1, 7, 14, 22, 26], "7b431dcd": [41, 42], "7c9d": [41, 42], "7croboto": 42, "7h2l3": 42, "7x": [5, 6], "8": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 18, 19, 21, 22, 24, 26, 28, 34, 35, 36, 38, 39, 41, 42], "80": [1, 5, 7, 8, 11, 14, 18, 21, 40], "800": [3, 5, 6, 8, 39], "800738334655762": 36, "801295280456543": 36, "802": 28, "802001953125": 36, "803051471710205": 36, "80307149887085": 36, "8037070035934448": [34, 38], "804": 28, "8040966987609863": 36, "805547714233398": 36, "806467056274414": 36, "806612491607666": 36, "807": [5, 6], "807152271270752": 36, "807299613952637": 36, "809548377990723": 39, "809581279754639": 39, "80978536605835": 36, "80f": [5, 6], "81": [5, 6, 11, 14], "810": 28, "810102939605713": 36, "810388565063477": 36, "8105340003967285": 36, "810624122619629": 36, "811124563217163": 36, "811209678649902": 36, "8114094734191895": 36, "8117189407348633": 36, "812191009521484": 36, "8126726150512695": 36, "8128983974456787": 36, "81308650970459": 36, "81414794921875": 36, "814231872558594": 36, "8145": [35, 36], "8146843910217285": 36, "815140247344971": 36, "8156819343566895": 36, "8167617321014404": 36, "816813945770264": 36, "8174004554748535": 36, "817617416381836": 36, "8177027702331543": 36, "8192": 22, "8197818994522095": 36, "819911003112793": 36, "819949626922607": 36, "81d6": 42, "82": [5, 6, 7, 14, 18, 36], "820557594299316": 36, "8216": 38, "8216800689697266": [34, 38], "821797847747803": 36, "821817398071289": 36, "822120189666748": 36, "8225502967834473": 36, "823371648788452": [34, 38], "823562145233154": 36, "823636054992676": 36, "824": 6, "824695587158203": [34, 38], "825289726257324": 36, "825384616851807": 36, "826181888580322": 36, "8262834548950195": 36, "826323509216309": 36, "8265886306762695": 36, "82674": 34, "826778411865234": [35, 36], "827072620391846": 36, "828341007232666": 36, "828f0e0ce7c3": [41, 42], "829176425933838": 36, "829235553741455": 36, "8292932510375977": 36, "829486131668091": 36, "82970666885376": 36, "83": [7, 11, 14], "830827236175537": 36, "831056118011475": 36, "831080675125122": 36, "831615447998047": 36, "832583427429199": 36, "833148002624512": 36, "833350658416748": 36, "833383560180664": 36, "8344197273254395": 36, "835850715637207": 36, "835949420928955": 36, "835978031158447": 36, "836": [6, 24], "836061954498291": 36, "836536407470703": 36, "8368377685546875": 36, "837181568145752": 36, "8372912406921387": 36, "837329864501953": 36, "837427139282227": 36, "8381655649834774": 39, "838168621063232": 36, "8385039567947388": [34, 38], "8390822410583496": 36, "8393359184265137": 36, "839694976806641": 36, "83f73b43": 42, "84": [5, 11, 14, 42], "843852519989014": 36, "845158576965332": [35, 36], "8457": 28, "845762729644775": 36, "8462512493133545": 36, "846373081207275": 36, "847": [35, 36], "8477879156293748": 39, "8480": [35, 36], "848109722137451": 36, "8482837677001953": 36, "848433494567871": 36, "849096417427063": [34, 38], "85": [5, 6, 11, 18, 24], "850": 39, "850433349609375": 36, "850610256195068": 36, "851036548614502": 36, "85136079788208": 36, "852": 28, "852313041687012": 36, "852490425109863": 36, "852870941162109": 36, "853": 28, "853394985198975": 36, "853605031967163": 36, "853939533233643": 36, "8541741371154785": 36, "8544": 34, "854536056518555": 36, "854578495025635": 36, "854784965515137": 36, "857": 6, "857684373855591": 36, "8582260608673096": 36, "858340263366699": 36, "85955286026001": 36, "85ec": [41, 42], "86": [5, 7, 14, 24], "860": 6, "86091": [34, 35, 36], "8609557151794434": 36, "861074447631836": 36, "861825942993164": 36, "861833095550537": [34, 38], "862": [35, 36], "862744331359863": [34, 38], "862921714782715": 36, "863290309906006": 36, "863368034362793": 36, "8637996912002563": [34, 38], "864298343658447": 36, "8648743629455566": 36, "865966796875": 36, "866605758666992": [34, 38], "866785049438477": 36, "867308616638184": 36, "868498802185059": 36, "87": [5, 6, 7, 11, 14, 24], "8703227043151855": 36, "8712005615234375": [34, 38], "871994972229004": 36, "872298240661621": 36, "872332572937012": 36, "872432708740234": 36, "872669696807861": 36, "87325382232666": 36, "873578071594238": 36, "8736047744750977": 36, "87380313873291": 36, "8741434812545776": 37, "8748": 17, "8751044273376465": 36, "876048564910889": 36, "876171588897705": 36, "8763": 17, "876376628875732": 36, "87647533416748": 36, "8768836422597044": 39, "8772687911987305": 36, "878566741943359": 36, "879708290100098": 36, "8797768950462341": 39, "88": [5, 11, 14, 28], "880929946899414": 36, "881252765655518": 36, "882": [35, 36], "882725715637207": 36, "883283615112305": 36, "883755207061768": 36, "884": [41, 42], "884681701660156": 36, "884730815887451": 36, "88575": [35, 36], "885791301727295": 36, "885951042175293": 36, "886054039001465": 36, "886f": [41, 42], "887": 9, "8876073360443115": 36, "8876633644104": 36, "8881": [35, 36], "888261795043945": 36, "888372898101807": 36, "888976573944092": 36, "889030933380127": 36, "889654159545898": [34, 38], "889729976654053": 36, "89": [5, 11, 14, 24, 42], "890717029571533": 36, "890924453735352": 36, "892027854919434": 36, "892342567443848": 36, "892409324645996": 36, "8928182125091553": 36, "8931796550750732": 36, "893668174743652": 36, "894": [34, 35, 36], "89480447769165": 36, "895185947418213": 36, "8953351974487305": 36, "895663738250732": 36, "895957946777344": 36, "896": [1, 22, 32, 35, 36], "896338701248169": 36, "897386074066162": 36, "897405624389648": 36, "897862672805786": 36, "8983609676361084": 36, "898429870605469": 36, "899875164031982": 36, "899890422821045": 36, "8a4": 42, "8aa8": [41, 42], "8b": [5, 6, 42], "8bit": [5, 6], "8k": [3, 42], "8l11": 42, "8z": 42, "9": [1, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 18, 22, 23, 24, 26, 27, 28, 34, 35, 36, 38, 41, 42], "90": [5, 7, 11, 18, 24, 34, 38, 41, 42], "900": [5, 6, 39], "900402545928955": 36, "90108060836792": 36, "90164852142334": 36, "90189790725708": 36, "9022767543792725": 36, "903525352478027": 36, "90477180480957": 36, "9049072265625": 36, "9050904512405396": [34, 38], "9056620597839355": 36, "906172513961792": 36, "9063": [35, 36], "90633487701416": 36, "906378746032715": 36, "906666278839111": 36, "9074": 38, "91": [5, 14, 24], "910447120666504": 36, "911383628845215": 36, "911465644836426": [34, 38], "91188907623291": 36, "912365198135376": 36, "912549018859863": 36, "9133124351501465": 36, "913785934448242": 36, "9140095710754395": 36, "9142746925354": 36, "914324760437012": 36, "914765357971191": 36, "916": [35, 36], "9162068367004395": 36, "916520118713379": 36, "91668176651001": 36, "917107582092285": 36, "917119979858398": 36, "917527198791504": 36, "918045997619629": 36, "918137550354004": 36, "918391704559326": 36, "918561935424805": 36, "9189252853393555": 36, "9197351932525635": 36, "92": [5, 6, 7, 14, 19, 42], "920": 5, "920042514801025": 36, "9200592041015625": 36, "9204912185668945": 36, "920564889907837": 36, "921731472015381": 36, "9226": [41, 42], "922638893127441": 36, "92359733581543": 36, "9241669178009033": 36, "9244496822357178": 36, "924680709838867": 36, "924805164337158": 36, "924842834472656": 36, "924886226654053": 36, "925065279006958": 36, "925262928009033": 36, "92586088180542": 36, "927282333374023": [35, 36], "927736759185791": 36, "928682327270508": 36, "9287333488464355": 36, "9288668632507324": 36, "929": 9, "929883003234863": 36, "92l10": 42, "93": [7, 11, 14, 19], "930153846740723": 36, "930305480957031": 36, "931658744812012": 36, "931668281555176": 36, "932027578353882": 36, "932221412658691": 36, "932360649108887": 36, "9327": [37, 39], "9330551624298096": 36, "934": 28, "9340012073516846": 36, "934116363525391": 39, "934217929840088": 36, "934983253479004": [35, 36], "935726165771484": 36, "936": 34, "9394731521606445": 36, "939565896987915": 36, "94": 5, "9410641193389893": 36, "9412453174591064": 36, "941544532775879": 36, "9419379234313965": 36, "942060433071201": 39, "94294548034668": 36, "943296194076538": 36, "9441943168640137": 36, "946": 28, "94623327255249": 36, "946823835372925": 36, "947456359863281": [35, 36], "948013305664062": 36, "9481024742126465": 36, "948268890380859": 36, "948304653167725": 36, "9484546184539795": 36, "948454856872559": 36, "948586463928223": 36, "949153900146484": 36, "95": 7, "950": [28, 39], "950073719024658": 36, "9502949714660645": 36, "950989246368408": 36, "951192378997803": 36, "951941967010498": 36, "952410697937012": 36, "952450275421143": 36, "95388650894165": 36, "95413064956665": 36, "954265594482422": 36, "9543941020965576": 36, "954722881317139": 36, "955": 28, "955168724060059": 36, "955503463745117": [34, 38], "9562225341796875": 36, "9569365978240967": 36, "956958293914795": 36, "9570159912109375": 36, "959106922149658": 36, "959136009216309": 36, "9597320556640625": 36, "95978886500486": 39, "95d43e88c7c1": [41, 42], "96": [1, 5, 7, 13], "96026611328125": 36, "961142539978027": 36, "961429595947266": 36, "961651802062988": [35, 36], "9625": [35, 36], "963241577148438": 36, "964": [37, 39], "964029312133789": [35, 36], "9645": [34, 35, 36], "965": 28, "9658665657043457": 36, "966070652008057": 36, "966353416442871": 36, "9665141105651855": 36, "967166423797607": 36, "967503786087036": 36, "968055009841919": [34, 38], "968337297439575": 36, "969112873077393": 36, "969647169113159": 36, "96h2": 42, "97": [5, 8, 41, 42], "970147609710693": 36, "9703688621521": 36, "970599412918091": 36, "971130132675171": 39, "9712347984313965": 36, "9737207889556885": 36, "9738078117370605": 36, "9749789237976074": 36, "975": [35, 36], "975719928741455": 36, "976319313049316": [34, 38], "977041721343994": 36, "97719144821167": 36, "977738380432129": 36, "978": [41, 42], "978025436401367": 36, "979550361633301": 36, "98": [5, 14, 41, 42], "980317115783691": 36, "981": [41, 42], "9820597171783447": 36, "982873797151425": 39, "9838547706604": 36, "9840877056121826": 36, "985": 6, "985239267349243": 36, "9856": [35, 36], "985677719116211": 36, "98590087890625": 36, "9863040447235107": 36, "9869866371154785": 36, "987048387527466": 36, "98706579208374": 36, "9870753288269043": [34, 38], "988": 6, "988377571105957": 36, "988438606262207": 36, "988609313964844": 36, "9887170791625977": [34, 38], "988809585571289": 36, "988922595977783": 36, "988944053649902": 36, "99": [5, 14], "992218255996704": 36, "992305278778076": 36, "99277925491333": 36, "9927866458892822": 36, "9929": 6, "993241786956787": 36, "9939": 6, "9949235916137695": 36, "995843887329102": 36, "995906829833984": 36, "9966230392456055": 36, "9968742728233337": 39, "997178077697754": 36, "9978317618370056": [34, 38], "998691082000732": 36, "999": 26, "999240875244141": 36, "999532699584961": 36, "999742269515991": 36, "999855995178223": 36, "9998772144317627": 36, "9bsdp": 22, "9fd33479": [41, 42], "9gb": 22, "9m": 24, "9z": 42, "9zm20": 42, "A": [0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 13, 14, 17, 19, 20, 22, 23, 25, 26, 31, 35, 40, 41, 42], "AND": 5, "ANDs": 5, "AT": 8, "And": [5, 14, 20, 21, 22, 23], "As": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 26, 41, 42], "At": [2, 5, 6, 7, 12, 14, 15, 17, 21, 22, 23, 24, 25], "Be": 21, "Being": [5, 13], "But": [5, 6, 9, 13, 19, 22, 23], "By": [0, 1, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 18, 21, 23, 26, 31, 40, 41, 42], "For": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 41, 42], "IN": [41, 42], "IT": [14, 21, 41, 42], "If": [1, 2, 3, 5, 6, 7, 8, 9, 12, 14, 15, 18, 20, 21, 22, 23, 25, 31, 40, 41, 42], "In": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 21, 22, 23, 24, 25, 26, 31, 32, 36, 40, 41, 42], "It": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42], "Its": [5, 17], "No": [9, 14, 19, 41, 42], "Not": [13, 20, 22, 26], "OR": [5, 12], "ORs": 5, "Of": [5, 42], "On": [1, 5, 7, 8, 12, 13, 19, 21, 22, 23, 24, 25, 26, 42], "One": [1, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 21, 23, 24, 25, 26, 41, 42], "Or": 25, "Such": [1, 5, 6, 13, 20, 21, 23, 41, 42], "That": [1, 5, 6, 7, 8, 11, 13, 14, 23, 25, 26], "The": [2, 3, 4, 6, 7, 10, 11, 17, 18, 19, 20, 21, 26, 31, 32, 34, 36, 39, 40, 41, 42], "Their": [1, 5, 8, 20, 41, 42], "Then": [5, 6, 8, 9, 14, 18, 26], "There": [4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21, 26, 31, 32, 40, 41, 42], "These": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 26, 41, 42], "To": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 14, 17, 18, 20, 21, 23, 24, 26, 39, 40, 42], "With": [1, 2, 5, 6, 8, 11, 12, 13, 14, 18, 20, 21, 22, 23, 25, 26, 41, 42], "_": [1, 2, 4, 5, 6, 7, 8, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 34, 40, 41, 42], "_0": [23, 24], "_1": [1, 2, 5, 6, 12, 31, 32, 40], "_2": [2, 5, 12], "__analyt": 42, "__call__": 33, "__config": 42, "__drawer": 42, "__getitem__": [34, 35, 36, 38], "__init__": [31, 32, 34, 35, 36, 37, 38, 39, 40], "__len__": [34, 35, 36, 38], "__main__": [32, 34, 35, 36, 38], "__md_analyt": 42, "__md_get": 42, "__md_hash": 42, "__md_scope": 42, "__md_set": 42, "__name__": [32, 34, 35, 36, 38], "__nav_1": 42, "__nav_1_5": 42, "__nav_1_5_label": 42, "__nav_1_8": 42, "__nav_1_8_label": 42, "__nav_1_label": 42, "__nav_2": 42, "__nav_2_3": 42, "__nav_2_3_2": 42, "__nav_2_3_2_label": 42, "__nav_2_3_label": 42, "__nav_2_4": 42, "__nav_2_4_label": 42, "__nav_2_5": 42, "__nav_2_5_label": 42, "__nav_2_6": 42, "__nav_2_6_label": 42, "__nav_2_8": 42, "__nav_2_8_2": 42, "__nav_2_8_2_label": 42, "__nav_2_8_label": 42, "__nav_2_9": 42, "__nav_2_9_2": 42, "__nav_2_9_2_label": 42, "__nav_2_9_3": 42, "__nav_2_9_3_label": 42, "__nav_2_9_4": 42, "__nav_2_9_4_label": 42, "__nav_2_9_5": 42, "__nav_2_9_5_label": 42, "__nav_2_9_label": 42, "__nav_2_label": 42, "__nav_3": 42, "__nav_3_label": 42, "__nav_4": 42, "__nav_4_10": 42, "__nav_4_10_label": 42, "__nav_4_11": 42, "__nav_4_11_label": 42, "__nav_4_12": 42, "__nav_4_12_label": 42, "__nav_4_13": 42, "__nav_4_13_label": 42, "__nav_4_14": 42, "__nav_4_14_label": 42, "__nav_4_15": 42, "__nav_4_15_label": 42, "__nav_4_16": 42, "__nav_4_16_label": 42, "__nav_4_17": 42, "__nav_4_17_label": 42, "__nav_4_18": 42, "__nav_4_18_label": 42, "__nav_4_19": 42, "__nav_4_19_label": 42, "__nav_4_2": 42, "__nav_4_20": 42, "__nav_4_20_label": 42, "__nav_4_21": 42, "__nav_4_21_label": 42, "__nav_4_22": 42, "__nav_4_22_label": 42, "__nav_4_23": 42, "__nav_4_23_label": 42, "__nav_4_24": 42, "__nav_4_24_label": 42, "__nav_4_25": 42, "__nav_4_25_label": 42, "__nav_4_26": 42, "__nav_4_26_label": 42, "__nav_4_27": 42, "__nav_4_27_label": 42, "__nav_4_28": 42, "__nav_4_28_label": 42, "__nav_4_29": 42, "__nav_4_29_label": 42, "__nav_4_2_label": 42, "__nav_4_3": 42, "__nav_4_30": 42, "__nav_4_30_label": 42, "__nav_4_31": 42, "__nav_4_31_label": 42, "__nav_4_32": 42, "__nav_4_32_label": 42, "__nav_4_33": 42, "__nav_4_33_label": 42, "__nav_4_34": 42, "__nav_4_34_label": 42, "__nav_4_35": 42, "__nav_4_35_label": 42, "__nav_4_36": 42, "__nav_4_36_label": 42, "__nav_4_37": 42, "__nav_4_37_label": 42, "__nav_4_38": 42, "__nav_4_38_label": 42, "__nav_4_39": 42, "__nav_4_39_label": 42, "__nav_4_3_label": 42, "__nav_4_4": 42, "__nav_4_4_label": 42, "__nav_4_5": 42, "__nav_4_5_label": 42, "__nav_4_6": 42, "__nav_4_6_label": 42, "__nav_4_7": 42, "__nav_4_7_label": 42, "__nav_4_8": 42, "__nav_4_8_label": 42, "__nav_4_9": 42, "__nav_4_9_label": 42, "__nav_4_label": 42, "__nav_5": 42, "__nav_5_10": 42, "__nav_5_10_5": 42, "__nav_5_10_5_label": 42, "__nav_5_10_label": 42, "__nav_5_11": 42, "__nav_5_11_label": 42, "__nav_5_13": 42, "__nav_5_13_label": 42, "__nav_5_2": 42, "__nav_5_2_2": 42, "__nav_5_2_2_label": 42, "__nav_5_2_label": 42, "__nav_5_3": 42, "__nav_5_3_label": 42, "__nav_5_4": 42, "__nav_5_4_2": 42, "__nav_5_4_2_label": 42, "__nav_5_4_4": 42, "__nav_5_4_4_label": 42, "__nav_5_4_5": 42, "__nav_5_4_5_label": 42, "__nav_5_4_6": 42, "__nav_5_4_6_label": 42, "__nav_5_4_label": 42, "__nav_5_5": 42, "__nav_5_5_label": 42, "__nav_5_6": 42, "__nav_5_6_label": 42, "__nav_5_7": 42, "__nav_5_7_10": 42, "__nav_5_7_10_label": 42, "__nav_5_7_2": 42, "__nav_5_7_2_label": 42, "__nav_5_7_3": 42, "__nav_5_7_3_label": 42, "__nav_5_7_4": 42, "__nav_5_7_4_label": 42, "__nav_5_7_5": 42, "__nav_5_7_5_label": 42, "__nav_5_7_6": 42, "__nav_5_7_6_label": 42, "__nav_5_7_9": 42, "__nav_5_7_9_label": 42, "__nav_5_7_label": 42, "__nav_5_8": 42, "__nav_5_8_label": 42, "__nav_5_9": 42, "__nav_5_9_label": 42, "__nav_5_label": 42, "__nav_6": 42, "__nav_6_4": 42, "__nav_6_4_label": 42, "__nav_6_5": 42, "__nav_6_5_label": 42, "__nav_6_label": 42, "__nav_7": 42, "__nav_7_10": 42, "__nav_7_10_label": 42, "__nav_7_11": 42, "__nav_7_11_label": 42, "__nav_7_12": 42, "__nav_7_12_11": 42, "__nav_7_12_11_label": 42, "__nav_7_12_label": 42, "__nav_7_13": 42, "__nav_7_13_label": 42, "__nav_7_14": 42, "__nav_7_14_label": 42, "__nav_7_15": 42, "__nav_7_15_label": 42, "__nav_7_16": 42, "__nav_7_16_label": 42, "__nav_7_17": 42, "__nav_7_17_label": 42, "__nav_7_18": 42, "__nav_7_18_label": 42, "__nav_7_19": 42, "__nav_7_19_label": 42, "__nav_7_2": 42, "__nav_7_20": 42, "__nav_7_20_label": 42, "__nav_7_21": 42, "__nav_7_21_label": 42, "__nav_7_22": 42, "__nav_7_22_label": 42, "__nav_7_23": 42, "__nav_7_23_label": 42, "__nav_7_24": 42, "__nav_7_24_label": 42, "__nav_7_25": 42, "__nav_7_25_label": 42, "__nav_7_26": 42, "__nav_7_26_label": 42, "__nav_7_27": 42, "__nav_7_27_label": 42, "__nav_7_28": 42, "__nav_7_28_label": 42, "__nav_7_29": 42, "__nav_7_29_label": 42, "__nav_7_2_label": 42, "__nav_7_3": 42, "__nav_7_30": 42, "__nav_7_30_label": 42, "__nav_7_31": 42, "__nav_7_31_label": 42, "__nav_7_32": 42, "__nav_7_32_1": 42, "__nav_7_32_1_label": 42, "__nav_7_32_2": 42, "__nav_7_32_2_label": 42, "__nav_7_32_3": 42, "__nav_7_32_3_label": 42, "__nav_7_32_4": 42, "__nav_7_32_4_label": 42, "__nav_7_32_5": 42, "__nav_7_32_5_label": 42, "__nav_7_32_6": 42, "__nav_7_32_6_label": 42, "__nav_7_32_7": 42, "__nav_7_32_7_label": 42, "__nav_7_32_label": 42, "__nav_7_33": 42, "__nav_7_33_label": 42, "__nav_7_34": 42, "__nav_7_34_label": 42, "__nav_7_3_label": 42, "__nav_7_4": 42, "__nav_7_4_label": 42, "__nav_7_5": 42, "__nav_7_5_label": 42, "__nav_7_6": 42, "__nav_7_6_label": 42, "__nav_7_7": 42, "__nav_7_7_label": 42, "__nav_7_8": 42, "__nav_7_8_label": 42, "__nav_7_9": 42, "__nav_7_9_label": 42, "__nav_7_label": 42, "__nav_8": 42, "__nav_8_3": 42, "__nav_8_3_label": 42, "__nav_8_5": 42, "__nav_8_5_label": 42, "__nav_8_label": 42, "__nav_9": 42, "__nav_9_label": 42, "__palett": 42, "__palette_0": 42, "__palette_1": 42, "__palette_2": 42, "__search": 42, "__tabbed_": 42, "__toc": 42, "_d": 2, "_execution_engin": 36, "_f": 1, "_get_batch_logp": 35, "_h": 1, "_i": [1, 2, 5, 6, 9, 12, 13], "_j": [1, 12], "_k": [13, 24, 26], "_m": 12, "_mkdocstr": 42, "_n": 15, "_prepare_4d_causal_attention_mask_with_cache_posit": [31, 40], "_q": [5, 14], "_r": 5, "_static": 42, "_t": [2, 5, 13, 15], "_tensor": 36, "_tied_weights_kei": [31, 32, 36, 40], "_update_causal_mask": [31, 40], "_v": 24, "_w": 14, "_x": 14, "a21a738": [41, 42], "a3a5": [41, 42], "a3e27ab0": [41, 42], "a3f1": [41, 42], "a94e91d": [41, 42], "a_": [1, 5, 6, 7, 8, 23], "a_0": [23, 25], "a_1": 25, "a_q": 5, "a_r": 5, "a_t": [23, 25], "aakanksha": [18, 24], "aapo": 26, "aaron": 6, "aayog": [41, 42], "ab": [1, 2, 6, 8, 12, 14, 18, 19, 22, 23, 24], "ab1d8deded01": [41, 42], "abbrevi": 5, "abcd": 11, "abdelrahman": 11, "abdomen": 5, "abhimanyu": 1, "abhinav": 1, "abiiti": [6, 21], "abil": [0, 1, 2, 3, 5, 6, 7, 8, 10, 13, 21, 23, 24, 26, 42], "abl": [5, 6, 7, 8, 9, 12, 13, 22, 23, 42], "ablat": [8, 14, 18], "abnorm": 5, "abolut": 1, "about": [1, 3, 5, 6, 7, 8, 14, 18, 20, 21, 23, 24, 40, 41, 42], "abov": [1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 19, 21, 23, 24, 25, 26, 31, 40, 42], "absenc": [5, 6, 23], "absmax": 14, "absolut": [5, 6, 8, 9, 14, 22], "absorb": 7, "abstract": [4, 5, 6, 11, 18, 25, 42], "abus": 3, "ac": [41, 42], "ac08b3e72275": [41, 42], "academ": [5, 6, 41, 42], "acc": [11, 24], "accademia": [], "acceler": [0, 1, 5, 6, 12, 15, 30], "accent": [5, 42], "accept": [5, 6, 11, 41, 42], "access": [0, 5, 6, 12, 14, 21, 40, 41, 42], "accid": [5, 6], "accident": [5, 6], "accommod": [5, 14], "accomplish": [5, 6, 7, 12, 19, 20, 22, 23], "accord": [5, 6, 14, 15, 21, 22, 25], "accordingli": [5, 7], "account": [1, 5, 6, 8, 31, 32, 40, 41, 42], "accountabilityprocess": [41, 42], "accredit": [41, 42], "accum": 14, "accumul": [5, 6, 14, 22, 26, 42], "accumulate_grad": 36, "accur": [1, 2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 18, 19, 20, 21, 24, 26, 40, 41, 42], "accuraci": [0, 5, 6, 9, 14, 18, 20, 21, 22, 41, 42], "accuracy_in_clinical_document": [41, 42], "acero": 6, "acheiv": 5, "achiev": [1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 23, 24, 31, 32, 40], "achin": [1, 2, 11, 12], "aci": [41, 42], "acid": [5, 6], "acklei": 5, "acl2023": [20, 21], "acm": [4, 6, 12, 21], "acquir": [1, 7, 8, 26], "acquisit": 2, "acronym": 21, "across": [0, 1, 2, 3, 5, 6, 7, 8, 12, 13, 14, 17, 18, 19, 21, 22, 24, 26, 31, 32, 40, 41, 42], "act": [1, 2, 5, 12, 19, 23, 24, 34, 41, 42], "action": [5, 6, 17, 19, 20, 23, 40, 42], "actit": 22, "activ": [1, 2, 5, 6, 7, 8, 12, 14, 21, 41, 42], "activeloop": 42, "actor": [3, 5], "actual": [5, 6, 8, 9, 13, 14, 21, 23, 24], "ad": [1, 2, 4, 7, 8, 9, 12, 14, 15, 17, 20, 21, 23, 24, 26, 41, 42], "ad54": [41, 42], "adam": [4, 5, 6, 11, 24], "adamw": [34, 35, 36, 37, 38, 39], "adap": 24, "adapt": [1, 2, 5, 6, 7, 8, 12, 15, 17, 19, 21, 23, 42], "adaptor": 24, "adc": [5, 6], "add": [1, 2, 5, 6, 8, 11, 12, 14, 15, 17, 21, 23, 24, 26, 31, 32, 40, 42], "addeventlisten": 42, "addison": 6, "addit": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 26, 40], "addition": [2, 22, 23], "additional_kwarg": [41, 42], "addon": 42, "address": [1, 2, 5, 6, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 41, 42], "adept": 24, "adequaci": 21, "adher": [5, 21], "adhocretrievaldemob": 5, "adhocretrievaldemogoogl": 5, "adiabat": 5, "aditya": [8, 17], "adject": [5, 9, 13], "adjust": [1, 2, 5, 6, 8, 13, 14, 21, 26, 40], "administr": [41, 42], "administrative_data": [41, 42], "admiss": [41, 42], "admit": [5, 18], "adopt": [1, 5, 6, 7, 8, 11, 12, 17, 21, 22, 23, 41, 42], "adpt": 24, "advanc": [0, 1, 2, 4, 5, 7, 8, 9, 12, 13, 17, 23, 30, 41, 42], "advanced_ingestion_pipelin": 42, "advanced_prompt": 42, "advanced_rag_with_llamapars": 42, "advanced_retriev": 42, "advanced_text_to_sql": 42, "advantag": [1, 5, 6, 8, 9, 10, 11, 12, 13, 14, 21, 22, 23, 26, 41, 42], "advent": [0, 8, 41, 42], "adventur": [7, 42], "adverb": 13, "adversari": [3, 8], "advertis": 5, "advic": [3, 5, 41, 42], "advis": 5, "advisor": [], "aer": 9, "affect": [1, 5, 6, 9, 13, 21, 23, 26], "affili": [41, 42], "affin": [2, 14], "afflin": 14, "afford": [5, 22], "aforement": 2, "africa": [41, 42], "after": [1, 4, 5, 6, 8, 9, 12, 13, 14, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "afterend": 42, "ag": [1, 3, 4, 5, 6, 30, 41, 42], "again": [5, 6, 14, 23], "against": [3, 5, 6, 8, 21, 23], "agarw": [17, 23], "agenc": 20, "agent": [4, 23, 25, 41, 42], "agent_around_query_pipeline_with_hyde_for_pdf": 42, "agent_build": 42, "agent_runn": 42, "agent_runner_rag_control": 42, "agent_search": 42, "agent_search_retriev": 42, "agentic_rag_using_vertex_ai": 42, "agentic_rag_with_llamaindex_and_vertexai_managed_index": 42, "agentic_strategi": 42, "agentop": 42, "agents_coa": 42, "agents_lat": 42, "agents_llm_compil": 42, "aggreg": [5, 6, 13, 22, 41, 42], "aggress": [1, 5, 14, 24, 26], "aghajanyan": 8, "agi": 0, "agiev": 3, "agnost": [5, 6, 7, 8, 11], "ago": [], "ago0": 5, "agre": 21, "agreement": [5, 6, 9], "ahm": [1, 6], "ahmad": 5, "ahz": 1, "ai": [1, 2, 5, 6, 9, 13, 21, 23, 30, 41, 42], "ai2019learn": 5, "ai21": 42, "aid": [5, 6, 20, 41, 42], "aidan": [6, 12], "aigc": 17, "aim": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 15, 17, 18, 20, 21, 23, 24, 26, 31, 32, 40, 41, 42], "aimcallback": 42, "ain": 13, "ainsli": 1, "aiohappyeyebal": [41, 42], "aiohttp": [41, 42], "aiosign": [41, 42], "airbyt": 42, "airbyte_cdk": 42, "airbyte_gong": 42, "airbyte_hubspot": 42, "airbyte_salesforc": 42, "airbyte_shopifi": 42, "airbyte_strip": 42, "airbyte_typeform": 42, "airbyte_zendesk_support": 42, "airlin": 5, "airtabl": 42, "airtrain": 42, "airtrainai": 42, "aisearch": 42, "aitchison": 24, "aixin": 2, "aka": 42, "akari": 20, "akc": 5, "al": [1, 2, 5, 6, 7, 9, 11, 12, 13, 14, 17, 22, 23, 24, 41, 42], "alan": 15, "alarm": 5, "albeit": [41, 42], "alben": 22, "albert": [1, 12, 24], "alberti": 6, "alcohol": [5, 6], "aldo": 24, "alec": [7, 9, 11, 12, 17, 23, 26], "aleph": 42, "alephalpha": 42, "alessandro": 6, "alex": [6, 20, 23, 24], "alexand": [12, 21], "alexandr": 1, "alexandra": 1, "alexei": 12, "alexi": 8, "alg": 25, "algebra": 23, "algolia": 42, "algorithm": [1, 5, 6, 13, 20, 22], "aliaksei": 6, "alibaba": 42, "alibabacloud": 42, "alibabacloud_aisearch": 42, "alibabacloud_aisearch_rerank": 42, "alibabacloud_opensearch": 42, "alibabacloudopensearchindexdemo": 42, "alic": 20, "align": [0, 1, 2, 6, 7, 8, 10, 11, 12, 13, 14, 17, 19, 21, 24, 25, 26, 30, 31, 40], "alik": 5, "all": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 31, 32, 40, 41, 42], "all_logit": 35, "all_logp": 35, "all_loss": [37, 39], "allan": [6, 23], "alleg": 9, "allen": 24, "aller": 7, "allerg": [5, 6], "allergi": [41, 42], "allevi": [1, 2, 5, 6, 9, 10, 12, 21], "allgath": 22, "alloc": [2, 5, 14, 41, 42], "allow": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 25, 26, 41, 42], "allow_unreach": 36, "allowed_speci": 38, "allreduc": 22, "almeida": 23, "almost": [5, 41, 42], "alon": [5, 7, 8, 12, 24, 40], "along": [1, 5, 6, 7, 21, 25, 31, 32, 40, 41, 42], "aloud": 19, "alpaca_data": [34, 35, 36], "alpha": [1, 2, 5, 6, 8, 13, 15, 24, 26, 42], "alpha_0": 26, "alpha_1": 2, "alpha_2": 2, "alpha_k": 26, "alphabet": [5, 6], "alreadi": [5, 6, 21, 24, 25, 31, 39, 40, 41, 42], "also": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 40, 41, 42], "alt": 42, "altdj": 1, "alter": 5, "altern": [5, 6, 8, 9, 13, 15, 21, 25, 41, 42], "although": [1, 5, 6, 8, 10, 12, 13, 21, 22, 23, 24, 25, 26], "alwai": [2, 5, 6, 7, 9, 19, 22, 42], "am": [5, 8], "amanda": [1, 7, 9, 12, 17, 23], "amaz": [5, 19], "amazon": [5, 42], "amazon_product_extract": 42, "amazonaw": [7, 9, 12], "amazonneptunevectordemo": 42, "ambigu": [4, 5, 6, 7, 20, 21, 23], "amen": [5, 11, 12], "amend": [41, 42], "america": [5, 13, 41, 42], "american": [4, 5], "amir": 6, "amodei": [7, 9, 11, 12, 23, 26], "among": [1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 24, 41, 42], "amount": [0, 1, 5, 6, 7, 8, 9, 12, 14, 15, 17, 21, 22, 23, 24, 26, 42], "amp": 42, "amper": 22, "an": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36, 40, 41, 42], "anaconda3": [28, 36, 41, 42], "analog": 5, "analys": 5, "analysi": [5, 6, 8, 13, 14, 21, 23, 41, 42], "analyt": [12, 23, 41, 42], "analyticdb": 42, "analyticdbdemo": 42, "analyz": [1, 2, 4, 5, 12, 14, 20, 21, 42], "anastomos": [41, 42], "anastomot": [41, 42], "anasw": 8, "anatomi": [7, 41, 42], "anc": [5, 6], "ancenegativesamplingdemo": 5, "anchor": [5, 6], "andi": 23, "andrea": 24, "andrei": 24, "andrej": 13, "andrew": [6, 24, 26], "angel": 4, "angestellt": 5, "angl": [1, 5, 21], "angola": 13, "angular": [5, 6], "ani": [1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 14, 19, 20, 21, 24, 41, 42], "anim": 5, "animos": 11, "anisotrop": 6, "ankur": 6, "ann": [1, 5, 6, 9, 23, 41, 42], "ann_18_02_05": [41, 42], "anna": 23, "annot": [5, 6, 9, 17, 20, 21, 23, 24, 41, 42], "annotated_typ": [41, 42], "announc": 42, "annual": [4, 13, 21, 41, 42], "anonym": 5, "anoth": [1, 5, 6, 8, 9, 10, 12, 13, 21, 26], "anserini": [5, 6], "answer": [1, 3, 4, 8, 11, 12, 13, 17, 18, 19, 20, 21, 24, 26, 40, 41, 42], "answer_and_context_relev": 42, "answer_relev": 42, "ant": [41, 42], "anthrop": [23, 42], "anthropic_ag": 42, "anthropic_haiku": 42, "anthropic_multi_mod": 42, "anthropic_prompt_cach": 42, "antic": 5, "anticip": 5, "antoin": 6, "anton": 21, "antonym": 5, "anyio": [41, 42], "anyon": [], "anyscal": 42, "anyth": [5, 41, 42], "anytim": [41, 42], "anywai": 5, "anywher": [41, 42], "apache_kafka": 42, "apart": [1, 5, 6], "api": 42, "api_kei": [41, 42], "api_refer": 42, "apifi": 42, "apiserv": 42, "apolog": 20, "apostroph": 5, "app": 42, "appar": [4, 13], "appeal": [1, 5], "appear": [3, 5, 6, 9, 10, 13, 14, 15, 20], "append": [5, 6, 28, 33, 34, 35, 36, 37, 38, 39], "appendix": 26, "appetit": 5, "appl": [8, 13, 41, 42], "appli": [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "applic": [0, 1, 5, 6, 8, 9, 11, 12, 13, 15, 20, 21, 24, 25, 26, 40, 41, 42], "applicationmaintain": [41, 42], "applicationnlp_irsearch": [5, 6], "apply_rotary_pos_emb": [31, 32, 40], "apporach": 15, "appreci": 5, "approach": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 25, 26, 38, 42], "approch": 23, "appropri": [2, 5, 6, 9, 21, 34, 35, 36, 40, 41, 42], "approv": 5, "approx": [5, 6, 9, 12, 13, 14, 22, 25, 26], "approx1": 13, "approxim": [1, 9, 13, 14, 23, 24], "apr": [41, 42], "april": [41, 42], "apurva": 20, "aquarium": 5, "ar": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 34, 35, 36, 40, 41, 42], "arab": 1, "arang": [17, 31, 32, 34, 40], "arango": 42, "arango_db": 42, "arbitrari": [5, 8, 21, 31, 40], "arbitrarili": [7, 9, 25], "arc": 7, "arcco": [5, 6], "archectur": 24, "archit": 23, "architectur": [0, 4, 7, 10, 11, 13, 14, 21, 22, 24, 26, 37, 38, 39, 40], "architur": 24, "area": [2, 5, 18, 21], "aren": 5, "arg": [5, 6, 25, 31, 32, 35, 40, 42], "arg_pack": 42, "argentina": 5, "argentinian": 5, "argentino": 5, "argentinocompar": 5, "argilla": 42, "argmax": [2, 13, 15, 21, 33], "argmax_": [], "argmin": 13, "argu": 23, "arguabl": [41, 42], "argument": [1, 5, 42], "ari": 6, "aria": 42, "aris": [0, 5, 6, 8, 21], "arithemat": 7, "arithmet": [1, 18, 22], "ariz": 42, "arize_phoenix": 42, "arize_phoenix_query_engin": 42, "arizona": [5, 6], "arka": 23, "arm": 5, "armand": 13, "armen": 8, "arnold": 6, "arora": 13, "around": [5, 6, 9, 13, 21, 41, 42], "arrai": [1, 4, 5, 8, 12, 13, 24, 25], "arrang": 5, "arriv": [5, 13, 18, 20, 22, 23], "ars": 21, "art": [0, 2, 5, 6, 7, 9, 11, 12, 20, 42], "arthur": 1, "articl": [3, 5, 6, 8, 9, 12, 14, 17, 21, 42], "artifici": [0, 1, 3, 9, 21], "artist": [5, 20], "artperform": 12, "arun": 6, "arvind": [1, 7, 9, 12], "arxiv": [1, 2, 4, 6, 8, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 32, 40, 42], "as_query_engin": [41, 42], "as_retriev": [41, 42], "asai": 20, "asana": 42, "asap": 5, "ascend": [5, 6], "ascii": 1, "ashish": [4, 6, 12], "ashwin": 15, "asia": [41, 42], "asian": [41, 42], "asid": 5, "ask": [1, 3, 5, 6, 7, 11, 17, 18, 19, 20, 21, 26, 40, 42], "askel": [1, 7, 9, 12, 17, 23], "asker": 5, "aspect": [2, 3, 5, 6, 10, 12, 19, 20, 21, 24, 26, 40, 41, 42], "aspel": 5, "assembl": 13, "assemblyai": 42, "assert": [34, 35, 37, 39], "assess": [3, 5, 7, 20, 21, 23, 24, 41, 42], "assesse": [41, 42], "assessor": [41, 42], "asset": [7, 9, 12, 41, 42], "assign": [2, 3, 5, 6, 9, 13, 23, 41, 42], "assignmodel": 5, "assist": [0, 5, 6, 21, 23, 24, 40, 42], "associ": [2, 4, 5, 6, 8, 12, 13, 15, 21, 23, 25, 26, 41, 42], "assum": [6, 8, 9, 12, 13, 14, 21, 22, 23, 25, 26, 31, 40], "assumpt": [3, 5, 6, 8, 10, 18, 24], "assur": [5, 41, 42], "ast18": 8, "astana": 13, "astonish": 5, "astra": 42, "astra_db": 42, "astradbindexdemo": 42, "asymmetr": [5, 6, 14], "async": [41, 42], "async_ingestion_pipelin": 42, "asynchron": [5, 6], "asyncindexcreationdemo": 42, "asyncio": [41, 42], "atari": 25, "athen": 13, "athena": 42, "athlet": 5, "atla": 42, "atom": [4, 13, 21], "att": [12, 34], "attach": [5, 11], "attack": 3, "attain": [41, 42], "attariyan": 24, "attempt": [5, 7, 19, 41, 42], "attend": [1, 4, 5, 6, 8, 12, 14, 17, 31, 40], "attent": [2, 4, 5, 6, 7, 8, 9, 11, 17, 21, 22, 24, 36, 37, 38, 39], "attentent": [5, 6], "attention_bia": [31, 40], "attention_dropout": [31, 32, 35, 36, 39, 40], "attention_logit": 34, "attention_mask": [31, 37, 39, 40], "attention_sc": [31, 32, 40], "attention_weight": 34, "attentionweight": 1, "attest": 3, "attitud": [41, 42], "attn": 8, "attn_output": [31, 32, 40], "attn_weight": [31, 32, 40], "attnet": [], "attornei": 5, "attr": [41, 42], "attract": [5, 8, 9], "attribut": [3, 5, 20, 41, 42], "au": 7, "audio": [9, 40], "audit": [21, 41, 42], "aug": 7, "augment": [0, 4, 5, 6, 8, 20, 40, 42], "australian": [41, 42], "auth": [41, 42], "authent": [41, 42], "author": [4, 5, 6, 8, 18, 21, 23, 41, 42], "auto": [5, 7, 11, 12, 21, 26, 42], "auto_merg": 42, "auto_merging_retriev": 42, "auto_prev_next": 42, "auto_retriev": 42, "auto_vs_recursive_retriev": 42, "autocomplet": 42, "autoencod": 5, "autograd": 36, "autom": [18, 21, 42], "automat": [3, 5, 6, 7, 8, 10, 14, 17], "automobil": [5, 6], "automodelforcausallm": [32, 35, 36], "autonom": 42, "autoref": 5, "autoregress": [11, 14, 17, 24, 26], "autoreload": [37, 39], "autoretriev": 42, "autotoken": [34, 35, 36, 37, 38, 39], "autr": 7, "auxiliari": [2, 7, 8], "auxillari": 23, "avail": [0, 5, 6, 8, 17, 21, 23, 25, 26, 41, 42], "avdl": 5, "averag": [1, 2, 3, 4, 6, 13, 17, 18, 23, 26], "average_log_prob": 35, "avg": 24, "avgdl": [5, 6], "avil": 26, "avirup": 20, "avocado": 5, "avoid": [2, 3, 5, 6, 8, 15, 17, 19, 20, 21, 22, 23, 26, 28, 41, 42], "aw": 42, "awadb": 42, "awadbdemo": 42, "awai": [5, 6, 7, 13, 23, 41, 42], "awar": [14, 17, 21], "awb": 6, "awesom": 4, "awsdocdb": 42, "awsdocdbdemo": 42, "aww": 20, "ax": 28, "axi": [17, 28], "azadeh": 6, "azalia": 23, "azcognit": 42, "azcognitive_search": 42, "azhar": 23, "azstorag": 42, "azstorage_blob": 42, "azur": [5, 42], "azure_code_interpret": 42, "azure_cv": 42, "azure_devop": 42, "azure_infer": 42, "azure_openai": 42, "azure_openai_multi_mod": 42, "azure_speech": 42, "azure_transl": 42, "azureaisearch": 42, "azureaisearchindexdemo": 42, "azurecosmosdbmongodbvcoredemo": 42, "azurecosmosdbnosqldemo": 42, "azurecosmosmongo": 42, "azurecosmosmongovcor": 42, "azurecosmosnosql": 42, "azuredocstoredemo": 42, "azureopenai": 42, "azzolini": [41, 42], "b": [1, 2, 3, 5, 6, 8, 10, 11, 13, 14, 15, 19, 21, 22, 25, 26, 35, 41, 42], "b02e": [41, 42], "b0e6799a25ad": [41, 42], "b130": [41, 42], "b13b": [41, 42], "b_": [1, 5, 12, 13], "b_1": [1, 8, 12], "b_2": [1, 8, 12], "b_i": 2, "b_j": 2, "b_x": 10, "b_y": 10, "ba": [5, 26], "babak": 14, "babi": 8, "bach": 4, "back": [4, 5, 6, 7, 8, 20, 21, 24, 32, 42], "backbon": [5, 6], "backend": 42, "backoff": [5, 9], "backpropag": [5, 22], "backpropg": 7, "backpropog": 22, "backslash": 21, "backtick": 21, "backup": [41, 42], "backward": [5, 8, 22, 25, 34, 35, 36, 37, 38, 39, 42], "bacteria": 5, "bad": [5, 7, 19, 20, 26], "badr": 26, "bag": [5, 6, 13], "bagel": 42, "bagelautoretriev": 42, "bagelindexdemo": 42, "bai": 23, "bai2020sparterm": 5, "bai2022constitut": [], "baidu": [22, 42], "baiduvectordb": 42, "baiduvectordbindexdemo": 42, "bajaj": 8, "bakalov": 21, "bake": 1, "balanc": [0, 1, 5, 6, 8, 14, 21, 23, 25, 26], "ball": [25, 26], "bamford": 1, "band": 5, "bandwidth": [1, 14, 22], "bangladesh": [41, 42], "bank": [7, 9, 13, 41, 42], "banknot": 9, "bao": [2, 8], "baosong": [1, 12, 22], "baptist": [15, 23, 26], "bar": 5, "bark": 5, "barla": 6, "barret": [1, 2, 24], "barri": [1, 5], "bart": [12, 30], "base": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 21, 22, 23, 26, 31, 32, 34, 36, 40, 41, 42], "baselin": [1, 5, 6, 9, 14, 20, 23], "basemodeloutputwithpast": [31, 40], "basi": [5, 13, 21, 41, 42], "basic": [0, 3, 6, 8, 9, 13, 20, 26, 30, 41, 42], "basic_ag": 42, "basic_flow": 42, "basic_strategi": 42, "bat": 25, "batch": [1, 2, 4, 8, 12, 14, 17, 22, 23, 31, 32, 34, 35, 36, 37, 38, 39, 40], "batch_ev": 42, "batch_siz": [31, 32, 34, 35, 36, 37, 38, 39, 40], "batchevalrunn": 42, "batra": 15, "battl": 42, "bb58": [41, 42], "bbq": 3, "bcc16": [5, 6], "bcca": [41, 42], "bce": [7, 23], "bd03": [41, 42], "bdvj03": 10, "beam": [5, 6, 14, 23], "bear": 5, "beat": 5, "beautifulsoup4": [41, 42], "becam": 0, "becaus": [3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 20, 21, 22, 23, 24, 26], "becom": [1, 2, 5, 6, 10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 26, 31, 40, 41, 42], "bed": [5, 41, 42], "bedrock": [26, 42], "bedrock_convers": 42, "bedrock_converse_ag": 42, "bedrock_retriev": 42, "bedroom": 10, "been": [0, 1, 4, 5, 6, 7, 8, 9, 12, 17, 21, 23, 24, 41, 42], "befor": [1, 5, 6, 7, 8, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 31, 32, 40], "beforehand": [17, 25], "began": 0, "begin": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 25, 26, 41, 42], "beginn": 42, "begun": [41, 42], "behav": [3, 21, 23], "behavior": [1, 5, 6, 7, 8, 20, 21, 23, 24], "behind": [4, 5, 6, 9, 15, 19, 21, 26, 42], "bei": 2, "beichen": [1, 26], "beihong": 6, "beij": [5, 6, 13], "being": [0, 1, 2, 5, 6, 7, 8, 9, 12, 13, 14, 15, 19, 20, 21, 23, 31, 32, 40, 41, 42], "beingoptim": 5, "beings": 9, "beir": 42, "beirevalu": 42, "belief": 21, "believ": 9, "belinkov": 5, "belkada": 14, "bell": [5, 21], "bellman": 25, "belong": [5, 6], "below": [1, 5, 6, 9, 13, 14, 20, 21, 31, 34, 35, 36, 40, 41, 42], "belvi": [41, 42], "bench": 42, "benchmark": [7, 11, 12, 14, 18, 21, 26, 42], "bend": 5, "benderski": 6, "benefici": [1, 5, 6, 21], "benefit": [1, 4, 5, 6, 8, 14, 18, 19, 21, 22, 24, 26, 31, 32, 40, 41, 42], "bengio": [6, 10], "benjamin": [1, 7, 9, 12, 26], "bennett": 6, "bentlei": 6, "berant": 6, "berkelei": 20, "berlin": [13, 23], "berlitz": 9, "berri": 5, "bert": [1, 7, 11, 12, 13, 14, 21, 30], "bert4rec": 12, "besid": [1, 5, 6, 11, 12, 19, 21, 23, 26, 41, 42], "best": [2, 5, 6, 7, 18, 20, 21, 23, 26, 42], "beta": [5, 6, 9, 23, 24, 35, 42], "beta_": 9, "beta_i": 23, "beta_j": 23, "better": [1, 2, 4, 5, 6, 7, 8, 9, 10, 13, 17, 19, 20, 21, 23, 24, 25, 26, 41, 42], "between": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 41, 42], "beyer": 12, "beyond": [1, 5, 6, 8, 18, 21, 22, 23, 41, 42], "bf": 20, "bf16": 22, "bfloat16": [14, 22, 32, 35, 36], "bge": 42, "bge_m3": 42, "bgem3demo": 42, "bgjm17": 13, "bhaskar": 6, "bi": [2, 21], "bia": [1, 2, 3, 5, 6, 13, 14, 18, 21, 23, 24, 26, 31, 32, 34, 36, 37, 38, 39, 40], "biao": [1, 24], "bias": [1, 2, 3, 5, 6, 10, 23, 24, 26], "bibliograph": 5, "bid": [5, 6], "bidirect": [4, 5, 6, 8, 11, 12, 17], "biencod": 5, "big": [4, 5, 6, 8, 9, 13, 20, 41, 42], "bigger": [0, 7, 24], "bigger_s": 28, "biggest": [8, 14], "bigram": [5, 6, 9], "bilibili": 42, "bilinear": 28, "bilingu": 8, "bill": [41, 42], "billion": [0, 1, 2, 5, 6, 7, 12, 14, 22, 26], "bin": 24, "binar": 5, "binari": [5, 6, 7, 8, 12, 13, 17, 23, 42], "bing": [2, 5, 6, 22, 42], "bing_search": 42, "binghai": 23, "bingxuan": 2, "binom": 23, "binwidth": 28, "binyuan": [1, 22], "biographi": 5, "biometrika": 23, "birch": 1, "bird": 8, "birth": [41, 42], "bit": [1, 5, 6, 7, 14, 22], "bitbucket": 42, "bitcoin": [5, 6], "bitlion": 26, "bitwis": 5, "bkk": 23, "black": [5, 42], "blankevoort": 14, "blaze": 5, "blend": [4, 5, 7], "blendfilt": 4, "bleu": [7, 21], "blind": 5, "blindli": 24, "blob": 42, "block": [1, 2, 5, 7, 12, 13, 21, 22, 23, 31, 32, 40], "blog": [5, 7, 9, 11, 12, 21, 42], "blood": [5, 21], "bloomberggpt": 26, "blow": 5, "blue": [2, 4, 5, 18], "blunsom": 8, "blur": 42, "bm": [5, 6], "bm25": [21, 42], "bm25_retriev": 42, "bm25model": [5, 6], "bm42": 42, "bmatrix": [1, 12], "bmod": 1, "bmr": [1, 7, 9, 12], "bnb21": 14, "bo": [1, 22], "boar": 5, "board": [9, 41, 42], "boarddoc": 42, "bob": 20, "bochao": 2, "bodi": [5, 6, 19, 21, 40, 42], "boil": [5, 6], "bojanowski": 13, "bold": [3, 9, 20], "boldsymbol": [5, 8, 14, 23], "bolt": [41, 42], "bondarenko": 14, "book": [5, 6, 12, 13, 26], "bookcorpu": [7, 12, 26], "bookmark": 5, "books1": 7, "books2": 7, "bookscorpu": [7, 8], "bool": [31, 34, 35, 40], "boolean": 5, "boolq": 3, "boost": [5, 7, 8, 24, 41, 42], "boostrap": 24, "bootstrap": 17, "bord": 6, "bore": [15, 19], "borgeaud": 15, "bori": 22, "borrow": [5, 9], "bos_token_id": [32, 35, 36], "bosco": 5, "bosma": [19, 24], "boss": [20, 21], "boston": [6, 41, 42], "bot": 6, "both": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26, 40, 41, 42], "bottl": 12, "bottleneck": [2, 5, 6, 8, 12, 17, 24, 41, 42], "bottom": [1, 5, 6, 8, 17, 28, 42], "bought": 8, "bound": [1, 5, 6, 12, 13, 14, 22, 25], "boundari": [0, 1, 5, 6, 13, 21], "bow": 5, "box": [7, 42], "bradlei": [20, 23], "brahma": 24, "brain": [5, 6, 14], "brainstorm": 3, "braintrust": 42, "bran": 5, "branch": [5, 6, 21, 41, 42], "branches_and_loop": 42, "brand": 5, "brauen": 5, "brave": 42, "brave_search": 42, "brazil": [41, 42], "breadown": 14, "breadth": 20, "break": [1, 4, 5, 6, 13, 14, 19, 20, 21, 34, 35, 36, 38], "breakout": 25, "breakpoint": 21, "breakthrough": 0, "breath": 5, "bred": 5, "breed": [5, 28], "bressand": 1, "brevet": 7, "breviti": [2, 5, 15], "brewer": 5, "brian": [17, 24], "brick": 25, "bridg": [5, 8, 17, 21, 24, 26], "brief": [5, 24, 41, 42], "briefli": 17, "bring": [1, 5, 6, 7, 10], "british": 9, "broad": [5, 6, 7, 15, 19, 21, 23, 24, 26], "broadcast": [22, 31, 32, 40], "broaden": 5, "broader": [3, 4, 13], "broadli": [5, 8, 18, 26], "brockman": 26, "broke": [], "bromlei": 5, "brother": 13, "brought": [0, 5, 6, 41, 42], "brown": [1, 3, 5, 7, 9, 12, 26], "brows": 5, "browser": 5, "bruce": 6, "bruch": 6, "bruna": 24, "brush": 5, "brute": [5, 6, 15], "bryan": [4, 11], "bsd": 22, "bsdp": 22, "bsz": [31, 32, 40], "bt": 23, "bt52": 23, "bu": [5, 6], "bucket": [5, 13], "bucklei": 5, "budget": [0, 2, 8], "buffer": [22, 34, 42], "bui": 5, "build": [1, 2, 6, 8, 9, 12, 13, 20, 21, 23, 25, 41, 42], "builder": 42, "building_a_chatbot": 42, "building_rag_from_scratch": 42, "built": [5, 6, 21, 23], "bullet": 21, "bullmastiffexplor": 5, "bundl": 42, "bur10": 6, "burda": 26, "burden": [1, 17, 21, 41, 42], "burg": [5, 6], "burges2005learn": 5, "burget": 10, "burr": 7, "busi": 5, "buttcher": 6, "butter": 5, "button": 42, "byproduct": [41, 42], "byte": [14, 22], "byvb1zve6j": 42, "c": [1, 2, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 20, 35, 36, 41, 42], "c4": [12, 26], "c_": [1, 5, 6], "c_0": 9, "c_1": [5, 6, 9], "c_2": 9, "c_3": 9, "c_4": 9, "c_5": 9, "c_6": 9, "c_i": [5, 6, 9], "c_k": [5, 6], "ca": 21, "cabl": 5, "cacciator": [41, 42], "cach": [1, 5, 6, 10, 22, 31, 40, 41, 42], "cache_posit": [31, 40], "caffein": [5, 6], "cai": [2, 15], "caim": [11, 17], "caishuang": 23, "cake": [5, 20], "cal": 5, "calcuat": 14, "calcul": [1, 4, 5, 6, 8, 12, 13, 14, 17, 19, 22, 25, 31, 40, 42], "calibr": [5, 6], "california": 13, "call": [2, 5, 6, 7, 8, 9, 12, 13, 17, 20, 22, 25, 26, 28, 36, 40, 41, 42], "call_llm_with_full_text": 40, "callan": [5, 6], "callback": 42, "callowai": 9, "calvin": 5, "cambieri": [41, 42], "cambodia": 13, "cambodian": 13, "cambridg": 6, "came": [41, 42], "camel": 42, "camera": [41, 42], "cameron": 23, "campo": 6, "can": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 31, 32, 40, 41, 42], "canada": 13, "canadian": [41, 42], "cancel": 23, "cancer": 5, "candid": [4, 6, 7, 9, 14, 15, 17, 23, 24], "cane": 5, "cannot": [0, 1, 4, 5, 6, 7, 11, 13, 14, 15, 17, 21, 22, 23, 24], "canon": [5, 42], "canonic": 5, "cao": [6, 8], "cap": [1, 5, 6, 13], "capabl": [0, 1, 3, 5, 6, 7, 8, 11, 12, 14, 17, 18, 19, 21, 24, 26], "capac": [1, 2, 4, 5, 6, 7, 8, 12, 23], "capfilt": 17, "capit": [4, 5, 6, 13, 23], "caption": [5, 9, 17, 21, 25, 42], "captur": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 20, 21, 23, 24, 41, 42], "car": [21, 24], "carb": 5, "carbohydr": [5, 6], "carbonel": 21, "card": 42, "cardin": [5, 6, 15], "care": [2, 5, 21, 41, 42], "carefulli": [5, 7, 15, 23, 24], "carignan": 18, "carlo": [5, 6, 22], "carnegi": [], "carolina": [5, 6], "carpineto": 5, "carri": [5, 6, 9, 18, 25, 41, 42], "carrol": 23, "cartesian": [5, 6], "cartoon": 5, "caruana": 6, "casa": 1, "case": [1, 2, 3, 5, 6, 7, 8, 12, 13, 15, 18, 21, 22, 24, 25, 26, 31, 40, 41, 42], "caslon": 8, "cassandra": 42, "cassandraindexdemo": 42, "cast": [5, 11, 32], "castro": 24, "casual": 9, "cat": [5, 10, 31, 32, 40], "catanzaro": 4, "catastroph": [17, 24, 26], "catch": [5, 42], "categor": [5, 6, 12], "categori": [3, 5, 6, 7, 12, 21, 41, 42], "caus": [1, 3, 5, 6, 8, 9, 14, 15, 20, 21, 24], "causal": [12, 17, 20, 31, 40], "causal_attent": 39, "causal_mask": [31, 40], "causallmoutputwithpast": [31, 40], "caveat": [5, 6], "cb753cb8dfd3": [41, 42], "cbi": 15, "cbow": 17, "cc": [1, 5, 13], "ccc": 5, "cccc": 13, "ccccc": 5, "ccccccc": 1, "cd": [5, 11], "cdk": 42, "cdn": 42, "cdot": [1, 2, 5, 6, 8, 9, 10, 12, 13, 14, 15, 23, 24, 26, 31, 32, 40], "cdpo": 23, "ce": [5, 6, 9], "ceil": 22, "cell": [5, 6, 36, 41, 42], "cellular": [41, 42], "center": [1, 5, 13, 21, 26, 41, 42], "centr": [41, 42], "central": [5, 6, 12, 13, 20, 41, 42], "centroid": [5, 6], "centrust": 9, "ceo": [4, 5], "cer": [41, 42], "cereal": 5, "cerebra": 42, "cernock\u00fd": 10, "cert": [41, 42], "certain": [1, 2, 4, 5, 6, 8, 9, 13, 14, 15, 18, 20, 21, 22, 26], "certainli": [5, 19], "certif": [41, 42], "certifi": [41, 42], "cfce": [41, 42], "cfgh20": 6, "cfwb17": [5, 6], "cg": [5, 6], "cg98": 21, "cg99": 9, "ch": [5, 6, 25], "ch02": [34, 38], "chain": [9, 15, 18, 21, 22, 24, 37, 39, 42], "chairman": 9, "challeng": [0, 1, 2, 7, 8, 9, 10, 12, 15, 17, 18, 19, 20, 22, 24, 26, 41, 42], "chan": [5, 6], "chanc": [5, 6, 14, 26], "chang": [1, 5, 6, 7, 8, 9, 12, 13, 14, 21, 23, 24, 25, 34, 41, 42], "chang2020pr": 5, "changelog": 42, "changer": 0, "changhua": 12, "chankyu": 4, "channel": 5, "chantai": 5, "chao": [20, 23], "chaoui": [41, 42], "chaplot": 1, "chapter": [1, 5, 12, 24, 26, 34, 38, 41, 42], "chapter_foundation_def_pretrained_lm_transformer_bert_encoder_lay": 8, "chapter_foundation_fig_language_model_feedforward_model": 10, "chapter_foundation_fig_word_embedding_word2vec_visu": [], "chapter_inference_eq_inference_acceleration_gptq_error_minimization_objective_matrix_form": 14, "chapter_rag_fig_promptagator_demo": [], "chapter_rag_fig_rag_knowledge_base_demo": [], "chapter_rag_fig_rag_llm_ft_data_sourc": [], "charact": [1, 3, 5, 8, 9, 13, 19, 21, 40], "character": [5, 6, 25], "characterist": [1, 2, 5, 6, 9, 21], "charcodeat": 42, "charcter": 23, "charl": 6, "charli": 15, "charset": [41, 42], "chart": [21, 41, 42], "chat": [5, 6, 40, 42], "chat_engin": 42, "chat_engine_best": 42, "chat_engine_condense_plus_context": 42, "chat_engine_condense_quest": 42, "chat_engine_condense_question_stream_respons": 42, "chat_engine_context": 42, "chat_engine_openai": 42, "chat_engine_person": 42, "chat_engine_react": 42, "chat_engine_repl": 42, "chat_memory_buff": 42, "chat_prompt": 42, "chat_stor": 42, "chatbot": [21, 42], "chatbot_sec": 42, "chatcompletionmessag": 40, "chatgpt": [3, 4, 42], "chatgpt_plugin": 42, "chatmessag": [41, 42], "chatprompttempl": [41, 42], "chaudhari": 8, "chauffer": 5, "chaumond": 8, "chd": 8, "cheap": [1, 5], "cheaper": [8, 14, 21, 41, 42], "cheapli": 20, "cheapter": 6, "cheatham": [], "chec": [41, 42], "check": [3, 5, 6, 21, 41, 42], "checkbox": 42, "checker": [5, 6], "checkpoint": [1, 5, 6, 23, 31, 32, 33, 34, 35, 36, 37, 38, 39], "chees": 5, "chelsea": 23, "chemic": 18, "chemistri": 18, "chen": [1, 2, 4, 6, 8, 9, 12, 13, 15, 18, 20, 22, 23, 24, 26], "cheng": [2, 6, 15, 18, 20, 21], "chengda": 2, "chenggang": 2, "chengqi": 2, "chenguang": 4, "chenxin": 1, "chenyan": 6, "chenyu": [2, 23], "chern": 6, "cherri": 24, "chess": 26, "chest": 5, "chi": [8, 18, 19, 24], "chicago": 13, "chief": 5, "chieh": 6, "child": [5, 7, 9, 11, 12, 21, 26], "childcar": [41, 42], "children": [5, 21, 41, 42], "chin": 14, "china": [5, 6, 13, 41, 42], "chines": [1, 5, 8, 26], "chip": 5, "chiyuan": 22, "chl": 24, "cho": [6, 21], "choi2021improv": 5, "choic": [2, 3, 5, 6, 8, 13, 15, 21, 24, 40], "cholesterol": 5, "chong": [2, 23], "choos": [5, 6, 8, 9, 15, 23, 25, 26, 33, 41, 42], "chose": [5, 7], "chosen": [2, 5, 13, 15, 17, 23, 35], "chosen_logp": 35, "chosen_reward": 35, "choudhuri": 5, "chowdheri": [18, 24], "chri": [1, 6, 17], "christian": [1, 10], "christiano": 23, "christoph": [6, 8, 9, 23, 26], "chroma": 42, "chroma_auto_retriev": 42, "chroma_autoretriev": 42, "chroma_metadata_filt": 42, "chromademo": 42, "chromafireworksnom": 42, "chromaindexdemo": 42, "chromamultimodaldemo": 42, "chromosom": [5, 6], "chronolog": [20, 41, 42], "chuck": 22, "chung": 24, "chunk": [14, 20, 38, 42], "chunk_data": [37, 39], "chunk_kei": [37, 39], "chunk_overlap": [41, 42], "chunk_siz": [37, 39, 41, 42], "chunker": 42, "chunyuan": 17, "church": 5, "cinema": 19, "cin\u00e9ma": 7, "circ": 20, "circumst": 14, "citat": [20, 21, 42], "citation_query_engin": 42, "citationqueryengin": 42, "cite": [5, 13, 15, 21], "citi": [5, 8, 13, 23], "citizen": [41, 42], "ckg": 8, "cklm19": 8, "cl": [5, 6, 8, 11, 17], "claim": 21, "clarifai": 42, "clariti": 21, "clark": [6, 8, 17], "class": [4, 5, 6, 7, 8, 11, 13, 17, 20, 24, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42], "classfici": 6, "classic": [8, 9, 13, 19, 23, 26], "classicrepresentationlearn": 5, "classif": [3, 4, 5, 6, 7, 8, 11, 12, 13, 17, 21, 22, 23, 41, 42], "classifi": [5, 6, 8, 11, 13, 17, 19, 40], "classroom": 8, "clean": [17, 21], "cleaner": 21, "cleanlab": 42, "cleanlab_tlm_rag": 42, "clear": [1, 6, 7, 12, 20, 21, 41, 42], "clearli": [5, 6, 7, 13, 23, 26, 41, 42], "clearn": 26, "cleverest": 7, "clg": 15, "cli": [41, 42], "click": [5, 6, 41, 42], "clickhous": 42, "clickhouseindexdemo": 42, "clicknum": 5, "clickthrough": [5, 6], "client": [40, 42], "clin": [41, 42], "clinic": [41, 42], "clinical_data": [41, 42], "clinical_govern": [41, 42], "clinician": [41, 42], "clip": [14, 42], "clipboard": 42, "cllm20": 8, "clone": [23, 27, 31, 35, 40], "close": [1, 3, 5, 6, 8, 9, 13, 20, 21, 22, 23, 41, 42], "closer": [0, 5, 6, 13], "closest": [5, 20], "cloth": [5, 13], "cloud": [5, 6, 21, 41, 42], "cloudflar": 42, "cloudflare_workersai": 42, "club": 5, "clubth": 5, "cluett": 9, "cluster": [10, 20], "cm": 28, "cms10": [5, 6], "cmu": [], "cmy": 6, "cnn": [11, 12], "cnndssm": 5, "co": [1, 5, 6, 8, 9, 10, 12, 13, 21, 31, 32, 40], "coa": 42, "coa_ag": 42, "coach": 5, "coars": [5, 6, 21], "coat": 5, "coco": 6, "coconut": 5, "code": [3, 4, 8, 12, 19, 21, 26, 31, 34, 38, 40, 41, 42], "code_hierarchi": 42, "code_interpret": 42, "codebook": [5, 6], "codebookmemorysavingdemo": 5, "codebookmemorysavingdemoproductquant": 5, "codecook": [5, 6], "codestr": 42, "codex": 26, "codi": 14, "coeffici": [5, 17, 23, 26], "coexist": 13, "coffe": [5, 6, 20], "cogniswitch": 42, "cogniswitch_ag": 42, "cogniswitch_query_engin": 42, "cognit": 5, "cogswel": 15, "coher": [1, 7, 8, 9, 12, 21, 40, 42], "cohere_citation_chat": 42, "cohere_custom_rerank": 42, "cohere_multi_mod": 42, "cohere_rerank": 42, "cohere_retriever_ev": 42, "cohereai": 42, "coherererank": 42, "cohes": [5, 6, 13, 15], "cohort": 5, "coil": 6, "coilembed": 5, "coilindexingmethod": 5, "col": [5, 6], "cola": 14, "colber": 5, "colbert": [28, 42], "colbert_rerank": 42, "colbertl2": [5, 6], "colbertrerank": 42, "coldest": [5, 6], "colect": 23, "colin": [4, 6, 11, 23, 24], "collabor": [2, 5, 20, 42], "collaps": 2, "collat": [41, 42], "collate_fn": [34, 35, 36, 37, 39], "collate_util": [37, 39], "collect": [5, 6, 7, 9, 17, 18, 20, 21, 22, 25, 28, 41, 42], "colleg": [5, 41, 42], "collin": 6, "collis": [5, 25], "collison": 13, "collobert": 13, "colloc": 5, "coloni": 23, "color": [1, 3, 4, 5, 17, 42], "colorama": [41, 42], "coloss": 26, "colpali": 42, "colpali_rerank": 42, "colpalirerank": 42, "column": [13, 14, 40], "com": [5, 7, 9, 12, 22, 34, 35, 36, 38, 42], "combat": [], "combin": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 20, 21, 22, 23, 24, 40, 41, 42], "comcast": 5, "come": [1, 4, 5, 6, 8, 9, 12, 17, 18, 20, 21, 31, 40, 42], "comment": [5, 7, 36], "commerc": [5, 6], "commerci": 5, "commnic": 22, "common": [1, 2, 5, 6, 8, 12, 13, 15, 18, 19, 21, 25, 26, 41, 42], "common_util": [37, 39], "commoncrawl": [8, 26], "commonli": [1, 3, 4, 5, 6, 12, 13, 15, 17, 21, 23], "commonsens": [7, 18], "commonsenseqa": 3, "commun": [0, 2, 5, 6, 9, 19, 20, 26, 37, 39, 41, 42], "communi": [41, 42], "comorbid": [41, 42], "compact": [5, 6, 8, 10, 41, 42], "compact_accumul": 42, "compact_and_refin": 42, "compani": [1, 4, 5, 13, 21, 41, 42], "compar": [1, 2, 4, 5, 6, 9, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 40, 41, 42], "comparis": [1, 14], "comparison": [1, 6, 8, 9, 10, 18, 19, 20, 21, 22, 23, 26, 42], "compat": 1, "compel": 21, "compens": [5, 13], "compet": [13, 41, 42], "competit": [3, 5, 17, 24], "competitor": [5, 6], "compil": [5, 42], "complaint": [5, 41, 42], "complement": [5, 6], "complementari": [5, 20, 21], "complet": [2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21, 22, 23, 24, 34, 35, 36, 40, 41, 42], "completion_prompt": 42, "complex": [0, 1, 2, 3, 4, 5, 6, 12, 13, 14, 18, 19, 20, 22, 23, 25, 26, 42], "compli": [41, 42], "complianc": 21, "compliant": 21, "complic": [5, 25, 41, 42], "compon": [1, 2, 5, 6, 7, 8, 9, 12, 13, 14, 18, 21, 24, 25, 31, 32, 34, 36, 40, 41, 42], "component_wise_evalu": 42, "components_of_llamaindex": 42, "componentwis": 1, "compos": [5, 9, 18, 42], "composable_memori": 42, "composable_retriev": 42, "composit": [5, 14, 26], "composition": [6, 13], "compound": 5, "comprehens": [0, 4, 5, 6, 7, 8, 11, 21, 23, 24, 41, 42], "compress": [2, 5, 6, 8, 12, 21], "compris": [4, 5, 6, 25], "compromis": [1, 8, 14, 24], "comput": [0, 2, 7, 9, 10, 13, 17, 19, 21, 22, 24, 25, 26, 31, 32, 40, 41, 42], "computatio": 14, "computation": [5, 6, 14, 21, 24, 26], "compute_batch_loss": [34, 35, 36, 37, 38, 39], "compute_eval_loss": [37, 39], "computeris": [41, 42], "con": [5, 6, 14, 24, 41, 42], "concat": [1, 10, 12, 24, 31, 32, 40], "concat_exampl": [37, 39], "concaten": [5, 6, 7, 8, 10, 13, 17, 21, 24, 31, 32, 40], "concatin": 6, "concentr": [5, 6, 23], "concept": [0, 4, 5, 6, 9, 13, 17, 18, 19, 20, 23, 26, 41, 42], "conceptu": [4, 5, 21], "concern": [5, 6, 20], "concis": [20, 21, 24], "conclud": [41, 42], "conclus": [1, 17, 19, 21, 40, 41, 42], "concret": [5, 6], "concurr": [5, 42], "concurrent_execut": 42, "conda": 27, "condens": [5, 6, 42], "condense_plus_context": 42, "condense_quest": 42, "condit": [1, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 21, 25, 41, 42], "conduct": [5, 8, 14, 21, 24, 41, 42], "conf": 10, "confer": [4, 5, 6, 8, 12, 13, 14, 15, 17, 21, 23, 26], "confid": [5, 6, 7, 15, 20], "confidenti": [41, 42], "config": [22, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42], "config_dict": 34, "configur": [5, 6, 7, 14, 26], "confirm": 20, "conflict": [20, 21], "confluenc": 42, "confus": 5, "conglomer": 9, "conneau": 8, "connect": [1, 2, 3, 4, 5, 8, 9, 10, 12, 17, 20, 21, 23, 25, 31, 32, 40, 41, 42], "connector": 42, "consecut": [1, 5, 8, 9, 21, 25, 41, 42], "consent": [41, 42], "consequ": [5, 8, 14], "conserv": [5, 23], "consid": [1, 2, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 20, 22, 23, 24, 26, 41, 42], "consider": [1, 5, 8, 9, 21], "consist": [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 36, 40, 41, 42], "consol": 24, "consolid": [2, 9], "const": 23, "constant": [1, 2, 5, 6, 8, 12, 14, 17, 23, 24, 26], "constantli": [0, 5, 6], "constitu": [5, 6, 9, 13], "constitut": [5, 23], "constrain": [1, 4, 5, 6], "constraint": [0, 4, 5, 6, 9, 14, 15, 22, 23, 26], "constrast": 23, "construct": [1, 6, 8, 9, 10, 12, 13, 19, 20, 21, 23, 24, 26, 42], "consult": [5, 41, 42], "consum": [5, 6, 14, 21, 22, 24, 41, 42], "consumpt": [5, 6, 22], "contact": 5, "contain": [1, 3, 5, 6, 7, 8, 9, 10, 14, 17, 21, 23, 25, 31, 32, 40, 41, 42], "contamin": 24, "content": [4, 5, 6, 18, 21, 22, 23, 24, 40, 41, 42], "content__inn": 42, "contest": 5, "context": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 25, 26, 34, 38, 41, 42], "context_length": [34, 37, 38], "context_msg": [41, 42], "context_relev": 42, "context_str": [41, 42], "context_vec": 34, "context_window": [41, 42], "contextu": [7, 12, 13, 14, 20, 21, 40, 42], "contextual_retriev": 42, "contextualencod": 8, "contexu": 12, "contigu": [14, 22, 31, 32, 34, 37, 39, 40], "contin": 23, "conting": [41, 42], "continu": [0, 1, 2, 5, 6, 7, 12, 13, 14, 20, 21, 23, 24, 25, 41, 42], "contract": [13, 25], "contradict": [8, 11], "contrari": [5, 26], "contrast": [4, 5, 6, 7, 8, 17, 22, 23, 25], "contribut": [2, 5, 6, 7, 11, 12, 13, 14, 18, 20, 24, 26, 34, 35, 36, 41, 42], "contributing_llamadataset": 42, "control": [5, 6, 7, 8, 9, 12, 17, 20, 23, 25, 26, 28, 42], "control_plan": 42, "controlnet": 17, "conv": 5, "convai2": 11, "convei": 5, "conveni": [5, 12, 25, 41, 42], "convens": 14, "convent": 5, "converg": [1, 5, 7, 8, 14, 22, 26], "convers": [5, 7, 8, 17, 26, 42], "convert": [5, 7, 9, 11, 12, 13, 14, 15, 17, 21, 23], "convex": 26, "convknrm": [5, 6], "convolut": [5, 6, 8, 14], "cookbook": 42, "cool": 5, "cooper": [5, 20], "coordin": [5, 20, 41, 42], "copi": [5, 6, 22, 31, 32, 40, 41, 42], "copyright": [41, 42], "core": [1, 4, 5, 6, 10, 12, 14, 23, 24, 25, 26, 31, 32, 40, 41, 42], "cormack": 6, "cornerston": [1, 26, 41, 42], "corollari": [41, 42], "corpora": [5, 6, 8, 9, 13, 26], "corpu": [4, 5, 6, 8, 9, 11, 12, 13, 21, 23, 26, 38, 40, 42], "corrado": [6, 13], "correct": [3, 6, 8, 17, 18, 19, 21, 23, 26, 42], "corrective_rag": 42, "corrective_rag_pack": 42, "correctli": [5, 6, 26, 31, 40], "correctness_ev": 42, "corrector": 5, "correl": [5, 41, 42], "correpond": [5, 6], "correspond": [1, 2, 6, 7, 8, 9, 11, 12, 13, 17, 21, 22, 23, 24, 26, 35, 36], "correspondingli": 2, "corrupt": [8, 11, 12], "corso": 5, "cose": 21, "cosin": [5, 6, 8, 12, 17, 31, 32, 40], "cosmo": 42, "cosmosdb": 42, "cossim": 17, "cossimilar": 8, "cost": [1, 2, 4, 5, 6, 13, 15, 17, 19, 20, 21, 22, 24, 26, 31, 32, 40, 41, 42], "cost_analysi": 42, "costli": [5, 6, 13, 21], "cot": [21, 24, 42], "cot\u00e9": 7, "couchbas": 42, "couchbasevectorstoredemo": 42, "couchdb": 42, "could": [4, 5, 6, 8, 10, 12, 13, 14, 15, 17, 20, 21, 24, 26, 41, 42], "count": [5, 6, 7, 9, 10, 17, 28, 42], "counter": [5, 10, 42], "counterpart": [2, 22, 25], "countersign": [41, 42], "countersunk": 4, "counti": 5, "countri": [4, 5, 21, 23, 41, 42], "countrywid": [41, 42], "coupl": [5, 6, 41, 42], "courag": 5, "cours": [5, 20, 41, 42], "court": [41, 42], "courvil": 6, "covari": 1, "cover": [0, 1, 3, 5, 6, 8, 9, 13, 17, 21, 23, 24, 25, 26], "coverag": [5, 24], "coverg": 1, "covid": [41, 42], "cowork": 20, "cp39": [41, 42], "cpp": 42, "cpu": [34, 35, 36, 37, 38, 39, 42], "cql": 6, "cr": 5, "cracker": 5, "craft": [17, 18, 21, 24], "crandal": 15, "crash": [5, 6, 9], "craswel": 6, "craswell2020overview": 5, "crawl": [5, 6, 7, 12, 26], "cream": 5, "creat": [1, 4, 5, 6, 9, 12, 13, 17, 20, 21, 22, 24, 25, 27, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "create_data_load": [34, 35, 36, 38], "create_graph": 36, "createel": 42, "creation": [21, 40, 42], "creation_d": [41, 42], "creativ": [0, 3, 5, 15, 41, 42], "creativecommon": [41, 42], "credit": [41, 42], "crewai": 42, "crewai_llamaindex": 42, "crf": 5, "crimin": [41, 42], "crisp": [5, 41, 42], "criteria": [5, 6, 14, 21, 23, 26], "criterion": [14, 18, 21], "critic": [1, 3, 5, 6, 7, 12, 14, 15, 20, 21, 24, 25], "critiqu": 20, "croft": [5, 6], "croft2010search": 5, "cross": [2, 3, 4, 7, 8, 11, 13, 14, 17, 20, 21, 23, 26, 42], "cross_encoder_finetun": 42, "cross_entropi": [34, 35, 36, 37, 38, 39], "cross_entropy_loss": 17, "crossentropi": [2, 8], "crossorigin": 42, "crow": 3, "crowd": 8, "crucial": [0, 1, 2, 3, 5, 6, 8, 12, 14, 17, 21, 23, 24, 26, 31, 40, 41, 42], "crush": 5, "crust": 5, "crutch": [41, 42], "crystal": [5, 6], "css": 42, "cssc": 5, "ctj": 26, "ctr": [5, 6], "cuda": [34, 35, 36, 37, 38, 39], "cue": [5, 6], "cuisin": [4, 5, 6], "cultur": 3, "cumbersom": [5, 6], "cumul": 25, "cunxiang": 21, "cup": [1, 5, 13], "curat": [4, 26], "currenc": 13, "current": [1, 3, 5, 6, 7, 8, 14, 21, 22, 23, 25, 26, 41, 42], "curriculum": 26, "currilumn": 6, "curs": [5, 6, 9, 10], "curv": [5, 21], "cusp": 0, "custom": [1, 5, 6, 21, 23, 24, 41, 42], "custom_ag": 42, "custom_collate_fn": [34, 35, 36], "custom_embed": 42, "custom_llm": 42, "custom_model": 32, "custom_modul": 42, "custom_prompt_synthes": 42, "custom_query_engin": 42, "customiz": 5, "customizatio": [], "customretriev": 42, "cut": [1, 5, 15], "cute": 5, "cv": [5, 13, 42], "cvi": 26, "cw08": 13, "cwct23": 1, "cxzg16": 22, "cy": 5, "cycl": [41, 42], "cypher": [41, 42], "d": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 28, 31, 32, 35, 40, 42], "d1033338": 28, "d1350520": 28, "d140227": 28, "d1439360": 28, "d213890": 28, "d2286511": 28, "d2342771": [5, 28], "d304123": 28, "d3048094": [5, 28], "d312959": 28, "d3233725": [5, 28], "d508131": 28, "d69114": 28, "d_": [1, 6, 7, 8, 9, 12, 14, 23, 24], "d_0": 12, "d_1": [4, 5, 6, 12, 20], "d_2": [5, 6, 12], "d_3": [5, 6], "d_e": 17, "d_f": 24, "d_h": 14, "d_head": 34, "d_i": [4, 5, 6, 9, 17, 21], "d_j": [5, 21], "d_k": [5, 6, 12, 21], "d_m": [4, 5, 6], "d_model": [1, 7, 34, 37, 38], "d_n": [5, 6, 12, 20], "d_q": 5, "d_t": 17, "d_v": 12, "d_x": 14, "da": [5, 6, 11, 20], "dad": 42, "dad_jok": 42, "dahl": 26, "dai": [2, 5, 6, 20, 21, 24, 41, 42], "daili": [5, 6, 41, 42], "daj24": 1, "dakota": [5, 6], "dale": [18, 19, 24], "dalf": 2, "damag": [5, 14, 24], "damai": 2, "damiani": [41, 42], "dan": 4, "danc": 13, "dane": 5, "danger": [5, 41, 42], "dani": 6, "daniel": [5, 6, 23], "danqi": [6, 8, 12, 23], "dao": 15, "dario": [7, 9, 11, 12, 23, 26], "dark": [5, 42], "darren": 20, "dash": 23, "dasha": 24, "dashscop": 42, "dashscope_ag": 42, "dashscope_embed": 42, "dashscope_multi_mod": 42, "dashscope_rerank": 42, "dashvector": 42, "dashvectorindexdemo": 42, "dashvectorreaderdemo": 42, "data": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 20, 24, 25, 41, 42], "data2": [34, 35, 36], "data_config": [37, 39], "data_connector": 42, "data_load": [34, 35, 36, 38], "data_stor": [41, 42], "databas": [5, 6, 21, 41, 42], "databasereaderdemo": 42, "databrick": 42, "databricksvectorsearchdemo": 42, "dataclass": [41, 42], "dataclasses_json": [41, 42], "datafram": 42, "datalay": 42, "dataload": [34, 35, 36, 37, 38, 39], "dataset": [0, 1, 2, 3, 4, 7, 11, 12, 17, 18, 21, 23, 24, 26, 34, 35, 36, 37, 38, 39, 41, 42], "dataset_gener": 42, "dataset_nam": [37, 39], "datasetdict": [37, 39], "date": [4, 5, 6, 12, 21, 40, 41, 42], "dateutil": [41, 42], "daughter": 5, "davi": 5, "david": [6, 7, 9, 11, 12, 14, 15, 22, 26], "dawei": 4, "daxiang": 6, "daxin": 6, "daya": 2, "db": [10, 42], "db7a12aa1b4d": [41, 42], "dbk": 12, "dblp": 10, "dc19": [5, 6], "dc7238350598": 42, "dca": 1, "dcbert": 5, "dcg": [5, 6], "dclt18": [5, 6, 8, 12], "dded": 13, "ddot": [1, 12], "ddz": 2, "de": [1, 5, 6, 7, 10, 13, 14, 24, 26, 41, 42], "deal": [1, 5], "dean": [6, 8, 13, 18, 24], "death": [5, 6, 41, 42], "debug": [21, 42], "debut": 8, "dec": 17, "dec_attn": [31, 32, 36, 40], "dec_featur": [31, 32, 36, 40], "dec_hidden": [31, 32, 36, 40], "decad": [5, 6, 9], "decai": 1, "decathlon": 11, "decent": 7, "decentr": [41, 42], "decid": [4, 5, 6, 11, 20, 21, 23, 42], "decis": [5, 6, 7, 19, 21, 41, 42], "deck": 42, "decod": [1, 2, 4, 5, 7, 8, 11, 17, 18, 21, 23, 30, 34, 35, 37, 38, 39], "decoder_lay": [31, 32, 40], "decodercausallm": [37, 39], "decoderlay": 12, "decompos": [2, 5, 8, 12, 13, 14, 21], "decomposit": [4, 9, 13, 20, 21], "decond": 12, "decor": 42, "decoupl": [5, 6, 26], "decreas": [1, 2, 5, 6, 9, 12, 23, 26], "dedic": [4, 26, 41, 42], "deduc": 21, "deem": [5, 6], "deep": [0, 1, 7, 8, 9, 12, 13, 14, 21, 22, 23, 26, 42], "deep_memori": 42, "deepai": 21, "deepct": [5, 6], "deepcttermimportancedemo": 5, "deeper": [1, 3, 10, 20], "deepev": 42, "deepimpact": 5, "deepinfra": 42, "deeplak": 42, "deeplake_deepmemory_retriev": 42, "deeplake_multimodal_retriev": 42, "deeplakeindexdemo": 42, "deeplakeread": 42, "deeplearn": 22, "deepli": 8, "deeplmpact": 5, "deepmemori": 42, "deepnet": 1, "deepnorm": 1, "deepseekmo": 2, "deerwest": 5, "def": [3, 19, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "default": [5, 6, 28, 31, 40, 42], "default_cyph": [41, 42], "default_data_col": [37, 39], "default_templ": [41, 42], "defaultdict": 28, "defect": [], "defenc": [41, 42], "defer": [5, 6], "defin": [1, 5, 6, 8, 9, 12, 13, 15, 21, 23, 25, 28, 40, 41, 42], "definit": [5, 6, 9, 13, 20, 25, 41, 42], "deflect": 25, "defragment": 22, "degener": 5, "degrad": [1, 14, 23, 24, 26], "degre": [5, 6, 9, 20, 23], "dehghani": [6, 12, 24], "dejian": 2, "deleg": 20, "delet": [5, 7, 11, 12, 14], "deli": 2, "deliber": 7, "delic": [5, 6], "delimit": [5, 6, 7, 21], "deliv": [5, 6, 12, 24, 41, 42], "deliveri": [41, 42], "delphic": 42, "delta": [5, 14, 24, 25, 26], "delta_": 5, "delv": 0, "demand": [5, 6, 20, 21, 41, 42], "deme": 15, "demeonstr": 23, "demo": 42, "demograph": [3, 41, 42], "demonstr": [0, 1, 5, 6, 7, 8, 9, 12, 14, 15, 17, 18, 19, 23, 26, 41, 42], "demostr": 42, "deng": [2, 4, 6], "deni": 9, "denker": 14, "denni": [8, 18, 19, 24], "denois": [11, 12], "denomer": 9, "denomin": [5, 6, 9, 13, 15], "denorm": 14, "denot": [2, 4, 5, 6, 8, 13, 14, 15, 20, 22, 24, 25], "dens": [0, 8, 10, 12, 13, 42], "dense_x_retriev": 42, "densiti": [4, 21, 28], "depart": [41, 42], "depend": [1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 21, 23, 24, 26], "depict": [2, 5, 21, 31, 40], "deploi": [1, 2, 5, 6, 8, 12, 14, 24, 42], "deplot": 42, "deplotread": 42, "deploy": [3, 5, 6, 41, 42], "deposit": 13, "deprec": [41, 42], "deprecated_term": 42, "depth": [1, 2, 19, 20, 21, 40, 42], "deq": 14, "derelict": [41, 42], "deriv": [1, 2, 5, 6, 12, 13, 14, 21, 23, 25, 26], "descend": 5, "descendingli": 15, "descent": [7, 10, 13, 24], "descreas": [1, 23], "describ": [3, 5, 6, 7, 11, 13, 17, 19, 21, 22, 31, 32, 34, 35, 36, 40], "describr": 21, "descrip": [41, 42], "descript": [4, 5, 6, 7, 8, 9, 11, 17, 21, 24, 41, 42], "descriptor": 5, "deserv": 3, "desig": 22, "design": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 22, 23, 24, 25, 26, 41, 42], "desipt": 22, "desir": [1, 2, 5, 6, 14, 15, 19, 21, 23, 24], "desm": 5, "despit": [5, 6, 21, 23, 41, 42], "destroi": [22, 25], "detach": [34, 35, 36, 37, 38, 39], "detail": [1, 4, 5, 8, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 26, 31, 40, 41, 42], "detect": [3, 5, 6, 7, 8, 19, 21], "deterior": 14, "determin": [2, 5, 6, 8, 9, 11, 12, 14, 20, 21, 22, 23, 25], "determinist": [2, 9, 15, 23, 25], "dettmer": 14, "dev": [5, 6], "devbal": 2, "develop": [0, 1, 2, 5, 6, 8, 9, 13, 14, 21, 22, 24, 26, 41, 42], "devendra": 1, "deviat": [1, 14, 23], "devic": [2, 5, 8, 14, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42], "devicelevel": [], "devlin": [5, 6, 8, 11, 12, 24], "devoid": [5, 6], "devop": 42, "df": 20, "df_program": 42, "dgcwcsnxhu": 42, "dhariw": [1, 7, 9, 12, 23, 26], "dhruv": 15, "dhs11": 26, "di": [1, 5, 12], "diabet": 5, "diag": [41, 42], "diagno": [41, 42], "diagnoal": 14, "diagnos": [21, 42], "diagnosi": [21, 41, 42], "diagon": [31, 34, 40], "diagram": [5, 11, 20, 23], "dialect": 20, "dialog": [5, 15, 17, 42], "dialog__inn": 42, "dialogu": [11, 17, 23, 40], "diamo": 22, "diaz": 6, "dichotomi": 5, "dict": [31, 40], "dict_item": [41, 42], "dictat": 5, "dictionari": [4, 5, 13, 21], "did": [4, 5, 7, 20, 21], "didn": [5, 20], "die": 5, "diederik": 26, "diego": 1, "diet": 5, "dietz": 6, "diff": 42, "diff_private_simple_dataset": 42, "diffcult": 20, "differ": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 23, 25, 26, 31, 32, 34, 36, 40, 41, 42], "differenti": [2, 5, 6, 14, 21], "difficult": [5, 7, 8, 12, 15, 17, 21, 24, 26, 41, 42], "difficulti": [1, 3, 4, 5, 6, 8, 10, 13, 21], "digest": [5, 6], "digi": [41, 42], "digit": [0, 41, 42], "dilemma": 25, "dili": [41, 42], "dilut": [4, 21], "dim": [5, 14, 22, 31, 32, 33, 34, 35, 40], "dimens": [1, 2, 4, 5, 6, 8, 12, 13, 14, 17, 21, 22, 23, 24, 26, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "dimension": [1, 2, 6, 8, 9, 10, 12, 13, 14, 21, 24, 26], "dimensionaltii": 10, "diment": 1, "diminish": [0, 4, 5, 6, 21], "ding": [2, 6], "diogo": 23, "dir": 42, "dir_graph": [41, 42], "dir_vector": [41, 42], "direct": [4, 5, 6, 7, 8, 9, 10, 11, 13, 17, 19, 21, 23, 24, 25, 26, 41, 42], "directli": [1, 2, 4, 5, 6, 8, 9, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 37, 38, 39, 41, 42], "director": 9, "directori": 42, "dirichlet": 5, "dirk": 12, "dirtyjson": [41, 42], "disabl": [3, 42], "disadvantag": [5, 6, 13, 14, 15], "disagr": 12, "disagre": 21, "disambigu": [4, 5], "disanc": 1, "disc": 8, "discard": [2, 6, 8, 13, 15, 18, 20, 22, 24], "discharg": [41, 42], "discharge_summari": [41, 42], "discographi": 5, "discontinu": 5, "discord": 42, "discord_thread_manag": 42, "discorddemo": 42, "discount": [15, 25], "discourag": 23, "discov": [5, 6, 26, 42], "discover": 21, "discover_llamaindex": 42, "discoveri": [0, 5], "discrep": [5, 6, 8], "discret": [], "discrimin": [5, 6, 8, 17, 23], "discriminatori": 3, "discuss": [0, 1, 6, 8, 9, 12, 13, 22, 26], "diseas": [5, 41, 42], "disease_a": [41, 42], "disease_b": [41, 42], "disjoint": 11, "disk": 14, "dispar": [14, 20], "dispatch": [2, 41, 42], "displac": 8, "displai": [5, 6, 41, 42], "disposit": 5, "disproportion": 14, "disregard": 13, "dissatisfact": 5, "dissatisfi": 5, "dissect": 4, "dissimilar": [5, 6, 13], "distanc": [1, 4, 9, 10, 13, 23], "distance_comput": 5, "distant": [5, 6], "distil": [0, 12, 21, 42], "distilbert": [5, 6, 8, 12], "distinct": [1, 2, 5, 6, 13, 21, 23], "distinguish": [3, 5, 6, 8, 12, 13, 17, 23], "distort": [5, 8], "distract": 21, "distractor": 21, "distribut": [1, 2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 21, 23, 25, 26, 31, 32, 36, 40, 41, 42], "distro": [41, 42], "disturb": 2, "div": 42, "dive": 5, "diverg": [5, 6, 8], "divers": [2, 3, 4, 5, 7, 8, 11, 12, 15, 18, 20, 23, 24, 26], "divid": [1, 5, 13, 14, 21, 26, 28], "divis": [1, 20, 26], "divisor": 22, "dl": 5, "dlbz22": 14, "dm": 11, "dmitri": 6, "dna": [5, 6], "dnn": [5, 6, 12, 22], "do": [1, 3, 5, 6, 7, 8, 9, 12, 13, 18, 19, 20, 21, 22, 23, 28, 31, 40, 41, 42], "doc": [1, 5, 12, 22, 28, 42], "doc2queri": [5, 6, 21], "doc_2_queri": 28, "doc_dict": 28, "doc_len": 28, "docarrai": 42, "docarrayhnswindexdemo": 42, "docarrayinmemoryindexdemo": 42, "docder": 12, "docexpansionarch": 5, "docl": 42, "doclingreaderdemo": 42, "docs_readm": 42, "docsearch": 42, "docstor": 42, "docstoredemo": 42, "docstr": [31, 40, 42], "docstring_walk": 42, "doct5queri": [5, 6], "doctor": [5, 41, 42], "doctrain": 28, "doctttttqueri": [5, 6], "doctyp": 42, "docuemnt": 21, "docugami": 42, "docugami_kg_rag": 42, "document": [1, 4, 7, 8, 9, 11, 12, 13, 19, 20, 26, 40, 41, 42], "document360": 42, "document_length_ms_marco": 28, "document_manag": 42, "document_management_pipelin": 42, "document_summari": 42, "documents_and_nod": 42, "doe": [3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 24, 41, 42], "doesn": [3, 5, 17, 22], "dog": [5, 6, 10, 13, 28], "dogcatch": 13, "dogo": [5, 28], "doi": [41, 42], "doll": 26, "dollar": 13, "domain": [0, 2, 3, 7, 12, 18, 21, 23, 24, 26, 42], "domainqa": 5, "domcontentload": 42, "domest": 5, "domiant": 14, "domin": [4, 5, 6, 8, 12, 26], "don": [1, 5, 8, 9, 21, 42], "donald": 6, "done": [5, 20, 21, 22, 23, 26, 41, 42], "dong": [1, 2, 6, 8, 26], "dongdong": 1, "dongji": 2, "dongxu": 17, "dongyu": 21, "doolei": 23, "door": [5, 6], "dosovitskii": 12, "dot": [1, 2, 5, 6, 8, 12, 17, 20, 31, 32, 40], "doteq": 25, "dou": 23, "doubl": 42, "doubt": [41, 42], "douz": 6, "down": [1, 4, 5, 6, 8, 14, 19, 20, 21, 22, 26, 31, 32, 40], "down_proj": [31, 32, 34, 40], "downgrad": 42, "download": [5, 41, 42], "downloading_llama_dataset": 42, "downstream": [1, 5, 7, 8, 11, 12, 21, 24], "downweight": [13, 23], "dpi": 28, "dpo": [21, 30], "dpop": 23, "dr": 5, "dramat": [0, 5, 14, 26], "dramatist": 3, "drastic": [5, 6, 12], "drave": [], "draw": [5, 12, 13, 21], "drawback": [1, 4, 5, 6, 8, 10, 13, 14, 15, 19, 21, 23, 40], "drawer": 42, "drawn": [5, 6, 23], "dress": 5, "drew": [7, 12], "drift": 5, "drive": [0, 5, 12, 42], "driven": [0, 5, 6, 25, 41, 42], "driver": [41, 42], "drop": [2, 5, 6, 12, 14], "drop_last": [34, 35, 36, 38], "dropbox": [], "dropout": [5, 6, 8, 22, 31, 32, 34, 37, 38, 39, 40], "drown": 5, "dtype": [31, 32, 40], "du": [1, 2, 7, 8, 12, 24, 26], "dub": 5, "dubei": 1, "ducharm": 10, "duchi": 26, "duckdb": 42, "duckdb_retriev": 42, "duckdbdemo": 42, "duckduckgo": 42, "duct": [41, 42], "due": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 18, 19, 21, 24, 41, 42], "duet": 6, "duli": [41, 42], "dum04": 13, "dumai": 13, "duobert": [5, 6], "duobertarch": 5, "duplic": [21, 41, 42], "durat": [14, 41, 42], "dure": [1, 2, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 34, 41, 42], "durm": 12, "dutch": [5, 9], "duti": [41, 42], "dvrc17": [5, 6], "dwell": [5, 6], "dy": 1, "dynam": [1, 2, 12, 14, 21, 22, 25, 26], "dynamo": 42, "dynamodb": 42, "dynamodbdocstoredemo": 42, "dysfunct": 5, "dz": [5, 6], "dzm": 21, "e": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "e2e_evalu": 42, "e_": [5, 6, 8, 9, 10, 12, 17, 23, 25], "e_0": [8, 12], "e_1": [8, 10, 12], "e_2": [8, 12], "e_d": [5, 6], "e_i": [2, 8, 12], "e_l": [8, 12], "e_n": [8, 12], "e_q": [5, 6], "e_t": 10, "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26, 31, 32, 40, 41, 42], "earli": [1, 5, 6, 9, 14, 26, 30], "earlier": 5, "earn": [1, 2, 11, 12, 41, 42], "earnings_call_transcript": 42, "earth": [5, 6, 23], "earthquak": [5, 6], "easi": [5, 6, 7, 13, 14, 17, 21, 22, 41, 42], "easier": [5, 6, 8, 19, 20, 21, 23, 34, 42], "easiest": 13, "easili": [5, 6, 7, 9, 13, 15, 20, 21, 41, 42], "eat": [5, 6, 13], "eb91": 42, "econom": [41, 42], "economi": [41, 42], "ecosystem": 42, "ed": [18, 19, 24], "ed4": [41, 42], "edg": [5, 19, 20, 21, 40], "edgar": 18, "edit": [5, 23, 31, 40, 41, 42], "editor": 10, "edouard": [8, 13], "educ": [41, 42], "edunov": 6, "edward": [24, 26], "ef96": [41, 42], "effeci": 10, "effect": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 24, 26, 31, 40, 41, 42], "efff": [41, 42], "effici": [0, 1, 2, 4, 10, 12, 13, 14, 15, 17, 21, 22, 23, 26, 41, 42], "efficieni": 22, "effiect": 24, "effort": [4, 5, 6, 8, 9, 12, 21, 26, 41, 42], "efron": 5, "ega": 13, "egg": 5, "eh": 8, "ehealth": [41, 42], "eid": 7, "eiffel": [4, 5], "eight": [7, 12], "ein": 12, "eisenstein": 6, "either": [1, 5, 6, 8, 13, 19, 25, 31, 40], "eival": 5, "el": 1, "elabor": 5, "elad": 26, "elast": 5, "elasticsearch": 42, "elasticsearch_auto_retriev": 42, "elasticsearch_demo": 42, "elasticsearchindexdemo": 42, "elec": [41, 42], "elect": [41, 42], "electron": [8, 41, 42], "electronic_medical_record": [41, 42], "eleg": 24, "elegxo": 5, "element": [2, 4, 5, 6, 7, 14, 15, 19, 21, 25, 31, 32, 34, 40, 41, 42], "elev": 5, "eli5": 11, "elicit": 19, "elif": 19, "elimin": [4, 8, 14], "ell": [7, 8], "ell_": 8, "ellen": 6, "ellipsi": 42, "els": [5, 15, 19, 20, 31, 34, 35, 36, 37, 38, 39, 40], "elsen": 22, "elsewher": 14, "em": 5, "emac": 20, "email": [5, 42], "email_data_extract": 42, "emb": [5, 17, 18, 31, 32, 40, 42], "emb_dropout": 34, "embark": 0, "embd": 8, "embed": [7, 10, 11, 12, 14, 17, 18, 20, 21, 23, 24, 26, 30, 34, 36, 41, 42], "embed_dim": [31, 32, 40], "embed_model": [41, 42], "embed_token": [31, 32, 40], "embedding_rec": 42, "emerg": [0, 1, 5, 7, 9, 12, 14, 24, 26, 41, 42], "emin": [6, 24], "emlo": 8, "emoji": 1, "emotion_prompt": 42, "emotionprompt": 42, "emphas": [1, 5, 13], "emphasi": [5, 6], "empir": [5, 6, 9, 13, 23, 24, 26], "emploi": [2, 5, 6, 8, 12, 13, 14, 17, 18, 21, 22, 23, 26], "employ": [5, 21], "employe": [5, 20], "empow": [5, 6], "empower": 5, "empti": 5, "emptyset": 1, "emr": [41, 42], "en": [5, 7, 42], "enabl": [1, 2, 3, 5, 6, 7, 8, 11, 12, 13, 14, 17, 20, 21, 22, 23, 24, 26, 41, 42], "encod": [2, 7, 11, 13, 17, 21, 24, 31, 32, 33, 34, 35, 36, 38, 40, 42], "encodd": 17, "encoderlaly": [8, 12], "encoderlay": [8, 12], "encompass": [14, 41, 42], "encount": [5, 13, 21, 28, 41, 42], "encourag": [2, 5, 6, 13, 15, 17, 18, 19, 23, 41, 42], "encourg": 23, "encyclopedia": 26, "end": [0, 1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 41, 42], "end_char_idx": [41, 42], "endoftext": 38, "endpoint": 42, "endto": 5, "energet": [], "energi": [5, 6, 14], "enforc": [5, 6, 17, 42], "engag": [2, 5, 22], "engin": [6, 7, 14, 18, 20, 21, 24, 26, 36, 42], "england": [41, 42], "english": [1, 3, 5, 6, 7, 8, 9, 11, 12, 17, 22, 26], "enhanc": [0, 1, 2, 6, 12, 18, 19, 20, 22, 23, 24, 26, 40, 42], "enjoi": [9, 21], "enlarg": 23, "enlist": [41, 42], "enorm": [1, 12, 22], "enough": [5, 8, 9, 20, 21, 22, 23, 26, 31, 32, 40], "enrich": [6, 8, 13, 21], "enrish": 21, "ensembl": [23, 42], "ensemble_query_engin": 42, "ensemble_retriev": 42, "ensur": [1, 2, 3, 4, 5, 6, 9, 15, 17, 21, 23, 24, 26, 31, 40, 41, 42], "entail": [7, 8, 11], "entangl": 5, "enter": [5, 12, 21, 42], "enterpris": 42, "entertain": [19, 40], "entir": [1, 5, 6, 7, 11, 14, 17, 21, 38, 41, 42], "entiti": [5, 6, 8, 9, 12, 17, 20, 21, 23, 41, 42], "entityextractionclim": 42, "entorpi": 9, "entri": [5, 6, 8, 12, 13, 35, 36, 41, 42], "entropi": [2, 5, 6, 7, 8, 11, 13, 23, 26], "enumer": [35, 41, 42], "env": [28, 36, 41, 42], "environ": [14, 23, 25, 41, 42], "environment": 0, "enyu": 23, "enzym": [5, 6], "eo": [12, 15, 23], "eoq": 5, "eos_token_id": [32, 35, 36, 39], "ep": [31, 32, 34, 40], "epeat": 25, "epic": [41, 42], "epidem": [41, 42], "epidemiolog": [41, 42], "epineurium": 5, "episod": 23, "epoch": [5, 34, 35, 36, 37, 38, 39], "epsilla": 42, "epsillaindexdemo": 42, "epsilon": [1, 5, 23, 25], "epstein": 6, "eq": [5, 14], "equal": [1, 2, 3, 5, 6, 8, 9, 12, 13, 22, 26, 41, 42], "equat": [5, 6, 13, 14, 23, 24, 25], "equip": [0, 5], "equiv": 5, "equival": [5, 6, 8, 9, 11, 14, 22, 23, 25, 26, 31, 32, 40], "er": 13, "era": [0, 12, 14], "erat": 5, "erhang": 2, "eric": [4, 6, 23], "erich": 22, "ericmitchel": 23, "erik": 6, "ermon": 23, "error": [6, 8, 13, 18, 19, 20, 21, 41, 42], "escap": 26, "esearch": [2, 11, 42], "esm": 5, "especi": [1, 5, 6, 9, 12, 13, 14, 19, 21, 22, 24, 26, 41, 42], "essai": 20, "essenc": [5, 24, 25], "essenti": [4, 5, 6, 9, 13, 21, 23, 26, 30, 41, 42], "est": [5, 6], "establish": [5, 9, 21, 23, 26, 41, 42], "estim": [5, 6, 7, 20, 22, 23, 26], "et": [1, 2, 5, 6, 7, 9, 11, 12, 13, 14, 17, 22, 23, 41, 42], "eta": [41, 42], "etc": [1, 5, 6, 7, 12, 13, 14, 15, 17, 20, 21, 23, 26, 41, 42], "ethic": [3, 13], "etreiv": 5, "euclidean": [5, 6, 13], "eural": [1, 7, 9, 12], "euro": 1, "eva": 17, "eval": [5, 6, 37, 39, 42], "eval_dataload": [37, 39], "eval_query_engine_tool": 42, "evalu": [1, 2, 7, 13, 20, 24, 26, 41, 42], "evaluating_evaluators_with_llamadataset": 42, "evaluating_rag_system": 42, "evaluating_with_llamadataset": 42, "evaluator_benchmark": 42, "evalut": 21, "evapor": 42, "evaporate_program": 42, "even": [0, 1, 2, 5, 6, 7, 8, 9, 12, 14, 15, 17, 20, 21, 23, 26, 41, 42], "evenli": [2, 5, 6], "event": [3, 4, 5, 6, 9, 17, 20, 21, 41, 42], "event_handl": 42, "event_typ": 42, "eventu": [2, 5, 13, 22], "ever": [0, 5, 9, 21], "everi": [1, 2, 5, 6, 8, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 41, 42], "everlyai": 42, "everydai": 3, "everyon": [3, 5, 41, 42], "everyth": [], "everywher": 5, "evid": [5, 6, 41, 42], "evok": 18, "evolut": [9, 20, 24], "evolv": [5, 6, 21, 24], "ex": 20, "exa": 42, "exacerb": [], "exact": [3, 14, 21], "exactli": [5, 9, 21], "examin": [0, 1, 5, 7, 21, 26, 41, 42], "exampifi": 1, "exampl": [3, 4, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 20, 22, 23, 24, 26, 37, 38, 39, 41, 42], "example_documents_msmarco": 5, "example_queries_msmarco": [5, 6], "examplifi": 6, "exapns": 5, "exce": [23, 41, 42], "exceed": [7, 14], "excel": [5, 6, 7, 20, 21, 41, 42], "excellet": 21, "except": [5, 6, 7, 8, 13, 22, 40, 41, 42], "exceptiongroup": [41, 42], "excess": [5, 21], "exchang": [2, 5], "excit": [0, 5], "exclu": 5, "exclud": [5, 8, 12, 19, 41, 42], "excluded_embed_metadata_kei": [41, 42], "excluded_llm_metadata_kei": [41, 42], "exclus": [12, 24, 41, 42], "excus": 5, "execut": [5, 14, 24, 41, 42], "exercis": [1, 5, 8, 40], "exhibit": [0, 5, 12, 14, 21, 23], "exist": [1, 5, 6, 8, 9, 17, 19, 21, 23, 24, 26, 34, 35, 36, 38, 41, 42], "existing_answ": [41, 42], "existing_data": 42, "exp": [4, 5, 6, 8, 9, 13, 15, 17, 23], "expand": [0, 4, 5, 6, 7, 24, 31, 32, 40, 42], "expans": [4, 13, 14, 21], "expbal": 2, "expect": [2, 4, 5, 6, 7, 8, 13, 21, 23, 24, 25], "expedit": [41, 42], "expenditur": [41, 42], "expens": [5, 6, 10, 12, 13, 14, 19, 21, 26, 41, 42], "experi": [1, 3, 5, 6, 17, 19, 24, 31, 32, 40, 41, 42], "experienc": [5, 6], "experiment": [5, 17, 26, 42], "expert": [0, 2, 5, 18, 40, 41, 42], "expertis": [2, 21], "explain": [5, 13, 17, 19, 20, 21, 23], "explan": [1, 14, 21], "explicit": [5, 6, 13, 19, 21, 23, 26], "explicitli": [0, 5, 6, 8, 20, 21, 23, 25], "explod": 1, "exploit": [5, 10, 25, 41, 42], "explor": [0, 1, 5, 6, 8, 10, 11, 18, 21, 24, 25, 26, 41, 42], "expon": 22, "exponenti": [0, 5, 9, 23, 26, 41, 42], "expos": [12, 22, 23], "exposur": 12, "express": [5, 6, 7, 13, 14, 21, 24, 25, 42], "extend": [5, 6, 8, 10, 17, 24, 37, 39, 42], "extens": [1, 4, 5, 7, 12, 15, 19, 24, 26, 39, 41, 42], "extent": [13, 23, 41, 42], "extern": [0, 5, 6, 20, 21, 23, 40], "extra": [1, 5, 6, 7, 21, 24], "extract": [3, 5, 6, 7, 9, 11, 12, 17, 21, 40, 41, 42], "extract_entities_from_pdf": [41, 42], "extractor": [5, 42], "extrapol": [1, 5, 41, 42], "extrem": [5, 6, 7, 14, 22, 26], "extropol": 1, "ey": 5, "f": [1, 2, 5, 6, 8, 9, 13, 14, 23, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42], "f1": 11, "f16": 14, "f_": [4, 5, 6, 26], "f_1": 14, "f_2": 14, "f_i": 2, "f_j": 2, "f_q": 5, "f_r": 5, "f_u": 26, "fabian": 26, "fabric": [41, 42], "face": [4, 5, 6, 13, 14, 21, 23, 42], "facebook": [8, 13], "facet": [21, 41, 42], "facil": 14, "facilit": [5, 6, 8, 13, 41, 42], "fact": [1, 3, 4, 5, 6, 7, 9, 12, 14, 17, 18, 20, 21, 23, 25], "factoid": [5, 6], "factor": [0, 1, 2, 5, 6, 8, 12, 13, 14, 15, 18, 22, 23, 24, 25, 26, 41, 42], "factual": [1, 3, 7, 18, 20, 21, 23, 26], "faecboek": 5, "fail": [5, 6, 9, 15, 20, 22, 23, 24], "failth": 21, "failur": [1, 5, 14, 21, 23], "fair": [3, 5], "fairli": [3, 5, 6], "faisal": 23, "faiss": [5, 6, 42], "faissdemo": 42, "faissindexdemo": 42, "fait": 7, "faith": [21, 42], "faithful": 42, "faithfulness_ev": 42, "falcon": 26, "falkordb": 42, "fall": [5, 6, 7, 12, 26, 41, 42], "fallback": 42, "fals": [3, 8, 17, 25, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "falsehood": 3, "famili": [8, 12, 42], "familiar": [5, 41, 42], "famou": 42, "fan": 6, "fandong": 24, "fang": [5, 6, 8], "fangyun": 2, "faq": 42, "far": [1, 3, 5, 6, 9, 13, 23, 26, 42], "fashion": [5, 6, 13], "fast": [1, 5, 6, 15, 26], "fastemb": 42, "faster": [2, 5, 8, 14, 22, 26], "fastest": 14, "fasttext": [5, 6, 13], "fat": 5, "fatal": [5, 6], "fatti": [5, 6], "favor": [5, 18, 21, 23], "favorit": 5, "fb74": [41, 42], "fbf77": [5, 6], "fc": 17, "feasibl": [5, 6, 41, 42], "feasibli": 14, "featur": [1, 2, 6, 8, 9, 12, 13, 14, 17, 21, 23, 24, 37, 39, 41, 42], "feb": 10, "februari": 21, "fed": [5, 6, 7, 8, 11, 12, 13, 17, 21, 24, 26], "federico": 1, "fedu": [2, 24], "feed": [1, 5, 8, 11, 12, 14, 17, 21, 26], "feedback": [6, 19, 23, 42], "feedback__not": 42, "feedforward": [1, 10, 22, 34], "feedfoward": [31, 32, 34, 36], "feedli": 42, "feedly_rss": 42, "feel": [5, 11, 40], "fei": [1, 12], "feishu": 42, "feishu_doc": 42, "feishu_wiki": 42, "felix": 6, "fell": 5, "femal": 5, "feng": [2, 6], "fernando": 6, "fetch": [5, 6], "few": [1, 2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 18, 21, 24, 26], "fewer": [2, 5, 6, 14], "ff": [8, 12, 34], "ffd": 24, "ffn": [2, 8, 12, 14, 17, 22, 24, 36], "fi": 5, "fibonacci": 19, "fibonacci_50th": 19, "fibroid": 5, "ficat": 5, "fiction": 23, "field": [0, 5, 6, 9, 21, 26, 41, 42], "fifth": [41, 42], "fig": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 41, 42], "figsiz": 28, "figur": [2, 5, 6, 14, 21, 26, 28], "file": [21, 28, 34, 35, 36, 38, 41, 42], "file_nam": [41, 42], "file_path": [34, 35, 36, 38, 41, 42], "file_s": [41, 42], "file_typ": [41, 42], "filenam": 42, "filenodeprocessor": 42, "filesystem": 42, "filip": [6, 23], "fill": [5, 6, 11, 31, 40], "fill_valu": [31, 40], "filter": [4, 5, 6, 7, 17, 20, 21, 24, 26, 41, 42], "final": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 26, 31, 40], "final_norm": 34, "financ": 42, "financi": [13, 21, 41, 42], "financial_data": [41, 42], "finchat": 42, "find": [0, 1, 3, 4, 5, 6, 8, 11, 14, 15, 18, 20, 21, 23, 24, 41, 42], "fine": [0, 1, 2, 5, 6, 9, 12, 14, 17, 19, 23, 26, 42], "fine_tun": 42, "finer": [2, 18], "finetin": 21, "finetun": [4, 12, 17, 19, 23, 26, 30, 42], "finetune_corpus_embed": 42, "finetune_embed": 42, "finetune_embedding_adapt": 42, "finetune_llm_judg": 42, "finetune_llm_judge_single_grading_correct": 42, "finfo": [31, 40], "fingertip": [41, 42], "finish": [5, 14], "finit": [5, 6, 14, 23], "finkel": 6, "finn": 23, "firat": [8, 24], "fire": 21, "firebas": 42, "firebase_realtimedb": 42, "firestor": 42, "firestoredemo": 42, "firestorevectorstor": 42, "firework": 42, "fireworks_cookbook": 42, "firm": 5, "firmli": 5, "first": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 31, 32, 34, 35, 36, 38, 40, 41, 42], "firstelementchild": 42, "firstli": 23, "fisch": 6, "fish": [5, 21], "fit": [3, 5, 6, 14, 21, 22, 23, 24, 42], "five": [3, 5, 6], "fix": [1, 2, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 23, 24, 25, 42], "fixed_rec": 42, "fixedwidth": 5, "fl": [41, 42], "flag": 42, "flag_embedding_rerank": 42, "flagembeddingrerank": 42, "flail": 5, "flan": 24, "flant5": 17, "flare": 42, "flare_query_engin": 42, "flasch": 12, "flash": [31, 40], "flat": [4, 5, 6, 26], "flat_label": [37, 39], "flat_logit": [34, 35, 36, 37, 38, 39], "flat_target": [34, 35, 36, 38], "flatten": [34, 35, 36, 37, 38, 39], "flavor": 22, "flexibl": [2, 5, 6, 8, 12, 19, 21, 24, 42], "flier": 5, "flight1ess": 8, "flip": [5, 23], "float": [1, 5, 6, 14, 31, 32, 35, 40], "float16": [14, 22, 31, 32, 40], "float32": [14, 22, 31, 32, 35, 40], "floattensor": [31, 32, 35, 40], "floor": 9, "flop": [5, 14], "flor": 5, "florenc": [], "florian": 1, "flow": [1, 4, 5, 17, 40, 42], "fluctuat": 1, "fluenci": 15, "fluent": 9, "fluffi": 5, "fluid": [5, 6], "fly": [6, 23], "flyout": 42, "fmt": [8, 24], "focu": [0, 1, 3, 5, 6, 9, 14, 21], "focus": [0, 2, 3, 5, 6, 8, 12, 20, 21, 23, 24, 41, 42], "fold": [5, 6, 8], "folder": 42, "follow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "font": [28, 42], "fontsiz": 28, "food": [5, 6, 9], "fool": 7, "footer": [40, 42], "footer__button": 42, "footer__direct": 42, "footer__inn": 42, "footer__link": 42, "footer__titl": 42, "footnot": 13, "footnotes": 5, "footprint": [1, 12, 14, 22, 41, 42], "foral": [5, 7, 14, 25, 26], "forc": [5, 6, 8, 15, 17, 23, 42], "forecast": [0, 21], "forexampl": 5, "forget": [17, 24, 26], "forgett": [19, 40], "form": [1, 4, 5, 6, 8, 9, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 31, 40, 41, 42], "formal": [5, 6, 8, 9, 10, 13, 15, 21, 25], "format": [5, 6, 7, 11, 14, 18, 19, 21, 22, 40, 41, 42], "format_input": [34, 35, 36], "former": [5, 9, 17, 41, 42], "formul": [2, 5, 6, 7, 11, 13, 23, 24], "formula": [1, 5, 6, 9, 12, 13, 14, 22, 31, 32, 40], "forrank": 5, "forth": [5, 42], "forum": 26, "forward": [0, 5, 7, 8, 12, 14, 15, 19, 21, 22, 23, 31, 32, 34, 36, 37, 39, 40, 42], "forword": 15, "found": [0, 1, 3, 4, 5, 6, 7, 8, 13, 14, 20, 21, 41, 42], "foundat": [0, 1, 5, 6, 9, 12, 18, 23], "founder": 5, "four": [1, 2, 5, 6, 7, 11, 21, 41, 42], "fourier": 5, "fp16": [22, 32], "fp32": [14, 22, 31, 32, 40], "fp8": 22, "fr": 7, "frac": [1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 31, 32, 40], "fraction": [2, 5, 6, 21, 22], "fractur": [41, 42], "fraemwork": 23, "fragment": [5, 6, 14, 21, 22, 41, 42], "frame": [5, 12], "framework": [7, 8, 9, 11, 13, 15, 17, 20, 23, 26, 40, 41, 42], "franc": [4, 13, 23], "franci": 4, "francisco": 8, "frank": [5, 26], "fraser": 23, "free": [1, 5, 7, 8, 23, 40, 42], "freedom": [41, 42], "freez": [17, 24], "frei": 5, "french": [5, 7, 8], "freq": [31, 32, 40], "frequenc": [1, 5, 6, 8, 9, 10, 13, 21, 31, 32, 40], "frequent": [1, 5, 6, 8, 9, 10, 15, 17, 21, 26, 42], "fresh": 21, "friction": [], "friedman": 6, "friend": [5, 9], "friendli": [24, 42], "fro": 13, "from": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "from_default": [41, 42], "from_docu": [41, 42], "from_pretrain": [32, 34, 35, 36, 37, 39], "fromstein": 9, "fromth": 21, "front": 9, "frontier": 0, "frozen": [17, 23, 24], "frozenlist": [41, 42], "fruit": 8, "fsdp": [31, 40], "fsspec": [41, 42], "ft": [21, 24], "fu": [2, 23, 24], "fucong": 2, "fuli": 2, "full": [5, 6, 9, 11, 14, 15, 21, 22, 23, 24, 26, 31, 40, 42], "full_stack_project": 42, "fulli": [1, 2, 4, 5, 6, 12, 13, 17, 20, 21, 24, 31, 32, 40], "fullstack_app_guid": 42, "fullstack_with_delph": 42, "fullyconnect": 5, "fun": 8, "funciton": [1, 23], "function": [1, 2, 3, 4, 7, 8, 10, 13, 14, 15, 17, 23, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "function_cal": 40, "function_calling_ag": 42, "function_map": [41, 42], "function_program": 42, "functool": [33, 34, 35, 36, 37, 39], "fund": [13, 20], "fundament": [0, 4, 7, 8, 9, 12, 24, 30, 41, 42], "fung": 6, "furhter": 18, "furna": 5, "further": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 23, 24, 25, 26, 40, 41, 42], "furthermor": [5, 12, 41, 42], "furu": [1, 4, 8], "fuse": [5, 6, 12, 14], "fusi": 18, "fusion": [6, 8, 17, 42], "fusion_retriev": 42, "futagi": 5, "futur": [0, 5, 7, 12, 26, 31, 40], "fuyu": 42, "fuzheng": 6, "fuzzi": 42, "fuzzy_cit": 42, "fzs22": 2, "g": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 41, 42], "g_": [1, 2, 5, 26], "g_0": 26, "g_i": 14, "g_t": 25, "ga": [5, 13, 18], "gabriel": [15, 17, 26], "gain": [0, 7, 8, 13, 14, 22, 23, 24, 25, 41, 42], "gal": 6, "gallon": 8, "game": [0, 5, 24, 25], "gamma": [2, 5, 6, 25, 31, 32, 40], "gan": 8, "ganesh": 22, "gao": [2, 5, 6, 8, 21, 23], "gao2021compl": 5, "gao2021unsupervis": 5, "gao2021your": 5, "gap": [5, 8, 17, 21, 23, 24, 26, 41, 42], "gar": 13, "garanti": 7, "garc": 8, "garcia": 22, "garciajsvaldes17": 8, "gardner": 8, "gate": [1, 2, 5, 31, 32, 40], "gate_proj": [31, 32, 40], "gather": [3, 5, 6, 14, 20, 22, 35], "gatsbi": 42, "gaudi": 42, "gaug": [9, 25], "gaurav": 24, "gaussian": 5, "gautier": 23, "gb": [4, 5, 8, 14, 22], "gbcb16": [5, 6], "gbm": 5, "gc": 42, "gca": 28, "gdc21": [5, 6], "gdn": 42, "gdollarg": 26, "gdp": [4, 5], "gdpr": 21, "ge": 2, "gelli": [12, 24], "gelu": [5, 34], "gement": [41, 42], "gementinpat": [41, 42], "gemini": [1, 21, 42], "gemma": 42, "gen": [5, 20, 41, 42], "genai": 42, "gender": [3, 5], "gene": [5, 6], "genearl": 10, "gener": [0, 1, 2, 3, 6, 8, 9, 10, 12, 13, 15, 17, 19, 20, 22, 24, 26, 28, 31, 40, 41, 42], "generalis": 8, "generalist": [4, 18, 21], "generalz": 23, "generationmixin": [31, 40], "genet": [5, 6], "geng": [6, 15], "geniu": 42, "genius": [], "genr": [5, 7], "genserp": 4, "genuin": [5, 9], "geo": 17, "geoffrei": [6, 8, 15, 26], "geograph": 23, "geographi": 3, "geometr": 5, "georg": [12, 26, 41, 42], "geq": [8, 25], "german": [5, 11], "germani": 23, "gesellschaft": 5, "gesmundo": 24, "get": [5, 6, 7, 9, 10, 11, 12, 14, 15, 18, 20, 26, 28, 31, 32, 40, 41, 42], "get_encod": [34, 35, 36, 38], "get_logp": 35, "get_next_token_prob": 33, "get_prompt": [41, 42], "getattribut": 42, "getelementbyid": 42, "getenv": 40, "getitem": 42, "getting_start": 42, "gfp": [5, 6], "gg": 42, "ghajar": 6, "ghazvininejad": 11, "ghosh": 6, "gianna": 1, "giant": 20, "gibberish": 15, "gigachat": 42, "gigant": 5, "gimpel": [8, 12], "ginsburg": 22, "girish": [1, 7, 9, 12, 17], "girozier": 26, "girshick": [6, 26], "git": 27, "gitano": 9, "gitbook": 42, "github": [5, 14, 26, 42], "github_issue_analysi": 42, "githubrepositoryreaderdemo": 42, "githubusercont": [34, 35, 36, 38], "gitlab": 42, "giurgiu": 24, "give": [1, 5, 6, 8, 9, 10, 14, 19, 21, 22, 23, 25, 31, 32, 40, 41, 42], "given": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 40, 41, 42], "gl14": 13, "glanc": [5, 25], "glass": 5, "glean": 4, "glitch": [41, 42], "global": [5, 6, 13, 20, 21, 41, 42], "global_step": [34, 35, 36, 37, 38, 39], "globerson": 6, "gloeckl": 26, "glove": 8, "glu": [1, 31, 32, 40], "glucos": [5, 6], "glue": [12, 14], "glycem": 5, "gmail": 42, "gmail_openai_ag": 42, "gnu_aspel": 5, "go": [1, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 23, 25, 31, 32, 40, 41, 42], "goal": [0, 5, 6, 7, 9, 11, 13, 15, 17, 21, 25, 41, 42], "god": 21, "goe": [1, 5, 6, 13, 41, 42], "gogh": 42, "goh": 17, "goir": 6, "gol17": 9, "golbandi": 6, "gold": [4, 5, 9, 21], "goldberg": [9, 13], "golden": 21, "goldi": 23, "goldstein": 21, "gomez": [6, 12], "gong": [1, 2, 42], "gonzalez": [14, 21], "good": [1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 17, 21, 23, 41, 42], "goodfellow": 6, "goodman": [8, 9, 12], "googl": [1, 3, 5, 6, 8, 21, 42], "google_palm": 42, "googleapi": 42, "googlechatdemo": 42, "googledemo": 42, "googledocsdemo": 42, "googledrivedemo": 42, "googlemapstextsearchreaderdemo": 42, "googlesheetsdemo": 42, "googletagmanag": 42, "gordon": 6, "gorilla": 9, "got": 5, "gotten": [], "gou": [2, 6], "gouvern": 7, "govern": [0, 7, 9, 41, 42], "goyal": [8, 11, 12, 23, 26], "gpt": [0, 1, 9, 11, 12, 14, 17, 18, 20, 21, 23, 30, 40, 41, 42], "gpt2": [34, 35, 36, 37, 38, 39], "gpt3": [7, 24], "gpt4": 42, "gpt4o_mm_structured_output": 42, "gpt4v": 42, "gpt4v_experiments_cot": 42, "gpt4v_multi_modal_retriev": 42, "gpt_model": 40, "gpt_repo": 42, "gptpretraindataset": 38, "gpu": [5, 6, 12, 14, 20, 24, 42], "gqa": [22, 31, 32, 40], "gr": 6, "grad": [], "grad_fn": 34, "grad_tensor": 36, "grad_tensors_": 36, "grad_vari": 36, "grade": [3, 5, 6, 24, 42], "gradient": [1, 2, 5, 6, 7, 8, 10, 13, 22, 23, 24, 36, 42], "gradio": 42, "gradio_agent_chat": 42, "gradio_react_agent_chatbot": 42, "gradual": [1, 7, 12, 25, 26], "graham": [8, 21], "grai": [5, 26], "graident": 22, "grain": [2, 5, 6, 8, 9, 14, 17, 18, 21, 42], "grainger": 5, "gram": [6, 10, 15], "grammar": [5, 6, 9, 10, 13, 15], "grammat": [5, 6], "granddaught": 13, "grandson": 13, "granular": [1, 5, 6], "graph": [6, 22, 41, 42], "graph_stor": [41, 42], "graphdatabas": [41, 42], "graphdb": 42, "graphdb_cyph": 42, "graphql": 42, "graphrag": 42, "graphrag_v1": 42, "graphrag_v2": 42, "graphwidget": [41, 42], "grasp": [1, 12], "grave": [8, 13], "gre": 13, "great": [5, 6, 7, 12, 13, 42], "greater": [4, 5, 6, 9, 12, 13, 14, 22, 41, 42], "greatest": 3, "greatli": [1, 5, 6, 19], "greec": 13, "greedi": [18, 25], "greedili": 15, "greedysampl": 33, "greenlet": [41, 42], "greg": [6, 13, 26], "gregari": 13, "gregori": [14, 22], "gression": 5, "grid": [28, 42], "grip": 19, "groom": [5, 9], "groq": 42, "gross": 5, "ground": [2, 4, 5, 6, 17, 18, 19, 20, 21, 23, 24], "groundtruth": 23, "groundwork": 5, "group": [2, 3, 5, 6, 9, 14, 21, 22, 31, 32, 34, 36, 40, 41, 42], "group_and_chunk": [37, 39], "groupwis": 6, "grow": [1, 5, 6, 7, 12, 13, 14, 21, 41, 42], "grown": [41, 42], "growth": [0, 5], "gsh23": 23, "gsl": [5, 6], "gsm8k": [3, 19], "gstatic": 42, "gt": [23, 42], "gtag": 42, "gu": [2, 19, 20, 21, 24], "guadalup": 8, "guan": 2, "guangbo": 2, "guangju": 23, "guant": 2, "guarante": [5, 6, 13, 15, 20, 21], "guarate": 21, "guard": 42, "guardrail": 42, "guardrailsdemo": 42, "guess": 5, "guestrin": 22, "gui": 7, "guid": [0, 1, 5, 6, 13, 17, 18, 19, 21, 22, 23, 41, 42], "guidanc": 42, "guidance_pydantic_program": 42, "guidance_sub_quest": 42, "guidelin": [21, 41, 42], "guideline_ev": 42, "guillaum": [1, 8], "guillermo": 4, "gun": 5, "guo": [2, 6], "guo2016deep": 5, "guowei": 2, "gurevych": 5, "guru": 42, "gut": 11, "gutenberg": 26, "guterman": 9, "guu": [21, 24], "guu2020retriev": 5, "guzm": 8, "gxg": 21, "h": [1, 2, 5, 6, 8, 10, 12, 14, 17, 18, 22, 24, 25, 31, 32, 40, 41, 42], "h1": [19, 40, 42], "h11": [41, 42], "h2": 42, "h3": 42, "h_": [5, 6, 7, 8, 10, 14], "h_0": [5, 6, 7], "h_1": [5, 6, 8], "h_2": 5, "h_3": 5, "h_4": 5, "h_5": 5, "h_6": 5, "h_7": 5, "h_8": 5, "h_9": 5, "h_i": 26, "h_l": 7, "h_n": [5, 6, 8], "h_t": [5, 8, 10], "ha": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "hack": [41, 42], "hacker": 20, "had": [0, 5, 7, 20], "haddad": 6, "haddow": 1, "haifeng": 6, "haikang": 4, "haiku": [40, 42], "hajishirzi": 20, "hakan": 13, "half": [1, 8, 14, 22, 31, 32, 40], "hall": 21, "hallaci": 17, "hallmark": 42, "halluci": 18, "hallucin": [1, 4, 20, 21, 23], "hambro": 23, "hame": 6, "hamlet": 3, "han": [2, 6], "hanburi": 6, "hand": [1, 3, 5, 6, 8, 9, 12, 13, 18, 19, 21, 23, 24, 25, 26, 41, 42], "handl": [1, 2, 5, 6, 10, 13, 14, 19, 20, 21, 24], "handle_torch_funct": 36, "handler": 42, "hang": 6, "hangbo": 8, "hannaneh": 20, "hanwei": 2, "hao": [2, 14], "haocheng": 2, "haofen": 21, "haoqi": 6, "haoran": 24, "haotian": 17, "haowei": 2, "happen": [5, 6, 8, 15, 17, 18, 20, 23], "happi": [5, 21], "harar": 13, "hard": [1, 4, 7, 13, 15, 21, 22, 23, 41, 42], "harder": [5, 6, 8], "hardli": [5, 9], "hardwar": [0, 14, 22, 41, 42], "harm": [21, 23, 24], "harmless": 23, "harmon": 5, "harper": 5, "harri": [5, 26], "harsh": 5, "harsha": 18, "harvard": [], "has_torch_function_unari": 36, "hash": [5, 13, 42], "hasn": [5, 13], "hassibi": 14, "hat": [5, 6, 8, 15, 23, 24, 26], "hate": [3, 5, 7, 11], "hatecheck": 3, "hatena": 42, "hatena_blog": 42, "have": [0, 1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42], "hazan": 26, "hdmi": 5, "he": [1, 2, 3, 5, 6, 8, 10, 12, 21, 22, 23, 26, 31, 40], "he2016learn": 5, "head": [2, 4, 5, 6, 7, 8, 11, 12, 14, 15, 19, 21, 22, 23, 24, 26, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "head_1": 12, "head_dim": [31, 32, 34, 40], "head_h": 12, "head_i": 12, "header": [21, 40, 42], "header__button": 42, "header__ellipsi": 42, "header__inn": 42, "header__opt": 42, "header__titl": 42, "header__top": 42, "headerlink": 42, "health": [5, 41, 42], "health_record": [41, 42], "healthcar": [41, 42], "healthcare_provid": [41, 42], "healthi": 5, "heard": [5, 7], "heart": [5, 6, 15], "heat": 14, "heath": 5, "heavi": 26, "heavili": [8, 12, 13, 21, 26], "heck": 6, "heewoo": 26, "height": [5, 42], "heigold": 12, "held": [5, 22], "helix": 5, "hellaswag": 3, "hello": [19, 34, 40], "help": [1, 3, 5, 6, 7, 8, 12, 19, 20, 21, 22, 23, 24, 26, 40, 41, 42], "helper": 42, "hemoglobin": 5, "henc": [5, 6, 41, 42], "henceforth": 5, "heng": 18, "henighan": 26, "henriqu": 26, "her": [5, 6, 13, 41, 42], "herd": 1, "here": [0, 1, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42], "hereaft": 5, "herebi": 20, "herv": 6, "hess": 26, "heterogen": [5, 6, 21], "heurist": [12, 15, 21], "hfill": 5, "hg19": [5, 6], "hgj": 24, "hh": 23, "hhg": [5, 6], "hi": [5, 6, 7, 20, 41, 42], "hickman": [41, 42], "hidden": [1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 21, 22, 23, 24, 26, 31, 32, 36, 40, 42], "hidden_act": [32, 35, 36], "hidden_s": [31, 32, 35, 36, 39, 40], "hidden_st": [31, 32, 36, 37, 39, 40], "hidn": 8, "hierach": 21, "hierarch": [21, 42], "hierarchi": [5, 20, 42], "high": [1, 2, 3, 6, 9, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 41, 42], "higher": [1, 2, 3, 4, 5, 6, 9, 14, 15, 18, 19, 20, 21, 23, 24, 26, 42], "highest": [1, 2, 4, 5, 6, 15, 17, 21, 23, 33], "highli": [1, 2, 4, 5, 8, 21, 23], "highlight": [5, 6, 14, 18, 19, 20, 40, 42], "highperform": 5, "highwai": [5, 6], "hill": 5, "hilton": 23, "hin12": 26, "hinder": [2, 13, 23, 41, 42], "hing": [5, 13, 41, 42], "hingeloss": 5, "hinrich": [6, 9], "hinton": [6, 8, 26], "hippa": [41, 42], "hire": 23, "hiros": 10, "histogram": 5, "histopathologi": [41, 42], "histor": [3, 5, 6, 7, 21, 26], "histori": [5, 6, 17, 24, 41, 42], "history1995th": 5, "history_sheet": [41, 42], "histplot": 28, "hit": 25, "hive": 42, "hkk": 26, "hkm": 5, "hline": [5, 13], "hlt24": 23, "hmm": 5, "hnsw": [5, 6, 42], "hnswlib": 42, "hnswlibindexdemo": 42, "hofst": 6, "hofstatter2020improv": 5, "hofstatter2021effici": 5, "hofstatterli": 6, "hoi": 17, "hold": 5, "holder": [41, 42], "hole": 5, "holidai": 5, "holist": 20, "hologr": 42, "hologresdemo": 42, "home": [28, 41, 42], "homework": 9, "homogen": 5, "homonym": 5, "honeyh": 42, "honeyhivellamaindextrac": 42, "hong": [6, 23], "honghui": 2, "hongkun": [8, 24], "honglei": 6, "hongwu": 15, "hongyin": 6, "hongyu": 1, "honour": [41, 42], "hop": [4, 18, 20, 21], "hope": [5, 6, 23], "hopefulli": [5, 26], "horizon": 23, "horizont": 26, "hors": 13, "hospit": [41, 42], "hospital_information_system": [41, 42], "host": 42, "hot": [5, 6, 8, 13, 14], "hotel": [4, 5, 6], "hotpotqadistractor": 42, "hottest": [5, 6], "hou": [1, 5, 24, 26], "houlsbi": 24, "hour": [3, 5, 6, 20, 26], "hourglass": 5, "hous": 23, "houston": 22, "how": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 41, 42], "howev": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 15, 17, 19, 21, 22, 23, 24, 25, 26, 40, 41, 42], "hr": 8, "href": 42, "hslw19": [5, 6], "hspace": 28, "hsw": 24, "hsw93": 14, "html": [5, 10, 19, 21, 22, 40, 42], "html_tag_read": 42, "http": [1, 2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 18, 21, 22, 23, 24, 31, 32, 34, 35, 36, 38, 40, 41, 42], "httpcore": [41, 42], "httpx": [41, 42], "htut": [5, 6], "hu": [2, 8, 21, 24], "hua": [6, 20], "huaixiu": 18, "huajian": 2, "huang": [1, 2, 6, 8, 23, 24], "huanyu": 21, "huazuo": 2, "hub": 42, "hubspot": 42, "huehn": 5, "hug": 42, "huge": [1, 5, 6, 8, 9, 13, 22, 42], "huggingfac": [31, 32, 34, 36, 42], "huggingface_api": 42, "huggingface_camel": 42, "huggingface_f": 42, "huggingface_itrex": 42, "huggingface_openvino": 42, "huggingface_optimum": 42, "huggingface_optimum_intel": 42, "huggingface_stablelm": 42, "hugo": [6, 23], "hui": [1, 2, 6, 22], "huiqiang": 14, "huishuai": [1, 12], "hullucil": 21, "human": [0, 1, 3, 5, 6, 8, 9, 13, 15, 18, 19, 21, 23, 24, 26, 41, 42], "human_in_the_loop_story_craft": 42, "humanev": 3, "humeau": [5, 6], "humeau2019poli": 5, "hundr": [0, 1, 5, 6, 7, 13, 20, 26], "hungari": 24, "hunspel": 5, "hunt": 5, "hurdl": [41, 42], "hurt": [1, 8], "hutter": 26, "hv": 8, "hvd15": [5, 6, 8], "hwp": 42, "hybrid": [6, 17, 21, 42], "hyde": 42, "hydequerytransformdemo": 42, "hydro": 9, "hygien": [41, 42], "hyken": 5, "hyper": [1, 2, 5, 6, 15], "hyperbol": 5, "hyperlink": 5, "hypermet": 14, "hypernym": 5, "hyperparamet": [1, 5, 6, 9, 23, 26, 42], "hyperplan": [5, 6], "hyperspher": [5, 6], "hyphen": 5, "hypothes": [1, 5, 15, 24, 31, 32, 40], "hypothesi": [5, 6, 7, 8, 11, 15], "hypothet": 23, "hyung": 24, "i": [0, 2, 3, 4, 7, 8, 9, 10, 11, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "i8": 14, "i_": [5, 17], "i_1": [5, 6, 8, 12], "i_d": [5, 6], "i_f": 17, "i_k": [5, 6], "i_n": [8, 12], "i_p": [8, 12], "i_q": [5, 6], "ian": 6, "ib": 8, "ibarra": 8, "ibm": [13, 42], "ibm_watsonx": 42, "ibuprofen": 21, "ic": [5, 13, 20], "iceberg": 42, "ich": 12, "ici": [5, 6], "icon": 42, "id": [5, 6, 31, 32, 33, 40, 41, 42], "id_": [41, 42], "idaa": 25, "idaho": [5, 6], "idcg": [5, 6], "idea": [1, 4, 5, 6, 8, 9, 10, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 26], "ideal": [5, 6, 13, 18, 21, 22], "iden": 5, "ident": [5, 12, 41, 42], "identi": 5, "identif": [0, 5], "identifi": [3, 4, 5, 6, 12, 14, 15, 20, 21, 40, 41, 42], "idf": [5, 13], "idiom": 3, "idl": 2, "idna": [41, 42], "idrissi": 26, "idx": [34, 35, 36, 38], "ieee": [6, 14, 22], "ient": [41, 42], "ientpatientdischarg": [41, 42], "iffals": 5, "ific": [41, 42], "ignit": 21, "ignor": [5, 6, 13, 14, 21, 22, 31, 34, 35, 36, 40], "ignore_idx": [34, 35, 36], "ii": [4, 14, 23], "iisel": 20, "iisup": 20, "ij": [1, 5, 9, 12, 13, 14], "ijsrp": [41, 42], "ik": 1, "iks16": 13, "il": 7, "ill": [41, 42], "illeg": 3, "illia": [6, 12], "illinoi": 13, "illiter": [41, 42], "illustr": [1, 2, 4, 5, 6, 8, 9, 11, 12, 14, 17, 18, 19, 20, 21, 23, 24, 26, 31, 32, 34, 36], "ilya": [6, 7, 9, 11, 12, 13, 26], "im": 5, "imag": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 18, 20, 21, 23, 24, 26, 41, 42], "image_encod": 17, "image_to_image_retriev": 42, "imagenet": 26, "imagin": [41, 42], "imaginari": 9, "imbal": [2, 8, 22], "imbecil": 7, "imc": [41, 42], "imdb": 42, "imdb_review": 42, "imf": 13, "img": 42, "imit": 23, "immeasur": [41, 42], "immedi": [5, 6, 25], "impact": [0, 1, 6, 7, 8, 9, 14, 15, 20, 21, 23, 24, 26, 41, 42], "impacthardnegativeonretriev": 5, "impair": 2, "imper": [41, 42], "imperfect": [5, 21, 23], "implement": [2, 5, 8, 14, 20, 22, 26, 31, 32, 34, 36, 40, 41, 42], "impli": [1, 5, 8, 11, 13, 14], "implic": [0, 1, 5, 14, 22], "implicit": [5, 8, 13, 21], "implicitli": [5, 6, 21, 25], "impor": 5, "import": [0, 1, 3, 4, 8, 9, 11, 12, 13, 14, 20, 21, 24, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "importantli": [5, 13], "impos": [5, 8, 15, 24, 42], "imposs": [5, 6, 8], "impossibli": 13, "impract": [5, 6, 9], "impress": [5, 6, 7, 12, 19, 26, 40], "improv": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 24, 26, 40, 41, 42], "imshow": 28, "inabl": 13, "inaccru": 23, "inaccur": 17, "inaccuraci": 10, "inaccurci": 14, "inadvert": 24, "inan": 13, "inappropri": [21, 23], "inbatchdistil": 5, "inbatchneg": 5, "inc": [5, 6, 26], "inch": [4, 5], "includ": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 19, 21, 22, 23, 24, 25, 26, 41, 42], "include_embed": [41, 42], "include_text": [41, 42], "inclus": [24, 41, 42], "incom": [5, 41, 42], "incomplet": [4, 21, 23], "inconsist": [10, 24], "inconveni": [5, 41, 42], "incopor": 21, "incorpo": 15, "incorpor": [2, 4, 5, 6, 8, 15, 20, 21, 26, 40, 41, 42], "incorrect": [1, 5, 13, 17, 18, 20, 21, 23], "incorrectli": [9, 23], "increas": [0, 1, 2, 6, 7, 8, 9, 10, 12, 14, 18, 19, 20, 21, 22, 23, 24, 26, 41, 42], "increasingli": [0, 1, 5, 14, 21, 41, 42], "increment": [5, 18, 24], "incres": [], "incrimin": [41, 42], "inculc": [41, 42], "incur": [5, 22, 24], "inde": [5, 13, 25], "indent": 5, "independ": [2, 5, 6, 7, 8, 11, 13, 14, 20, 21, 23, 26], "index": [1, 2, 8, 12, 13, 25, 35, 41, 42], "index_guid": 42, "index_stor": 42, "india": [41, 42], "indian": [41, 42], "indic": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 21, 24, 31, 35, 40, 41, 42], "indici": 23, "indigo": 42, "indirectli": [5, 17], "indiscrimin": [], "indispens": [5, 9, 41, 42], "individu": [1, 2, 3, 4, 5, 6, 8, 13, 20, 23], "indoor": [41, 42], "induc": 5, "induct": 13, "industri": [0, 5, 9, 12, 20, 21, 24], "ineffect": 24, "ineffici": [5, 6, 8, 14, 23, 26], "inefficien": [41, 42], "inexact": [5, 6, 21], "inexpens": [5, 6], "inf": [12, 15, 34], "infer": [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 15, 18, 21, 22, 23, 26, 42], "infer_retrieve_rerank": 42, "inferenc": 14, "inferior": [5, 6, 25], "inflect": 13, "inflow": 5, "influenc": [5, 14, 24, 41, 42], "influenti": [8, 12, 24], "inform": [0, 1, 2, 3, 4, 7, 8, 11, 12, 13, 14, 17, 20, 21, 23, 26, 40, 41, 42], "infrastructur": [5, 14, 41, 42], "infrequ": [5, 6, 13], "infti": [5, 6, 9, 12, 23, 25, 26], "ing": 5, "ingest": 42, "ingestion_gdr": 42, "ingestion_pipelin": 42, "ingrati": 5, "ingredi": 5, "inhabit": 3, "inher": [5, 6, 21, 23], "iniit": 26, "init": 1, "init8": 42, "initi": [1, 3, 4, 5, 6, 7, 8, 11, 12, 14, 17, 21, 23, 25, 26, 31, 40, 41, 42], "initializer_rang": [32, 35, 36], "initil": 24, "inject": [5, 21, 31, 40], "inmemori": 42, "inner": [1, 5, 6, 8, 12, 14], "innov": [0, 2, 5, 8, 20], "inpati": [41, 42], "inpatient_record": [41, 42], "input": [1, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 34, 35, 36, 38, 40, 42], "input_batch": [34, 35, 36, 38], "input_chunk": 38, "input_dtyp": [31, 32, 40], "input_embed": 34, "input_fil": [41, 42], "input_id": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "input_idx": 34, "input_layernorm": [31, 32, 40], "input_mask": 35, "input_tensor": [31, 40], "input_text": [34, 35, 36], "inputs_emb": [31, 32, 40], "insensit": [1, 13, 22], "insert": [5, 6, 8, 11, 20], "insertadjacentel": 42, "insid": 13, "insight": [1, 3, 4, 5, 20, 41, 42], "inspect": [41, 42], "inspir": [7, 18, 20, 21, 26], "inst": 24, "instabl": [1, 23, 24], "instal": [5, 41, 42], "instanc": [1, 5, 6, 12, 15, 21, 24, 41, 42], "instant": 42, "instead": [1, 5, 6, 8, 9, 13, 14, 15, 18, 20, 21, 23, 24, 26], "institut": [41, 42], "instruct": [3, 4, 7, 20, 21, 22, 23, 26, 35, 36, 41, 42], "instructblip": 17, "instructgpt": [19, 23, 24], "instruction_data": [35, 36], "instruction_plus_input": [34, 35, 36], "instruction_text": [34, 35, 36], "instructiondataset": [34, 35, 36], "instructor": 42, "instrument": 42, "insturct": 21, "insuffici": [5, 6, 8, 21], "insur": [5, 41, 42], "int": [3, 5, 6, 14, 31, 32, 34, 38, 40, 41, 42], "int16": 14, "int32": 14, "int4": 14, "int64": [31, 32, 40], "int8": 22, "int_": [5, 6], "intak": [41, 42], "intang": [41, 42], "integ": [1, 5, 6, 8, 12, 13, 14, 22], "integr": [2, 5, 6, 9, 18, 21, 24, 41, 42], "intel": [13, 42], "intellectu": 5, "intellig": [0, 1, 3, 5, 6, 7, 8, 9, 42], "intend": [5, 8, 9, 12, 15, 23, 41, 42], "intens": [4, 5, 6, 14, 18, 21, 41, 42], "intensifi": 14, "intent": [4, 5, 6, 19, 21, 23, 24, 41, 42], "intention": 8, "intents": 21, "inter": [1, 8, 9, 12, 21, 23], "interact": [0, 1, 3, 6, 12, 13, 17, 19, 20, 21, 24, 25, 42], "intercom": 42, "interconnect": [20, 21], "interconnected": 20, "interest": [5, 6, 7, 12, 21], "interf": 5, "interfac": [5, 17, 42], "interfer": 2, "interleaf": 20, "interleav": [5, 20], "intermedi": [1, 2, 5, 6, 12, 14, 19, 22, 25, 42], "intermediate_s": [31, 32, 35, 36, 39, 40], "intermedid": 26, "intermitt": 20, "intern": [1, 4, 5, 6, 8, 12, 13, 14, 15, 17, 20, 21, 22, 23, 26, 41, 42], "internet": [1, 5, 17, 41, 42], "interoper": [41, 42], "interplai": 0, "interpol": [19, 28], "interpolat": 1, "interpret": [1, 3, 4, 5, 6, 8, 9, 19, 21, 23, 24, 25, 42], "intersect": 5, "interspeech": 10, "interspeech2010": 10, "interst": [5, 6], "intertwin": 40, "interv": [5, 7], "intervent": [41, 42], "intra": [1, 41, 42], "intract": [5, 9], "intric": [1, 23], "intricaci": 0, "intrins": [7, 21], "intro": 42, "introduc": [1, 2, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25], "introduct": [12, 42], "introspect": 42, "introspective_agent_toxicity_reduct": 42, "intuit": [1, 4, 5, 6, 7, 9, 12, 14, 18, 24, 26], "intut": 21, "intutivi": 1, "inv": [31, 32, 40], "inv_freq": [31, 32, 40], "inv_freq_expand": [31, 32, 40], "invalid": [41, 42], "invalu": 0, "invari": 1, "invent": [4, 12, 21], "invers": [1, 5, 6, 9, 13, 26, 31, 40], "invert": [8, 21, 31, 40], "invest": [0, 5, 41, 42], "investig": [4, 5, 6, 7, 41, 42], "invit": 11, "invok": [1, 21], "involv": [1, 2, 4, 5, 6, 7, 8, 9, 12, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 40], "invovl": 21, "io": [5, 14, 41, 42], "ioff": 1, "ion": [14, 21], "ionic": 42, "ionic_shop": 42, "iou": 13, "iowa": 5, "ip": 5, "ipad": 5, "ipex": 42, "ipex_llm": 42, "ipex_llm_gpu": 42, "iphon": 4, "ipo": [9, 23, 35], "ipykernel": 28, "ipykernel_60922": 28, "ipykernel_launch": 28, "ipynb": 42, "ipython": [41, 42], "ir": 30, "iran": 13, "irr": [41, 42], "irrelev": [5, 6, 8, 13, 17, 20, 21], "irrelv": 21, "irreplac": 21, "irrespect": [13, 26], "irrespons": 20, "irrit": [5, 6], "irv": 15, "is15": 1, "is_avail": [34, 35, 36, 37, 38, 39], "is_caus": [31, 32, 40], "is_chat_model": [41, 42], "is_prim": 3, "isca": 10, "isn": [5, 21, 41, 42], "isnext": 8, "isol": [2, 5], "isola": 6, "isr": [41, 42], "isrel": 20, "issn": [41, 42], "issu": [1, 2, 5, 6, 12, 13, 14, 20, 21, 22, 23, 26, 41, 42], "issup": 20, "issup\u548cisuse\u7b49": [], "ist": [11, 41, 42], "isus": 20, "italian": [5, 6, 41, 42], "itc": 17, "itch": 5, "item": [5, 6, 22, 23, 33, 34, 35, 36, 37, 38, 39, 41, 42], "iter": [1, 2, 4, 5, 6, 11, 14, 15, 17, 24, 26, 42], "itertool": [37, 39], "itg": 17, "itlian": [5, 6], "itm": 17, "itrex": 42, "its": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42], "itself": [5, 6, 7, 8, 12, 14, 18, 22, 23, 40], "iv": [8, 11, 19, 23, 24], "ivf": [5, 6], "ivfadc": 5, "iwasawa": 19, "iyyer": 8, "izacard": 23, "j": [1, 2, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 17, 23, 24, 25, 41, 42], "j_": [5, 6], "j_i": [5, 6], "j_n": [5, 6], "j_p": [5, 6], "jaap": 6, "jaccard": 5, "jack": 17, "jacki": [5, 6], "jackson": [23, 26], "jacob": [6, 8, 12, 23, 24, 26], "jade": 21, "jae": 17, "jaguar": 42, "jaguarindexdemo": 42, "jaim": 21, "jain": 21, "jakob": [6, 12], "jame": [1, 5, 23, 26], "jami": 6, "jan": [10, 23], "jang2021ultra": 5, "januari": [5, 6], "japan": 4, "japanes": 5, "jare": [1, 7, 9, 12, 26], "jargon": [21, 22], "jason": [5, 6, 13, 15, 18, 19, 24], "jastrzebski": 24, "jauhri": 1, "jaundic": 5, "jauvin": 10, "java": 5, "javascript": 42, "jc": 6, "jdiq": 6, "jdjegou19": [5, 6], "je": 7, "jean": [4, 10, 15], "jeff": [6, 8, 13, 22, 23, 24], "jeffrei": [7, 9, 11, 12, 13, 23, 26], "jejun": [41, 42], "jelli": 5, "jennimaria": 6, "jerom": 6, "jerri": 26, "jgbm16": 13, "jheng": 6, "ji": [1, 2, 21, 26], "jia": [20, 21, 26], "jiafeng": 6, "jialin": 6, "jian": [1, 2, 6, 12, 26], "jianfeng": 6, "jiang": [1, 4, 6, 8, 12, 14, 23, 26], "jianlin": 1, "jianmo": 21, "jianzhong": 2, "jiao": [6, 8], "jiaq": 21, "jiaqi": 2, "jiashi": 2, "jiawei": [2, 21], "jiaxuan": 23, "jiayang": 21, "jie": 24, "jimmi": [6, 21, 26], "jin": [2, 6, 23], "jina": 42, "jina_embed": 42, "jinaai": 42, "jinaai_embed": 42, "jinaai_rerank": 42, "jinarerank": 42, "jing": [6, 21], "jingang": 6, "jingchang": 2, "jingfei": [8, 12], "jingyang": 2, "jingyaogong": 27, "jinhao": [1, 26], "jinliu": 21, "jira": 42, "jiter": [41, 42], "jiwoo": 23, "jo": 5, "job": [5, 20], "joblib": [41, 42], "joe": 24, "john": [5, 14, 15, 23, 26], "johnson": [5, 6, 8], "join": [9, 28, 40, 42], "joint": [5, 6, 8, 9, 10, 17, 24, 42], "jointli": [1, 5, 12, 17, 24], "jointqasummari": 42, "joke": 42, "joliett": 7, "jon": 6, "jonah": 22, "jonathan": [4, 6, 18, 20], "jone": [5, 6, 12, 23], "jong": [1, 17], "joplin": 42, "jose": 21, "joseph": [6, 14, 21, 26], "joshi": [8, 12], "joshua": [1, 9, 20], "joulin": 13, "journal": [6, 8, 9, 10, 26], "journei": 0, "joydeep": 6, "jsdelivr": 42, "jsm": 1, "json": [33, 34, 35, 36, 41, 42], "json_query_engin": 42, "jsonalayz": 42, "jsonalyz": 42, "jsonalyze_query_engin": 42, "jsonpatch": [41, 42], "jsonpoint": [41, 42], "jstor": 23, "ju": 4, "judg": [5, 6, 42], "judgement": [5, 42], "judgment": [5, 20], "juic": 13, "jul": [26, 41, 42], "juli": [4, 5, 6], "julien": [4, 8], "jump": 7, "jumper": 15, "jumpstart": 26, "jun": [1, 12, 26, 41, 42], "junaid": 6, "june": 21, "junji": [1, 2, 8, 26], "junlong": 2, "junnan": 17, "junxiao": 2, "junyi": [1, 26], "jurafski": 5, "jurisdict": [41, 42], "just": [1, 5, 6, 7, 8, 9, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 31, 40, 41, 42], "justif": [5, 21], "justifi": [5, 13], "jwl": 14, "jy": 8, "k": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 31, 32, 37, 39, 40, 41, 42], "k_": [1, 2, 5, 6, 20], "k_1": [5, 6], "k_emb": [31, 32, 40], "k_i": 1, "k_j": 1, "k_n": 1, "k_proj": [31, 32, 40], "k_r": 2, "kadavath": 23, "kafka": 42, "kai": [1, 2, 6, 12, 13, 17, 24], "kaig": 2, "kaim": [6, 26], "kaiser": [6, 12], "kalman": 15, "kaltura": 42, "kaltura_esearch": 42, "kamp": 6, "kamyar": 6, "kandpal": 4, "kang": 2, "kangxiang": 21, "kansa": [5, 6], "kaplan": [1, 7, 9, 12, 26], "karafi\u00e1t": 10, "karen": 5, "karkhani": 23, "karpukhin": 6, "karpukhin2020dens": 5, "karthik": [7, 9, 12], "kartikai": 8, "katarina": 23, "kate": 8, "katherin": [6, 11], "katz": 26, "kazakhstan": 13, "kb": [41, 42], "kb14": 26, "kd": [5, 6, 8], "kdb": 42, "kdbai": 42, "kdbai_advanced_rag_demo": 42, "kdr": 4, "keep": [1, 2, 5, 6, 9, 15, 17, 21, 24, 41, 42], "keepdim": [31, 32, 34, 40], "keeper": 5, "keerthi": [41, 42], "kei": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 24, 26, 28, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42], "keikichi": 10, "keith": 21, "kelton": 23, "kelvin": [21, 24], "kenton": [6, 8, 12], "kentucki": [5, 6], "kept": [5, 6, 19, 40, 41, 42], "kernel": [1, 5, 8], "kernion": 23, "keskar": 11, "keskar2019ctrl": 15, "kevin": [8, 12, 24], "kexin": 2, "key_sequence_length": [31, 40], "key_stat": [31, 32, 40], "key_value_length": [31, 40], "keyboard": 5, "keyboardinterrupt": 36, "keyphras": 21, "keyvalu": 4, "keyword": [5, 6, 20, 21, 41, 42], "kg": [21, 42], "kg_index": [41, 42], "kg_node": [41, 42], "kg_rag_query_engin": [41, 42], "kg_retriev": [41, 42], "kgr": 19, "khalifa": [41, 42], "khamlichi": [41, 42], "khandelw": 8, "khashayar": 13, "khattab": [5, 6], "khennou": [41, 42], "khosravi": 13, "khudanpur": 10, "kia": 9, "kibela": 42, "kid": [], "kihyuk": 6, "kill": [5, 6], "kim": 17, "kind": [5, 8, 42], "kindli": 5, "king": [5, 18], "kingma": [5, 26], "kitten": 5, "kj": 1, "kl": [5, 8, 23], "klau": 8, "klimov": 23, "klist": [41, 42], "klz": 14, "kmh": 26, "kn": 42, "kneser": 9, "knew": [], "knn": 18, "knolwedg": 21, "know": [5, 7, 9, 14, 20, 21, 23, 25], "knowl": 5, "knowledg": [0, 2, 4, 7, 8, 12, 13, 18, 19, 24, 25, 26, 40, 41, 42], "knowledge_graph": 42, "knowledge_graph_query_engin": 42, "knowledge_graph_rag_query_engin": 42, "knowledgegraphindex": [41, 42], "knowledgpt": 21, "known": [5, 6, 8, 9, 12, 13, 14, 18, 21, 23, 24, 25], "knrm": 6, "kobayashi": 10, "koda": 42, "koda_retriev": 42, "kojima": 19, "kolesnikov": 12, "kong": 1, "konko": 42, "kor": 5, "korean": 1, "kouguzm": [5, 6], "kpr": [5, 6], "krikun": 8, "kristina": [6, 8, 12], "kuai": 2, "kuchaiev": 22, "kukich": 5, "kullback": [5, 6], "kumar": 6, "kun": [1, 26], "kundu": 23, "kurt": 6, "kusner": 8, "kuula": 21, "kuzu": 42, "kv": [31, 32, 40], "kv_store": 42, "kvstore": 42, "kw": [1, 12], "kw_i": 12, "kwanza": 13, "kwarg": [31, 40, 41, 42], "kwargsforcausallm": [31, 40], "kwiatkowski": 6, "kwin": 25, "kwok": [5, 6], "kwon": 14, "kwout": 25, "kwret": 25, "kyrola": 26, "kyunghyun": [6, 21], "kz20": [5, 6], "l": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 22, 23, 24, 25, 26, 31, 32, 40], "l2": [5, 6], "l2_normal": 17, "l_": [5, 6, 8, 14, 17, 23], "l_2": [5, 6], "l_n": 26, "l_q": [5, 14], "l_r": 5, "la": [1, 6], "lab": 30, "label": [7, 8, 11, 12, 13, 17, 18, 21, 24, 25, 26, 28, 31, 35, 37, 39, 40, 42], "label_smooth": 35, "labelledbi": 42, "labelledevaluatordataset": 42, "labelledragdataset": 42, "labels": 28, "labor": 20, "laboratori": [41, 42], "lachaux": [1, 6, 23], "lack": [1, 4, 5, 6, 8, 9, 13, 14, 19, 21, 23, 24, 26, 40, 41, 42], "lacroix": [1, 23], "lacuna": [41, 42], "ladi": 5, "lagrang": [9, 14], "lagrangian": 14, "lake": 42, "lambda": [1, 2, 5, 9, 14, 21, 23, 26], "lambda_": 5, "lambda_i": 9, "lambdaloss": 5, "lambdamart": [5, 6], "lambdarank": [5, 6], "lamda": 18, "lampl": [1, 8], "lan": [1, 8, 12], "lancedb": 42, "lancedbindexdemo": 42, "land": [5, 6], "landmark": [41, 42], "landscap": 0, "lang": 42, "langaug": [31, 32, 36, 40], "langchain": [41, 42], "langchain_cor": [41, 42], "langchain_text_splitt": [41, 42], "langchainoutputparserdemo": 42, "langfus": 42, "langfusecallbackhandl": 42, "langfusemistralposthog": 42, "langl": [1, 5, 6, 23], "langsmith": [41, 42], "languag": [1, 2, 3, 6, 13, 15, 18, 19, 20, 21, 23, 26, 30, 42], "languageunsupervis": [7, 9, 12], "languga": 26, "lanka": [41, 42], "lantern": 42, "lanternautoretriev": 42, "lanternindexdemo": 42, "laplac": 9, "laptop": [4, 5, 42], "larc21": [17, 24], "larg": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 40, 41, 42], "large_language_model": 42, "larger": [0, 1, 2, 5, 6, 7, 8, 9, 12, 13, 14, 22, 23, 24, 26], "largest": [5, 7, 12, 22, 41, 42], "larnguag": 9, "laroussilh": 24, "larri": 6, "larson": [18, 20], "lasso": 5, "last": [1, 4, 5, 6, 7, 8, 11, 20, 23, 28, 31, 32, 36, 40, 41, 42], "last_accessed_d": [41, 42], "last_hidden_st": [31, 40], "last_modified_d": [41, 42], "lat": 42, "late": [5, 6], "latenc": [1, 2, 5, 6, 20, 21, 24], "latent": [2, 4, 5, 6, 10, 13, 26], "later": [5, 6, 25], "latest": [1, 5, 6, 9], "lats_ag": 42, "latter": 5, "launch": 5, "laura": 6, "laurenc": 24, "laurent": 15, "lavaud": 1, "lavrenko2017relev": 5, "lavril": [1, 23], "law": [0, 2, 9, 18, 21, 23, 26, 41, 42], "lawyer": 5, "lax": 5, "layer": [2, 4, 5, 6, 7, 10, 11, 13, 14, 17, 18, 21, 22, 23, 24, 26, 36, 37, 38, 39], "layer_idx": [31, 32, 40], "layer_output": [31, 40], "layer_st": [31, 32, 36, 40], "layernorm": [1, 8, 12, 31, 32, 34, 40], "layerwis": 8, "layout": [5, 21, 22], "lb": 15, "lc": 5, "lc19": 8, "lcc": 5, "lccc": 5, "lcccc": 5, "lceil": 5, "lcg": [8, 12], "ldot": [1, 2, 4, 5, 6, 7, 8, 9, 13, 15, 20, 24, 26], "lds89": 14, "le": [1, 6, 8, 9, 18, 19, 24], "lead": [1, 2, 4, 5, 6, 12, 13, 14, 17, 18, 19, 20, 21, 22, 24, 25, 26, 40], "leader": 7, "leagu": 3, "leak": [41, 42], "leakag": [3, 17], "lean": 2, "leap": 0, "lear": 26, "learn": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 24, 30, 42], "learnabl": [1, 8, 17, 24, 31, 32, 40], "learner": [1, 7, 8, 9, 11, 12, 24], "learning_r": [34, 35, 36, 37, 38, 39], "learningcan": 5, "learnt": 5, "least": [1, 5, 6, 14, 18, 23, 41, 42], "leav": [5, 6, 21], "leben": 5, "lebensversicherungsgesellschaftsangestellt": 5, "lebr\u00f3n": 1, "lecong": 2, "lectur": [6, 9], "lecun": 14, "led": [0, 5, 6, 8, 24], "ledel": 6, "ledger": 5, "lee": [1, 4, 6, 8, 11, 12, 15, 17, 18, 23, 24], "lee2020learn": 5, "lee2021phras": 5, "left": [1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 20, 21, 23, 24, 25, 26, 28, 42], "leftarrow": [6, 25, 26], "leftto": 5, "legaci": [41, 42], "legal": [26, 41, 42], "legal_data": [41, 42], "legend": 28, "legisl": [41, 42], "legitim": 23, "lei": 2, "leibler": [5, 6], "leik": 23, "leimao": 14, "lemma": 25, "lemmat": [5, 13], "lemon": 5, "len": [8, 28, 34, 35, 36, 37, 38, 39, 42], "length": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 21, 22, 23, 24, 28, 31, 34, 38, 40], "lengthi": [5, 6, 20, 21, 42], "lengyel": 1, "leo": 23, "leonardo": 20, "leq": [1, 5, 6, 9, 13, 14, 25], "leqslant": 2, "lesion": [41, 42], "lespiau": 15, "less": [1, 2, 4, 5, 6, 8, 9, 13, 14, 15, 19, 21, 23, 24, 41, 42], "lesson": 5, "lester": [17, 24], "let": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 19, 21, 23, 24, 25, 26, 35], "letc21": [5, 6], "letter": [1, 5], "level": [0, 2, 3, 4, 7, 8, 9, 12, 13, 14, 18, 21, 23, 24, 25, 41, 42], "lever": 5, "leverag": [4, 5, 6, 8, 12, 14, 17, 20, 21, 22, 23, 24, 37, 38, 39, 40, 41, 42], "levi": [6, 8, 11, 12, 13], "leviathan": 15, "lewi": [1, 6, 8, 11, 12, 14], "lex": 5, "lexi": 5, "lexic": [4, 5, 6, 13, 21], "lexicon": 5, "leyi": 2, "lfloor": [1, 14], "lh17": 26, "li": [1, 2, 5, 6, 8, 11, 12, 13, 14, 15, 17, 18, 21, 24, 26, 42], "liabil": [41, 42], "liang": [2, 4, 6, 13, 21, 24], "liangjian": 1, "lianmin": 14, "lib": [28, 36, 41, 42], "liber": 5, "librari": [5, 6, 41, 42], "licens": [41, 42], "lie": [1, 7], "life": [5, 24], "lifeng": 8, "lift": [5, 42], "light": [2, 42], "lighter": 8, "lightn": [5, 6], "lightweight": [5, 6, 17, 20, 23], "liguist": 26, "liji": 15, "like": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42], "likehood": 23, "likelihood": [1, 5, 6, 7, 8, 9, 13, 15, 18, 23, 26], "likert": 23, "likewis": 7, "lilac": 42, "lili": [6, 14], "lilianweng": 14, "lim_": [9, 25], "limit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 21, 23, 24, 25, 26, 41, 42], "lin": [2, 5, 6, 12, 14, 21], "lin2021batch": 5, "lincoln": 5, "lindgren": 6, "lindorm": 42, "lindormdemo": 42, "line": [5, 6, 8, 21, 23, 28, 36, 40, 41, 42], "linear": [1, 4, 5, 6, 7, 8, 11, 12, 13, 17, 22, 26, 31, 32, 34, 36, 37, 39, 40, 42], "linearli": [1, 5, 6, 8, 10, 14, 17, 22, 31, 32, 36, 40], "ling": 20, "lingl": 24, "lingpeng": 1, "lingual": [8, 26], "linguist": [1, 5, 6, 8, 9, 11, 13, 17, 24], "lingyong": 4, "link": [5, 9, 13, 20, 21, 41, 42], "linkedin": [5, 42], "linli": 26, "linlin": 8, "linq": 6, "lior": 13, "lipani": 24, "lisa": 24, "lisp": 20, "list": [1, 6, 11, 15, 17, 20, 21, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42], "listen": 7, "listwis": [4, 5, 6], "lite": [8, 12], "litellm": 42, "liter": [5, 7], "literalai": 42, "literatur": [5, 23, 26, 41, 42], "lithophil": 5, "liti": 8, "litig": [41, 42], "litong": 2, "littl": [5, 6, 14, 26], "liu": [1, 2, 6, 8, 11, 12, 17, 18, 23, 24, 26], "liu2021pr": 5, "live": [5, 10, 20, 42], "liver": [5, 6], "liwei": [1, 12], "liyu": 2, "ljz20": [5, 6], "lkb20": 8, "lkm23": 15, "ll": [5, 6, 8, 12, 14, 20, 24, 26], "ll21": 24, "llama": [1, 3, 26, 30, 34, 36, 41, 42], "llama2": [23, 42], "llama3": [1, 42], "llama3_cookbook": 42, "llama3_cookbook_groq": 42, "llama3_cookbook_ollama_repl": 42, "llama7b": 14, "llama_2": 42, "llama_2_llama_cpp": 42, "llama_2_rap_battl": 42, "llama_api": 42, "llama_cloud": [41, 42], "llama_cloud_index": 42, "llama_cpp": 42, "llama_dataset": 42, "llama_dataset_metadata": 42, "llama_debug": 42, "llama_deploi": 42, "llama_extract": 42, "llama_guard_moder": 42, "llama_hub": 42, "llama_index": [41, 42], "llama_index_agent_openai": [41, 42], "llama_index_cli": [41, 42], "llama_index_cor": [41, 42], "llama_index_embeddings_openai": [41, 42], "llama_index_indices_managed_llama_cloud": [41, 42], "llama_index_legaci": [41, 42], "llama_index_llms_openai": [41, 42], "llama_index_multi_modal_llms_openai": [41, 42], "llama_index_program_openai": [41, 42], "llama_index_question_gen_openai": [41, 42], "llama_index_readers_fil": [41, 42], "llama_index_readers_llama_pars": [41, 42], "llama_pack": 42, "llama_pack_ollama": 42, "llama_pack_resum": 42, "llama_packs_exampl": 42, "llama_pars": [41, 42], "llamaattent": [31, 32, 40], "llamacloud": 42, "llamaconfig": [31, 32, 40], "llamacpp": 42, "llamadataset": 42, "llamadebughandl": 42, "llamadecoderlay": [31, 32, 40], "llamafil": 42, "llamaforcausallm": [31, 32, 35, 36, 40], "llamahub": 42, "llamaindex": 42, "llamaindext": 42, "llamalogobrowsertab": 42, "llamamlp": [31, 32, 40], "llamamodel": [31, 32, 36, 40], "llamapack": 42, "llamapars": 42, "llamapretrainedmodel": [31, 40], "llamarmsnorm": [31, 32, 40], "llamarotaryembed": [31, 32, 40], "llamasquareblack": 42, "llava": 42, "llava_complet": 42, "llava_demo": 42, "llava_multi_modal_tesla_10q": 42, "llg": 11, "llion": [6, 12], "lll": 8, "lllr": 5, "llm": [2, 7, 12, 15, 17, 18, 20, 41, 42], "llm_book": [], "llm_compil": 42, "llm_env": 27, "llm_judg": 42, "llm_lab": [37, 38, 39], "llm_predictor": 42, "llm_program": 42, "llm_question_gen": 42, "llm_rail": 42, "llm_rerank": 42, "llm_text_complet": 42, "llmlingua": 14, "llmrail": 42, "llmrerank": 42, "lloyd": [5, 6], "llsh23": 17, "llustrat": [4, 21], "llwl24": 17, "llxh22": 17, "llxl21": [5, 6], "lm": [5, 17, 19, 20, 22, 24, 42], "lm_head": [31, 32, 34, 36, 37, 39, 40], "lmformatenforc": 42, "lmformatenforcer_pydantic_program": 42, "lmformatenforcer_regular_express": 42, "lmstudio": 42, "ln": [1, 9, 13], "lny21": [5, 6], "lo": [4, 41, 42], "load": [1, 5, 6, 14, 22, 32, 34, 35, 36, 39, 41, 42], "load_and_search": 42, "load_data": [41, 42], "load_dataset": [37, 38, 39], "load_ext": [37, 39], "load_index_from_storag": [41, 42], "load_medical_records_data": [41, 42], "load_state_dict": 32, "loader": 42, "loan": [], "local": [1, 5, 6, 12, 13, 17, 20, 21, 26, 42], "local_model": 42, "localai": 42, "localhost": [41, 42], "localstorag": 42, "locat": [4, 5, 6, 8, 10, 14, 21, 26, 41, 42], "log": [1, 2, 4, 5, 6, 7, 8, 9, 12, 13, 15, 17, 23, 24, 26, 35, 42], "log10": 28, "log_": [5, 6], "log_2": [5, 6], "log_freq": [37, 39], "log_softmax": 35, "logarithm": [5, 6], "logdiscount": 5, "logic": [1, 3, 5, 6, 9, 10, 12, 18, 19, 21], "logist": [5, 13, 41, 42], "logit": [5, 6, 8, 13, 15, 17, 23, 31, 32, 34, 35, 36, 37, 38, 39, 40], "logo": 42, "logsigmoid": 35, "london": 4, "long": [0, 4, 5, 9, 10, 12, 13, 14, 15, 23, 26, 31, 40, 41, 42], "long_context_reord": 42, "long_context_test": 42, "long_rag_pack": 42, "longcontextreord": 42, "longer": [1, 5, 6, 8, 9, 10, 12, 14, 15, 18, 23, 24], "longest": [34, 35, 36], "longllmlingua": 42, "longpr": 24, "longrag": 42, "longtensor": [31, 32, 35, 36, 40], "look": [3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 23], "lookup": [5, 6], "loop": 42, "loophol": [41, 42], "loos": [5, 6], "lopez": 26, "lose": [5, 13, 22, 23], "loshchilov": 26, "loss": [4, 7, 8, 9, 11, 12, 13, 14, 17, 21, 22, 26, 31, 34, 35, 36, 37, 38, 39, 40], "loss_funct": [31, 40], "loss_i": 17, "loss_kwarg": 35, "loss_mark": 35, "loss_mask": 35, "loss_t": 17, "lost": [5, 6, 11, 21], "lot": [5, 17, 21, 41, 42], "lott": 5, "lou": [17, 24], "loui": 6, "love": [5, 8, 13], "low": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 18, 20, 21, 22, 23, 26, 42], "low_level": 42, "lower": [2, 5, 6, 8, 9, 13, 14, 15, 21, 22, 23, 24, 41, 42], "lower_level": 42, "lowercas": 9, "lowest": [15, 21], "loyal": 5, "lpg_index_guid": 42, "lr": [34, 35, 36, 37, 38, 39], "lrx": 4, "lsa": [5, 6, 13], "lstm": [5, 6, 8], "lt": 42, "ltr": [5, 42], "lty": 12, "lu": [1, 2, 6, 21, 23, 24], "luan": [5, 6, 7, 9, 11, 12, 21], "luan2021spars": 5, "luca": 12, "lucen": [5, 6], "lucil": 1, "lucki": 13, "luckiest": 13, "lukasz": 26, "luke": [8, 11, 12, 14, 23], "luk\u00e1": 10, "luo": [2, 24], "luong": 8, "luxuri": 25, "luyu": 6, "lvert": 25, "lwlq21": [5, 6], "ly": [5, 6], "lyft": 42, "lyl21": [5, 6], "lym": 24, "lyme": 5, "lysandr": 8, "lyu": 12, "lzy24": [17, 24], "l\u00e9lio": 1, "m": [1, 2, 4, 7, 8, 9, 11, 12, 13, 14, 20, 22, 23, 24, 26, 31, 32, 40, 41, 42], "m12": 42, "m13": 42, "m14": 42, "m3": 42, "m365": 5, "m4": 42, "m9": 42, "m_": [5, 8, 13, 14, 22, 26], "m_1": 8, "m_k": 26, "m_m": 8, "m_t": 8, "ma": [1, 2, 4, 5, 6, 8, 13, 21, 23], "ma2021pr": 5, "maarten": [19, 24], "mac": 13, "machel": 19, "macherei": 8, "machin": [1, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 22, 23, 26], "machineri": 5, "macintosh": 13, "macrometa": 42, "macrometa_gdn": 42, "macrothal": 5, "maddi": 23, "made": [5, 6, 7, 9, 11, 15, 20, 21, 37, 38, 39, 41, 42], "magazin": [], "magnitud": [1, 5, 14, 26], "mahal": 4, "maher": 5, "mai": [1, 3, 4, 5, 6, 8, 13, 14, 15, 19, 20, 21, 23, 24, 25, 26, 41, 42], "main": [2, 3, 5, 6, 7, 21, 22, 34, 35, 36, 38, 40, 41, 42], "main__inn": 42, "mainli": [1, 2, 5, 6, 8, 14, 21, 22], "mainstream": [1, 14], "maintain": [1, 2, 5, 6, 8, 14, 21, 22, 41, 42], "maintainentc": 24, "mainten": [21, 24, 41, 42], "mairal": 4, "major": [1, 5, 6, 7, 8, 12, 13, 14, 17, 18, 41, 42], "majumd": 6, "make": [1, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 40, 42], "make_com": 42, "makedemo": 42, "makedir": [41, 42], "makhzani": 5, "male": 5, "malkov": 6, "malonei": [41, 42], "malpractic": [41, 42], "mammal": [5, 6], "man": [6, 7, 8, 9, 13, 23, 41, 42], "manag": [0, 4, 5, 6, 8, 12, 14, 20, 21, 41, 42], "manage_retrieval_benchmark": 42, "mandar": [8, 12], "mandatori": [41, 42], "mangadex": 42, "mangoapp": 42, "mangoapps_guid": 42, "mani": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 21, 22, 24, 25, 26, 41, 42], "manifest": [], "manifold": 5, "manisha": 6, "manlei": 23, "mann": [1, 7, 9, 12], "manner": [0, 5, 6, 8, 11, 20, 21, 25, 41, 42], "mantissa": 22, "manual": [5, 8, 17, 18, 21, 41, 42], "manual_se": [34, 35, 36, 37, 38, 39], "manufactur": [4, 24], "map": [1, 5, 6, 8, 9, 12, 13, 14, 21, 22, 24, 25, 37, 39, 42], "mappign": 24, "mar": [23, 41, 42], "mar94": 9, "marc": 6, "marcinkiewicz": 9, "margin": [5, 6, 18, 21, 23, 24, 42], "mari": [1, 6, 9, 23, 24], "mariadb": 42, "marineri": 23, "maritalk": 42, "marjan": 11, "mark": [1, 7, 8, 12, 26, 41, 42], "markdown": [21, 41, 42], "markdown_el": 42, "marker": [5, 6, 8, 41, 42], "market": [5, 21, 42], "marketwatch": 5, "markings10learn": 5, "markov": 9, "marku": 14, "marshmallow": [41, 42], "marten": 26, "martin": [5, 10], "martinet": 23, "marvin": 42, "marvinmetadataextractordemo": 42, "mask": [1, 5, 6, 11, 17, 22, 31, 34, 35, 36, 40, 42], "mask_bool": 34, "mask_fil": [], "mask_length": [31, 40], "masked_fil": [31, 34, 35, 36, 40], "maskedmultiheadattent": 12, "mass": [5, 7, 9], "massiv": [0, 1, 3, 5, 7, 8], "master": 22, "masteri": 21, "masterpiec": 19, "mastiff": 5, "matan": 15, "match": [1, 7, 8, 9, 17, 18, 20, 21, 22, 24, 31, 32, 40, 41, 42], "matchmedia": 42, "matei": [6, 21], "matena": [6, 11], "materi": [21, 26, 41, 42], "math": [1, 3, 13, 31, 32, 33, 34, 35, 36, 38, 40], "mathbb": [1, 2, 4, 5, 6, 7, 8, 12, 13, 14, 23, 24, 25, 26], "mathbf": [1, 2, 5, 6, 7, 8, 11, 14, 15, 18, 20, 24, 26], "mathcal": [1, 2, 4, 5, 6, 7, 8, 9, 13, 15, 20, 23, 24, 25], "mathemat": [1, 5, 6, 19, 23, 24, 26], "mathemati": 23, "mathrm": [2, 6, 8, 9, 11, 14, 20, 23, 24, 26], "matia": 15, "matmul": [31, 32, 40], "matplotlib": 28, "matric": [1, 4, 8, 10, 12, 13, 14, 24, 31, 32, 40], "matrix": [1, 5, 7, 8, 9, 11, 12, 13, 22, 24, 25, 26, 31, 40], "matryoshka": 42, "matsuo": 19, "matt": 8, "matter": [5, 6, 8, 26, 31, 40], "matthew": 8, "matthia": 12, "matthij": 6, "matur": 5, "max": [5, 6, 8, 12, 13, 14, 21, 23, 24, 25], "max_": [13, 14, 23, 25], "max_a": 25, "max_ae_": 25, "max_font_s": 28, "max_length": [34, 35, 36, 38], "max_new_token": 33, "max_position_embed": [31, 32, 35, 36, 39, 40], "max_seq_len": [31, 32, 40], "max_seq_len_cach": [31, 32, 40], "max_triplets_per_chunk": [41, 42], "max_val": 14, "max_window_lay": [32, 35, 36], "maxdcg": 5, "maxheap": 5, "maxim": [0, 5, 6, 7, 8, 9, 10, 13, 14, 15, 21, 23, 25], "maximum": [1, 5, 6, 9, 13, 14, 15, 25, 42], "maxsim": 5, "maxsimilar": [5, 6], "mayb": 5, "maynard": 5, "mb": [41, 42], "mbart": 7, "mbb": [41, 42], "mbox": 42, "mboxreaderdemo": 42, "mbpp": 3, "mbps09": 4, "mc": [5, 6], "mc19": [5, 6], "mccandlish": 26, "mccann": 11, "mccd13": 13, "mckinnon": 23, "mcrank": 5, "md": 42, "mdc17": [5, 6], "me": [8, 11, 19, 20, 21, 40], "mean": [2, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 21, 22, 23, 24, 25, 26, 31, 32, 34, 35, 37, 39, 40], "mean_loss": [37, 39], "meaning": [5, 6, 9, 13, 15, 21, 41, 42], "meaningless": 5, "meant": [5, 20], "meanwhil": [2, 4, 5, 6], "measur": [3, 5, 6, 7, 12, 13, 21, 23], "mebert": 5, "mechan": [2, 5, 6, 8, 10, 12, 14, 17, 21, 24, 41, 42], "mechnism": 14, "med": [5, 17], "medal": 21, "medi": [41, 42], "media": [5, 13, 26, 42], "medic": [5, 18, 21, 41, 42], "medical_record": [41, 42], "medicin": [5, 18, 26, 41, 42], "medico": [41, 42], "medico_legal_data": [41, 42], "medium": [8, 26, 41, 42], "medium_s": 28, "medprompt": 18, "medqa": 18, "meet": [5, 6, 10, 15, 21, 24, 41, 42], "meetup": 5, "megatron": 22, "mei": 23, "melani": [1, 7, 9, 12], "melvin": 8, "mem0": 42, "mem0memori": 42, "member": 15, "memgraph": 42, "memo": 42, "memor": [4, 5, 6, 9], "memori": [1, 2, 5, 6, 8, 12, 13, 31, 40, 42], "memotec": 9, "meng": [2, 4, 23, 24], "mengyao": 4, "mengzhou": 23, "menopaus": 5, "mensch": 1, "mental": [41, 42], "mentez": 7, "mention": [5, 6, 8, 10, 19, 20, 21, 26, 40, 41, 42], "merg": [1, 5, 6, 17, 41, 42], "merit": [41, 42], "mesnil": 6, "mesomorph": 5, "mess": 5, "messag": [5, 40, 42], "message_consum": 42, "message_publish": 42, "message_queu": 42, "message_templ": [41, 42], "messagerol": [41, 42], "met": 26, "meta": [1, 3, 5, 6, 20, 23, 42], "meta__inn": 42, "metadata": [5, 21, 23, 41, 42], "metadata_extract": 42, "metadata_replac": 42, "metadata_seper": [41, 42], "metadata_str": [41, 42], "metadata_templ": [41, 42], "metadataextraction_llmsurvei": 42, "metadataextractionsec": 42, "metadatareplacementdemo": 42, "metal": 42, "metalindexdemo": 42, "metaphon": 5, "metaphor": 42, "metat": 21, "method": [0, 1, 2, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 22, 23, 25, 31, 40, 42], "methodolog": 24, "methodologi": [5, 6, 26], "meticul": [41, 42], "metric": [0, 7, 21, 23, 42], "metzler": 6, "mha": [14, 22], "mi": 23, "miao": 15, "miaojun": 2, "mice": 13, "michael": [4, 5, 6, 11, 12, 15, 21, 22], "michiel": 1, "micikeviciu": 22, "microservic": 42, "microsoft": [1, 5, 6, 13, 20, 42], "microsoft_onedr": 42, "microsoft_outlook": 42, "microsoft_sharepoint": 42, "mid": [2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 23, 24, 26], "mid1": 12, "mid2": 12, "middl": [1, 5, 12, 21, 22, 24, 41, 42], "might": [1, 2, 5, 6, 8, 9, 13, 14, 20, 21, 23, 24], "migrain": 5, "mike": [1, 8, 11, 12, 14], "mikolov": [6, 9, 10, 13], "mikolovkbck10": 10, "mildew": 5, "mile": [3, 5, 24], "milk": 8, "miller": [5, 23], "million": [1, 5, 6, 7, 9, 12, 13, 17, 21, 26], "millisecond": 5, "milton": 23, "milvu": 42, "milvushybridindexdemo": 42, "milvusindexdemo": 42, "milvusoperatorfunctiondemo": 42, "milvusread": 42, "milvusreaderdemo": 42, "mimetyp": [41, 42], "mimic": [5, 19, 23], "mimick": 8, "min": [1, 5, 6, 14, 24, 26, 31, 40, 42], "min_": [8, 14], "min_dtyp": [31, 40], "min_length": 15, "min_val": 14, "mind": 5, "minder": 12, "mine": [5, 6, 13, 21], "ming": [6, 8, 12, 21], "mingchuan": 2, "mingda": [8, 12], "minghua": 2, "minghui": 2, "mingm": 2, "mingxuan": 4, "minh": 8, "mini": [5, 6, 8, 17, 40, 42], "minibatch": [17, 22], "minigpt4": 42, "minim": [2, 5, 6, 7, 8, 9, 13, 23, 26, 30, 41, 42], "minimind": 27, "minimum": [5, 6, 12, 14, 21, 26, 41, 42], "minio": 42, "minor": 8, "mip": [5, 6], "mir": 6, "mirac": 24, "miracul": [], "mirhoseini": 23, "mirror": 5, "miscellan": 5, "misconcept": [3, 21], "mishkin": [17, 23], "mishra": [18, 24], "mislead": [20, 21], "mismatch": [5, 6, 8, 26], "miss": [5, 6, 8, 13, 21, 41, 42], "mission": [41, 42], "missouri": [5, 6], "misspel": [5, 6], "mistak": [5, 6, 41, 42], "mistakenli": [5, 20], "mistral": 42, "mistral_ag": 42, "mistral_multi_mod": 42, "mistral_r": 42, "mistralai": 42, "mistralai_fine_tun": 42, "mistralr": 42, "mistyp": 5, "misunderstand": 5, "mit": [6, 9], "mit23": 23, "mitchel": 23, "mitig": [1, 2, 3, 5, 6, 10, 12, 14, 15, 18, 21, 22, 23, 26, 41, 42], "mitra": 6, "mitra2016du": 5, "mix": [5, 6, 7, 8, 13, 14, 19, 21, 40], "mixedbread": 42, "mixedbread_rerank": 42, "mixedbreadai": 42, "mixedbreadai_rerank": 42, "mixedbreadairerank": 42, "mixtur": [0, 2, 17, 21, 24, 42], "mixture_of_ag": 42, "mkb": 10, "mkdoc": 42, "mkxs18": 11, "ml": [5, 41, 42], "mla": 2, "mlflow": 42, "mllm": 17, "mlm": [5, 8, 12], "mlp": [4, 5, 6, 17, 31, 32, 40], "mlp_bia": [31, 32, 35, 36, 39, 40], "mlx": [9, 42], "mm": [5, 6], "mm_agent": 42, "mmlm": 8, "mmlu": 3, "mmmu": 3, "mmr": 21, "mna": 22, "mncc16": 6, "mnist": [5, 6], "mnli": [11, 14, 24], "mnt": [], "mobil": [4, 5, 41, 42], "moco": 6, "modal": [5, 6, 17, 21, 41, 42], "mode": [5, 23, 41, 42], "model": [3, 15, 18, 19, 20, 26, 30, 35, 38, 41, 42], "model_config": [32, 34, 35, 36, 37, 38, 39], "model_input": [37, 39], "model_max_length": [37, 39], "model_nam": 32, "model_name_or_path": [37, 39], "model_output": 35, "model_typ": [32, 35, 36], "modelscop": 42, "moder": [2, 42], "modern": [0, 1, 9, 12, 13, 14, 22], "modest": [5, 14], "modi": 20, "modif": [1, 5, 17, 21, 26], "modifi": [5, 6, 7, 9, 11, 12, 13, 21, 23], "modul": [1, 2, 4, 5, 6, 7, 14, 17, 21, 24, 25, 28, 31, 32, 34, 36, 37, 39, 40, 42], "module_guid": 42, "module_usag": 42, "modulelist": [31, 32, 40], "moe": 30, "moham": 11, "mohammad": [4, 8], "mohit": 8, "mold": 5, "molossian": 5, "moment": [5, 11, 26], "momentum": [6, 22, 41, 42], "mon": 23, "mona": 24, "mondaydotcom": 42, "monei": [], "monetari": 13, "mongodb": 42, "mongodb_atlas_bm25_retriev": 42, "mongodb_retrieval_strategi": 42, "mongodbatlasvectorsearch": 42, "mongodbatlasvectorsearchragfirework": 42, "mongodbatlasvectorsearchragopenai": 42, "mongodemo": 42, "mongodocstoredemo": 42, "monitor": [2, 5, 21, 41, 42], "mono": 42, "monobert": [5, 6], "monobertarch": 5, "monolingu": [7, 8], "monolith": 23, "monont": 1, "monoton": [1, 5, 6, 26], "monounsatur": 5, "monster": 42, "monsterapi": 42, "mont": [5, 6], "montana": [5, 6], "month": [5, 6], "monton": 13, "mood": 5, "mor": 26, "morbid": [41, 42], "more": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 40, 41, 42], "moreat": 5, "moreov": [4, 5, 6, 9, 12, 19, 20], "morocco": [41, 42], "morphem": 13, "morpholog": [5, 6, 13], "morphologi": 13, "morron": 24, "mortal": [41, 42], "most": [1, 2, 5, 6, 7, 9, 12, 13, 14, 15, 17, 18, 20, 21, 22, 24, 25, 26, 28, 36, 41, 42], "mostafa": [6, 12, 24], "mostli": [5, 6, 9, 15, 24, 41, 42], "mother": 20, "motiv": [7, 8, 11, 12, 14, 17, 19, 26], "motorist": [5, 6], "mou": 6, "mountain": 4, "mous": 13, "move": [5, 14, 23, 25, 26], "move_to_devic": [37, 39], "movement": [5, 26], "movi": [5, 6, 7, 8, 21, 40], "moz": 15, "mr": 9, "mrpc": 14, "mrr": [6, 21], "msc": [5, 6, 13], "mschutze99": 9, "mse": [5, 8], "msmarco": [5, 6, 28], "mt": 42, "mt_bench_human_judg": 42, "mt_bench_single_grad": 42, "mtp": [], "mu": [1, 5, 6, 25, 26], "mu_": 5, "much": [1, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 21, 22, 23, 24, 25, 26, 31, 32, 40, 42], "multi": [2, 4, 8, 11, 12, 13, 14, 17, 18, 19, 20, 24, 26, 31, 32, 34, 36, 40, 41, 42], "multi_doc_auto_retriev": 42, "multi_doc_together_hybrid": 42, "multi_document_ag": 42, "multi_mod": 42, "multi_modal_llm": 42, "multi_modal_pydant": 42, "multi_modal_rag_evalu": 42, "multi_modal_rag_nom": 42, "multi_modal_rag_system": 42, "multi_modal_retriev": 42, "multi_modal_video_rag": 42, "multi_modal_videorag_videodb": 42, "multi_step": 42, "multi_step_query_engin": 42, "multi_strategy_workflow": 42, "multi_ten": 42, "multi_tenancy_rag": 42, "multiarith": 19, "multiclass": 5, "multicolumn": 5, "multidict": [41, 42], "multidoc": 42, "multidoc_autoretriev": 42, "multihead": [1, 22, 24], "multiheadattent": [8, 12, 34], "multihop": 4, "multilingu": [1, 3, 5, 6, 26], "multimedia": [5, 13], "multimod": [17, 42], "multinomi": 5, "multion": 42, "multipl": [1, 2, 3, 4, 6, 7, 8, 11, 12, 13, 15, 17, 18, 20, 21, 22, 24, 42], "multipli": [1, 2, 5, 6, 9, 10, 12, 14, 15, 22, 26], "multiprocessor": 14, "multirow": 5, "multistageretrievalrankingbert": 5, "multistep": 42, "multitask": [3, 7, 9, 11, 12, 13, 24], "multivari": 6, "murtadha": 1, "muscl": [5, 6], "music": 5, "must": [3, 5, 6, 8, 17, 21, 22, 23, 41, 42], "mutual": [5, 13], "mxc24": 23, "my": [11, 19, 20, 21, 40], "my18": [5, 6], "myaeng": 5, "myle": [8, 12], "mymag": 42, "mypi": [41, 42], "mypy_extens": [41, 42], "myscal": 42, "myscaleindexdemo": 42, "myscalereaderdemo": 42, "mysteri": [], "m\u00f6chte": 12, "n": [1, 2, 3, 7, 8, 10, 12, 13, 14, 15, 17, 19, 20, 23, 24, 25, 26, 27, 34, 35, 36, 40, 41, 42], "n1": [12, 41, 42], "n10": [41, 42], "n12": [41, 42], "n2": [12, 41, 42], "n45": [41, 42], "n45medic": [41, 42], "n529": [41, 42], "nOT": [41, 42], "n_": [1, 5, 6, 8, 9, 13], "n_d": 22, "n_pair_loss": 5, "n_q": [5, 6], "n_r": 2, "n_rep": [31, 32, 40], "n_t": [5, 6], "na": [5, 41, 42], "nabbrevi": [41, 42], "nabh": [41, 42], "nabil": [41, 42], "nabl": [41, 42], "nabla": 26, "nabla_": [23, 26], "naccess": [41, 42], "naccount": [41, 42], "nadapt": [41, 42], "nadav": 6, "nadopt": [41, 42], "nadvanc": [41, 42], "nag": [41, 42], "nagel": 14, "nagement": [41, 42], "nahb": 9, "naidu": 23, "naiv": [6, 13, 20, 22], "najork": 6, "nakamura": 10, "nalisnick": 6, "nall": [41, 42], "nalli": 5, "nalwai": [41, 42], "naman": [8, 11, 12, 21, 23], "name": [1, 4, 5, 6, 8, 9, 12, 17, 20, 21, 23, 26, 28, 41, 42], "nameerror": 28, "namongst": [41, 42], "nan": [4, 8, 22, 24, 41, 42], "nanalog": [41, 42], "nanc": [41, 42], "nand": [41, 42], "nandroid": [41, 42], "nanosecond": 5, "nanswer": [41, 42], "napr": [41, 42], "narang": [6, 11, 18, 22, 24], "narasimhan": [7, 9, 12], "nare": [41, 42], "narea": [41, 42], "narrow": [5, 6, 8, 15, 23, 26], "nassess": [41, 42], "nasti": 5, "nation": [3, 5, 13, 41, 42], "nativ": 42, "natur": [0, 1, 3, 8, 9, 10, 11, 12, 13, 15, 17, 19, 21, 23, 24, 40, 41, 42], "natura": 7, "naudit": [41, 42], "nausea": 5, "nav": 42, "nav__button": 42, "nav__contain": 42, "nav__icon": 42, "nav__item": 42, "nav__link": 42, "nav__list": 42, "nav__titl": 42, "nav__toggl": 42, "navig": [0, 6, 21, 25, 42], "na\u00efv": 5, "nb": 42, "nba": [5, 6], "nbe": [41, 42], "nbecom": [41, 42], "nbesid": [41, 42], "nbetween": [41, 42], "nbsp": [5, 6], "nc19": [5, 6], "ncabl": [41, 42], "ncal": [41, 42], "ncare": [41, 42], "ncasualti": [41, 42], "ncate": [41, 42], "nccl": 22, "nce": 13, "nchanc": [41, 42], "nchina": [41, 42], "nci": [41, 42], "nclinic": [41, 42], "nclinicam": [41, 42], "ncome": [41, 42], "ncommon": [41, 42], "nconnect": [41, 42], "nconsid": [41, 42], "ncours": [41, 42], "ncqa": [41, 42], "ncreatico": [41, 42], "ncredit": [41, 42], "ncumbersom": [41, 42], "ncurrent": [41, 42], "ndaili": [41, 42], "ndard": [41, 42], "ndata": [41, 42], "ndcg": 21, "ndeath": [41, 42], "ndepart": [41, 42], "ndestroi": [41, 42], "ndevelop": [41, 42], "ndigit": [41, 42], "ndirect": [41, 42], "ndischarg": [41, 42], "ndischargeemerg": [41, 42], "ndischargemor": [41, 42], "ndocument": [41, 42], "ndoi": [41, 42], "ne": 7, "neach": [41, 42], "nearbi": [5, 6, 12, 13], "nearest": [13, 14], "nearli": [5, 6, 13, 24], "neas": [41, 42], "nebula": 42, "nebulagraph": 42, "nebulagraph_query_engin": 42, "necess": 21, "necessari": [1, 4, 5, 6, 9, 14, 15, 18, 20, 22, 26, 31, 32, 40, 41, 42], "necessarili": [5, 6, 15], "necessarymeet": 5, "necessit": 21, "need": [0, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 32, 40, 41, 42], "neelakantan": [1, 7, 9, 12], "neg": [1, 4, 8, 9, 15, 17, 19, 21, 23, 26, 40], "negat": 5, "negativesamplingstrategi": 5, "neh": [41, 42], "nei": 9, "neighbor": 13, "neil": 24, "neither": [11, 21, 41, 42], "nelectron": [41, 42], "nemr": [41, 42], "nenabl": [41, 42], "nendless": 40, "neo4j": [41, 42], "neo4j_metadata_filt": 42, "neo4j_query_engin": 42, "neo4jvector": 42, "neo4jvectordemo": 42, "neptun": 42, "neq": [5, 6, 13, 14, 24], "ner": [5, 41, 42], "ner_pii": 42, "neri": [41, 42], "nership": [41, 42], "nespeci": [41, 42], "nest": [21, 41, 42], "nest_asyncio": [41, 42], "net": [5, 22, 42], "nethic": [41, 42], "netowk": 10, "networ": 13, "network": [0, 1, 2, 5, 6, 7, 8, 9, 10, 12, 13, 17, 21, 22, 26, 31, 32, 34, 36, 42], "networkx": [41, 42], "neubig": 8, "neumann": 8, "neural": [0, 1, 2, 6, 8, 9, 12, 13, 15, 17, 22, 23, 26, 30], "neurologist": 5, "neuron": [2, 5, 6], "neutral": [8, 11, 19, 40], "neutrino": 42, "nevada": [5, 6], "nevalu": [41, 42], "neven": [41, 42], "never": [5, 6, 20, 41, 42], "nevertheless": [5, 23], "new": [0, 1, 4, 5, 6, 8, 9, 11, 12, 14, 15, 17, 19, 20, 21, 22, 23, 24, 26, 31, 32, 40, 41, 42], "newest": 5, "newli": [11, 24], "newlin": 9, "newman": 20, "newsi": 5, "nexcel": [41, 42], "nexclud": [41, 42], "nexecut": [41, 42], "nexpect": [41, 42], "next": [1, 3, 5, 7, 9, 10, 12, 14, 15, 20, 21, 22, 23, 24, 25, 26, 42], "next_token_prob": 33, "nextrapol": [41, 42], "nfig": [41, 42], "nfinanci": [41, 42], "nfollow": [41, 42], "nfor": [41, 42], "nform": [41, 42], "nformat": [1, 7, 9, 12, 41, 42], "nformul": [41, 42], "nfour": [41, 42], "nfrom": [41, 42], "ngentli": [41, 42], "ngiven": [41, 42], "ngo": [41, 42], "ngood": [41, 42], "ngram": 5, "ngroup": [41, 42], "ngrow": [41, 42], "nguyen": 6, "nha": [41, 42], "nhealth": [41, 42], "nheavi": [41, 42], "nhi": [41, 42], "nhistor": [41, 42], "nhospit": [41, 42], "nhowev": [41, 42], "ni": [2, 21, 41, 42], "nice": 1, "nichola": [18, 26], "nick": [1, 6, 7, 9, 12], "nicolo": 18, "nidentifi": [41, 42], "nie": [1, 2, 6, 26], "nient": [41, 42], "nikhil": 4, "niki": [6, 12], "nile": 42, "nilevectorstor": 42, "nim": 42, "nimag": [41, 42], "nimport": [41, 42], "nimprov": [41, 42], "nin": [41, 42], "ninadequ": [41, 42], "ninclud": [41, 42], "nincom": [41, 42], "nincreas": [41, 42], "nindia": [41, 42], "nindic": [41, 42], "nindirectli": [41, 42], "nine": 24, "ninfluenc": [41, 42], "ninform": [41, 42], "ning": [2, 41, 42], "niniti": [41, 42], "ninpati": [41, 42], "nintern": [41, 42], "ninvestig": [41, 42], "nip": 6, "niqu": 5, "nirm": 5, "nisan": 23, "nit": [41, 42], "niti": [41, 42], "nitish": 11, "nitrat": 5, "nixon": 5, "nj": 12, "nl": 42, "nl_sql_tabl": 42, "nlayer": 40, "nlegal": [41, 42], "nlegibl": [41, 42], "nlegibli": [41, 42], "nlg": 12, "nli": 24, "nlp": [0, 1, 5, 6, 7, 8, 9, 11, 12, 13, 21, 24, 41, 42], "nltk": [5, 41, 42], "nlu": [12, 15], "nlvr2": 17, "nlz": 18, "nm": 12, "nmai": [41, 42], "nmaintain": [41, 42], "nmana": [41, 42], "nmandat": [41, 42], "nmateri": [41, 42], "nmaterialsclin": [41, 42], "nmedic": [41, 42], "nmedico": [41, 42], "nmember": [41, 42], "nmendou": [41, 42], "nminimum": [41, 42], "nmodel": [41, 42], "nmore": [41, 42], "nmost": [41, 42], "nn": [5, 6, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42], "nnation": [41, 42], "nncoder": [], "nnear": [41, 42], "nnecessarili": [41, 42], "nness": [41, 42], "nnever": [41, 42], "nnew": [41, 42], "nnific": [41, 42], "nnosi": [41, 42], "nnot": [41, 42], "nnurs": [41, 42], "no_grad": [31, 32, 37, 39, 40], "noah": [1, 17, 23, 24], "noam": [1, 2, 6, 11, 12], "node": [2, 5, 20, 21, 22, 41, 42], "node_label_map": [41, 42], "node_pars": [41, 42], "node_parser_semantic_chunk": 42, "node_postprocessor": 42, "nof": [41, 42], "nogueira": [6, 21], "nogueira2020docu": 5, "nois": [1, 5, 6, 8, 11, 17, 21], "noisi": [5, 6, 11, 17, 21, 23], "nomic": 42, "nomin": 9, "non": [1, 4, 8, 9, 12, 13, 14, 15, 20, 21, 24, 26, 41, 42], "nonc": [41, 42], "noncommerci": 5, "none": [5, 6, 28, 31, 32, 36, 37, 39, 40, 41, 42], "nonetheless": 5, "nonexecut": 9, "nonlinear": [8, 12, 14, 24], "nonneg": 5, "nonperform": 8, "nonrelev": [5, 6], "nonsens": 19, "nonsmooth": 1, "nonzero": [2, 5], "noordhui": 26, "nopd": [41, 42], "nopen": [41, 42], "noper": [41, 42], "nor": [41, 42], "nordli": 5, "norganis": [41, 42], "nori": 18, "norigin": [41, 42], "norm": [5, 34, 36], "norm1": 34, "norm2": 34, "norm_x": 34, "normal": [2, 7, 8, 9, 12, 13, 14, 20, 21, 22, 23, 24, 28, 31, 32, 40, 41, 42], "normalis": 5, "norouzi": 8, "north": [5, 6, 41, 42], "norvig": 5, "norwai": 13, "notabl": [5, 8, 12, 13, 14, 24, 25], "notat": [5, 15, 22, 23, 24], "notdiamond": 42, "note": [1, 2, 8, 9, 10, 11, 12, 13, 14, 18, 21, 22, 23, 25, 26, 31, 32, 40, 41, 42], "notebook": 42, "noth": [10, 19, 31, 40], "notic": [5, 6, 7, 41, 42], "notin": [5, 14], "notion": [5, 42], "notiondemo": 42, "notnext": 8, "notsotini": 5, "notwithstand": 5, "nougat": 42, "nougat_ocr": 42, "noun": [5, 6, 9, 13], "nout": [41, 42], "noutpati": [41, 42], "nov": 9, "novel": [0, 1, 2, 5, 7, 8, 12], "novelti": 21, "novic": 5, "now": [1, 5, 6, 7, 9, 12, 13, 14, 15, 19, 20, 21, 22, 25, 26, 41, 42], "nowadai": [5, 6, 21], "nown": [41, 42], "np": [5, 17, 28, 37, 39], "npairloss": 5, "npakistan": [41, 42], "npaper": [41, 42], "nparamed": [41, 42], "npatient": [41, 42], "npersonnel": [41, 42], "nphysic": [41, 42], "npire": [41, 42], "npm": 42, "npmc6220686": [41, 42], "npmc6442402": [41, 42], "npmj": 42, "npoint": [41, 42], "npopular": [41, 42], "npost": [41, 42], "npower": [41, 42], "npre": [41, 42], "npredict": [41, 42], "npresent": [41, 42], "nprocess": [41, 42], "nproduct": [41, 42], "nprofession": [41, 42], "nprogramm": [41, 42], "nprogress": [41, 42], "nproport": [41, 42], "npublic": [41, 42], "nq": 3, "nqualiti": [41, 42], "nqueri": [41, 42], "nr": [5, 6], "nreal": [41, 42], "nrecommend": [41, 42], "nrecord": [41, 42], "nreduc": [41, 42], "nrefer": [41, 42], "nreferencescons": [41, 42], "nrefin": [41, 42], "nreflect": [41, 42], "nregard": [41, 42], "nregion": [41, 42], "nregul": [41, 42], "nreiter": [41, 42], "nrelat": [41, 42], "nrequir": [41, 42], "nresearch": [41, 42], "nresourc": [41, 42], "nrespons": [41, 42], "nreview": [41, 42], "nright": [41, 42], "nrm": 5, "nrr": 5, "nscan": [41, 42], "nshort": [41, 42], "nsi": [41, 42], "nsign": [41, 42], "nsn18": [5, 6], "nsome": [41, 42], "nsp": 12, "nspecimen": [41, 42], "nspectiv": [41, 42], "nstand": [41, 42], "nstatist": [41, 42], "nstatutori": [41, 42], "nstorag": [41, 42], "nstore": [41, 42], "nsuch": [41, 42], "nsultat": [41, 42], "nsuper": [41, 42], "nsurger": [41, 42], "nsystem": [41, 42], "ntain": [41, 42], "ntal": [41, 42], "ntechnologi": [41, 42], "ntem": [41, 42], "nternat": [1, 12, 17], "nthan": [41, 42], "nthat": [41, 42], "nthe": [41, 42], "nthei": [41, 42], "ntheir": [41, 42], "nthere": [41, 42], "nthi": [41, 42], "nthose": [41, 42], "ntice": [41, 42], "ntive": [41, 42], "nto": [41, 42], "ntransfer": [41, 42], "ntranspar": [41, 42], "ntreatment": [41, 42], "ntronic": [41, 42], "nuanc": [1, 5, 12, 13, 21, 26], "nucleu": [5, 6], "nudg": 42, "num": 2, "num_attention_head": [31, 32, 35, 36, 40], "num_epoch": [34, 35, 36, 37, 38, 39], "num_head": [31, 32, 34, 37, 38, 39, 40], "num_hidden_lay": [31, 32, 35, 36, 40], "num_key_value_group": [31, 32, 40], "num_key_value_head": [31, 32, 35, 36, 39, 40], "num_lay": [34, 37, 38, 39], "num_logits_to_keep": [31, 40], "num_output": [41, 42], "num_row": [37, 39], "num_token": 34, "num_work": [34, 35, 36, 37, 38, 39], "number": [0, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 18, 19, 21, 23, 24, 25, 26, 31, 32, 34, 37, 38, 39, 40, 41, 42], "numel": [34, 35, 36, 38], "numer": [4, 5, 6, 9, 13, 14, 21, 23, 31, 32, 40], "numpi": [28, 37, 39, 41, 42], "numref": [], "nundi": [41, 42], "nupdat": [41, 42], "nupload": [41, 42], "nurs": [41, 42], "nuse": [41, 42], "nut": 5, "nutil": [41, 42], "nutrient": 5, "nutrit": [5, 42], "nv": [], "nvalu": [41, 42], "nvascular": [41, 42], "nvice": [41, 42], "nvide": [41, 42], "nvidia": [4, 14, 22, 42], "nvidia_ag": 42, "nvidia_nim": 42, "nvidia_output_pars": 42, "nvidia_rerank": 42, "nvidia_sub_question_query_engin": 42, "nvidia_tensorrt": 42, "nvidia_text_complet": 42, "nvidia_triton": 42, "nvidiarerank": 42, "nvirus": [41, 42], "nw": [41, 42], "nward": [41, 42], "nware": [41, 42], "nwe": [5, 41, 42], "nwell": [41, 42], "nwere": [41, 42], "nwhen": [41, 42], "nwhere": [41, 42], "nwhich": [41, 42], "nwide": [41, 42], "nwith": [41, 42], "nwjo": [41, 42], "nword": [41, 42], "nworkforc": [41, 42], "nycl19": [5, 6], "nylc19": [5, 6, 21], "nzg": [5, 6], "o": [1, 4, 5, 6, 8, 9, 12, 13, 14, 15, 22, 24, 33, 34, 35, 36, 38, 40, 41, 42], "o_": [5, 6, 8], "o_1": 12, "o_bia": [32, 35, 36, 39], "o_m": 12, "o_n": 12, "o_p": 12, "o_proj": [31, 32, 40], "oat": 5, "object": [2, 7, 8, 12, 13, 14, 17, 20, 23, 24, 26, 41, 42], "object_index": 42, "objectbox": 42, "objectboxindexdemo": 42, "observ": [5, 6, 7, 8, 9, 10, 12, 13, 14, 20, 24, 25, 26, 42], "observatori": [41, 42], "obsidian": 42, "obsidianreaderdemo": 42, "obsolet": [5, 20, 21, 25], "obtain": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 21, 22, 23, 25, 31, 32, 40, 41, 42], "obviou": [5, 17, 20], "obvious": 9, "oc": 5, "occasion": 5, "occup": 5, "occupi": [5, 6, 14], "occur": [5, 6, 7, 8, 9, 13, 14, 21], "occurr": [5, 6, 9, 10, 13, 21], "oceanbas": 42, "oceanbasevectorstor": 42, "oci": 42, "oci_genai": 42, "ocr": [17, 21, 42], "octoai": 42, "odd": [1, 5, 12, 23], "odot": [5, 26], "ofdistribut": 23, "ofelia": 8, "off": [2, 5, 6, 15, 20, 21, 24, 28, 42], "offer": [2, 5, 6, 7, 8, 9, 14, 17, 19, 21, 22, 24, 25, 26, 41, 42], "offic": [5, 9, 41, 42], "offici": [5, 6], "offlin": [3, 6, 21, 23], "offset": [1, 5, 6, 8, 11, 14], "ofir": [1, 13], "often": [0, 1, 5, 6, 8, 9, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42], "ofth": [5, 6], "ofword": 5, "oil": [5, 24], "ok": 5, "okai": 19, "okapi": [5, 6], "oklahoma": [5, 6], "olatunji": 22, "old": [9, 20], "older": 5, "oldest": 5, "oleg": 23, "oleksii": 22, "olga": 6, "oliaro": 15, "oliveira": 26, "olivia": 6, "ollama": 42, "ollama_cookbook": 42, "ollama_embed": 42, "ollama_gemma": 42, "ollama_query_engin": 42, "olp": [41, 42], "olymp": 21, "olympu": 23, "omar": 6, "omegaconf": [32, 33, 34, 35, 36, 37, 38, 39], "omer": [6, 8, 11, 12, 13], "omit": [1, 5, 12], "onc": [5, 6, 26, 41, 42], "ondemand": 42, "ondemand_load": 42, "ondemandloadertool": 42, "one": [1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 31, 32, 38, 40, 41, 42], "onedr": 42, "oner": 5, "ones": [0, 5, 6, 9, 13, 20, 21, 23, 31, 32, 34, 40, 41, 42], "onfer": [1, 12, 17], "ongo": [5, 6, 26, 41, 42], "onli": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 21, 22, 24, 26, 31, 32, 40, 41, 42], "onlin": [4, 17, 20, 21, 23, 26], "onogo": 26, "onset": [5, 41, 42], "onto": [5, 13, 24, 41, 42], "onu": [41, 42], "oov": [5, 6, 13], "op": [41, 42], "open": [0, 1, 3, 7, 9, 21, 23, 24, 26, 28, 34, 35, 36, 38, 42], "openai": [0, 1, 7, 9, 11, 12, 23, 37, 39, 40, 41, 42], "openai_ag": 42, "openai_agent_context_retriev": 42, "openai_agent_lengthy_tool": 42, "openai_agent_parallel_function_cal": 42, "openai_agent_query_cookbook": 42, "openai_agent_query_plan": 42, "openai_agent_retriev": 42, "openai_agent_tool_call_pars": 42, "openai_agent_with_query_engin": 42, "openai_api_kei": [40, 41, 42], "openai_assistant_ag": 42, "openai_assistant_query_cookbook": 42, "openai_fine_tun": 42, "openai_fine_tuning_funct": 42, "openai_forced_function_cal": 42, "openai_json_vs_function_cal": 42, "openai_legaci": 42, "openai_lik": 42, "openai_multi_mod": 42, "openai_pydantic_program": 42, "openai_retrieval_benchmark": 42, "openai_sub_quest": 42, "openaiembed": [41, 42], "openalex": 42, "openapi": 42, "openbookqa": 7, "opend": 42, "openehr": [41, 42], "openinfer": 42, "openinferencecallback": 42, "openllm": 42, "openllmetri": 42, "openqa": [5, 6], "openrout": 42, "opensearch": 42, "opensearchdemo": 42, "openvino": 42, "openvino_multimod": 42, "openvino_rerank": 42, "oper": [1, 2, 4, 5, 6, 8, 10, 12, 14, 20, 21, 25, 26, 31, 32, 40, 41, 42], "operative_not": [41, 42], "operatornam": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 21, 23, 24, 26, 31, 32, 40], "opik": 42, "opikcallback": 42, "opinion": 5, "opportun": [2, 10, 41, 42], "opportunti": 21, "oppos": [1, 5, 9], "opposit": [5, 13, 21], "opt": [14, 17], "optic": [9, 21], "optim": [0, 1, 2, 5, 6, 8, 10, 11, 12, 14, 15, 17, 23, 24, 25, 34, 35, 36, 37, 38, 39, 42], "optimis": 23, "optimizerdemo": 42, "optimum": 42, "optimum_intel": 42, "optimumintelllm": 42, "option": [5, 6, 9, 10, 15, 18, 26, 31, 32, 33, 34, 35, 36, 38, 40, 42], "oracl": 42, "oracleai": 42, "oracleai_demo": 42, "oracledb": 42, "oral": [41, 42], "orallamav": 42, "orang": [5, 18], "orchestr": 42, "order": [2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 18, 20, 21, 26, 31, 32, 40, 41, 42], "ordinari": [5, 8], "oreget": 5, "oreilly_course_cookbook": 42, "org": [1, 2, 5, 6, 8, 9, 12, 13, 14, 18, 19, 22, 23, 24, 31, 32, 40, 41, 42], "organ": [5, 6, 9, 12, 14, 20, 21, 41, 42], "orhan": [8, 24], "ori": 6, "orient": [3, 21], "orig": [34, 38], "origin": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 21, 22, 23, 24, 41, 42], "original_inv_freq": [31, 32, 40], "original_max_seq_len": [31, 32, 40], "oriol": [6, 8], "orjson": [41, 42], "orthogon": 5, "oslo": 13, "oss_ingestion_retriev": 42, "ot": [5, 6, 41, 42], "other": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 31, 40, 41, 42], "otherwis": [2, 5, 6, 8, 9, 14, 41, 42], "otim": [1, 14, 31, 32, 40], "ott": [8, 12], "otuput": 12, "ou": [2, 12, 13], "our": [0, 2, 3, 5, 6, 7, 8, 9, 11, 14, 19, 21, 23, 25, 26, 41, 42], "ournal": [2, 11], "out": [1, 4, 5, 6, 7, 8, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 36, 41, 42], "out_vec": 34, "outbound": 5, "outcom": [3, 20, 21, 22, 23], "outcompet": 18, "outdat": 21, "outer": 14, "outlier": 14, "outlin": [5, 23], "outlook": 42, "outnumb": [5, 6], "outpati": [41, 42], "outpatient_record": [41, 42], "outperform": [0, 5, 7, 8, 13, 23], "output": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 34, 35, 36, 40, 41, 42], "output_attent": [31, 40], "output_hidden_st": [31, 40], "output_pars": [41, 42], "outsid": [14, 23], "ouyang": 23, "over": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 20, 21, 24, 26, 31, 32, 36, 40, 41, 42], "overal": [1, 2, 6, 8, 13, 14, 15, 19, 20, 21, 22, 40, 41, 42], "overbear": 5, "overcom": [1, 12, 13, 14, 22, 23], "overestim": 9, "overfit": [8, 9, 12, 23, 24, 26], "overflow": [2, 22], "overgener": 23, "overhead": [1, 5, 6, 14, 31, 32, 40], "overlai": 42, "overlap": [4, 5, 6, 21], "overli": 5, "overlin": 5, "overload": [2, 5], "overoptim": 23, "oversight": [41, 42], "overst": 0, "overview": [8, 20, 21, 41, 42], "overwijk": 6, "owj": 23, "own": [1, 5, 6, 12, 14, 20, 21, 26, 41, 42], "owner": 5, "ownership": [41, 42], "p": [1, 2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "p9124": [41, 42], "p_": [1, 2, 5, 6, 8, 9, 13, 14, 15, 22, 23, 24, 26], "p_0": 15, "p_1": 24, "p_2": 24, "p_i": [2, 5, 15], "p_j": [2, 5], "p_k": 24, "p_l": 24, "p_n": 13, "p_t": 5, "p_v": 24, "p_x": 14, "pa": [7, 8, 41, 42], "pack": [5, 42], "packag": [5, 28, 36, 41, 42], "pact": 5, "pad": [5, 6, 8, 9, 12, 31, 34, 35, 36, 40], "pad_token_id": [31, 32, 34, 35, 36, 39, 40], "padding_idx": [31, 32, 40], "padding_mask": [31, 40], "padmask": [8, 12], "page": [4, 5, 6, 7, 17, 19, 21, 23, 24, 31, 32, 40, 41, 42], "page_label": [41, 42], "page_path": 42, "pagedattent": 14, "pai": [5, 21], "paid": [], "paiea": 42, "pain": 5, "paint": 20, "pair": [1, 3, 8, 10, 12, 13, 17, 21, 23, 24, 26], "pairwis": [4, 17, 23, 42], "pairwise_comparison": 42, "pairwise_ev": 42, "pakistan": [41, 42], "pal": 23, "palett": 42, "palm": [0, 5, 42], "palomaki": 6, "pamela": [17, 23], "pan": [1, 2, 21, 41, 42], "pancrea": [5, 41, 42], "pancreat": 5, "panda": [28, 41, 42], "pandas_ai": 42, "pandas_query_engin": 42, "pandem": [41, 42], "panel": 42, "panel_chatbot": 42, "pang": 6, "panpan": 2, "paper": [1, 4, 6, 7, 9, 12, 17, 23, 24, 26, 31, 32, 40, 41, 42], "paper_medical_record": [41, 42], "paper_record": [41, 42], "paperswithcod": 7, "par": [1, 31, 32, 40], "paradigm": [7, 11, 12, 22, 24, 25], "paraemt": [14, 22], "paragraph": [5, 6, 7, 8, 9, 13, 21], "paragrpah": 21, "paral": 22, "parallel": [1, 5, 8, 12, 14, 17, 26, 42], "parallel_execut": 42, "parallel_execution_ingestion_pipelin": 42, "paralleliz": 12, "param": [1, 24, 42], "param_optim": 42, "paramed": [41, 42], "paramet": [0, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 21, 22, 26, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "parameter": [1, 5, 6, 8, 10, 23, 24], "paramountci": [41, 42], "paramt": 14, "paraphras": [4, 5], "parent": 21, "parenthes": 5, "parfum": 7, "pari": [4, 13, 23], "parikh": 6, "parmar": [6, 12], "pars": [5, 41, 42], "parser": 42, "parsimoni": 5, "part": [0, 5, 6, 7, 8, 9, 11, 12, 14, 17, 20, 21, 22, 23, 24, 26, 28, 31, 34, 40, 41, 42], "parti": [11, 41, 42], "partial": [5, 6, 9, 14, 20, 33, 34, 35, 36, 37, 39], "particip": [5, 6, 41, 42], "participl": 13, "particular": [1, 2, 5, 6, 8, 18, 19, 21, 23, 26, 41, 42], "particularli": [1, 4, 5, 6, 11, 12, 14, 15, 18, 21, 23, 24, 25, 26, 40], "partit": [2, 5, 6, 22, 23], "pascal": 10, "pass": [4, 5, 6, 7, 8, 12, 14, 15, 17, 22, 23, 36], "passag": [3, 4, 12, 20, 21, 41, 42], "passage2queri": 5, "passagequeri": 5, "passio": 42, "passio_nutrition_ai": 42, "passiv": 5, "password": [41, 42], "past": [1, 5, 9, 13, 14, 21, 31, 40, 41, 42], "past_key_valu": [31, 40], "past_present": 42, "patch": 5, "patent": 7, "patentsview": 42, "path": [18, 20, 34, 35, 36, 38, 41, 42], "pathnam": 42, "pathwai": 42, "pathway_retriev": 42, "pathwayreaderdemo": 42, "patient": [41, 42], "patient_clinical_data": [41, 42], "patient_demographic_data": [41, 42], "patient_inform": [41, 42], "patil": 21, "patit": 22, "patrick": [6, 12], "pattern": [1, 2, 5, 6, 9, 10, 12, 15, 21, 23, 41, 42], "pauciti": [41, 42], "paul": [6, 23], "paul_graham": [], "paul_graham_essai": [], "pauliu": 22, "pave": [5, 6], "pavillion": 5, "payal": 8, "paz": 26, "pca": 13, "pd": 28, "pdate": 24, "pdb": 42, "pdf": [5, 7, 9, 12, 21, 23, 31, 32, 40, 41, 42], "pdf_marker": 42, "pdf_path": [41, 42], "pdf_tabl": 42, "pe": [1, 8, 12], "peac": 5, "peak": [5, 6], "pear": 13, "pebblo": 42, "peer": [41, 42], "peft": [21, 26], "pegasu": 12, "pei": [2, 12], "peilin": 6, "peiyi": 2, "peiyu": [1, 26], "pellat": 24, "penal": [2, 5, 15, 21, 23, 26], "penalti": [5, 15, 23], "peng": [2, 12, 15, 21], "pengji": 4, "penguin": 8, "penn": [7, 9], "pennington2014glov": 13, "penntre": 9, "peopl": [3, 5, 9, 21], "per": [3, 5, 6, 8, 12, 22, 41, 42], "per_token_logp": 35, "perceiv": [5, 6, 17, 25, 41, 42], "percentag": [8, 21], "percept": 21, "perci": 24, "pereira": 5, "perfect": [5, 6, 21, 23], "perfectli": 21, "perform": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "perfum": 7, "perhap": [5, 41, 42], "period": [1, 41, 42], "perk": 9, "perman": [5, 42], "permiss": [41, 42], "permit": [5, 41, 42], "permut": [5, 11, 12, 31, 32, 40], "perplex": [0, 3, 7, 24, 42], "persist": [31, 32, 40, 41, 42], "persist_dir": [41, 42], "person": [21, 41, 42], "persona": 3, "personnel": [41, 42], "perspect": [1, 3, 4, 6, 9, 13, 14, 15, 20, 21, 23, 24], "perspectiveapi": 3, "perus": [41, 42], "pet": 24, "peter": [6, 8, 11, 23], "petrov": 24, "pgvecto": 42, "pgvecto_r": 42, "pgvector": 42, "pgvector_sql": 42, "pgvector_sql_query_engin": 42, "pgvectorsdemo": 42, "pharmaci": [41, 42], "pharmacist": 5, "phase": [5, 6, 7, 9, 11, 13, 21, 24, 26], "phd": [], "phenomena": 5, "phenomenon": [8, 13, 14, 23], "phenomonon": 23, "phi": [5, 23, 24], "phi_": 5, "phi_0": 24, "phil": 8, "philadelphia": 8, "philip": 6, "phillip": [6, 24], "philz": 20, "phoenix": 42, "phone": [4, 5, 41, 42], "phonet": 5, "photo": [5, 17, 41, 42], "photograph": [41, 42], "phrase": [4, 6, 9, 13, 17, 21, 24], "physic": [3, 5, 7, 9, 18, 25, 26], "pi": [1, 5, 6, 12, 23, 25], "pi_": [23, 25], "pi_logratio": 35, "pi_r": 23, "piao": 2, "pick": [5, 6, 12, 13], "pictur": [17, 41, 42], "piec": [4, 5, 8, 20, 21, 40], "pierr": [1, 9], "pieter": 26, "pigeon": 11, "pii": 42, "pile": 1, "pileup": [5, 6], "pilferag": [41, 42], "pill": 5, "pillow": [41, 42], "pilot": 5, "pin": [41, 42], "pinecon": 42, "pinecone_auto_retriev": 42, "pinecone_existing_data": 42, "pinecone_metadata_filt": 42, "pineconedemo": 42, "pineconeindexdemo": 42, "ping": [4, 6], "pink": 5, "pinpoint": 4, "pinto": 26, "pioneer": [0, 2, 5, 6, 23], "piotr": [13, 26], "pip": [41, 42], "pipelin": [4, 21, 22, 23, 26, 42], "pipeshift": 42, "piqa": [3, 7], "pit": 5, "pivot": [41, 42], "pixtral": 42, "piyush": [8, 12], "pizza": 5, "pkd": 23, "place": [5, 6, 12, 23, 24, 31, 40, 42], "placehold": [41, 42], "plai": [1, 3, 4, 5, 6, 8, 12, 13, 21, 23, 25, 26, 41, 42], "plain": [5, 41, 42], "plan": [3, 20, 41, 42], "plane": 13, "planet": 23, "planning_workflow": 42, "plant": 5, "plastic": 5, "plateau": [5, 6, 7], "platform": [5, 26, 41, 42], "platitud": 5, "plausibl": [1, 5, 21], "playground": 42, "playwright": 3, "plc": 9, "plcae": [31, 40], "pleas": 5, "plm": 24, "plot": [19, 40], "plt": 28, "plu": [5, 6, 7, 8, 11, 12, 14, 17, 19, 20, 21, 23, 31, 32, 36, 40, 42], "plug": 4, "plugin": 42, "plural": [9, 13], "pmcid": [41, 42], "pmi": 13, "pmid": [41, 42], "pmlr": [1, 4, 6, 8, 12, 15, 17, 23], "png": [28, 42], "pni": 8, "po": [6, 8], "poet": 3, "point": [1, 8, 12, 14, 21, 22, 23, 24, 25, 41, 42], "pointwis": [1, 13, 22], "poli": [5, 6], "polic": [41, 42], "polici": [35, 41, 42], "policy_chosen_logp": 35, "policy_evalu": 25, "policy_improv": 25, "policy_rejected_logp": 35, "policy_t": 25, "policyst": 25, "polit": [5, 23], "polo": 5, "polosukhin": [6, 12], "polysem": 5, "polysemi": [5, 6, 13], "polyunsatur": 5, "ponc": 4, "pond": 26, "pont": 5, "pool": [4, 5, 6, 14, 17, 24], "poor": [5, 6, 10, 13, 21, 23, 41, 42], "poorli": [5, 6, 9, 20, 23], "popul": [4, 23, 41, 42], "popular": [3, 4, 8, 9, 12, 13, 14, 24, 26, 42], "pormpt": 19, "portabl": [41, 42], "portion": [8, 12, 14, 22], "portit": 26, "portkei": 42, "pos_emb": 34, "pos_embed": 34, "poscia": [41, 42], "pose": [3, 5, 6, 13, 14], "posit": [2, 7, 8, 11, 13, 14, 17, 18, 19, 21, 24, 25, 26, 31, 32, 34, 36, 40, 42], "position_embed": [31, 32, 40], "position_id": [31, 32, 40], "position_ids_expand": [31, 32, 40], "posot": 5, "possess": [5, 24, 41, 42], "possibl": [0, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21, 22, 24], "possibli": [5, 13, 21], "post": [1, 5, 7, 12, 14, 26, 41, 42], "post1": [41, 42], "post3": [41, 42], "post_attention_layernorm": [31, 32, 40], "post_init": [31, 40], "poster": [41, 42], "posterior": [5, 6], "postgr": 42, "postgresml": 42, "postgresmldemo": 42, "postgresql": 42, "posthog": 42, "postnorm": 1, "postprocessor": 42, "potenti": [0, 1, 3, 4, 5, 6, 12, 14, 17, 19, 20, 21, 22, 24, 41, 42], "pound": 5, "pour": 7, "pow": [31, 32, 40], "power": [0, 1, 2, 5, 6, 8, 12, 14, 17, 21, 24, 41, 42], "ppl": 11, "pr": 23, "prabhakar": 6, "prac": [41, 42], "practic": [0, 1, 2, 6, 8, 13, 14, 15, 22, 24, 26, 41, 42], "practis": 22, "practition": [41, 42], "prafulla": [1, 7, 9, 12, 23, 26], "prais": 5, "prajit": 1, "pranav": [1, 7, 9, 12], "prank": 5, "pre": [1, 4, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 21, 23, 24, 26, 31, 32, 34, 40, 42], "preced": [1, 7, 8, 9, 10, 11, 12, 14, 15, 17, 20, 21, 26], "precis": [1, 2, 4, 9, 14, 19, 20, 21], "preconnect": 42, "pred": [5, 8], "predecessor": [0, 2], "predefin": [5, 6, 21, 42], "predibas": 42, "predic": 20, "prediciton": [31, 32, 36, 40], "predict": [0, 1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 23, 24, 31, 32, 33, 36, 40, 41, 42], "predictor": [5, 23, 42], "predominantli": 26, "prefer": [5, 6, 21, 24, 26, 30, 42], "preference_loss": 35, "prefil": 14, "prefix": [5, 11, 13, 17], "preganc": 21, "pregnanc": 21, "pregnant": 21, "premai": 42, "premis": [7, 8, 11], "prenorm": 1, "preoper": [41, 42], "prepar": [5, 6, 21, 41, 42], "prepend": [5, 6, 24], "preprint": [1, 2, 4, 6, 8, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26], "preprocess": [9, 11, 17, 18, 21, 42], "preprocessreaderdemo": 42, "prescript": [41, 42], "presenc": [5, 6, 26], "present": [1, 2, 4, 5, 6, 7, 8, 13, 19, 21, 26, 31, 32, 34, 36, 42], "present_key_valu": [31, 40], "preserv": [5, 12, 13, 14, 21, 24], "presid": [4, 5, 41, 42], "presidio": 42, "presoftmax": 1, "press": [1, 6, 9, 13], "pressur": [5, 18, 21], "pretain": 8, "pretrain": [2, 5, 6, 15, 19, 21, 23, 24, 30, 34], "pretrained_model_nam": [35, 36], "pretti": [5, 20, 31, 40], "prev": 42, "prev_next": 42, "prevent": [12, 14, 15, 17, 23, 26, 31, 40, 41, 42], "preventdefault": 42, "prevers": 1, "previou": [1, 5, 6, 10, 12, 13, 14, 21, 22, 23, 24, 31, 32, 36, 37, 38, 39, 40, 41, 42], "previous": [0, 5, 11, 12, 14, 19, 21, 26], "prevnextpostprocessordemo": 42, "prf": 5, "prfarch": 5, "price": 4, "primari": [5, 6, 12, 24, 26, 42], "primarili": [1, 5, 6, 7, 23], "prime": [1, 2, 3, 5, 6, 8, 9, 13, 25], "princip": [2, 13], "principl": [0, 3, 9, 10, 14, 15, 18, 21, 25], "print": [19, 23, 28, 34, 35, 36, 37, 38, 39, 40, 41, 42], "print_formatted_respons": 40, "print_response_stream": [41, 42], "printbibliographi": 5, "prior": [5, 6, 7, 8, 9, 22, 24, 41, 42], "priori": 5, "priorit": 21, "privaci": [3, 41, 42], "privat": [21, 24, 41, 42], "priviat": 21, "priya": 26, "pro": [5, 6, 8, 14, 24, 41, 42], "prob": [5, 12], "probabilist": [6, 7, 9, 10, 15], "probabilti": 15, "probabl": [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 15, 21, 23, 25, 26, 33, 35], "probe": 7, "probirsec": 5, "problem": [1, 2, 3, 6, 8, 11, 14, 15, 18, 19, 20, 21, 22, 25, 26, 42], "problemat": [5, 6, 9, 23], "proc": [41, 42], "proce": [5, 14], "procedur": [5, 6, 8, 11, 12, 25, 41, 42], "proceed": [4, 6, 12, 13, 14, 21], "process": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 24, 26, 31, 37, 39, 40, 41, 42], "procur": [41, 42], "prod_": [5, 9, 15, 23, 24], "produc": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 40], "product": [1, 2, 8, 12, 14, 15, 21, 22, 31, 32, 40, 42], "production_rag": 42, "profession": [0, 5, 8, 21, 41, 42], "profil": [5, 41, 42], "profit": [41, 42], "profound": [0, 5, 6, 7], "program": [3, 5, 20, 21, 25, 40, 41, 42], "progress": [5, 6, 17, 23, 24, 41, 42], "progress_sheet": [41, 42], "prohibit": [5, 6, 8, 25, 26], "proj": [17, 41, 42], "projeciton": 24, "project": [1, 2, 5, 6, 8, 10, 11, 13, 14, 17, 22, 24, 26, 31, 32, 40, 42], "projector": 13, "projet": [31, 32, 40], "prometheu": 42, "prometheus2_cookbook": 42, "prometheus_evalu": 42, "promin": 12, "promis": [0, 21, 23], "promot": [2, 5, 8, 21, 41, 42], "prompt": [0, 1, 3, 4, 7, 12, 17, 20, 23, 26, 33, 42], "prompt_mixin": 42, "prompt_optim": 42, "prompt_typ": [41, 42], "prompt_with_complet": [34, 35, 36], "promptag": 21, "promptlay": 42, "promptlayerhandl": 42, "prompts_dict": [41, 42], "prompts_rag": 42, "prompttempl": [41, 42], "prompttyp": [41, 42], "prone": 20, "pronoun": 21, "pronounc": 24, "pronunci": 5, "proof": [5, 25], "propag": [1, 21], "propcach": [41, 42], "proper": [5, 6, 8, 41, 42], "properit": 1, "properli": [9, 21, 23, 24], "properti": [5, 6, 8, 12, 42], "property_graph": 42, "property_graph_advanc": 42, "property_graph_bas": 42, "property_graph_custom_retriev": 42, "property_graph_neo4j": 42, "propog": 1, "proport": [5, 6, 8, 9, 13, 26, 41, 42], "proportion": 5, "propos": [1, 4, 5, 6, 8, 10, 11, 13, 17, 18, 20, 21, 23, 24, 31, 32, 40, 41, 42], "proposit": 8, "proprieti": [], "propto": 5, "prospect": [41, 42], "protect": [5, 41, 42], "protein": 5, "prototyp": [5, 42], "prove": [1, 5, 6, 10, 41, 42], "proven": [0, 5], "provid": [0, 1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 40, 41, 42], "provision": [41, 42], "proxi": [4, 6, 23], "proxim": [5, 23], "pseudo": 9, "pseudoqueryembed": 5, "pseudorelev": 5, "psi": [5, 22], "psi_": [5, 6], "psl22": 1, "psychic": 42, "psychicdemo": 42, "pt": [34, 35, 36], "ptb": [5, 6, 9], "pth": [34, 37, 38, 39], "ptq": 14, "ptx": 23, "pub": [41, 42], "public": [1, 21, 26, 41, 42], "publicli": [17, 41, 42], "publish": [5, 6, 8, 9, 12, 41, 42], "puesedo": 6, "pull": [5, 6, 13], "puma": 5, "pump": 5, "punctuat": [5, 6, 8, 9], "punish": 5, "punk": 5, "punt": 9, "puppiesth": 5, "puppyhood": 5, "pure": [2, 5], "purpl": 42, "purpos": [5, 6, 8, 11, 17, 18, 19, 21, 26], "pursuant": [41, 42], "pursuit": [0, 5], "purview": [41, 42], "push": [0, 5, 6, 11, 13, 42], "put": [5, 6, 13, 21, 23, 42], "putting_it_all_togeth": 42, "puzzl": 1, "pw16": 13, "pxid": 42, "py": [28, 36], "py2": [41, 42], "py3": [41, 42], "pydant": [41, 42], "pydantic_cor": [41, 42], "pydantic_program": 42, "pydantic_query_engin": 42, "pydantic_tree_summar": 42, "pydanticextractor": 42, "pypars": [41, 42], "pypdf": [41, 42], "pypdf2": [41, 42], "pypi": 42, "pyplot": 28, "pythagorean": 42, "python": [3, 5, 6, 19, 21, 27, 36, 41, 42], "python3": 28, "python_fil": 42, "python_sdk": 42, "pytorch_latest": [36, 41, 42], "pytz": [41, 42], "pyyaml": [41, 42], "q": [1, 2, 4, 5, 6, 7, 12, 14, 17, 21, 22, 23, 24, 26, 28, 31, 32, 40, 41, 42], "q_": [6, 14, 25], "q_0": 24, "q_1": [5, 6], "q_and_a": 42, "q_emb": [31, 32, 40], "q_i": [1, 5, 6], "q_ik": 1, "q_j": 5, "q_l": [5, 6], "q_len": [31, 32, 40], "q_m": [1, 5, 6], "q_max": 14, "q_n": [5, 6], "q_proj": [31, 32, 40], "q_t": 5, "qa": [5, 6, 11, 17, 21, 24, 42], "qat": 14, "qdl": [5, 6], "qdrant": 42, "qdrant_bm42": 42, "qdrant_hybrid": 42, "qdrant_metadata_filt": 42, "qdrant_using_qdrant_filt": 42, "qdrantdemo": 42, "qdrantindexdemo": 42, "qi": [8, 20], "qiancheng": 2, "qianfan": 42, "qianhui": 14, "qianwen": 21, "qianyu": 21, "qid": 5, "qihao": 2, "qime": 26, "qin": [6, 8, 24], "qing": 15, "qingyang": 17, "qingyao": 6, "qinyu": 2, "qiu": [1, 2, 6, 14, 21], "qiu2020pretrain": 8, "qiushi": 2, "qk": 1, "qkv": 1, "qkv_bia": [32, 34, 35, 36, 37, 38, 39], "qnli": 14, "qp": 5, "qq": 14, "qqp": 14, "qrel": 28, "qrw": 5, "qsx": 8, "qtr": [5, 6], "qu": [2, 6], "quac": 3, "quad": [1, 5, 6, 14, 20, 23, 25], "quadrant": 21, "quadrat": [1, 12, 22], "qualiti": [1, 2, 3, 4, 5, 6, 7, 9, 13, 15, 17, 18, 19, 20, 22, 24, 25, 26, 40, 41, 42], "quan": 6, "quandari": [41, 42], "quantat": 14, "quantifi": 5, "quantiti": [5, 6, 7, 9, 17, 22, 23], "quarter": 5, "quebec": 9, "queen": 5, "quel": 7, "quelqu": 7, "quentin": 24, "queri": [0, 2, 3, 8, 12, 14, 17, 20, 22, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42], "querstion": 21, "query2doc": 4, "query_dict": 28, "query_engin": [41, 42], "query_fus": 42, "query_len": 28, "query_length": [31, 40], "query_length_ms_marco": 28, "query_pipelin": 42, "query_pipeline_ag": 42, "query_pipeline_async": 42, "query_pipeline_memori": 42, "query_pipeline_panda": 42, "query_pipeline_rout": 42, "query_pipeline_sql": 42, "query_plan": 42, "query_respons": 42, "query_sequence_length": [31, 40], "query_st": [31, 32, 40], "query_str": [41, 42], "query_transform": 42, "query_transform_cookbook": 42, "query_understanding_ag": 42, "query_word_cloud": 28, "querydocu": 5, "queryengin": 42, "queryexpansionarch": 5, "querylengthdoclengthmsmarco": 5, "queryselector": 42, "queryselectoral": 42, "quesion": 20, "question": [0, 1, 3, 4, 8, 11, 12, 13, 17, 18, 19, 20, 21, 23, 24, 26, 40, 41, 42], "question_answ": [41, 42], "question_gen": 42, "questiongener": 42, "queue": 6, "quick": [5, 19], "quickli": [5, 6, 7, 21, 26, 42], "quickstart": 42, "quietli": 5, "quip": 42, "quirk": 5, "quit": [5, 6, 7, 8, 13, 41, 42], "quiz": 3, "qun": 8, "quoc": [1, 8, 18, 19, 24], "quora": [5, 6], "quot": [5, 42], "qw": [1, 12], "qw_i": 12, "qwen": [1, 32, 34, 35, 36, 42], "qwen2": [22, 24, 32, 34, 35, 36], "r": [1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 20, 21, 23, 25, 26, 31, 34, 35, 36, 38, 40, 41, 42], "r1": 24, "r1000": 5, "r2": [24, 42], "r200": 5, "r50": 5, "r_": [5, 6, 23, 25], "r_0": [5, 6, 23], "r_1": [4, 5], "r_2": 5, "r_i": [4, 5], "r_j": 4, "r_l": 23, "r_m": 4, "r_n": [5, 6], "r_q": [5, 6], "r_t": 25, "ra": [41, 42], "rabbitmq": 42, "race": [0, 3], "racial": 3, "radford": [7, 9, 11, 12, 17, 23, 26], "radio": [41, 42], "radiologi": [41, 42], "radiu": 5, "radlinski": 6, "radu": [8, 12], "rae": 15, "rafael": 23, "rafailov": 23, "raffel": [4, 6, 11], "raft": 42, "raft_dataset": 42, "rag": [0, 26, 40, 42], "rag_ag": 42, "rag_cli": 42, "rag_cli_loc": 42, "rag_evalu": 42, "rag_fusion_query_pipelin": 42, "rag_learn": [], "ragatouil": 42, "ragatouille_retriev": 42, "ragcheck": [21, 42], "ragdataset_submission_templ": 42, "raghavan": 6, "rag\u4e0d\u4ec5\u5173\u6ce8\u68c0\u7d22\u7684\u51c6\u786e\u6027": [], "rag\u7684\u4f18\u52bf\u5728\u4e8e\u5176\u80fd\u591f\u6309\u9700\u68c0\u7d22": [], "rag\u8fd8\u901a\u8fc7\u5f15\u5165\u53cd\u601dtoken\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u63a7\u6027": [], "rag\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5b9e\u73b0": [], "rai": 23, "rail": 42, "raiman": 4, "rain": [5, 6], "rais": [0, 5], "rajarshi": 4, "rajbhandari": 22, "rake": 9, "ralph": 23, "ram": [4, 6], "ramachandran": 1, "ramamurthi": 6, "ramelson": [41, 42], "ramesh": 17, "ramet": [41, 42], "rami": [17, 24], "ramprasath": 15, "random": [8, 9, 11, 24, 25, 26], "randomli": [5, 6, 8, 11, 12, 15, 25], "rang": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 22, 23, 24, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42], "rangan": 6, "rangl": [1, 5, 6, 19, 23], "rank": [8, 13, 14, 17, 20, 21, 22, 23, 30, 41, 42], "rank0": 22, "ranker": 21, "rankgpt": 42, "rankgpt_rerank": 42, "rankllm": 42, "rankllm_rerank": 42, "ranknet": [4, 6], "rap": 42, "raphael": 6, "rapid": [5, 6, 7, 13], "rapidli": [5, 13], "raptor": 42, "rare": [1, 5, 6, 8, 10, 13, 14, 15, 21, 26], "rasbt": [34, 38], "raslei": 22, "raspberri": 5, "rate": [1, 5, 6, 8, 18, 21, 25, 34, 37, 38, 39, 41, 42], "rategi": 5, "rather": [1, 4, 5, 6, 7, 8, 12, 13, 14, 19, 21], "rathnayak": [41, 42], "ratio": [5, 6, 9, 12, 13, 22, 23, 24, 26], "rational": [4, 5, 6, 8, 18, 21], "raw": [1, 5, 6, 8, 20, 21, 34, 35, 36, 37, 38, 39], "raw_dataset": [37, 39], "raxa": [41, 42], "rayyan": 42, "rbf": 5, "rc": 28, "rceil": [5, 14], "re": [0, 1, 4, 6, 9, 10, 13, 14, 18, 21, 23, 26, 31, 32, 40, 41, 42], "reach": [1, 5, 6, 7, 8, 15, 18, 21, 25], "react": 42, "react_ag": 42, "react_agent_finetun": 42, "react_agent_with_query_engin": 42, "reaction": [5, 6], "read": [5, 6, 7, 8, 13, 14, 25, 34, 35, 36, 38, 42], "read_text_data": [34, 35, 36, 38], "reader": [4, 5, 6, 41, 42], "readi": 8, "readili": 21, "readm": 42, "readthedoc": 42, "readwis": 42, "real": [0, 5, 6, 8, 9, 21, 23, 24, 25, 41, 42], "realist": [5, 7, 12], "realiz": [2, 5, 6, 8, 13, 20, 25, 26], "realli": [5, 20], "realtim": 21, "realtimedb": 42, "realtoxicityprompt": 3, "reaons": 21, "reason": [1, 4, 5, 6, 8, 9, 12, 14, 15, 17, 18, 19, 20, 23, 24, 26, 36, 42], "reasongin": 1, "recal": [4, 10, 21, 25, 42], "recalcul": [14, 22], "receiv": [2, 5, 6, 13, 22, 25, 41, 42], "recenc": 42, "recencypostprocessordemo": 42, "recent": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 24, 28, 36, 41, 42], "recip": 5, "reciproc": [6, 42], "reciprocal_rerank_fus": 42, "recis": 22, "recogn": [5, 12, 21, 41, 42], "recognit": [5, 8, 9, 12, 17, 21], "recommend": [12, 24, 41, 42], "recomposit": 20, "recomput": 14, "reconcil": [5, 6], "reconstruct": [5, 6, 11, 12], "record": [5, 6, 21, 37, 39, 41, 42], "record_list": [37, 39], "recov": [1, 5, 11], "recruit": [41, 42], "rectifi": 5, "recurisve_retriever_nodes_braintrust": 42, "recurs": [40, 42], "recursive_retriev": 42, "recursive_retriever_ag": 42, "recursive_retriever_nod": 42, "red": 5, "reddit": [1, 26, 42], "redefin": 0, "redfield": 6, "redi": 42, "redis_ingestion_pipelin": 42, "redisdocstoreindexstoredemo": 42, "redisindexdemo": 42, "redistribut": 9, "redo": 22, "redpajama": 26, "reduc": [1, 2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 26, 31, 32, 40, 41, 42], "reduced_error": [41, 42], "reducescatt": 22, "reduct": [1, 5, 6, 8, 14, 18, 22, 37, 39], "redund": [2, 14, 21, 22], "ref": [23, 34, 35, 36], "ref_logratio": 35, "ref_model": 35, "refe": 4, "refer": [1, 3, 5, 6, 8, 13, 14, 15, 17, 21, 22, 23, 24, 41, 42], "reference_chosen_logp": 35, "reference_fre": 35, "reference_output": 35, "reference_rejected_logp": 35, "referr": [41, 42], "referrerpolici": 42, "refin": [4, 5, 6, 7, 20, 21, 41, 42], "refine_templ": [41, 42], "refinedweb": 26, "reflect": [5, 9, 13, 23, 41, 42], "reformul": [5, 21], "refresh": [6, 21], "refsect": 5, "refus": [21, 40], "reg": 13, "regard": [3, 5, 7, 12, 21, 24, 41, 42], "regardless": [2, 5, 6, 18], "regatta": 9, "regex": [41, 42], "region": [6, 26, 41, 42], "register_buff": [31, 32, 34, 40], "regress": [7, 11, 12, 13, 26], "regul": [5, 6, 21, 41, 42], "regular": [1, 5, 6, 8, 12, 13, 14, 23, 24, 26, 41, 42], "regularli": [41, 42], "regulatori": 21, "reid": 19, "reimer": 5, "reinforc": [19, 30], "reival": 5, "reject": [20, 21, 23], "rejected_logp": 35, "rejected_reward": 35, "reka": 42, "rel": [1, 5, 6, 7, 13, 14, 18, 21, 26, 41, 42], "rel_": 5, "rel_q": [5, 6], "relat": [0, 1, 3, 4, 5, 6, 8, 9, 11, 13, 15, 20, 21, 22, 23, 24, 26, 41, 42], "related": 5, "related_to": [41, 42], "relationship": [1, 4, 5, 6, 8, 10, 11, 12, 17, 20, 26, 41, 42], "relative_score_dist_fus": 42, "relax": 6, "relearn": 5, "releas": [5, 6], "relev": [2, 3, 4, 6, 7, 8, 13, 17, 18, 20, 21, 40, 41, 42], "relevancy_ev": 42, "reli": [1, 2, 5, 6, 8, 12, 19, 21, 23, 24, 25], "reliabl": [1, 4, 5, 9, 20, 21, 24, 26], "relianc": 5, "religion": 3, "relik": 42, "reload": 39, "reload_ext": 39, "relu": [1, 5, 12, 14], "relyt": 42, "relytdemo": 42, "remain": [1, 2, 5, 6, 7, 9, 12, 14, 18, 23, 24, 26, 41, 42], "remark": [0, 1, 2, 5], "remedi": [5, 9, 26], "rememb": 5, "reminisc": 8, "remot": [41, 42], "remote_depth": 42, "remov": [4, 5, 6, 8, 9, 11, 14, 17, 21, 23, 24], "remove_column": [37, 39], "ren": [1, 2, 4, 6, 26], "renaiss": 20, "renard": 1, "renji": 8, "rent": [], "renz": [17, 24], "reorder": [21, 42], "rep": 5, "repeat": [1, 5, 15, 25, 26, 31, 32, 36, 40, 41, 42], "repeat_interleav": [31, 32, 40], "repeat_kv": [31, 32, 40], "repel": [5, 6], "repetit": [5, 6, 15], "repl": 42, "repl4nlp": 6, "replac": [5, 6, 8, 9, 11, 17, 23, 41, 42], "repli": 17, "replic": [5, 42], "replicate_multi_mod": 42, "repo": 42, "repond": [], "repons": [23, 24], "report": [1, 2, 5, 6, 9, 22, 41, 42], "repositori": [41, 42], "repres": [0, 1, 4, 5, 6, 8, 9, 10, 12, 13, 14, 18, 20, 21, 22, 23, 24, 25, 26], "represen": 5, "represent": [1, 4, 7, 8, 10, 11, 12, 13, 14, 17, 21, 22, 23, 24, 26, 42], "representationss": 13, "reprocess": 14, "reproduc": [5, 6], "reproduct": [5, 6, 41, 42], "repurpos": 2, "request": [5, 6, 14, 21, 22, 23, 34, 35, 36, 38, 41, 42], "requests_toolbelt": [41, 42], "requir": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 31, 40, 41, 42], "rerank": [4, 5, 6, 42], "rescal": [1, 5, 12, 15], "research": [0, 2, 5, 6, 8, 10, 11, 12, 13, 14, 17, 20, 21, 22, 26, 41, 42], "researchcov": [7, 9, 12], "resembl": [5, 6, 8, 17], "reserv": [14, 22], "reset": 8, "reshap": [0, 5, 6, 31, 32, 40], "resid": [1, 5, 14, 21, 41, 42], "residu": [1, 5, 12, 22, 31, 32, 40], "resil": [41, 42], "resnet": 17, "resnetd": 17, "resolv": [5, 21, 42], "resourc": [0, 2, 5, 8, 20, 21, 22, 24, 26, 41, 42], "respect": [3, 5, 6, 8, 12, 13, 14, 21, 22, 23, 24, 25], "respond": [1, 5, 19, 21, 25], "respons": [1, 2, 3, 4, 5, 6, 15, 17, 18, 19, 20, 21, 25, 26, 34, 35, 36, 38, 40, 41, 42], "response_graph_rag": [41, 42], "response_mod": [41, 42], "response_synthes": [41, 42], "response_synthesi": 42, "response_vector_rag": [41, 42], "rest": [5, 6, 9, 11, 14, 22], "restaur": [4, 5, 6], "restaurat": [5, 6], "restera": 7, "restor": [8, 21], "restrict": [1, 5, 6, 12, 19, 42], "result": [1, 2, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 26, 33, 41, 42], "result_dict": [37, 39], "resum": 42, "resume_screen": 42, "ret": 5, "retain": [1, 2, 5, 6, 9, 12, 21, 22, 24, 31, 32, 40, 41, 42], "retain_graph": 36, "retent": [41, 42], "retrain": [8, 14, 19, 21, 23, 41, 42], "retreiv": 5, "retri": 42, "retriev": [0, 7, 8, 17, 18, 40, 41, 42], "retrievalrerankingtask": 5, "retrievel": 4, "retriever_ev": 42, "retriever_mod": [41, 42], "retriever_rout": 42, "retrieverankingarch": 5, "retrieverrouterqueryengin": 42, "retro": [41, 42], "retrospect": [41, 42], "retry_engine_weavi": 42, "retry_polici": 42, "retryqueri": 42, "return": [0, 1, 3, 5, 6, 19, 21, 25, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "return_dict": [31, 40], "return_direct_ag": 42, "return_tensor": [34, 35, 36], "reus": [5, 6, 14], "reveal": [5, 9, 12, 13, 14, 21, 23], "revers": [5, 6], "review": [1, 5, 6, 8, 13, 23, 24, 40, 41, 42], "revis": [41, 42], "revisit": [5, 6], "revolut": 0, "revolution": [0, 1, 21], "revolutionari": [0, 13], "reward": [5, 15], "reweigh": 5, "rewon": [7, 9, 11, 12, 26], "rewrit": [3, 4, 41, 42], "rewritten": [5, 6, 21], "rfloor": 1, "rfou": [17, 24], "rhetor": 5, "rho": 26, "rho_1": 26, "rho_2": 26, "rho_i": 26, "rhodesian": 5, "rial": 13, "ricciardi": [41, 42], "rice": 5, "rich": [5, 6, 8, 12, 13, 15, 23], "richard": [5, 11, 13, 18], "richer": [5, 6], "rico": 1, "ride": 7, "ridgeback": 5, "right": [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 23, 24, 25, 26, 28, 41, 42], "rightarrow": [6, 9, 23], "rigor": [41, 42], "ring": [5, 22], "ringallreduc": 22, "ringreducescatt": 22, "rio": 13, "risd": [], "rise": [41, 42], "risk": [2, 3, 5, 6, 14, 22, 23, 24, 41, 42], "risteski": 13, "river": [4, 13], "rkh": 17, "rl": [24, 25], "rlhf": 19, "rm": [23, 34, 36], "rms_norm_ep": [31, 32, 35, 36, 39, 40], "rmsnorm": [1, 31, 32, 40], "rnn": [10, 12], "rnss18": [7, 9, 12], "ro": [7, 24], "road": [5, 6], "rob_bas": 24, "robert": [4, 6, 11, 23], "roberta": [8, 12], "roberts2020trec": 5, "robertson": [5, 6], "robertson2009probabilist": 5, "robinson": 24, "roboto": 42, "robust": [1, 2, 3, 11, 18, 21, 23], "robustli": [8, 12], "roc71": [5, 6], "rocchio": [5, 6], "rocess": [1, 7, 9, 12], "rocketqa": 6, "rockset": 42, "rocksetdb": 42, "rocksetindexdemo": 42, "rodrigo": [6, 21], "roform": 1, "roi": 4, "role": [0, 1, 5, 6, 8, 12, 20, 21, 23, 25, 26, 40, 41, 42], "roll": [6, 41, 42], "romanc": 7, "romano": 5, "rome": 13, "ronan": 13, "rong": [1, 26], "room": [5, 6, 10, 41, 42], "root": [5, 6, 8, 13, 15, 42], "rope": [31, 32, 40], "rope_init_fn": [31, 32, 40], "rope_kwarg": [31, 32, 40], "rope_theta": [31, 32, 35, 36, 40], "rosenberg": 6, "ross": [6, 26], "rotari": [31, 32, 34, 36, 40], "rotary_decod": 39, "rotary_emb": [31, 32, 40], "rotarydecodermodel": 39, "rotat": [1, 8, 11, 12, 31, 32, 40], "rotate_half": [31, 32, 40], "roug": 24, "roughli": [1, 5, 9, 26], "round": [5, 14, 21, 23], "rout": [2, 42], "router": [2, 42], "router_and_subquestion_queryengin": 42, "router_finetun": 42, "router_query_engin": 42, "router_retriev": 42, "routerqueryengin": 42, "routin": [41, 42], "row": [1, 4, 5, 12, 13, 14], "rozi": [23, 26], "rqh": 21, "rr": 5, "rr_": 5, "rr_q": 5, "rrrh20": 22, "rsj": 5, "rsl": [5, 6], "rsm": 23, "rsqrt": [31, 32, 40], "rsr": [5, 6, 11], "rss": 42, "rte": 14, "rtn": 14, "ru": 21, "ruan": 2, "ruben": 9, "ruder": 8, "rudolph": 9, "rui": 23, "ruibin": [1, 12], "ruin": 5, "ruiqi": [2, 6], "ruisong": 2, "ruiyang": [1, 6, 26], "ruizh": 2, "rule": [1, 5, 6, 8, 9, 10, 13, 15, 21, 22, 26, 41, 42], "rumor": 9, "run": [5, 6, 10, 13, 14, 18, 19, 21, 23, 24, 36, 41, 42], "run_backward": 36, "rungpt": 42, "runji": 2, "runllm": 42, "runner": 42, "runtim": [9, 13, 14], "runtimewarn": 28, "runxin": 2, "ruofei": 6, "ruoyu": 2, "russo": 20, "ruwas": 22, "ruyi": 2, "rvert": 25, "rvert_": 25, "rw": 5, "rwc": [7, 9, 11, 12], "rwe": 5, "rx": 2, "ryan": 23, "ryder": [1, 7, 9, 12], "rz09": [5, 6], "rzl17": 1, "s13584": [41, 42], "s2": 42, "s3": [7, 9, 12, 42], "s_": [2, 5, 6, 8, 10, 14, 23, 25], "s_0": 25, "s_1": [5, 6, 25], "s_2": [5, 6], "s_3": [5, 6], "s_4": [5, 6], "s_5": [5, 6], "s_i": [4, 5, 6, 8, 23], "s_j": [4, 5, 23], "s_q": 5, "s_r": 5, "s_t": [23, 25], "s_w": 14, "sa": [41, 42], "sabharw": 4, "sablayrol": 1, "sacrif": 5, "sacrifac": 6, "sacrific": 5, "safe": [3, 5, 21], "safeti": [21, 23, 41, 42], "sagemak": [26, 42], "sagemaker_embedding_endpoint": 42, "sagemaker_endpoint": 42, "sagemaker_endpoint_llm": 42, "saharan": [41, 42], "sai": [1, 4, 5, 6, 7, 8, 9, 13, 19, 21, 24, 25, 26], "said": 5, "saint": 5, "sake": 5, "saksham": 8, "sale": [5, 6, 42], "saleforc": 17, "salesforc": [17, 42], "salienc": 14, "salient": [5, 6], "saliman": [7, 9, 12], "salton": 5, "sam": 26, "sambanova": 42, "sambanovacloud": 42, "same": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 21, 22, 23, 24, 25, 31, 32, 36, 40, 41, 42], "sampl": [4, 9, 11, 18, 19, 21, 23, 24, 25, 26], "samsum": 24, "samuel": [6, 23], "samyam": 22, "san": [7, 21], "sandhini": [17, 23], "sandipan": 23, "sanghai": 1, "sanh": 8, "sanita": [41, 42], "sanjeev": [10, 13], "sanjiv": 6, "sanyal": 4, "sapiro": 4, "sara": 14, "sarathchandra": [41, 42], "sastri": [1, 7, 9, 12, 17], "satisfact": [5, 41, 42], "satisfactori": [7, 8, 12], "satisfi": [1, 5, 6, 9, 23, 25, 41, 42], "satisifi": 23, "satoshi": 10, "satur": [5, 6, 12], "saudi": [41, 42], "saulnier": 1, "saurabh": [6, 8], "saurav": 23, "savares": 17, "save": [5, 6, 12, 13, 14, 22, 24, 31, 34, 37, 38, 39, 40], "save_load": 42, "savefig": 28, "saw": 5, "sbd": 22, "sbert": 42, "sbert_rerank": 42, "scaffold": 42, "scalabl": [2, 5, 6, 13, 14, 21], "scalar": [1, 5, 6, 15, 23], "scale": [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 17, 20, 21, 22, 23, 26, 31, 32, 34, 40, 42], "scan": [5, 26], "scann": [5, 6], "scao": 1, "scarciti": 21, "scarf": 42, "scatter": [21, 22], "scenario": [1, 3, 5, 6, 8, 13, 21, 24, 41, 42], "scene": 17, "sch": [6, 9], "schedual": [], "schedul": 1, "scheinkman": 5, "schema": 42, "schemat": [5, 14], "scheme": [1, 7, 11, 12, 14, 25, 42], "school": [3, 18], "schulman": 23, "schuster": 8, "schutzemr08": [5, 6], "schuurman": [18, 19, 24], "sci": [41, 42], "scienc": [0, 3, 5, 13, 20, 21], "scientif": [3, 5, 6, 7, 8, 21, 26, 41, 42], "scope": [4, 6], "score": [1, 2, 3, 4, 6, 7, 9, 13, 14, 15, 17, 20, 21, 23, 24, 25, 41, 42], "scoreencod": 5, "scorer": [5, 21], "scott": 26, "scrape": 26, "scratch": [5, 6, 12, 26, 34, 38, 42], "screen": 4, "screener": 42, "screw": 4, "scribe": [41, 42], "script": [5, 20, 42], "scriptsiz": 5, "scrollfix": 42, "sdc": [5, 6], "sdcw19": 8, "sdk": 42, "seaborn": 28, "search": [0, 1, 4, 13, 14, 17, 20, 21, 23, 41, 42], "search_term": 42, "searchabl": 21, "searchain": 42, "searcher": 6, "season": 5, "seat": [19, 40], "seattl": [5, 6], "sebastian": [6, 8, 12, 15], "sec": [5, 42], "sec_fil": 42, "sec_tabl": 42, "secgpt": 42, "secinsight": 42, "second": [1, 4, 5, 6, 7, 8, 11, 12, 13, 14, 17, 22, 25, 31, 32, 40, 42], "secondari": 42, "secondli": [], "secret": 23, "secretli": 23, "sect": [41, 42], "section": [0, 1, 3, 5, 6, 8, 9, 12, 13, 14, 20, 21, 22, 37, 38, 39, 41, 42], "sector": [41, 42], "secur": [41, 42], "see": [1, 5, 6, 8, 13, 14, 17, 19, 21, 22, 23, 25, 26, 31, 40], "seed": [24, 34, 35, 36, 37, 38, 39], "seek": [2, 4, 5, 21, 25], "seem": [5, 20, 25], "seen": [5, 6, 8, 9, 12, 13, 15, 21, 22, 24, 26, 41, 42], "seg": 8, "segmenet": 8, "segment": [2, 6, 8, 11, 12, 20], "select": [2, 6, 7, 8, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 42], "selectedmanu": 5, "selector": 42, "selectorprompttempl": [41, 42], "self": [5, 6, 8, 11, 12, 14, 17, 21, 23, 24, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "self_attn": [31, 32, 40], "self_attn_weight": [31, 40], "self_discov": 42, "self_discover_workflow": 42, "self_rag": 42, "sell": 5, "seltzer": 8, "selvaraju": 15, "semant": [1, 4, 7, 8, 9, 10, 11, 17, 20, 21, 26, 42], "semantic_chunk": 42, "semantic_double_merging_chunk": 42, "semantic_similar": 42, "semantic_similarity_ev": 42, "semantic_splitt": 42, "semanticscholar": 42, "sement": 21, "semi": [21, 42], "semin": 5, "semnat": 21, "sen": 6, "send": [21, 22], "senior": 5, "senji": 23, "sennrich": 1, "sens": [5, 6, 9, 13, 42], "sensibl": 9, "sensit": [5, 6, 18, 21, 22, 24], "sensor": 5, "sent": [4, 5, 17, 21, 22], "sentenc": [3, 5, 6, 7, 9, 11, 12, 13, 14, 15, 17, 19, 20, 21, 23, 42], "sentence_optim": 42, "sentence_splitt": 42, "sentence_window": 42, "sentence_window_retriev": 42, "sentencesplitt": [41, 42], "sentencetransformerrerank": 42, "sentiment": [5, 8, 13, 40], "sep": [5, 6, 8], "separ": [1, 5, 6, 7, 8, 12, 14, 17, 21, 23, 24, 28], "seq": [5, 6], "seq2seq": [12, 30], "seq_len": [31, 32, 35, 40], "seq_length": 35, "seqlen": [31, 32, 40], "seqmask": 12, "seqmask_i": 12, "sequenc": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 19, 21, 22, 23, 24, 26, 31, 35, 40], "sequence_length": [31, 40], "sequencen": 10, "sequenti": [0, 1, 2, 8, 9, 12, 21, 22, 23, 24, 34], "ser": [41, 42], "sergei": [1, 6], "seri": [1, 12, 30, 42], "seriou": [5, 6], "serp": [5, 42], "serv": [2, 4, 6, 8, 14, 15, 17, 20, 21, 23, 25, 26, 42], "server": [5, 42], "servic": [5, 6, 20, 21, 41, 42], "service_context": [41, 42], "servicecontext": [41, 42], "session": [5, 6, 21, 41, 42], "set": [1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 31, 34, 35, 36, 38, 40, 41, 42], "set_styl": 28, "set_xtick": 28, "set_xticklabel": 28, "setattribut": 42, "setitem": 42, "setup": [2, 5, 6, 42], "setwis": 4, "seven": [7, 12], "sever": [0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 17, 19, 21, 23, 24, 26], "severyn": 6, "sewon": 6, "sex": [5, 6], "sexual": [3, 23], "sft": 21, "sgd": 26, "sh": 42, "sha": 2, "sha19": 1, "sha20": 1, "shachaf": 6, "shakeri": 6, "shakespear": 3, "shallow": [1, 5, 6], "shan": 2, "shane": [19, 24], "shang": 8, "shanghao": 2, "shangyan": 2, "shanhuang": 2, "shansan": 1, "shao": 2, "shaohan": [1, 8], "shaoq": 2, "shape": [0, 1, 14, 15, 21, 31, 32, 34, 35, 37, 39, 40], "sharan": [6, 11, 18, 22, 24], "share": [1, 2, 5, 7, 8, 11, 12, 13, 14, 17, 20, 23, 26, 31, 32, 40, 41, 42], "sharepoint": 42, "sharma": [8, 12, 23], "sharp": 25, "sharpli": 23, "shayn": 24, "shazeer": [1, 2, 6, 11, 12], "shb15": 1, "she": 21, "shean": 24, "shed": 5, "sheer": [5, 6], "sheet": [41, 42], "sheetinpat": [41, 42], "sheetopd": [41, 42], "shelf": [5, 21, 24], "shen": [2, 6, 21, 23, 24], "shen2014lat": 5, "sheng": [6, 14, 18, 21], "shengfeng": [1, 2], "shep": 5, "sherman": 1, "shg": 6, "shi": [2, 15, 20, 21, 23, 24], "shichao": 21, "shift": [0, 1, 11, 12, 14, 34, 36, 38], "shihan": 23, "shiji": 12, "ship": [5, 13], "shirish": 11, "shirong": 2, "shirt": 5, "shishir": 21, "shixiang": [19, 24], "shiyu": 2, "shoeybi": 4, "shop": [5, 6, 20, 42], "shopifi": 42, "short": [1, 5, 6, 12, 13, 17], "shortag": [5, 6], "shortcom": [5, 6, 12, 13], "shortcut": 34, "shorten": [22, 34, 38], "shorter": [1, 5, 6, 14], "shortest": 20, "shorthand": [9, 15], "shot": [1, 4, 5, 7, 8, 9, 12, 17, 18, 21, 24], "should": [5, 6, 7, 8, 9, 11, 12, 14, 19, 21, 22, 23, 24, 25, 31, 40, 42], "shouldn": [5, 6], "shouyuan": 1, "show": [1, 5, 6, 7, 8, 9, 11, 13, 14, 17, 18, 20, 23, 24, 25, 26, 31, 32, 40], "showgraph": [41, 42], "shown": [1, 5, 6, 7, 8, 9, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24], "showroom": 4, "shrink": 26, "shuaichen": 21, "shuaiqiang": 4, "shuang": 2, "shuffl": [9, 11, 34, 35, 36, 37, 38, 39], "shuguang": 6, "shuip": 2, "shume": [1, 8], "shunfeng": 2, "shuohang": 4, "shusheng": 23, "shuster": 6, "shute": 2, "shutterstock": 5, "shuxin": [1, 12], "shyam": [1, 7, 9, 12], "si": 24, "siames": 5, "sick": 21, "siddartha": 23, "siddhant": 8, "siddhartha": 24, "side": [5, 6, 7, 8, 12, 21], "sidebar": 42, "sidebar__inn": 42, "sidebar__scrollwrap": 42, "sierra": [5, 6], "sifr": 15, "sift": 5, "sig": [41, 42], "sight": [5, 6], "sigir": [6, 21], "sigma": [1, 5, 6, 13, 23, 31, 32, 40], "sigma_": 5, "sigmoid": [1, 8, 10], "sign": [22, 41, 42], "signal": [5, 6, 9, 13, 20, 21, 23, 25], "signfic": [5, 6], "signficicantli": 21, "signific": [0, 1, 3, 5, 6, 7, 8, 9, 12, 13, 14, 18, 19, 21, 22, 31, 40, 41, 42], "significantli": [0, 2, 5, 6, 7, 8, 12, 13, 14, 15, 18, 19, 21, 23, 24, 26, 40, 41, 42], "sil": 20, "siliconflow": 42, "siliconflow_rerank": 42, "silu": [31, 32, 35, 36, 40], "silvio": 17, "sim": [5, 6, 9, 13, 14, 21, 23, 25], "simcha": 6, "simclr": [], "simen": 23, "simiarl": 18, "similar": [1, 7, 8, 9, 10, 11, 13, 15, 17, 18, 21, 22, 23, 24, 26, 31, 32, 40, 41, 42], "similarli": [2, 5, 6, 9, 12, 25, 41, 42], "similiar": [21, 23], "simpl": [1, 2, 6, 7, 12, 13, 14, 15, 17, 19, 20, 21, 22, 26, 40, 42], "simple_composable_memori": 42, "simple_directory_read": 42, "simple_directory_reader_parallel": 42, "simple_directory_reader_remote_f": 42, "simple_fus": 42, "simple_multi_mod": 42, "simple_summar": 42, "simplebm25f": 5, "simpledirectoryread": [41, 42], "simplegraphstor": [41, 42], "simpleindexdemo": 42, "simpleindexdemollama": 42, "simpleindexdemollama2": 42, "simpleindexdemommr": 42, "simpleindexons3": 42, "simpler": [2, 4, 5, 6, 9, 19, 21], "simplest": [5, 6, 15, 21], "simplewebpageread": 42, "simpli": [1, 4, 5, 6, 7, 8, 9, 11, 14, 15, 17, 21, 23, 26, 41, 42], "simplic": [1, 5, 6, 8, 12, 21, 25], "simplif": [1, 5, 19, 25], "simplifi": [1, 5, 6, 14, 21, 23, 31, 32, 34, 36, 40, 41, 42], "simplist": [5, 6], "simpo": 23, "simul": [5, 25, 41, 42], "simultan": [1, 2, 6, 8, 14, 23], "sin": [1, 12, 31, 32, 40], "sinatra": 5, "sinc": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 22, 23, 24, 25, 26], "sine": [12, 31, 32, 40], "singer": 26, "singh": 1, "singhal": [5, 8], "singl": [1, 2, 4, 6, 7, 8, 11, 12, 13, 14, 15, 19, 21, 22, 23, 24, 40, 41, 42], "singlestor": 42, "singlestoredb": 42, "singular": [13, 20], "sinkhorn": [], "sinusoid": 1, "sir": 5, "sister": 13, "sit": 22, "site": [5, 6, 28, 36, 41, 42], "situat": [3, 5, 20, 25], "sive": 5, "six": [8, 41, 42], "siyuan": 14, "sizabl": 1, "size": [0, 1, 2, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 21, 23, 24, 28, 31, 32, 34, 37, 38, 39, 40, 41, 42], "sizemedium": 5, "sk": [41, 42], "skew": 7, "skill": [0, 3, 5, 7, 20], "skin": 5, "skip": [5, 42], "slack": 42, "slackdemo": 42, "slama": 23, "slate": 42, "slav": 24, "slice": [31, 40, 42], "slide": [4, 5, 21, 38, 42], "slightli": [5, 6, 11], "slim": 4, "slimpajama": 26, "slm": 21, "slope": 1, "slow": [5, 7, 8, 21, 22, 26, 41, 42], "slower": [1, 22], "slp": 1, "slug": 42, "slw": 12, "small": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 41, 42], "small_siz": 28, "smaller": [0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 20, 21, 23, 24, 26], "smallest": [5, 13, 14], "smart": [5, 6, 42], "smart_pdf_load": 42, "smartphon": [41, 42], "smaug": 23, "smdh13": 26, "smith": 1, "smooth": [1, 5, 6, 7, 10, 15, 41, 42], "smoother": [1, 5], "smoothin": 9, "smoothli": [7, 24], "smt": 5, "sn": 28, "snack": [5, 9], "sniffio": [41, 42], "snippet": [5, 19, 21], "snowflak": 42, "snowflake_query_engin": 42, "snrm": 6, "snscrape": 42, "snscrape_twitt": 42, "so": [2, 5, 6, 8, 9, 11, 12, 13, 14, 19, 23, 26, 28, 41, 42], "soap": [41, 42], "socher": [11, 13], "social": [3, 5, 26], "societi": 3, "socioeconom": [3, 41, 42], "soft": [5, 6, 8, 15, 17, 24, 41, 42], "soften": [5, 6], "softer": [5, 6], "softli": 5, "softmax": [1, 2, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 22, 26, 31, 32, 34, 40], "softwar": [14, 20, 21, 41, 42], "soh16": [5, 6], "soheil": 7, "sohn": 6, "solar": 42, "sold": 4, "sole": [5, 6, 19], "solid": [5, 13, 23], "solitari": 5, "solla": 14, "solut": [2, 5, 6, 8, 15, 18, 21, 23, 24, 42], "solv": [1, 2, 3, 5, 8, 11, 13, 14, 17, 19, 20, 21, 22, 23, 25, 42], "some": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 36, 40, 41, 42], "someth": [5, 7, 19, 20, 21], "sometim": [1, 5, 6, 21, 23], "somewhat": [5, 7], "song": [2, 6, 8], "soon": 5, "sop": [8, 12], "sophist": [0, 5, 6, 20, 21], "sophositc": 21, "sordoni": 6, "soricut": [8, 12], "sort": [5, 6, 9, 12, 13, 15, 41, 42], "sota": 17, "soumya": 4, "sound": [1, 5, 7, 21], "soupsiev": [41, 42], "sourc": [1, 4, 5, 6, 8, 11, 20, 23, 41, 42], "source_1": 21, "source_2": 21, "source_3": 21, "sources_1": 21, "sources_2": 21, "sources_3": 21, "south": [5, 6, 41, 42], "sow": 23, "space": [2, 8, 10, 11, 12, 13, 14, 15, 17, 21, 22, 23, 25, 31, 32, 36, 40], "spaghetti": 5, "spam": 6, "span": [5, 6, 8, 11, 42], "span_handl": 42, "span_typ": 42, "spanish": 5, "spanner": 5, "spark": 5, "spars": [0, 4, 13, 30, 42], "sparse_embed": 42, "sparsif": 5, "sparsifi": 5, "sparsiti": [2, 5, 10], "spdi": [41, 42], "speak": [5, 13], "speaker": 5, "spealiz": 6, "spec": 42, "specchia": [41, 42], "speci": [], "special": [0, 1, 2, 5, 6, 7, 8, 10, 11, 14, 15, 18, 19, 20, 21, 22, 26, 31, 40, 41, 42], "specialist": 18, "specif": [0, 1, 2, 4, 6, 7, 8, 9, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 31, 40, 41, 42], "specifi": [1, 5, 6, 7, 8, 9, 11, 12, 13, 15, 19, 21, 23, 25, 31, 32, 40, 41, 42], "specifici": 14, "specificlli": 23, "specimen": [41, 42], "specinf": 15, "speclial": 21, "specul": [0, 2, 9], "sped": 8, "speech": [3, 5, 9, 42], "speed": [1, 2, 5, 6, 7, 8, 21, 22, 26, 31, 40], "speedup": [5, 6], "spell": [6, 8, 21], "spellnet": 5, "spend": [14, 21], "spent": [5, 6], "spink": 5, "spirit": 4, "spite": [41, 42], "split": [2, 5, 6, 12, 17, 28], "split_posit": [34, 38], "splitter": [41, 42], "sponsor": [5, 6], "spontan": [], "spoon": 5, "sport": 5, "spotifi": 42, "sprain": 5, "spread": 5, "spreadsheet": [41, 42], "spur": 0, "sp\u00e4rck": 5, "sql": [5, 42], "sql_join": 42, "sql_table_retriev": 42, "sqlalchemi": [41, 42], "sqlautovectorqueryengin": 42, "sqljoinqueryengin": 42, "sqlrouterqueryengin": 42, "sqrt": [1, 5, 6, 8, 12, 13, 26, 31, 32, 40], "squad": [3, 5, 6, 11], "squar": [5, 6, 8, 13, 31, 32, 40], "squeez": 35, "src": 42, "sri": [41, 42], "srivastava": 5, "srnm": 5, "ssangyong": 9, "sst": 14, "st": [5, 14], "stabil": [1, 5, 31, 32, 40], "stabl": [1, 22, 23, 24, 42], "stablelm": 42, "stabli": 26, "stabliz": [1, 24, 31, 32, 40], "stack": [1, 8, 12, 36, 41, 42], "stackoverflow": [26, 42], "staff": [41, 42], "stage": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 17, 21, 26], "stage1": 22, "stai": [1, 5, 6, 13, 21, 41, 42], "stakehold": [41, 42], "staliz": [], "stamp": [41, 42], "stamptim": 21, "stan": [41, 42], "stand": [0, 5, 6, 8, 12, 13, 17, 22, 40, 41, 42], "standalon": 42, "standard": [1, 5, 6, 8, 13, 21, 22, 23, 41, 42], "stanford": [3, 5], "stanford_alpaca": [34, 35, 36], "stanislaw": 24, "stanlei": 9, "starch": [5, 6], "start": [1, 5, 6, 7, 8, 9, 11, 12, 14, 15, 21, 23, 24, 25, 42], "start_char_idx": [41, 42], "starter": 42, "starter_exampl": 42, "starter_example_loc": 42, "starter_tool": 42, "startswith": 42, "stat": 28, "state": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 20, 21, 23, 24, 31, 32, 34, 36, 40, 41, 42], "state_dict": [32, 34, 37, 38, 39], "statement": [20, 21, 41, 42], "static": [1, 8, 13, 31, 40, 42], "staticmethod": [31, 40], "station": 5, "statist": [5, 6, 10, 13, 21, 41, 42], "statu": [3, 21, 41, 42], "steam": 13, "steamship": 42, "steep": 7, "stefan": [6, 15], "stefano": 23, "stem": [3, 5, 13, 21, 22], "step": [1, 2, 4, 5, 6, 8, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36, 37, 38, 39, 40, 41, 42], "step_back_argilla": 42, "stephen": 6, "stepregard": 18, "stepwis": 23, "stern": 5, "steven": [17, 18, 20], "stiennon": 23, "still": [1, 2, 5, 6, 7, 10, 12, 13, 14, 18, 21, 23, 26, 41, 42], "stimul": [41, 42], "stochast": [5, 15, 23, 25], "stock": [1, 5, 21, 42], "stock_market_data_query_engin": 42, "stockton": 13, "stoica": [14, 21], "stomach": [5, 6], "stool": 5, "stop": [3, 5, 6, 8, 11, 14, 21, 26], "stopfilt": 5, "stopper": 5, "stopword": 20, "storag": [14, 21, 41, 42], "storage_context": [41, 42], "storage_context_vector": [41, 42], "storagecontext": [41, 42], "store": [5, 6, 8, 9, 10, 12, 14, 21, 22, 41, 42], "stori": [5, 15, 19], "stork": 14, "stoyanov": [8, 11, 12], "str": [40, 41, 42], "straight": [5, 8, 19, 21], "straightforward": [5, 17, 20, 21], "strand": [5, 6], "strang": [], "strateg": [5, 6], "strategi": [2, 9, 10, 11, 12, 14, 18, 20, 21, 22, 24, 25, 26, 42], "strawberri": 5, "stream": [8, 14, 42], "streamlit": 42, "streamlit_chatbot": 42, "street": [5, 9], "strength": [2, 3, 5, 6, 8, 21, 23, 26, 40, 41, 42], "strengthen": 6, "stress": [41, 42], "stretch": [5, 6, 7], "strict": 32, "strictli": [5, 21, 41, 42], "stride": [5, 34, 35, 36, 38], "strike": 5, "string": [5, 6, 21, 24, 40, 42], "string_iter": 42, "stringifi": 42, "strip": [5, 9, 20, 40], "stripe": 42, "stripe_doc": 42, "striprtf": [41, 42], "strohman": 6, "strong": [4, 5, 6, 7, 14, 23, 42], "stronger": [5, 6], "strongest": [5, 6], "strongli": 26, "struc": 5, "structr": 21, "structur": [0, 1, 2, 5, 6, 7, 8, 9, 12, 13, 17, 20, 21, 24, 26, 41, 42], "structured_data": 42, "structured_image_retriev": 42, "structured_llm": 42, "structured_output": 42, "structured_plann": 42, "structured_predict": 42, "structured_refin": 42, "struggl": [4, 5, 7, 13, 14, 20, 21, 23], "stud": [41, 42], "student": [0, 4, 5, 6, 8], "studi": [0, 1, 5, 6, 7, 8, 9, 12, 13, 17, 18, 23, 41, 42], "studio": 42, "stun": [19, 40], "style": [5, 6, 8, 11, 19, 21, 22, 42], "stylesheet": 42, "su": [1, 2], "sub": [5, 6, 7, 8, 12, 13, 14, 17, 23, 41, 42], "sub_quest": 42, "sub_question_query_engin": 42, "sub_question_weavi": 42, "subbiah": [1, 7, 9, 12], "subclass": 42, "subcompon": [5, 6], "subcutan": 5, "subdivis": [21, 41, 42], "subdoc": 42, "subdoc_summari": 42, "subfigur": 5, "subgradi": 26, "subgraph": 20, "subject": [3, 5, 9, 20, 21, 41, 42], "sublay": [1, 31, 32, 40], "sublinear": 22, "submiss": 42, "submit": [5, 6, 42], "subordin": 21, "subplots_adjust": 28, "subquant": [5, 6], "subqueri": [4, 21], "subquest": 42, "subscrib": 42, "subscript": [5, 12], "subsequ": [0, 4, 5, 6, 7, 14, 15, 23, 41, 42], "subset": [2, 5, 6, 8, 12, 13, 14, 24], "subspac": [1, 5, 12, 14], "substack": 5, "substanti": [2, 5, 14, 22, 24], "substitut": [5, 6], "substr": 5, "subtask": [5, 6], "subtitl": 7, "subtl": [5, 12], "subtop": [5, 6], "subtract": [1, 23], "subunit": 13, "subvector": [5, 6], "subword": [1, 8], "succ": [1, 5, 6, 23], "success": [1, 2, 5, 6, 7, 8, 12, 17, 20, 21, 22, 23, 41, 42], "successfulli": [5, 24, 41, 42], "successor": 7, "succinct": [5, 41, 42], "sucess": 26, "suffer": [5, 6, 8, 9, 24], "suffic": [19, 24], "suffici": [2, 5, 6, 13, 14, 21, 22, 25], "suffix": [5, 13, 17], "sugar": [5, 6], "suggest": [0, 6, 7, 8, 19, 24, 26, 40, 41, 42], "sui": 7, "suit": [2, 3, 5, 8, 9, 12, 21, 26, 41, 42], "suitabl": [1, 5, 6, 11, 14, 21, 23], "suitcas": 3, "sum": [5, 6, 7, 12, 13, 14, 15, 35], "sum_": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 23, 24, 25, 26, 31, 32, 40], "sum_i": [9, 14, 15, 23], "sum_j": [5, 15], "sum_t": 26, "sumit": 1, "summar": [1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 20, 21, 23, 24, 25, 26, 42], "summari": [1, 2, 5, 6, 14, 20, 21, 41, 42], "summat": [5, 6, 8, 13, 14, 15, 22], "summer": [13, 20], "sump": 5, "sun": [2, 4, 5, 6, 8, 12, 15, 21], "sunshin": [5, 6], "supabas": 42, "supabasevectorindexdemo": 42, "super": [31, 32, 34, 35, 36, 37, 38, 39, 40], "superfici": [9, 21], "superglu": 12, "superior": [5, 23], "superl": 13, "superscript": 25, "supervis": [1, 5, 6, 8, 12, 17, 21, 23, 24, 26], "supervisori": 5, "supplement": [5, 21], "supplementari": 8, "suppli": [5, 6, 20, 41, 42], "support": [1, 5, 20, 21, 22, 31, 32, 40, 41, 42], "supporting_modul": 42, "suppos": [1, 4, 5, 6, 7, 8, 9, 15, 21, 23, 25], "suprem": [41, 42], "suprisinli": 1, "sure": [5, 42], "surfac": [5, 6, 26], "surfer": 5, "surgeon": 14, "surgeri": [41, 42], "surgi": [41, 42], "surgic": [41, 42], "surpass": [41, 42], "surpris": [15, 20], "surprisingli": 8, "surreptiti": [], "surrog": [5, 41, 42], "surround": [5, 8, 13], "survei": [1, 4, 5, 6, 8, 12, 17, 21, 24, 26, 41, 42], "surviv": 20, "susan": 13, "susana": 8, "suscept": 5, "suspect": [41, 42], "sutskev": [6, 7, 9, 11, 12, 13, 26], "sutur": [41, 42], "suzgun": 24, "svg": 42, "svm": 5, "swallow": 5, "swallowl": 5, "swam": 13, "swap": [5, 8], "swape": 5, "swapo": 9, "swaroop": 18, "swd": 23, "swedish": 5, "sweep": 5, "swiglu": [1, 31, 32, 40], "swim": [4, 13], "swish": [1, 31, 32, 40], "swiss": 13, "switch": [5, 6, 8, 21, 41, 42], "switzerland": 13, "sy": [8, 40, 41, 42], "syfhpxcosnyi_6cmwd1w7u04myn1l3h7na5dsb0w7u0h6ntzz4bprgnuufga_saxlbcnrt": [41, 42], "sylvain": [12, 24], "sym": 4, "symbol": [1, 5, 6, 7, 8, 9, 11, 12, 13], "symmetr": [5, 6, 17], "symmetri": 5, "symposium": 14, "symptom": [5, 41, 42], "symptom_1": [41, 42], "symptom_2": [41, 42], "synact": 9, "synnaev": 26, "synonym": [4, 5, 6, 17], "synonymi": 5, "syntact": [3, 5, 6, 8, 21], "syntat": 9, "syntax": [5, 8, 21, 41, 42], "syntaxerror": [41, 42], "synthes": [5, 17, 20, 42], "synthesi": [6, 9, 20, 42], "synthet": [17, 21], "syrup": 5, "system": [0, 1, 7, 8, 9, 12, 13, 14, 17, 20, 21, 23, 25, 40, 41, 42], "systemat": [14, 18], "syw": 24, "szegedi": 1, "szu": 26, "t": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 28, 41, 42], "t0": [], "t3blbkfj_qu1cejyslo8ttahtnxwviczgguifyqhu191po4zofik3r8zik4ovn5ts_kzspcaevhkpqj": [41, 42], "t5": [6, 12, 22, 30], "t5layernorm": [31, 32, 40], "t_": [2, 5, 6, 8], "t_1": [5, 12], "t_2": [5, 12], "t_e": 17, "t_f": 17, "t_i": [2, 6, 8, 12, 15], "t_j": 12, "t_m": [5, 12], "t_n": 5, "t_p": 12, "t_q": [5, 6], "tab": [5, 6, 42], "tabindex": 42, "tabl": [1, 4, 5, 6, 9, 11, 12, 13, 14, 18, 20, 21, 22, 23, 24, 42], "tablestor": 42, "tablestoredemo": 42, "tablestorevectorstor": 42, "tablet": 5, "tabs__item": 42, "tabs__link": 42, "tabs__list": 42, "tabular": [4, 5, 13, 42], "tackl": [5, 8, 12, 19, 20, 24], "tag": [5, 8, 21, 40, 42], "tagger": 5, "tahami": [5, 6], "tai": 24, "tail": [4, 5, 6, 9, 15], "tailor": [5, 21], "tair": 42, "tairindexdemo": 42, "taj": 4, "tak": 18, "takao": 10, "take": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 18, 21, 22, 23, 24, 25, 41, 42], "taken": [5, 8, 9, 12, 25, 41, 42], "takeshi": 19, "taliti": [41, 42], "talk": 5, "tan": 2, "tang": [1, 2, 6, 26], "tang2021improv": 5, "tangent": [1, 5], "tanh": [5, 10], "tant": 5, "tao": [2, 6, 24], "target": [2, 3, 5, 6, 7, 8, 11, 12, 13, 17, 22, 23, 24, 25, 26, 31, 34, 35, 36, 40, 42], "target_batch": [34, 35, 36, 38], "target_chunk": 38, "target_id": 38, "target_length": [31, 40], "task": [0, 1, 2, 4, 9, 12, 13, 14, 15, 17, 20, 21, 23, 24, 25, 26, 34, 35, 36, 42], "tast": 5, "tat": 18, "tation": 5, "tatsu": [34, 35, 36], "tau": [6, 8, 17, 25], "tavili": 42, "tavily_research": 42, "tax": 21, "taylor": 14, "tcp": [5, 6], "tctcolbertv2": 5, "teach": [5, 6, 8, 17, 24, 26, 41, 42], "teacher": [8, 23], "teacherstudentdistillationschem": 5, "team": [21, 23], "teaspoon": 5, "tech": [1, 5], "techer": [5, 6], "technic": [1, 2, 5, 21, 22, 26, 41, 42], "techniqu": [0, 1, 2, 4, 6, 8, 11, 12, 13, 19, 21, 24, 26, 30, 31, 32, 40, 41, 42], "technol": [41, 42], "technologi": [0, 6, 9, 12, 13, 21, 41, 42], "tediou": 5, "tei": 42, "tei_rerank": 42, "telegram": 42, "telemedicin": [41, 42], "telephon": [4, 21, 41, 42], "tell": [5, 6, 21], "tem": 21, "temperament": 5, "temperatur": [4, 5, 6, 8, 17, 18, 40, 41, 42], "templat": [17, 41, 42], "template_var": [41, 42], "template_var_map": [41, 42], "tempor": [4, 20, 42], "temporari": 22, "tempt": 5, "ten": [5, 7, 8, 26], "tenac": [41, 42], "tenanc": 42, "tenant": 42, "tencent": 42, "tencentvectordb": 42, "tencentvectordbindexdemo": 42, "tend": [5, 6, 9, 11, 13, 15, 21, 26, 41, 42], "tendenc": [4, 5, 6, 18], "tengyu": 13, "tens": 13, "tensor": [31, 32, 34, 35, 36, 38, 40], "tensorfloat": 22, "tensorflow": 13, "tensorrt": 42, "term": [1, 2, 4, 8, 9, 12, 13, 14, 15, 17, 19, 21, 23, 26, 28, 41, 42], "termbas": 5, "termin": [21, 25], "terminologi": 21, "terms_definitions_tutori": 42, "terri": 23, "terribl": 19, "terribli": 20, "tesla": [21, 42], "tesla_10q_t": 42, "test": [1, 3, 5, 6, 7, 8, 9, 13, 17, 18, 21, 37, 39, 42], "test_data_compon": [34, 35, 36, 38], "test_model": 34, "teven": 1, "texa": 5, "text": [0, 1, 2, 3, 4, 8, 9, 10, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42], "text_column_nam": [37, 39], "text_data": [34, 35, 36, 38], "text_embedding_infer": 42, "text_embeddings_infer": 42, "text_encod": 17, "text_generation_infer": 42, "text_qa": [41, 42], "text_qa_templ": [41, 42], "text_templ": [41, 42], "text_to_imag": 42, "textbook": [5, 6], "textemb": 42, "textit": [], "textual": [5, 6, 7, 11, 17], "textur": [41, 42], "textwidth": 5, "textwrap": 40, "textwrapp": 40, "tf": [5, 13], "tf32": 22, "tfidfsimilar": 5, "th": [1, 2, 5, 6, 8, 12, 14], "than": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 19, 21, 22, 23, 24, 25, 26, 40, 41, 42], "thang": 8, "thank": [1, 5, 9, 11], "theater": 7, "thedist": 5, "thei": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 40, 41, 42], "them": [1, 3, 5, 6, 9, 11, 12, 13, 14, 17, 20, 21, 22, 24, 26, 31, 40, 41, 42], "themselv": 5, "theorecti": 23, "theorem": [5, 42], "theoret": [5, 10, 23], "theori": [1, 5, 6, 12, 23], "thereaft": 25, "therebi": [1, 5, 18], "therefor": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 21, 22, 23, 25, 26], "thesi": [], "theta": [1, 4, 7, 8, 9, 13, 15, 23, 24, 26, 31, 32, 40], "theta_": [1, 8, 9, 26], "theta_1": [1, 8], "theta_2": [1, 8], "theta_i": 1, "theta_k": [1, 26], "theta_q": 1, "theta_x": 1, "thi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 40, 41, 42], "thibaut": [1, 23], "thin": [19, 40], "thing": [5, 6, 13, 20], "think": [3, 5, 13, 18, 19], "thinnest": 20, "third": [4, 5, 6, 8, 25, 41, 42], "thirti": 8, "thoma": [1, 8, 12], "thorn": 23, "thorough": 5, "thorp": 1, "those": [1, 5, 6, 8, 9, 13, 14, 20, 21, 23, 41, 42], "though": [5, 6, 9, 41, 42], "thought": [0, 8, 9, 18, 20, 21, 24, 42], "thousand": [1, 5, 6, 7, 26], "thread": [5, 42], "threadlik": [5, 6], "threat": [41, 42], "three": [1, 5, 6, 7, 8, 12, 13, 17, 20, 21, 22, 23, 24, 26], "threshold": [5, 9, 13, 15], "through": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 17, 18, 20, 21, 23, 24, 25, 41, 42], "throughout": [5, 7, 8, 26], "throughput": 14, "thu": [1, 5, 6, 8, 9, 10, 12, 13, 14, 15, 18, 20, 22, 24], "ti": 1, "tian": [1, 2], "tianhang": 21, "tianjun": 21, "tianl": 15, "tianqi": 22, "tianyang": 6, "tianyi": [1, 26], "tianyu": 2, "tick": 28, "tick_label": 28, "tidb": 42, "tidbvector": 42, "tie": 6, "tie_word_embed": [32, 35, 36], "tieyan": [1, 12], "tifi": 5, "tific": [41, 42], "tificatedeath": [41, 42], "tight": 5, "tightli": 6, "tijmen": 14, "tiktoken": [33, 34, 35, 36, 38, 41, 42], "tild": [1, 5, 6, 12, 13, 25, 26], "tim": [7, 9, 12, 14], "time": [1, 2, 4, 6, 7, 8, 9, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 40, 41, 42], "time_weight": 42, "timelin": 1, "timeout": [41, 42], "timescal": 42, "timescale_vector_autoretriev": 42, "timescalevector": 42, "timestamp": 21, "timeweightedpostprocessordemo": 42, "timoth": 23, "timoth\u00e9": 1, "tini": 8, "tinybert": 12, "tissu": 5, "titl": [5, 6, 7, 19, 21, 28, 40, 41, 42], "titles": 28, "tiwari": [6, 8], "tli": 23, "tll": [5, 6], "tlm": 8, "tmp": 28, "toc": 42, "todai": [5, 7], "todo": 5, "togeth": [5, 6, 7, 10, 12, 13, 14, 20, 21, 23, 41, 42], "toggl": 42, "tok": [5, 8], "token": [2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 23, 24, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42], "token_count": 42, "token_emb": 34, "token_embed": 34, "token_id": 38, "token_text_splitt": 42, "tokencountinghandl": 42, "tokenized_dataset": [37, 39], "tokenized_exampl": [37, 39], "tokenizer_and_chunk_text": 38, "tokenizer_nam": [34, 35, 36], "tokens_seen": [34, 35, 36, 38], "tokyo": 4, "tol": 25, "toler": [21, 25], "tolist": [37, 39], "toll": [5, 6], "tom": [1, 6, 7, 9, 12, 21, 26], "toma": [6, 10, 13], "tomorrow": 9, "tong": 12, "tongzhou": 6, "tonic": 42, "tonic_valid": 42, "tonicvalidateevalu": 42, "too": [2, 3, 5, 6, 8, 9, 14, 21, 23, 26], "took": [5, 6, 23], "tool": [0, 1, 5, 21, 41, 42], "tool_cal": 40, "tool_retriever_rout": 42, "tool_runn": 42, "tool_spec": 42, "toolbelt": [41, 42], "toolhous": 42, "toolhouse_llamaindex": 42, "top": [1, 2, 5, 6, 8, 9, 11, 12, 13, 17, 20, 21, 22, 23, 26, 28, 42], "topic": [8, 13, 15, 20, 21, 42], "topic_pars": 42, "topicnodepars": 42, "topk": 2, "topologi": 21, "tor": [5, 6], "torch": [31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "torch_dtyp": [32, 35, 36], "tori": 7, "toronto": [5, 6, 26], "total": [1, 2, 5, 6, 8, 9, 12, 13, 14, 17, 21, 25, 26], "total_length": [37, 39], "totext": 17, "tough": 13, "tougher": 13, "toujour": 7, "tour": [5, 6], "toutanova": [6, 8, 12], "touvron": 23, "toward": [0, 2, 5, 6, 8, 11, 22, 23, 25, 26, 41, 42], "tower": [4, 5, 25], "toxigen": 3, "tqdm": [41, 42], "tr": [5, 6, 25], "tra": 4, "tracabl": 21, "trace": [5, 20, 21, 42], "traceback": [28, 36], "tracer": 42, "tracing_and_debug": 42, "track": [15, 21], "track_token_seen": [34, 35, 36, 38], "tractabl": [5, 26], "trade": [2, 5, 6], "tradeoff": 5, "tradict": 21, "tradit": [1, 7, 10, 14, 20, 21, 23, 24, 40, 41, 42], "tradition": 12, "traditional_invertedlist": 5, "traditionalirengin": 5, "traffic": [5, 17], "train": [0, 1, 2, 3, 4, 7, 9, 12, 13, 14, 15, 18, 19, 20, 21, 24, 31, 32, 40, 41, 42], "train_config": [37, 39], "train_data": [34, 38], "train_dpo": 35, "train_load": [34, 35, 36, 37, 38, 39], "train_loss": [34, 35, 36, 37, 38, 39], "train_main": [34, 35, 36, 37, 38, 39], "train_model": [], "train_model_epoch": [34, 35, 36, 37, 38, 39], "train_ratio": [34, 38], "train_set": [34, 35, 36, 37, 38, 39], "trainabl": [4, 5, 6, 24], "trajectori": [23, 25], "tran": [41, 42], "trane": 1, "transact": [6, 13], "transcript": [5, 42], "transfer": [5, 6, 7, 8, 11, 17, 21, 24, 26, 41, 42], "transform": [0, 4, 7, 8, 11, 14, 15, 17, 21, 22, 24, 26, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42], "transformer_backbon": 34, "transformerlay": [7, 34], "transformers_vers": [32, 35, 36], "transformsev": 42, "transfrom": 4, "transit": [5, 9, 23, 25, 41, 42], "translanguag": 8, "translat": [0, 1, 5, 8, 9, 11, 12, 13, 15, 22, 23, 24, 26, 42], "transmiss": [41, 42], "transpar": [5, 19, 20, 21], "transpos": [1, 31, 32, 34, 40], "transposit": 5, "trap": 42, "travel": 3, "travers": [5, 20, 21], "tre": [41, 42], "treat": [1, 3, 5, 6, 9, 13, 21, 41, 42], "treatment": [1, 5, 41, 42], "treatment_1": [41, 42], "treatment_2": [41, 42], "tree": [5, 6, 7, 9, 15, 21, 42], "tree_summar": [41, 42], "treebank": [7, 9], "treival": 5, "trello": 42, "tremend": [5, 6], "trend": [5, 6, 7, 41, 42], "trevor": 6, "tri": [5, 6, 15], "triangl": [5, 12], "triangleq": [5, 6, 25], "triangleright": 20, "triangular": [31, 40], "trick": [4, 5, 6, 9, 13, 23], "tricki": 5, "trier": 10, "trigger": [20, 21], "trigram": [5, 6, 9], "trillion": [0, 2, 22, 26], "trinh": 20, "trip": [21, 42], "tripl": [5, 6, 8, 21], "tripleloss": 8, "triplet": 20, "triton": 42, "triu": [31, 34, 40], "trivia": 3, "trivial": [5, 15, 21], "triviaqa": [3, 7], "trmd": 5, "trmdcolbert": 5, "trophi": 3, "troubl": 5, "troubleshoot": 21, "true": [3, 4, 5, 6, 9, 15, 17, 23, 25, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "trueli": 5, "truitt": 20, "trulen": 42, "trulens_eval_pack": 42, "truli": [20, 21], "truncat": [5, 6, 8, 9, 13, 21, 34, 35, 36], "trunk": 26, "trust": [20, 41, 42], "trustworthi": [5, 42], "truth": [2, 3, 5, 6, 17, 18, 19, 21, 23, 40], "try": [5, 19, 21, 22, 40, 42], "tsai": 6, "tsj": [5, 6], "tsv": 28, "tt": [22, 41, 42], "tter": 6, "tu": [7, 12], "tulloch": 26, "tumor": 5, "tun": 24, "tunabl": 5, "tune": [0, 1, 2, 4, 5, 6, 12, 14, 15, 17, 18, 19, 23, 26, 42], "tupl": [5, 6, 19, 23, 25, 31, 32, 33, 34, 35, 36, 38, 40], "turbo": [41, 42], "ture": 5, "turn": [5, 6, 13, 23, 25, 42], "turnov": [41, 42], "tutori": [20, 21, 42], "tv": 5, "tweet": [5, 6], "twice": [5, 6, 15], "twin": 6, "twinbert": [5, 6], "twitter": [26, 42], "twitterdemo": 42, "twizmer": 5, "two": [1, 2, 3, 4, 7, 9, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 26, 31, 32, 34, 35, 36, 38, 40, 41, 42], "twoparadigm": 5, "tworek": 26, "txt": [34, 38], "txtai": 42, "txtaiindexdemo": 42, "ty": 13, "type": [1, 2, 3, 4, 8, 11, 12, 14, 17, 18, 20, 21, 24, 26, 31, 32, 33, 34, 35, 36, 38, 41, 42], "typeform": 42, "typeof": 42, "typescript": 42, "typesens": 42, "typesensedemo": 42, "typeset": 42, "typic": [1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24, 26, 40], "typing_extens": [41, 42], "typing_inspect": [41, 42], "typo": 5, "typograph": 5, "typolog": 8, "tze": [6, 9, 18], "u": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12, 13, 14, 15, 20, 21, 25, 41, 42], "u_": [5, 6], "u_1": 5, "u_2": 5, "u_i": 5, "u_k": 5, "u_q": 14, "u_t": 5, "ual": 5, "ubiquit": 5, "ubuntu": 28, "uhdarch": 5, "uk": [41, 42], "ukasz": [6, 12], "ukrainian": 20, "ul": 42, "ultim": [2, 5, 6, 7, 8, 25], "un": [5, 6, 7, 8, 12, 23], "unabl": 5, "unambigu": [5, 41, 42], "unattain": 0, "unavail": 25, "unbias": [9, 26], "unbound": [1, 42], "unbound_funct": 42, "uncertainti": 23, "unchang": [8, 18], "unclear": [5, 6, 21], "unclick": [5, 6], "uncommon": [13, 15], "unconvent": 1, "uncoordin": [41, 42], "uncorrupt": 12, "uncov": [4, 5], "undefin": [5, 42], "under": [2, 5, 6, 7, 8, 9, 23, 24, 25, 26, 31, 40, 41, 42], "underbrac": [1, 5, 6, 8, 13, 22, 23, 24, 31, 32, 40], "underflow": 22, "undergo": [5, 6, 12, 26], "undergon": [41, 42], "underli": [0, 5, 11, 21, 25], "underload": 2, "underneath": [41, 42], "underperform": 7, "underscor": [41, 42], "underset": 15, "understand": [0, 1, 2, 3, 7, 8, 9, 12, 13, 14, 15, 18, 19, 20, 23, 26, 41, 42], "understood": [5, 8, 9, 20], "undesir": [21, 23, 24], "undoubtedli": 14, "unembed": 26, "unequivoc": 4, "uneth": 13, "uneven": 2, "unevenli": 2, "unexpectedli": 23, "unexplain": 5, "unfairli": 7, "unforgiv": 5, "unfortun": [5, 6], "unhealthi": 5, "uni": [10, 11], "unicod": [1, 5], "unicoil": 5, "unifi": [1, 6, 8, 11, 12, 13, 17, 42], "uniform": [2, 5, 6, 9, 13, 26, 41, 42], "uniformli": [1, 5, 6, 14, 15], "unimod": 17, "uninstal": [41, 42], "unintend": 23, "unintention": 8, "unintuit": 5, "union": [5, 31, 32, 33, 34, 35, 36, 38, 40], "uniqu": [5, 6, 18, 25], "unit": [1, 4, 5, 6, 8, 12, 13, 14, 21, 22, 41, 42], "univari": 5, "univers": [6, 7, 8, 9, 11, 12, 15, 26, 41, 42], "unk": 9, "unknown": [5, 6, 9], "unlabel": [1, 7, 8], "unless": [21, 41, 42], "unlik": [0, 1, 3, 5, 6, 21, 23, 24], "unlimit": [10, 23, 42], "unlock": [7, 24], "unnatur": 1, "unnecessari": [5, 6, 20], "unnecessarili": 14, "unnorm": [1, 8], "unobserv": 9, "unpack": [31, 40], "unparallel": [5, 6], "unpopular": [5, 6], "unpreced": 0, "unpredict": 23, "unrealist": 9, "unrecord": 21, "unrel": [5, 6], "unsaf": 23, "unsafeviewbackward0": 34, "unseen": [1, 5, 9, 10, 19, 23, 24], "unselect": 21, "unsequeez": 35, "unsmooth": 9, "unsqueez": [31, 32, 34, 40], "unsqueeze_dim": [31, 32, 40], "unstabl": [1, 24], "unstruct": 21, "unstructr": 21, "unstructur": [5, 6, 21, 26, 42], "unstructured_el": 42, "unsupervis": [5, 6, 8, 9, 11, 12], "unterthin": 12, "until": [5, 6, 15, 23, 25, 26, 28], "untrac": 21, "untrustworthi": 4, "unus": [14, 22], "unwant": 23, "up": [0, 1, 5, 6, 7, 8, 9, 11, 12, 13, 15, 17, 20, 21, 22, 24, 25, 26, 31, 32, 34, 35, 36, 38, 40, 41, 42], "up_proj": [31, 32, 34, 40], "upcast": [31, 32, 40], "updat": [1, 2, 5, 6, 7, 12, 13, 14, 15, 21, 22, 23, 24, 25, 26, 34, 41, 42], "updateth": 23, "upgrad": 42, "upload": [41, 42], "uploading_llama_dataset": 42, "upon": [1, 2, 5, 6, 21], "upper": [5, 12, 31, 40, 41, 42], "upset": [5, 6], "upstag": 42, "upstash": 42, "upstashvectordemo": 42, "uptrain": 42, "uptraincallback": 42, "upward": 7, "upweight": 23, "uri": [41, 42], "url": [1, 2, 6, 7, 8, 9, 10, 12, 14, 18, 22, 23, 24, 34, 35, 36, 38, 42], "urllib": [33, 34, 35, 36, 38], "urllib3": [41, 42], "urlopen": [34, 35, 36, 38], "urvashi": 8, "us": [2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 24, 25, 26, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42], "usa": [5, 41, 42], "usag": [1, 5, 6, 8, 14, 17, 19, 20, 21, 22, 42], "usage_custom": 42, "usage_docu": 42, "usage_metadata_extractor": 42, "usage_nod": 42, "usage_pattern": 42, "usage_pattern_retriev": 42, "usage_standalon": 42, "use_cach": [31, 32, 35, 36, 40], "use_cas": 42, "use_fast": [37, 39], "use_mrop": [32, 35, 36], "usecas": 42, "user": [3, 5, 6, 15, 19, 20, 21, 22, 24, 36, 40, 41, 42], "using_llm": 42, "usual": [1, 5, 6, 7, 8, 13, 14, 18, 20, 21, 22, 23, 24, 25, 26], "uszkoreit": [6, 12], "utah": [5, 6], "utf": [1, 34, 35, 36, 38, 42], "util": [1, 2, 4, 5, 6, 8, 11, 12, 13, 14, 17, 18, 25, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "uv": 13, "uz": 6, "v": [1, 4, 5, 6, 8, 9, 10, 12, 14, 15, 18, 20, 22, 24, 37, 39, 41, 42], "v0": [28, 42], "v0_10_0_migrat": 42, "v1": [23, 37, 39, 42], "v2": [2, 42], "v4": 23, "v5": 23, "v_": [1, 5, 6, 13, 25, 26], "v_c": 13, "v_i": [1, 13], "v_j": 13, "v_k": 26, "v_proj": [31, 32, 40], "v_t": 13, "v_w": 13, "vacat": 20, "vagu": [5, 41, 42], "vakili": 6, "val_data": [34, 38], "val_load": [34, 37, 38, 39], "val_loss": [34, 35, 36, 37, 38, 39], "vald": 8, "valid": [0, 1, 5, 6, 9, 20, 21, 37, 39, 41, 42], "valium": 5, "vall": 23, "vallei": 26, "valter": 24, "valu": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 21, 22, 23, 24, 26, 28, 31, 32, 34, 37, 38, 39, 40, 41, 42], "valuabl": [5, 6], "value_st": [31, 32, 40], "valueiterationalg": 25, "van": [12, 42], "vancouv": 5, "vanilla": [1, 21, 22, 24], "vanilla_decod": [37, 38], "vanilladecodermodel": [37, 38], "vanish": [1, 5, 6], "vanna": 42, "var": [34, 42], "vari": [1, 2, 3, 5, 6, 14, 19, 21, 26, 41, 42], "variabl": [1, 5, 9, 13, 19, 25, 36, 42], "varianc": [1, 5, 6, 22, 26, 31, 32, 40], "variance_epsilon": [31, 32, 40], "variant": [5, 6, 8, 9, 11, 12, 26, 42], "variat": [1, 9, 13, 21, 26, 31, 32, 40], "varieti": [4, 5, 6, 14, 21, 42], "variou": [0, 1, 2, 3, 5, 6, 9, 12, 15, 17, 20, 21, 23, 24, 26, 41, 42], "vast": [0, 1, 5, 6, 8, 13, 41, 42], "vastli": [5, 6, 8, 15, 25], "vaswani": [6, 12], "vaue": 1, "vault": 5, "vc": 15, "vdot": [1, 12], "ve": [5, 8, 11, 20, 21], "vearch": 42, "vearchdemo": 42, "vec": [5, 6], "vechtomova": 6, "vecotr": 12, "vectara": 42, "vectara_auto_retriev": 42, "vectara_queri": 42, "vectara_rag": 42, "vectarademo": 42, "vector": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 17, 20, 21, 24, 42], "vector_databas": 42, "vector_db": 42, "vector_index": [41, 42], "vector_memori": 42, "vector_rag": [], "vector_rag_query_engin": [41, 42], "vector_stor": [41, 42], "vector_store_index": 42, "vectordb": 42, "vectorstor": 42, "vectorstoreindex": [41, 42], "vehicl": [5, 6, 24], "vein": 5, "veloc": 26, "venkatesh": 22, "verb": [5, 6, 9, 13], "verbos": [5, 6, 21, 41, 42], "verdict": [34, 38], "veri": [1, 5, 6, 7, 13, 15, 20, 21, 22, 26, 41, 42], "verif": [15, 20, 21], "verifi": [20, 21, 41, 42], "verma": 6, "vers": 5, "versa": [5, 6, 15], "versatil": [0, 1, 24], "versicherung": 5, "version": [5, 6, 8, 9, 12, 13, 23, 36, 41, 42], "vertex": 42, "vertex_ai_search_retriev": 42, "vertex_embedding_endpoint": 42, "vertex_endpoint": 42, "vertexai": 42, "vertexai_search": 42, "vertexaidemo": 42, "vertexaivectorsearch": 42, "vertexaivectorsearchdemo": 42, "vertic": [5, 6, 24], "veselin": [8, 12], "vespa": 42, "vespaindexdemo": 42, "vestig": [41, 42], "via": [2, 4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 21, 23, 24, 25, 26], "viabl": 25, "vice": [5, 6, 15, 41, 42], "vicin": 5, "victor": 8, "vicuna": 42, "video": [5, 6, 17, 24, 41, 42], "videodb": 42, "videodb_retriev": 42, "view": [5, 6, 7, 8, 13, 23, 25, 31, 32, 34, 37, 39, 40], "viewbox": 42, "viewport": 42, "vigor": 5, "vijayakumar": 15, "vincent": [10, 21, 24], "vinci": 20, "vinyal": [6, 8], "violat": 5, "violenc": 3, "viral": 5, "virginia": [5, 6], "virtu": 5, "virtuou": 42, "visdial": 17, "vishrav": 8, "vision": 12, "visit": 23, "visitor": [41, 42], "visual": [5, 6, 17, 19, 23, 40], "visuallanguag": 17, "vit": 17, "vital": [41, 42], "vitamin": 5, "viterbi": 5, "vl": 42, "vladimir": 6, "vllm": 42, "vocab": 8, "vocab_s": [31, 32, 34, 35, 36, 37, 38, 39, 40], "vocabulari": [5, 7, 8, 10, 11, 12, 13, 15, 21, 23, 26, 31, 32, 34, 36, 37, 38, 39, 40], "void": 42, "volum": [5, 6, 18, 21, 22, 41, 42], "voorhe": [5, 6], "voronoi": [5, 6], "voss": 23, "vote": [5, 6, 18], "vowel": 5, "voyag": 42, "voyage_query_engin": 42, "voyageai": 42, "voyageai_rerank": 42, "voyageairerank": 42, "vp": 5, "vpn": 5, "vqa": 17, "vqg": 17, "vr": 8, "vscodecontentref": [31, 40], "vsp": [5, 6, 12], "vtgs20": [5, 6], "vulner": [5, 6], "vulnerbl": 23, "vw": [1, 12], "vw_i": 12, "w": [1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 23, 24, 34, 35, 36, 38, 41, 42], "w3": 42, "w32a8": 14, "w8a32": 14, "w8a8": 14, "w_": [5, 7, 8, 9, 10, 12, 13, 14], "w_0": [9, 12], "w_1": [1, 5, 8, 9, 12, 13], "w_2": [1, 5, 8, 9, 12, 13, 31, 32, 40], "w_c": 13, "w_g": 2, "w_i": [5, 6, 9, 13, 14, 15, 17], "w_j": [1, 5, 6, 9, 13, 14], "w_k": [13, 24, 34], "w_l": 23, "w_m": 13, "w_n": [5, 9], "w_o": [1, 14, 22, 34], "w_q": [5, 14, 24, 34], "w_quant": 14, "w_t": [10, 13, 17], "w_v": [24, 34], "w_xx_t": 10, "w_y": 10, "wa": [1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 17, 19, 20, 21, 22, 23, 24, 26, 40, 41, 42], "wachter": 9, "wai": [0, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 17, 18, 20, 21, 23, 24, 25, 26, 41, 42], "waii": 42, "wainwright": 23, "walk": [4, 5, 10, 13, 42], "walker": 42, "wall": [9, 20], "wallac": 4, "walli": 24, "wandb": 42, "wandbcallbackhandl": 42, "wang": [1, 2, 4, 5, 6, 8, 12, 15, 18, 19, 20, 21, 23, 24, 26, 41, 42], "wang2018lambda": 5, "wang2020understand": 5, "wang2021bert": 5, "wangd": 2, "wanjia": 2, "want": [5, 6, 12, 14, 15, 19, 20, 23], "war": [4, 20], "ward": [41, 42], "warm": 1, "warranti": 7, "wash": [41, 42], "washington": [5, 6], "wasn": [], "wasser": 12, "wast": [5, 14, 22], "watch": [5, 8], "water": [5, 12, 13], "watsonx": 42, "watt": 5, "wave": [1, 12], "wavebreakmedia": 5, "wavelength": [1, 12], "wayn": [1, 6, 26], "wbz": 24, "we": [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42], "weak": [3, 5, 6, 23], "weaker": 5, "weakest": [5, 6], "weakli": [5, 6], "wealth": [41, 42], "weather": [5, 6, 21, 42], "weaviat": 42, "weaviate_existing_data": 42, "weaviatedemo": 42, "weaviateindex_auto_retriev": 42, "weaviateindex_metadata_filt": 42, "weaviateindexdemo": 42, "web": [3, 5, 6, 7, 17, 20, 21, 26, 41, 42], "webimagetext": 17, "webpag": 21, "webpagedemo": 42, "webquest": 7, "websit": [3, 5, 7, 12], "webson": 24, "webtext": [7, 12, 17, 26], "webtext2": 7, "wednesdai": 5, "week": 11, "weekli": 5, "wei": [1, 2, 4, 5, 6, 8, 11, 12, 18, 19, 21, 23, 24], "weigh": [5, 6], "weight": [2, 5, 7, 8, 9, 10, 13, 14, 21, 22, 24, 31, 32, 36, 40, 42], "weight_decai": [34, 35, 36, 37, 38, 39], "weiglit": 14, "weilin": 23, "weishung": 18, "weissenborn": 12, "weiwei": 4, "weizhu": 24, "welcom": [41, 42], "welind": 23, "well": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 21, 22, 23, 24, 41, 42], "wen": [1, 2, 6, 26], "wenfeng": 2, "wenhao": [4, 6], "wenhui": 8, "wenji": 23, "wenjun": 2, "wenpeng": [17, 24], "wenqin": 2, "went": [5, 8, 13], "wentao": 2, "wenwu": 12, "wenzek": 8, "were": [0, 1, 5, 6, 9, 12, 17, 19, 20, 22, 23, 24, 26, 40, 41, 42], "weslei": 6, "wesolowski": 26, "west": [7, 9, 12], "weston": [6, 13], "wettest": [5, 6], "wh": [5, 6, 13], "what": [0, 3, 4, 5, 6, 7, 8, 17, 18, 19, 20, 21, 22, 23, 28, 40, 41, 42], "whatsapp": 42, "whe": 13, "when": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 24, 26, 31, 40, 41, 42], "whenev": [23, 26], "where": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 40, 41, 42], "wherea": [1, 5, 6, 7, 14], "whether": [0, 5, 6, 8, 11, 17, 20, 21, 23, 31, 40, 41, 42], "which": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 35, 40, 41, 42], "while": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 26, 40, 41, 42], "white": [5, 23, 42], "whitegrid": 28, "whitespac": 5, "whl": [41, 42], "who": [3, 4, 5, 21, 41, 42], "whole": [2, 4, 5, 8, 12, 22, 23, 24, 25, 26, 41, 42], "whom": [41, 42], "whose": [1, 5, 6, 9, 12, 13, 17, 24], "why": [8, 19, 21, 23, 24, 41, 42], "wi20": [5, 6], "wide": [0, 1, 3, 5, 6, 7, 8, 9, 12, 17, 18, 19, 22, 24, 40, 41, 42], "wider": [4, 5, 8, 14], "widespread": [1, 5, 6, 41, 42], "widetild": 5, "widget": [41, 42], "width": [1, 14, 15, 40, 42], "wiki": [5, 42], "wikipedia": [3, 5, 6, 7, 8, 9, 12, 17, 21, 26, 42], "wikipediaread": 42, "wikipidia": 8, "wikitext": [1, 9, 37, 39], "wilcox": [41, 42], "wild": 5, "william": [1, 2, 3, 24], "willing": 5, "win": [5, 23], "win_amd64": [41, 42], "window": [4, 5, 6, 7, 10, 13, 21, 22, 26, 38, 42], "wine": 13, "wing": 5, "winner": [5, 7], "wip": [30, 42], "wisconsin": [41, 42], "wise": [7, 8, 12, 14, 23, 24, 42], "wish": 5, "wit": [0, 17], "within": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 20, 21, 23, 41, 42], "without": [1, 2, 4, 5, 6, 7, 8, 10, 12, 14, 15, 17, 19, 20, 21, 24, 25, 26], "wmd": 1, "wolf": [8, 13], "wolff": 14, "wolfgang": 8, "wolfram": 42, "wolfram_alpha": 42, "wolski": 23, "woman": 13, "won": [5, 21, 24], "wonder": 5, "wong": [1, 15], "wook": 17, "woosuk": 14, "word": [1, 8, 10, 11, 12, 14, 15, 17, 19, 21, 23, 24, 26, 30, 41, 42], "word2vec": [5, 6, 8], "wordcloud": 28, "wordlift": 42, "wordliftdemo": 42, "wordnet": [5, 17, 21], "wordpiec": [5, 6, 8], "wordpress": 42, "work": [1, 5, 6, 7, 11, 13, 14, 20, 21, 22, 24, 26], "workaround": 42, "worker": 42, "workersai": 42, "workflow": [21, 42], "workflows_cookbook": 42, "workshop": 6, "world": [0, 1, 4, 5, 6, 7, 9, 19, 21, 24, 25, 26, 40, 41, 42], "worldwid": [41, 42], "worri": 42, "wors": [5, 6, 22], "worst": [5, 6], "worth": [5, 12, 41, 42], "worthi": 20, "would": [0, 1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 23, 25, 41, 42], "wouldn": 20, "wrap": 40, "wrapped_text": 40, "wrapper": 40, "wrapt": [41, 42], "wright": [41, 42], "wrist": 5, "write": [0, 1, 3, 5, 6, 9, 13, 14, 15, 17, 18, 19, 20, 23, 25, 34, 35, 36, 38, 40, 42], "writer": [3, 5, 9], "written": [3, 5, 8, 9, 13, 14, 41, 42], "wrong": [5, 23], "wrote": [3, 5, 7, 23], "wsc": 8, "wspace": 28, "wta": 5, "wu": [2, 6, 7, 8, 9, 11, 12, 14, 17, 20, 23, 24, 26], "ww": [18, 19, 24], "wwd": 8, "www": [5, 23, 42], "wyq": 21, "wyw23": 4, "wzc": 23, "x": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 22, 23, 24, 26, 28, 31, 32, 34, 35, 40, 42], "x1": [31, 32, 40], "x2": [31, 32, 40], "x_": [5, 6, 7, 8, 13, 14, 26], "x_0": 23, "x_1": [5, 7, 8, 12, 24, 26], "x_2": [12, 24], "x_i": [1, 12, 24, 31, 32, 40], "x_j": 5, "x_m": [5, 23, 24], "x_n": 12, "x_p": 12, "x_t": [5, 7, 8, 10, 26], "xa0": [41, 42], "xa045": [41, 42], "xa0a": [41, 42], "xa0administr": [41, 42], "xa0adopt": [41, 42], "xa0audit": [41, 42], "xa0bush": [41, 42], "xa0challeng": [41, 42], "xa0clin": [41, 42], "xa0compli": [41, 42], "xa0data": [41, 42], "xa0depart": [41, 42], "xa0develop": [41, 42], "xa0do": [41, 42], "xa0emr": [41, 42], "xa0futur": [41, 42], "xa0implement": [41, 42], "xa0improv": [41, 42], "xa0leg": [41, 42], "xa0med": [41, 42], "xa0pap": [41, 42], "xa0perceiv": [41, 42], "xa0proc": [41, 42], "xa0south": [41, 42], "xa0technolog": [41, 42], "xa0ther": [41, 42], "xa0typ": [41, 42], "xa0year": [41, 42], "xavier": 23, "xfg": 23, "xi": 5, "xia": [2, 6, 8, 12, 23], "xiang": 24, "xiangkun": 21, "xiangyang": 6, "xiangyu": 2, "xianzu": 2, "xiao": [2, 8, 12, 21], "xiaodan": 8, "xiaodong": [2, 6], "xiaohan": 2, "xiaohua": 12, "xiaohui": 24, "xiaojin": 2, "xiaokang": 2, "xiaolei": [1, 26], "xiaoqi": 8, "xiaosha": 2, "xiaotao": 2, "xiaowen": 2, "xiaoxiang": [2, 15], "xie": [2, 24], "xin": [1, 2, 6, 8, 26], "xinfer": 42, "xinference_local_deploy": 42, "xinference_rerank": 42, "xing": [1, 12], "xingchao": 2, "xingkai": 2, "xingwu": 6, "xinhao": 15, "xinlei": 6, "xinnan": 2, "xintao": 21, "xinxia": 2, "xinyi": 2, "xinyu": [1, 2, 4, 21, 26], "xinyuan": 2, "xinyun": [18, 24], "xiong": [1, 2, 6, 11, 12, 17, 21], "xiong2017end": 5, "xiong2020approxim": 5, "xipeng": [1, 6], "xiubo": 6, "xlabel": 28, "xlm": 7, "xml": 5, "xmln": 42, "xorbit": 42, "xsum": 11, "xtick": 28, "xtreme": 8, "xu": [2, 4, 5, 22, 23, 24], "xuanhui": 6, "xue": 2, "xuecheng": 2, "xueqi": 6, "xuezhi": [18, 19, 24], "xuheng": 2, "xupeng": 15, "xv": [1, 31, 32, 40], "xw": [1, 24], "xw_1": [1, 31, 32, 40], "xwvd20": 12, "xxl": [5, 6], "xxq": 24, "xyh": [1, 12], "y": [1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 15, 20, 21, 23, 24, 26, 28, 41, 42], "y_": [5, 6, 10, 15, 20, 23, 24], "y_1": [5, 6, 12, 15, 23, 24], "y_2": [5, 6, 12, 23, 24], "y_3": [5, 6], "y_4": [5, 6], "y_5": [5, 6], "y_i": [5, 6, 12, 23, 24], "y_j": 24, "y_l": 23, "y_m": 12, "y_n": [15, 24], "y_p": 12, "y_t": [8, 15, 20, 23, 24], "y_w": 23, "yafu": 24, "yahoo": [5, 42], "yahoo_fin": 42, "yamada": 5, "yan": [2, 4, 6, 20, 23], "yandexgpt": 42, "yanen": 5, "yang": [1, 2, 4, 5, 6, 8, 12, 14, 15, 21, 22, 24, 26], "yang2018anserini": 5, "yanghua": 21, "yangi": [36, 41, 42], "yangq": 26, "yanhong": 2, "yaniv": 15, "yann": 14, "yanp": [2, 24], "yanqi": [6, 11], "yanyan": [1, 12], "yao": [2, 6], "yaofeng": 2, "yaohui": 2, "yarl": [41, 42], "yashunin": 6, "yate": 6, "ye": [2, 6, 20, 23], "year": [0, 1, 4, 5, 6, 9, 12, 20, 21, 41, 42], "yeast": 5, "yee": 15, "yellow": [1, 4, 5], "yelong": [6, 24], "yelp": 42, "yelysei": 14, "yet": [5, 6, 15, 31, 40], "yew": 14, "yexpect": [41, 42], "yfl18": 6, "ygzl24": 20, "yi": [2, 6, 21, 23, 24, 41, 42], "yichao": 2, "yichong": 4, "yichun": 8, "yield": [0, 1, 5, 6, 12, 14, 19, 26, 41, 42], "yifan": [1, 2, 6, 26], "yih": 6, "yiliang": 2, "yilmaz": [6, 24], "yime": 8, "yin": [4, 8, 17, 18, 24], "ying": [2, 14, 15], "yingqi": 6, "yingqian": [1, 26], "yingyu": 13, "yinhan": [8, 11, 12], "yishi": 2, "yisong": 2, "yiw": 4, "yix": 6, "yixuan": 2, "yiyang": 2, "yiyuan": 2, "yizhi": 6, "yizhong": 20, "ylabel": 28, "ymainten": [41, 42], "yoav": [9, 13], "yolk": 5, "yong": 17, "yonghui": 8, "yongqiang": 2, "yongt": 21, "yoram": 26, "york": [4, 8], "yoshua": [6, 10], "yossi": 15, "you": [0, 1, 2, 5, 6, 7, 8, 11, 12, 14, 17, 19, 20, 21, 22, 24, 31, 32, 40, 41, 42], "you_retriev": 42, "youbi": 26, "youn": 14, "your": [5, 11, 17, 20, 21, 23, 24, 41, 42], "yourself": [5, 21], "youtub": 42, "youtube_metadata": 42, "youtube_transcript": 42, "ystem": [1, 7, 9, 12], "ytick": 28, "yu": [1, 2, 4, 6, 8, 14, 23, 24], "yuan": [2, 8, 26], "yuandong": 1, "yuanzhi": [13, 18, 24], "yuchen": [2, 6], "yuduan": 2, "yue": [2, 24], "yuheng": 2, "yuhong": 15, "yujia": 2, "yukun": 2, "yun": [1, 2, 6, 20, 21, 24, 26], "yunchang": [1, 12], "yunfan": [2, 21], "yunfeng": 1, "yuntao": 23, "yunxian": 2, "yunxuan": 24, "yupeng": [1, 26], "yuqe": 14, "yuri": [1, 26], "yushuo": [1, 26], "yusuk": 19, "yutaka": 19, "yute": 2, "yuxi": 21, "yuxiang": 2, "yuxin": 6, "yuxiong": 22, "yuxuan": 2, "yuyang": 2, "yuyu": 6, "yyhbz24": [1, 22], "yzl": 4, "z": [2, 5, 6, 7, 8, 11, 13, 14, 23, 24, 41, 42], "z_": [5, 6, 15, 26], "z_g": 13, "z_i": [5, 8, 15], "z_j": [5, 8, 15], "zaharia": [5, 6, 21], "zamani": [5, 6], "zamani2018neur": 5, "zapier": 42, "zaragoza": 6, "zcpdemo": 42, "zehui": 2, "zemlyanskii": 1, "zendesk": [5, 42], "zeng": [2, 4], "zenguard": 42, "zep": 42, "zephyr": 42, "zephyr_query_engin": 42, "zepindexdemo": 42, "zeqiu": 20, "zero": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 21, 24, 26, 28, 31, 34, 40], "zero_grad": [34, 35, 36, 37, 38, 39], "zero_point": 14, "zeropoint": 14, "zeroshot": 14, "zettlemoy": [8, 11, 12, 14], "zewen": 8, "zeyu": 15, "zeyuan": 24, "zha": 2, "zhai": [5, 12], "zhang": [1, 2, 4, 6, 12, 14, 15, 17, 18, 21, 22, 23, 24, 26], "zhangli": 2, "zhao": [1, 2, 6, 21, 24, 26], "zhaochun": 4, "zhaopeng": 12, "zhe": [2, 6], "zhean": 2, "zhen": [2, 6, 20, 24], "zhenda": 2, "zheng": [1, 2, 12, 14, 18, 22, 23], "zhenghao": 6, "zhengxin": 15, "zhengyan": [2, 24], "zhengyang": 15, "zhenwen": 4, "zhenzhong": [8, 12], "zhewen": 2, "zhibin": 2, "zhicheng": 2, "zhifeng": 8, "zhigang": 2, "zhihan": 4, "zhihao": 15, "zhihong": 2, "zhipeng": [1, 2, 26], "zhipuai": 42, "zhiqe": 8, "zhiyu": [2, 23], "zhiyuan": 6, "zhongtao": 24, "zhongyu": 2, "zhou": [1, 2, 6, 8, 11, 18, 19, 23, 24, 26], "zhouhong": 21, "zhu": [2, 4, 5, 15, 20, 24], "zhuang": [6, 14], "zhumin": 4, "zhuohan": 14, "zhuoshu": 2, "zhuyun": [6, 21, 24], "zican": [1, 26], "ziegler": 23, "zihui": 2, "zijia": 2, "zijun": 2, "zikang": [1, 26], "zilin": 2, "zilliz": 42, "zimbabw": 13, "zip": [34, 35, 36], "ziwei": 2, "ziyang": 2, "ziyi": 2, "zizheng": 2, "zlcf24": 24, "zmc": 18, "zoph": [1, 2, 24], "zou": 2, "zpj": 21, "zqh": [5, 6], "zs19": 1, "zulip": 42, "zyte": 42, "zyte_serp": 42, "zyteserpdemo": 42, "zzl": [1, 26], "\u00e1": [8, 26], "\u00e4": 6, "\u00e8": [23, 26], "\u00e9": [6, 8, 10, 23], "\u00ed": 8, "\u00fc": [6, 9], "\u011f": 6, "\u0142": [6, 12], "\u4f7f\u5176\u80fd\u591f\u6839\u636e\u4e0d\u540c\u4efb\u52a1\u9700\u6c42\u8c03\u6574\u751f\u6210\u884c\u4e3a": [], "\u5177\u4f53\u800c\u8a00": [], "\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u68c0\u7d22\u64cd\u4f5c": [], "\u5219\u66f4\u8fdb\u4e00\u6b65": [], "\u521b\u65b0": [], "\u53cd\u601dtoken\u751f\u6210": [], "\u5728\u751f\u6210\u7b54\u6848\u540e": [], "\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d": [], "\u5927\u6a21\u578brag": [], "\u5982retriev": [], "\u5e76\u5e76\u884c\u5904\u7406\u591a\u4e2a\u68c0\u7d22\u5230\u7684\u6bb5\u843d": [], "\u5e76\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u63d0\u9ad8\u751f\u6210\u7b54\u6848\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6574\u4f53\u8d28\u91cf": [], "\u6309\u9700\u68c0\u7d22": [], "\u652f\u6301\u5ea6\u548c\u6574\u4f53\u6548\u7528": [], "\u6839\u636e\u53cd\u601dtoken\u7684\u6307\u793a": [], "\u68c0\u7d22\u589e\u5f3a": [], "\u6a21\u578b\u4f1a\u751f\u6210\u7279\u6b8a\u7684\u53cd\u601dtoken": [], "\u6a21\u578b\u51b3\u5b9a\u662f\u5426\u9700\u8981\u8fdb\u4e00\u6b65\u68c0\u7d22\u76f8\u5173\u6587\u6863": [], "\u6a21\u578b\u5229\u7528\u53cd\u601dtoken\u8fdb\u884c\u81ea\u6211\u8bc4\u4f30": [], "\u6b64\u5916": [], "\u751f\u6210\u4e0e\u8bc4\u4f30": [], "\u8bc4\u4f30\u68c0\u7d22\u6587\u6863\u7684\u76f8\u5173\u6027": [], "\u8fd8\u5173\u6ce8\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u63a7\u6027\u548c\u53cd\u601d\u80fd\u529b": [], "\u8fd9\u4e9btoken\u5206\u522b\u7528\u4e8e\u6307\u793a\u662f\u5426\u9700\u8981\u68c0\u7d22": [], "\u9009\u62e9\u6700\u4f73\u8f93\u51fa": [], "\u901a\u8fc7\u5f15\u5165\u81ea\u6211\u53cd\u601d\u673a\u5236\u6765\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf": []}, "titles": ["<span class=\"section-number\">1. </span>Introduction: LLM in the Age of AI", "<span class=\"section-number\">9. </span>LLM Architectures Fundamentals", "<span class=\"section-number\">10. </span>MoE Sparse Architectures (WIP)", "LLM Evaluation", "<span class=\"section-number\">28. </span>Application of LLM in IR (WIP)", "Neural text ranking and information retrieval", "<span class=\"section-number\">27. </span>Information Retrieval and Text Ranking", "<span class=\"section-number\">8. </span>GPT Series", "<span class=\"section-number\">6. </span>BERT", "<span class=\"section-number\">2. </span>Language Models", "<span class=\"section-number\">3. </span>Early Neural Language Models", "<span class=\"section-number\">7. </span>Seq2Seq: T5 and BART", "<span class=\"section-number\">5. </span>Transformers", "<span class=\"section-number\">4. </span>Word Embeddings", "<span class=\"section-number\">21. </span>Inference Acceleration (WIP)", "<span class=\"section-number\">20. </span>Decoding", "Multimodality fundamentals", "<span class=\"section-number\">26. </span>Vision Language Pretraining", "<span class=\"section-number\">23. </span>Advanced Prompting Techniques", "<span class=\"section-number\">22. </span>Basic Prompting", "<span class=\"section-number\">25. </span>Advanced RAG (WIP)", "<span class=\"section-number\">24. </span>RAG", "<span class=\"section-number\">16. </span>LLM Training Acceleration (WIP)", "<span class=\"section-number\">14. </span>LLM Alignement and Preference Learning", "<span class=\"section-number\">13. </span>LLM Finetuning", "<span class=\"section-number\">15. </span>*Reinforcement Learning Essentials", "<span class=\"section-number\">12. </span>LLM Training Fundamentals", "&lt;no title&gt;", "Analysis of Queries", "markmap", "Table of Contents", "<span class=\"section-number\">10. </span>*Annotated LLama", "<span class=\"section-number\">11. </span>*Lab: Minimal LLama", "*Lab: Decoding", "*Lab: Instruction Finetuning", "<span class=\"section-number\">19. </span>*Lab: DPO Training", "<span class=\"section-number\">18. </span>*Lab: Finetuning", "<span class=\"section-number\">17. </span>*Lab: LLM Pretraining", "*Lab: LLM Pretraining", "*Lab: LLM Pretraining", "Prompting Lab", "&lt;no title&gt;", "&lt;no title&gt;"], "titleterms": {"": 9, "0": 5, "1": [5, 7], "175b": 24, "1982": [], "2": [5, 7, 17, 23], "200": 7, "3": [5, 7, 24], "4": 5, "5": 5, "A": [5, 21, 24], "And": [6, 8], "As": 6, "For": [6, 22], "In": [6, 18], "It": 8, "Of": [9, 12], "On": [6, 9], "One": 22, "The": [0, 1, 5, 8, 9, 12, 13, 14, 15, 22, 23, 24, 25], "To": 6, "about": 0, "absolut": 1, "acceler": [14, 22], "accur": 23, "accuraci": [7, 24], "across": 11, "action": 25, "activ": 22, "ad": [5, 6], "adagrad": 26, "adam": [22, 26], "adamw": 26, "adapt": [24, 26], "add": 9, "advanc": [6, 14, 18, 20, 21], "ag": 0, "agent": [20, 30], "ai": 0, "albert": 8, "algorithm": [14, 23, 25, 26], "alibi": 1, "alic": [], "align": [5, 23], "alloc": 22, "alpha": 9, "among": [7, 21], "an": 5, "analysi": [11, 12, 28], "anatomi": [8, 12], "annot": 31, "answer": [5, 6, 7], "ap": 5, "appear": 7, "appendix": 22, "applic": [4, 17, 30], "approach": [5, 21, 24], "approxim": [5, 6], "ar": [5, 7, 8], "architectur": [1, 2, 5, 6, 8, 12, 17, 30, 34], "arithmet": 7, "around": 7, "articl": 7, "aspect": 23, "assum": 5, "assumpt": 14, "attent": [1, 12, 14, 31, 32, 34, 40], "attribut": 6, "augment": 21, "averag": 5, "avoid": [], "awar": [1, 5, 6], "awq": 14, "b": 24, "back": [9, 18], "balanac": 2, "balanc": 2, "bart": 11, "base": [5, 6, 13, 19, 20, 24, 25], "basic": [1, 5, 14, 15, 19, 21, 24], "batch": [5, 6], "bay": 5, "bbpe": 1, "beam": [15, 33], "begin": 5, "behavior": 15, "below": [], "benchmark": [3, 5, 6, 8, 9, 24], "berkelei": [], "bert": [5, 6, 8], "bertbas": 8, "bertlarg": 8, "beta": 1, "between": 6, "bi": [5, 6], "bia": 9, "bibliographi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26], "bipartit": 5, "blender": 5, "blip": 17, "block": 14, "bm25": [5, 6], "bm25f": 5, "bob": [], "book": [0, 7], "bootstrap": 24, "bpe": 1, "branch": 12, "breadown": 1, "breakdown": [1, 12, 14], "build": 5, "byte": 1, "cach": 14, "can": [7, 23], "candid": 5, "car": [5, 6], "case": [9, 14], "categor": [4, 21], "caveat": 9, "cbow": 13, "chain": 19, "challeng": [5, 6, 13, 14, 21], "channel": 14, "char": 5, "checkpoint": 22, "choic": [1, 9, 18, 26], "choos": 21, "chunk": [1, 21], "classic": [5, 6], "classif": 19, "clean": 26, "clear": 5, "clip": 17, "close": 7, "cluster": [5, 6], "cnn": [5, 6], "code": [5, 6], "coffe": [], "coil": 5, "colbert": [5, 6], "collect": [4, 23], "collis": 6, "combin": [1, 14, 18, 26], "common": [3, 7], "commonli": 8, "commun": 22, "compar": 8, "comparis": 24, "comparison": [5, 7, 11, 12, 24], "complex": [15, 21], "compon": 22, "componen": [2, 8], "composit": [1, 3], "comprehens": 3, "compress": 14, "comput": [1, 5, 6, 8, 12, 14, 15], "concept": [14, 21], "configur": [1, 8], "connect": 6, "consid": [5, 21], "consider": [2, 11, 17], "consist": [11, 18], "construct": 5, "content": [3, 30], "context": [1, 5, 6, 18, 19, 21], "contextu": [5, 6, 8], "continu": 26, "contrast": 13, "control": [15, 21], "convent": 12, "converg": 25, "convers": 21, "corpu": 7, "correct": [5, 20], "correspond": 5, "cort": 5, "cost": 14, "cot": [18, 19], "covid": 5, "crag": 20, "criterion": 25, "critic": 23, "cross": [5, 6, 9], "ct": [5, 6], "cumul": [5, 6], "d_": 5, "data": [5, 6, 21, 22, 23, 26, 34, 35, 36, 37, 38, 39], "dataset": [5, 6, 9], "dc": [5, 6], "decai": 26, "decis": [23, 25], "decod": [12, 15, 31, 32, 33, 36, 40], "deep": [5, 6], "deepseek": 2, "deepspe": 22, "demonstr": 11, "denois": [5, 6], "dens": [1, 2, 5, 6, 21], "depend": 5, "dequant": 14, "deriv": 9, "descent": 26, "design": [17, 20], "detail": 17, "develop": 12, "devic": 22, "diagon": 14, "differ": [12, 21, 22, 24], "dimension": 5, "discount": [5, 6, 9], "discuss": [5, 21, 23], "distanc": [5, 6], "distil": [4, 5, 6, 8], "distillbert": 8, "distribut": 22, "divers": 21, "doc": [4, 6], "document": [5, 6, 21, 28], "doe": 1, "domain": [5, 6], "down": 13, "downstream": 17, "dpo": [23, 35], "drive": 23, "drmm": 5, "dropout": 12, "dssm": [5, 6], "dual": [1, 5, 6], "duet": 5, "duo": [5, 6], "dure": 22, "dynam": [5, 6, 18], "e": 8, "earli": 10, "effect": 23, "effici": [5, 6, 8, 24], "electra": 8, "elmo": 8, "emb": 4, "embed": [1, 4, 5, 6, 8, 13, 31, 32, 40], "encod": [1, 5, 6, 8, 12], "end": 5, "engin": 5, "enhanc": [5, 21], "enrich": 5, "ensembl": [5, 6, 18], "entri": [34, 37, 38, 39], "entropi": 9, "error": [5, 14, 25], "essenti": 25, "estim": [1, 9, 13, 25], "evalu": [3, 5, 6, 8, 9, 21, 23, 25], "exact": [5, 6], "exampl": [1, 5, 6, 13, 18, 21, 25], "exhaust": [5, 6], "expans": [5, 6, 26], "exploit": 23, "explor": 23, "extend": 1, "extract": [19, 20], "extrem": 8, "factor": 21, "fals": [5, 6], "featur": 5, "feed": 10, "feedback": [4, 5], "feedforward": 12, "few": 19, "ffn": [1, 31, 32, 34, 40], "file": [5, 6], "fill": 14, "fine": [7, 8, 11, 21, 24], "finetun": [21, 24, 34, 36], "finit": 25, "five": 13, "float": 22, "flop": 1, "form": [], "forward": [1, 10], "found": [], "foundat": 30, "fp8": 14, "frac": 5, "framework": [5, 6, 14, 21, 25], "free": [2, 25], "frequent": 13, "from": [1, 5, 6, 23], "function": [5, 6, 24, 25], "fundament": [1, 2, 5, 6, 14, 15, 16, 21, 26], "further": 21, "fuse": 17, "fusion": 5, "g_k": 26, "gain": [5, 6], "gamma": [1, 23], "gefe": 4, "gener": [4, 5, 7, 11, 14, 18, 21, 23], "given": 5, "glove": 13, "glue": 24, "gpt": [7, 24], "gptq": 14, "gpu": 22, "gqa": [1, 14], "gradient": 26, "gram": [5, 9, 13], "granular": [14, 21], "graph": [5, 20, 21], "graphrag": 20, "greedi": [15, 33], "group": 1, "groupwis": 14, "happen": 14, "hard": [5, 6], "harm": 3, "hash": 6, "have": 5, "head": 1, "hessian": 14, "heurist": [5, 6], "hierarch": [5, 6], "high": 5, "hoc": [5, 6], "how": 23, "human": 7, "hybrid": 5, "hyperparamet": 8, "hypothesi": 24, "i": [1, 5, 6, 12, 13, 14, 23], "identifi": 7, "idf": 6, "ii": [5, 6, 13], "imag": 17, "impact": 5, "imperfect": 8, "implement": [6, 17, 23], "implicit": 23, "import": [5, 6, 23, 26], "improv": [23, 25], "increas": 5, "index": [5, 6, 21], "infer": [14, 20, 24, 30], "infil": 11, "inform": [5, 6, 30], "initi": 24, "input": [8, 12], "instruct": [17, 19, 24, 34], "insturct": 24, "int8": 14, "interact": 5, "interpol": [1, 5], "introduct": [0, 5, 6, 7, 8, 17, 30], "invert": [5, 6], "ir": [4, 5, 6], "iter": [23, 25], "k": 15, "katz": 9, "kei": [2, 20], "kl": 6, "knowledg": [3, 5, 6, 20, 21], "knrm": 5, "kv": [1, 14], "l_2": 26, "lab": [32, 33, 34, 35, 36, 37, 38, 39, 40], "label": [5, 6, 23], "lambdanet": 5, "languag": [0, 4, 5, 7, 8, 9, 10, 11, 12, 14, 17, 24, 31, 32, 36, 40], "larg": [0, 6], "latent": 1, "law": 24, "layer": [1, 8, 12, 31, 32, 34, 40], "lead": 23, "learn": [5, 6, 18, 19, 23, 25, 26, 35], "learnabl": 5, "left": 5, "legal": 21, "let": 22, "letter": 6, "level": [1, 5, 6], "limit": 13, "lingual": 7, "link": 29, "list": [4, 5], "llama": [23, 31, 32, 40], "llm": [0, 1, 3, 4, 14, 19, 21, 22, 23, 24, 26, 30, 34, 37, 38, 39], "lm": 8, "load": 2, "logist": 23, "long": [1, 6, 21], "lora": 24, "loss": [2, 5, 6, 23, 24], "low": 24, "m": [5, 6], "machin": 7, "marco": [5, 6], "markmap": 29, "markov": [23, 25], "mask": [8, 12], "match": [5, 6], "mathemat": 3, "mathrm": 5, "matrix": 14, "mbert": 8, "mdp": [23, 25], "me": 5, "mean": [1, 5], "mechan": 1, "med": 18, "medusa": 15, "memori": [14, 22], "method": [5, 6, 24, 26], "methodologi": 23, "metric": [3, 5, 6, 9], "mha": 1, "minibatch": 26, "minilm": 8, "minim": [14, 21, 32], "mismatch": 21, "mistral": 1, "mix": 22, "mixtral": [], "mixtur": 26, "mla": 1, "mle": 9, "mmlu": 18, "mobilebert": 8, "model": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 21, 22, 23, 24, 25, 31, 32, 34, 36, 37, 39, 40], "modern": [5, 6], "modul": [8, 12], "moe": 2, "momentum": 26, "monitor": 23, "mono": [5, 6], "more": 9, "most": [8, 11], "mother": [], "motiv": [1, 2, 5, 6, 9, 10, 20, 21, 23, 24], "movi": 19, "mqa": 1, "mrr": 5, "mse": 6, "mtp": 2, "multi": [1, 5, 6, 7, 15, 21], "multihead": [12, 15], "multilingu": 8, "multimod": 16, "multinli": 24, "multipl": [5, 14, 26], "multistag": [5, 6], "n": [5, 6, 9, 22], "naiv": 5, "natur": [4, 5, 6, 7], "ndcg": [5, 6], "nearest": [5, 6], "necessari": 12, "need": [1, 6], "neg": [5, 6, 13], "neighbor": [5, 6], "network": 14, "neural": [5, 7, 10, 14], "new": 7, "next": 8, "ngram": 6, "nine": 13, "nois": 13, "non": [5, 6], "nonlinear": 1, "norm": [1, 31, 32, 40], "normal": [1, 5, 6], "notat": 25, "note": [5, 6], "nprf": 5, "nq": [5, 6], "nsp": 8, "ntk": 1, "number": [1, 6, 22], "nv": 4, "ob": 14, "object": [5, 6, 11, 21], "off": [9, 14], "offlin": 5, "one": 22, "onli": [5, 23], "onlin": [5, 6], "oov": 9, "open": [5, 6], "oper": 22, "opportun": [5, 6], "optim": [4, 13, 21, 22, 26], "other": 24, "out": 9, "output": 12, "over": 23, "overal": [5, 12, 23], "overview": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 17, 22, 23, 24, 25, 26], "p": 15, "page": 14, "pair": [5, 6, 7], "pairwis": [5, 6], "paper": 5, "paradigm": [5, 6], "parallel": 22, "paramet": [1, 8, 9, 24], "pars": 21, "part": 1, "pass": 1, "passag": [5, 6], "peft": 24, "per": 14, "perform": [7, 11, 13, 14, 18], "perplex": 9, "person": 5, "perspect": 5, "phi": 22, "philz": [], "phrase": 5, "pipelin": [5, 6], "point": [5, 6], "pointwis": [5, 6, 12], "polici": [23, 25], "polyencod": 5, "popular": [5, 6], "posit": [1, 5, 6, 12, 23], "postion": 1, "ppo": 23, "practic": [5, 9, 21, 23], "pre": [5, 8, 11, 14], "precis": [5, 6, 22], "predic": [], "predict": [5, 6, 8, 26], "prefer": [23, 35], "prefix": 24, "preliminari": 23, "preprocess": 5, "pretrain": [7, 8, 11, 12, 17, 26, 37, 38, 39], "principl": [5, 6], "probabilist": 5, "problem": [5, 13], "process": [5, 22, 23, 25], "product": [5, 6], "program": 19, "prompt": [14, 18, 19, 21, 24, 30, 40], "properti": [1, 25], "provid": [], "prune": 14, "pseudo": [5, 6], "put": 8, "q": 25, "q_": 5, "qualiti": [21, 23], "quant": 14, "quantiz": [5, 6, 14], "queri": [1, 4, 5, 6, 21, 28], "question": [5, 6, 7], "qw": 5, "qwen2": 1, "r": [8, 24], "raft": 21, "rag": [4, 20, 21, 30], "random": [5, 6], "rank": [4, 5, 6, 24], "ranker": [4, 5, 6], "ranknet": 5, "rare": 9, "rate": 26, "re": 5, "read": 3, "reason": [3, 7, 21], "recal": [5, 6], "reciproc": 5, "recommend": 5, "recurr": [10, 12], "recurs": 25, "reflect": 20, "regress": [5, 6, 23], "reinforc": [23, 25], "relat": 25, "relationship": [9, 13, 21, 23, 25], "relax": 5, "relev": 5, "represent": [5, 6], "requir": [14, 22], "rerank": 21, "residu": 6, "respons": [23, 24], "result": [6, 21, 24], "retriev": [4, 5, 6, 20, 21, 30], "review": 19, "reward": [23, 25], "rewrit": [5, 6, 21], "right": 5, "rightarrow": 5, "rise": 0, "rl": 23, "rlhf": 23, "rm": [1, 31, 32, 40], "rm3": 5, "rmsprop": 26, "robert": 24, "robust": [5, 6], "root": 1, "rope": 1, "rotari": 1, "rotori": [31, 32, 40], "safeti": 3, "sampl": [5, 6, 8, 13, 15], "scale": [6, 24], "schedul": 26, "scheme": [5, 6], "scope": 5, "score": 5, "search": [5, 6, 15], "searcher": 5, "segment": 5, "select": 5, "self": [1, 18, 20], "semant": [5, 6, 13], "sens": [3, 7], "sentenc": 8, "sentiment": 19, "seq2seq": 11, "sequenc": [5, 12], "seri": 7, "serp": 4, "serv": 5, "set": 8, "sft": 23, "share": 6, "shop": [], "short": 7, "shot": 19, "shuffl": 18, "signal": 17, "similar": [5, 6], "simpl": [5, 9, 23], "singl": 5, "site": 29, "size": [6, 22, 26], "skip": 13, "slide": 1, "smooth": [9, 14, 23], "snrm": 5, "softwar": [5, 6], "some": [], "sota": 7, "sourc": [21, 26], "space": [5, 6], "spars": [2, 5, 6, 21], "sparterm": 5, "special": 9, "specif": [3, 5], "specul": 15, "speed": 14, "speical": 14, "spell": 5, "speller": 5, "split": 21, "squar": 1, "stack": [31, 32, 40], "stage": 22, "standard": 14, "star": 9, "state": [22, 25], "statement": 5, "static": [5, 6], "statist": 9, "step": [15, 18], "stochast": 26, "stop": 25, "stopword": [], "storag": [5, 6, 22], "strategi": [5, 6, 8, 17], "stream": 5, "strong": 11, "studi": 24, "subject": [], "subword": 13, "suggest": 5, "summari": [12, 22], "superglu": 7, "supervis": 7, "svd": 13, "switch": 2, "syntact": 13, "system": [5, 6], "t5": [5, 11], "tabl": 30, "task": [3, 5, 6, 7, 8, 11, 18, 19], "teacher": [5, 6], "techniqu": [5, 9, 14, 18, 22], "temperatur": 15, "tensor": [14, 22], "terc": [5, 6], "term": [5, 6], "test": [32, 34], "text": [5, 6, 7, 11, 19], "tf": 6, "theorem": 25, "thi": 0, "thought": 19, "time": 5, "tinybert": 8, "todai": 8, "togeth": [8, 18, 26], "token": [1, 5, 6, 26], "tokenzi": 1, "top": 15, "topic": [5, 6], "total": 22, "toxic": 3, "track": [5, 6], "trade": [9, 14], "tradit": [3, 5, 6], "train": [5, 6, 8, 11, 17, 22, 23, 26, 30, 34, 35, 36, 37, 38, 39], "transform": [1, 2, 5, 6, 12, 34], "translat": 7, "trec": [5, 6], "triplet": [5, 6], "tune": [7, 8, 11, 21, 24], "turn": 21, "tutori": 5, "two": [5, 6, 8], "ty": 1, "type": [5, 6, 13, 22], "uhd": 5, "ultra": 5, "understand": [4, 5, 6, 11, 17, 21, 24], "uni": 5, "unifi": 5, "unigram": [5, 9], "unsupervis": 7, "up": 14, "url": 5, "us": [1, 5, 6, 8, 22, 23], "util": 21, "v": [2, 13, 19, 21, 23, 25], "v3": 2, "valid": 24, "valu": 25, "vari": 11, "varianc": 9, "variant": [1, 23], "variat": [5, 6], "variou": 8, "vector": [5, 6], "via": [1, 5, 6, 14, 22], "vision": [17, 30], "visual": 13, "vocabulari": [1, 6, 9], "vocalbulari": 21, "volumn": 22, "we": [1, 5, 6], "weight": [1, 6, 12, 26], "what": [1, 14], "when": 21, "where": 14, "whether": 7, "which": 1, "why": [1, 5, 6], "wikisql": 24, "window": 1, "wip": [2, 4, 14, 20, 22], "wise": [5, 6], "word": [5, 6, 7, 9, 13], "word2vec": 13, "work": 23, "world": 3, "xlm": 8, "yarn": 1, "zero": [19, 22]}})