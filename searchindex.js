Search.setIndex({"alltitles": {"": [[1, "example-1"], [1, "example-3"], [1, "remark-5"], [1, "example-6"], [5, "example-1"], [8, "example-0"], [8, "example-1"], [10, "example-0"], [11, "example-0"], [12, "example-0"], [12, "example-1"], [13, "example-0"], [13, "example-2"], [18, "example-3"], [19, "example-1"], [19, "example-2"], [20, "example-3"], [20, "example-6"], [21, "example-0"]], " ((Skip-gram vs CBOW performance))": [[12, "remark-3"]], " (A minimal RAG example)": [[20, "example-0"]], " (A,B initialization and model inference)": [[23, "remark-1"]], " (Adam stochastic gradient descent algorithm with weight decay)": [[25, "Adam_stochastic_gradient_descent_algorithm_with_weight_decay"]], " (Adam stochastic gradient descent algorithm)": [[25, "Adam_stochastic_gradient_descent_algorithm"]], " (BPE)": [[1, "BPE-algorithm"]], " (Caveats)": [[8, "remark-3"]], " (Challenging reasoning queries for dense retriever)": [[20, "example-4"]], " (Comparision of base LLM and instructed LLM in response to a prompt)": [[23, "example-0"]], " (Design considerations for fusing image understanding signals)": [[16, "remark-0"]], " (Dropout on attention weight)": [[11, "remark-1"]], " (Effective implementing PPO is critical)": [[22, "remark-8"]], " (Encoder layer)": [[7, "definition-0"], [11, "chapter_foundation_def_pretrained_LM_transformer_encoder_layer"]], " (Expansion of G_k)": [[25, "remark-2"]], " (FLOPs estimation)": [[1, "remark-7"]], " (Finite state Markov decision process (MDP))": [[24, "definition-0"]], " (How DPO loss work)": [[22, "remark-6"]], " (Imperfections of the masking strategy.)": [[7, "remark-2"]], " (Implicit reward)": [[22, "remark-5"]], " (Importance of adaptive learning rate)": [[25, "remark-3"]], " (Is feedforward layer necessary for Transformer?)": [[11, "remark-3"]], " (Iterative reward model and policy improvement)": [[22, "example-0"]], " (KV-cache pre-fill for prompts)": [[13, "remark-1"]], " (Knowledge graph example)": [[20, "example-1"]], " (LLM prompt to query rewrite)": [[20, "example-2"]], " (Minibatch stochastic gradient descent algorithm)": [[25, "Minibatch_stochastic_gradient_descent_algorithm"]], " (Monitor DPO training process)": [[22, "remark-7"]], " (OBS Neural Network Pruning Algorithm)": [[13, "OBS_network_pruning_algorithm"]], " (Per-channel quantization)": [[13, "example-4"]], " (Per-tensor quantization)": [[13, "example-3"]], " (Practical simple back-off)": [[8, "remark-2"]], " (Relationship to Cross Entropy)": [[8, "remark-4"]], " (Relationship to logistic regression)": [[22, "remark-4"]], " (SFT on positive only data can lead to over-generalization)": [[22, "example-3"]], " (Self-RAG Inference)": [[19, "algorithm-0"]], " (Skip-gram and CBOW optimization problem)": [[12, "chapter_foundation_word_embedding_def_skipGramOptimization"]], " (The importance of accurate reward model)": [[22, "remark-1"]], " (The policy iteration algorithm for MDP)": [[24, "ch:reinforcement-learning:alg:policyIterationMDP"]], " (Translation pairs can appear naturally in pretraining text corpus)": [[6, "example-0"]], " (Value iteration algorithm for a finite state MDP)": [[24, "ch:reinforcement-learning:alg:valueIterationAlg"]], " (Weighting scheme for long queries)": [[5, "remark-2"]], " (What does Byte-level mean?)": [[1, "remark-4"]], " (Why we need \\gamma and \\beta)": [[1, "remark-0"]], " (Why we need a semantic understanding model)": [[5, "remark-0"]], " (Zero shot prompt for movie review sentiment classification)": [[18, "example-0"]], " (Zero shot prompt for programming task)": [[18, "example-2"]], " (Zero shot prompt for text extracting)": [[18, "example-1"]], " (choice of minibatch size)": [[25, "remark-1"]], " (computation in decoder module)": [[11, "definition-5"]], " (computation in encoder module)": [[7, "chapter_foundation_def_pretrained_LM_transformer_bert_encoder_computation"], [11, "chapter_foundation_def_pretrained_LM_transformer_encoder_computation"]], " (connections between MSE loss and KL loss)": [[5, "remark-3"]], " (convergence property of iterative policy evaluation)": [[24, "ch:reinforcement-learning:th:convergenceIterativePolicyEvaluation"]], " (convergence property of value iteration)": [[24, "ch:reinforcement-learning:th:valueIterationConvergence"]], " (error estimation and stopping criterion)": [[24, "remark-8"]], " (examples of reward functions)": [[24, "example-1"]], " (exploitation and exploration aspects from \\gamma)": [[22, "remark-2"]], " (policy improvement theorem)": [[24, "ch:reinforcement-learning:th:policyImprovementT"]], " (recursive relation for value functions)": [[24, "remark-6"]], " (recursive relations of the Q function)": [[24, "lemma-5"]], " (recursive relationship of value functions)": [[24, "ch:reinforcement-learning:th:recursiveRelationshipValueFunctionMDP"]], " (shared product quantizer for residuals)": [[5, "remark-4"]], " (sparse retrieval vs dense retrieval for legal documents)": [[20, "example-5"]], " (state-action value function - Q function)": [[24, "definition-4"]], " (value functions)": [[24, "definition-2"]], " (value iteration vs. policy iteration; model-based vs. model-free)": [[24, "remark-13"]], "*Annotated DPO Training": [[33, null]], "*Annotated LLama": [[30, null]], "*Lab: Annotated Finetuning": [[34, null]], "*Lab: Instruction Finetuning": [[32, null]], "*Lab: LLM Pretraining": [[35, null]], "*Lab: Minimal LLama": [[31, null]], "*Reinforcement Learning Essentials": [[24, null]], "A unified perspective from matching": [[4, "a-unified-perspective-from-matching"]], "ALBERT": [[7, "albert"]], "ALiBi": [[1, "alibi"]], "AWQ": [[13, "awq"]], "About This Book": [[0, "about-this-book"]], "Absolute Position Encoding": [[1, "absolute-position-encoding"]], "Activation Checkpointing Techniques": [[21, "activation-checkpointing-techniques"]], "Activations": [[21, "activations"]], "Ad-hoc Retrieval": [[5, "ad-hoc-retrieval"]], "Ad-hoc retrieval": [[4, "ad-hoc-retrieval"]], "Adam": [[25, "adam"]], "Adapter Tuning": [[23, "adapter-tuning"]], "Adaptive Gradient (AdaGrad)": [[25, "adaptive-gradient-adagrad"]], "Adaptive Gradient Method": [[25, "adaptive-gradient-method"]], "Add \\alpha Smoothing and Discounting": [[8, "add-alpha-smoothing-and-discounting"]], "Advanced Architectures": [[5, "advanced-architectures"]], "Advanced Prompting Techniques": [[17, null]], "Advanced Query Categorization": [[20, "advanced-query-categorization"]], "Advanced RAG (WIP)": [[19, null]], "Advanced quantization techniques": [[13, "advanced-quantization-techniques"]], "Agentic RAG": [[19, "agentic-rag"]], "Alignment Using RLHF": [[22, "alignment-using-rlhf"]], "Analysis of Documents": [[27, "analysis-of-documents"]], "Analysis of Queries": [[27, null]], "Appendix": [[21, "appendix"]], "Application in Information Retrieval": [[29, null]], "Application in RAG": [[3, "application-in-rag"]], "Application of LLM in IR (WIP)": [[3, null]], "Approach to Complex Multi-Concept Queries": [[20, "approach-to-complex-multi-concept-queries"]], "Approach to Multi-Turn Conversations": [[20, "approach-to-multi-turn-conversations"]], "Approach to Vocalbulary Mismatch": [[20, "approach-to-vocalbulary-mismatch"]], "Approximate Nearest Neighbor Search": [[5, "approximate-nearest-neighbor-search"]], "Approximate Non-exhaustive Nearest Neighbor Search": [[5, "approximate-non-exhaustive-nearest-neighbor-search"]], "Approximate Representation And Storage": [[5, "approximate-representation-and-storage"]], "Approximate nearest neighbor search": [[4, "approximate-nearest-neighbor-search"]], "Approximate non-exhaustive nearest neighbor search": [[4, "approximate-non-exhaustive-nearest-neighbor-search"]], "Approximate representation and storage": [[4, "approximate-representation-and-storage"]], "Approximating Distances Using Quantized Codes": [[5, "approximating-distances-using-quantized-codes"], [5, "id66"]], "Approximating distances using quantized codes": [[4, "approximating-distances-using-quantized-codes"], [4, "id80"]], "Architecture": [[2, "architecture"], [4, "architecture"], [4, "id88"]], "Arithmetic tasks": [[6, "arithmetic-tasks"]], "Attention Layer": [[30, "attention-layer"], [31, "attention-layer"], [33, "attention-layer"], [34, "attention-layer"], [36, "attention-layer"]], "Attention and FFN": [[32, "attention-and-ffn"], [35, "attention-and-ffn"]], "BART": [[10, "bart"]], "BERT": [[7, null]], "BERT Architecture": [[7, "bert-architecture"]], "BERT Architecture Componenents": [[7, "bert-architecture-componenents"]], "BERT bi-encoder and BM25": [[4, "bert-bi-encoder-and-bm25"]], "BERT model parameters": [[7, "id1594"]], "BLIP": [[16, "blip"]], "BLIP-2": [[16, "blip-2"]], "BM25": [[4, "bm25"], [5, "bm25"]], "BM25 Implementation": [[5, "bm25-implementation"]], "BPE Tokenization": [[1, "bpe-tokenization"]], "Base LLM vs Instructed LLM": [[18, "base-llm-vs-instructed-llm"]], "Basic Concepts": [[13, "basic-concepts"]], "Basic Prompting": [[18, null]], "Basic RAG": [[20, "basic-rag"]], "Basics": [[4, "basics"], [13, "basics"], [14, "basics"], [23, "basics"]], "Beam search decoding": [[14, "beam-search-decoding"]], "Benchmark Datasets": [[5, "benchmark-datasets"]], "Benchmark datasets": [[4, "benchmark-datasets"]], "Benchmarking": [[8, "benchmarking"]], "Bi-encoder Teacher Distillation": [[5, "bi-encoder-teacher-distillation"]], "Bibliography": [[1, "bibliography"], [2, "bibliography"], [4, "bibliography"], [5, "bibliography"], [6, "bibliography"], [7, "bibliography"], [8, "bibliography"], [9, "bibliography"], [10, "bibliography"], [11, "bibliography"], [12, "bibliography"], [13, "bibliography"], [14, "bibliography"], [16, "bibliography"], [17, "bibliography"], [18, "bibliography"], [19, "bibliography"], [20, "bibliography"], [21, "bibliography"], [22, "bibliography"], [23, "bibliography"], [25, "bibliography"]], "Blender": [[4, "blender"]], "Blocked KV Caching via Paged Attention": [[13, "blocked-kv-caching-via-paged-attention"]], "Bootstraping Instruction Finetuning": [[23, "bootstraping-instruction-finetuning"]], "Building a language model": [[4, "building-a-language-model"]], "Building an Error Model": [[4, "building-an-error-model"]], "Building models": [[4, "building-models"]], "CLEAR": [[4, "clear"]], "CLIP": [[16, "clip"]], "CNN-DSSM": [[4, "cnn-dssm"], [5, "cnn-dssm"]], "COIL": [[4, "coil"]], "COIL-token and uni-COIL": [[4, "coil-token-and-uni-coil"]], "Candidate generation": [[4, "candidate-generation"], [4, "id89"]], "Chain-of-Thought (CoT) Prompting": [[18, "chain-of-thought-cot-prompting"]], "Challenges": [[20, "challenges"]], "Challenges And Opportunities In IR Systems": [[5, "challenges-and-opportunities-in-ir-systems"]], "Challenges and approaches": [[4, "challenges-and-approaches"]], "Challenges and opportunities in IR systems": [[4, "challenges-and-opportunities-in-ir-systems"]], "Char-level N grams": [[4, "char-level-n-grams"]], "Choice Shuffling Ensembling": [[17, "choice-shuffling-ensembling"]], "Choices Of n and Bias-variance Trade-off": [[8, "choices-of-n-and-bias-variance-trade-off"]], "Classic Representation-based Learning": [[5, "classic-representation-based-learning"]], "Classic interaction-based matching": [[4, "classic-interaction-based-matching"]], "Classic representation-based learning": [[4, "classic-representation-based-learning"]], "Classic semantic dense retrieval models": [[4, "classic-semantic-dense-retrieval-models"]], "Closed-book question answering": [[6, "closed-book-question-answering"]], "CoRT": [[4, "cort"]], "CoT with Self-Consistency": [[17, "cot-with-self-consistency"]], "ColBERT": [[4, "colbert"], [5, "colbert"]], "Collections": [[3, "collections"]], "Combined Together: Adam and AdamW": [[25, "combined-together-adam-and-adamw"]], "Combined with GQA": [[13, "combined-with-gqa"]], "Combining Together Example: Med Prompt": [[17, "combining-together-example-med-prompt"]], "Common Sense Reasoning": [[6, "common-sense-reasoning"]], "Communication volumne summary for different operations. Let \\Phi be the total data size in one device and N be the total number of devices.": [[21, "id1572"]], "Compared with ELMO": [[7, "compared-with-elmo"]], "Comparison of pre-training objectives. Performance varies considerably across tasks, but the BART models with text infilling demonstrate the most consistently strong performance. .": [[10, "id1573"]], "Comparison with Recurrent Layer in Sequence Modeling": [[11, "comparison-with-recurrent-layer-in-sequence-modeling"]], "Comparison with other approaches": [[23, "comparison-with-other-approaches"]], "Comparison with recommender system": [[4, "comparison-with-recommender-system"]], "Computation breakdown": [[1, "id1597"], [13, "id1578"]], "Computational Breakdown Analysis": [[11, "computational-breakdown-analysis"]], "Computational Efficiency": [[5, "computational-efficiency"]], "Computational complexity": [[14, "computational-complexity"]], "Computational cost with KV Cache": [[13, "computational-cost-with-kv-cache"]], "Computational efficiency": [[4, "computational-efficiency"]], "Context specific features": [[4, "context-specific-features"]], "Context-aware Term Importance: Deep-CT": [[5, "context-aware-term-importance-deep-ct"]], "Context-aware term importance: Deep-CT": [[4, "context-aware-term-importance-deep-ct"]], "Context-dependent and personalized search": [[4, "context-dependent-and-personalized-search"]], "Contextualized Term Importance": [[5, "contextualized-term-importance"]], "Contextualized sparse representation": [[4, "contextualized-sparse-representation"]], "Contextualized term importance": [[4, "contextualized-term-importance"]], "Continued Pretraining": [[25, "continued-pretraining"]], "Controling beam search behavior": [[14, "controling-beam-search-behavior"]], "Corrective RAG (CRAG)": [[19, "corrective-rag-crag"]], "Cross-Encoder Embedding Similarity Distillation": [[5, "cross-encoder-embedding-similarity-distillation"]], "DC-BERT": [[4, "dc-bert"], [5, "dc-bert"]], "DPO": [[22, "dpo"]], "DPO Variants": [[22, "dpo-variants"]], "DPO-Positive": [[22, "dpo-positive"]], "DRMM": [[4, "drmm"]], "DSSM": [[4, "dssm"], [5, "dssm"]], "Data": [[32, "data"], [33, "data"], [34, "data"], [35, "data"]], "Data Source Augmentation": [[20, "data-source-augmentation"]], "Data mixture and schedule": [[25, "data-mixture-and-schedule"]], "Data sources and cleaning": [[25, "data-sources-and-cleaning"]], "Datasets": [[8, "datasets"]], "Decoder Anatomy": [[11, "decoder-anatomy"]], "Decoder for language modeling": [[30, "decoder-for-language-modeling"], [31, "decoder-for-language-modeling"], [33, "decoder-for-language-modeling"], [34, "decoder-for-language-modeling"], [36, "decoder-for-language-modeling"]], "Decoding": [[14, null]], "Decoding Fundamentals": [[14, "decoding-fundamentals"]], "DeepSeek MoE": [[2, "deepseek-moe"]], "DeepSeek V3": [[2, "deepseek-v3"]], "Dense Architecture Examples": [[1, "dense-architecture-examples"]], "Detailed Implementations": [[16, "detailed-implementations"]], "Different Branches Of Developments": [[11, "different-branches-of-developments"]], "Different factors to consider when choosing among prompting, fine-tuning, and RAG.": [[20, "id1582"]], "Discussion": [[4, "discussion"]], "Discussion: DPO vs RL": [[22, "discussion-dpo-vs-rl"]], "Discussion: Reward Model Criticality": [[22, "discussion-reward-model-criticality"]], "Discussion: SFT vs RLHF": [[22, "discussion-sft-vs-rlhf"]], "DistillBERT": [[7, "distillbert"]], "Distributed Parallel Training": [[21, "distributed-parallel-training"]], "Diversity Optimization": [[20, "diversity-optimization"]], "Doc-Doc N-pair Loss": [[5, "doc-doc-n-pair-loss"]], "Document Chunk Relationship": [[20, "document-chunk-relationship"]], "Document Expansion Via Query Prediction": [[5, "document-expansion-via-query-prediction"]], "Document Parsing": [[20, "document-parsing"]], "Document Ranking Task": [[4, "document-ranking-task"], [5, "document-ranking-task"]], "Document Splitting and Granularity": [[20, "document-splitting-and-granularity"]], "Document expansion via query prediction": [[4, "document-expansion-via-query-prediction"]], "Document offline ranking": [[4, "document-offline-ranking"]], "Document selection": [[4, "document-selection"], [4, "id76"]], "Document selection overview": [[4, "document-selection-overview"]], "Document specific features": [[4, "document-specific-features"]], "Document term generation": [[4, "document-term-generation"]], "Downstream Application": [[16, "downstream-application"]], "Driving the DPO": [[22, "driving-the-dpo"]], "Dual Chunk Attention": [[1, "dual-chunk-attention"]], "Duet": [[4, "duet"]], "Duo-BERT For Pairwise Ranking": [[5, "duo-bert-for-pairwise-ranking"]], "Duo-BERT for pairwise ranking": [[4, "duo-bert-for-pairwise-ranking"]], "Dynamic Hard Negative Examples": [[5, "dynamic-hard-negative-examples"]], "Dynamic In-Context Learning": [[17, "dynamic-in-context-learning"]], "Dynamic hard negative examples": [[4, "dynamic-hard-negative-examples"]], "Early Neural Language Models": [[9, null]], "Efficient BERT Models": [[7, "efficient-bert-models"]], "Embedding-based approach": [[4, "embedding-based-approach"]], "Encoder Computation Summary": [[11, "encoder-computation-summary"]], "Enhancing sparse IR via dense methods": [[4, "enhancing-sparse-ir-via-dense-methods"]], "Enriching document representations": [[4, "enriching-document-representations"]], "Enriching query representations": [[4, "enriching-query-representations"]], "Ensemble Teacher Distillation": [[5, "ensemble-teacher-distillation"]], "Ensemble teacher distillation": [[4, "ensemble-teacher-distillation"]], "Evaluation Metrics": [[8, "evaluation-metrics"]], "Exact Match And Semantic Match": [[5, "exact-match-and-semantic-match"]], "Exact Match Framework": [[5, "exact-match-framework"]], "Exact match and semantic match": [[4, "exact-match-and-semantic-match"]], "Example Distillation Strategies": [[5, "example-distillation-strategies"]], "Example distillation strategies": [[4, "example-distillation-strategies"]], "Examples of five types of semantic relationships.": [[12, "id1576"]], "Examples of nine types of syntactic relationships.": [[12, "id1577"]], "Extending Context Windows via RoPE": [[1, "extending-context-windows-via-rope"]], "FFN Layer": [[30, "ffn-layer"], [31, "ffn-layer"], [33, "ffn-layer"], [34, "ffn-layer"], [36, "ffn-layer"]], "FP8": [[13, "fp8"]], "False Negatives": [[5, "false-negatives"]], "False Positives": [[5, "false-positives"]], "False negatives": [[4, "false-negatives"]], "False positives": [[4, "false-positives"]], "Feature engineering": [[4, "feature-engineering"]], "Feed-forward Neural Language Model": [[9, "feed-forward-neural-language-model"]], "Few-shot and in-context learning": [[18, "few-shot-and-in-context-learning"]], "Fine-tuning and Evaluation": [[7, "fine-tuning-and-evaluation"]], "Finite-state MDP": [[24, "finite-state-mdp"]], "Floating Data Types": [[21, "floating-data-types"]], "Forward Pass Computation Breadown": [[1, "forward-pass-computation-breadown"]], "Framework": [[4, "framework"]], "From BPE to BBPE": [[1, "from-bpe-to-bbpe"]], "From Vector Quantization To Product Quantization": [[5, "from-vector-quantization-to-product-quantization"]], "From vector quantization to product quantization": [[4, "from-vector-quantization-to-product-quantization"]], "Fundamentals": [[20, "fundamentals"], [25, "fundamentals"]], "Further RAG Discussion": [[20, "further-rag-discussion"]], "GEFEED (Retrieval Feedback)": [[3, "gefeed-retrieval-feedback"]], "GPT Series": [[6, null]], "GPT-1": [[6, "gpt-1"]], "GPT-1 Fine Tuning": [[6, "gpt-1-fine-tuning"]], "GPT-2": [[6, "gpt-2"]], "GPT-3": [[6, "gpt-3"]], "GPT-3-175B with different adaptation methods on the language understanding benchmark.": [[23, "id1588"]], "GPTQ": [[13, "gptq"]], "GPU Memory Allocation": [[21, "gpu-memory-allocation"]], "GPU Parallel Operations": [[21, "gpu-parallel-operations"]], "General Case": [[13, "general-case"]], "Generative SERP": [[3, "generative-serp"]], "GloVe": [[12, "glove"]], "Graph-based Retrieval": [[19, "graph-based-retrieval"]], "GraphRAG": [[19, "graphrag"]], "Greedy decoding": [[14, "greedy-decoding"]], "Grouped Query Attention (GQA)": [[1, "grouped-query-attention-gqa"]], "Groupwise quantization": [[13, "groupwise-quantization"]], "Hard Positives": [[5, "hard-positives"]], "Hierarchical Quantization And Inverted File Indexing": [[5, "hierarchical-quantization-and-inverted-file-indexing"]], "Hierarchical quantization and inverted file indexing": [[4, "hierarchical-quantization-and-inverted-file-indexing"]], "How labeler evaluates the response quality": [[22, "id1587"]], "Human accuracy in identifying whether short (around 200 word) news articles are model generated.": [[6, "id1571"]], "Hybrid retrieval models": [[4, "hybrid-retrieval-models"]], "Indexing Data Sources": [[20, "indexing-data-sources"]], "Indexing and serving": [[4, "indexing-and-serving"]], "Indexing tokens": [[4, "indexing-tokens"]], "Inference Acceleration (WIP)": [[13, null]], "Inference Memory Requirement with KV Cache": [[13, "inference-memory-requirement-with-kv-cache"]], "Information Retrieval and Text Ranking": [[5, null]], "Information retrieval and neural matching": [[4, "information-retrieval-and-neural-matching"]], "Input Embeddings": [[7, "input-embeddings"]], "Input Output Conventions": [[11, "input-output-conventions"]], "Instruct BLIP": [[16, "instruct-blip"]], "Instruction Finetuning": [[23, "instruction-finetuning"]], "Insturction Finetuning Loss Functions": [[23, "insturction-finetuning-loss-functions"]], "Introduction": [[4, "introduction"], [4, "id43"], [4, "id59"], [4, "id83"], [4, "id85"], [4, "id90"], [5, "introduction"], [5, "id53"], [6, "introduction"], [6, "id4"], [7, "introduction"], [7, "id19"], [16, "introduction"], [29, null]], "Introduction: LLM in the Age of AI": [[0, null]], "Inverted file indexing and non exhaustive search": [[4, "inverted-file-indexing-and-non-exhaustive-search"]], "Inverted index": [[4, "inverted-index"]], "Inverted indexing": [[4, "inverted-indexing"]], "Inverted indexing construction": [[4, "inverted-indexing-construction"]], "Iterative Alignment": [[22, "iterative-alignment"]], "KNRM": [[4, "knrm"]], "KV Cache": [[13, "kv-cache"]], "Katz\u2019s Back-off": [[8, "katz-s-back-off"]], "Key Componenents": [[2, "key-componenents"]], "Key Design": [[19, "key-design"]], "Knowledge Distillation": [[5, "knowledge-distillation"]], "Knowledge Distillation Training Framework": [[5, "knowledge-distillation-training-framework"]], "Knowledge Extraction": [[19, "knowledge-extraction"]], "Knowledge distillation": [[4, "knowledge-distillation"]], "Knowledge distillation training framework": [[4, "knowledge-distillation-training-framework"]], "LLM Alignement and Preference Learning": [[22, null]], "LLM Architectures": [[29, null]], "LLM Architectures Fundamentals": [[1, null]], "LLM Embedding Model": [[3, "llm-embedding-model"]], "LLM Finetuning": [[23, null]], "LLM Foundations": [[29, null]], "LLM Inference": [[29, null]], "LLM Model": [[32, "llm-model"], [35, "llm-model"]], "LLM Training": [[29, null]], "LLM Training Acceleration (WIP)": [[21, null]], "LLM Training Fundamentals": [[25, null]], "LLM.int8()": [[13, "llm-int8"]], "LLama Decoder Layer": [[30, "llama-decoder-layer"], [31, "llama-decoder-layer"], [33, "llama-decoder-layer"], [34, "llama-decoder-layer"], [36, "llama-decoder-layer"]], "LLama-2 Alignment in Practice": [[22, "llama-2-alignment-in-practice"]], "L_2 Weight Decay and AdamW": [[25, "l-2-weight-decay-and-adamw"]], "Label Denoising": [[5, "label-denoising"]], "Label denoising": [[4, "label-denoising"]], "LambdaNet": [[4, "lambdanet"]], "Language Models": [[8, null]], "Language Understanding Tasks": [[10, "language-understanding-tasks"]], "Language modeling": [[6, "language-modeling"]], "Language models for speller": [[4, "language-models-for-speller"]], "Language-model based approach": [[4, "language-model-based-approach"]], "Large-Scale Negatives": [[5, "large-scale-negatives"]], "Layer Normalization": [[1, "layer-normalization"]], "Layer normalization basics": [[1, "layer-normalization-basics"]], "Layer normalization example choices": [[1, "layer-normalization-example-choices"]], "Layer normalization position": [[1, "layer-normalization-position"]], "Learnable context-aware term importance: Deep-Impact": [[4, "learnable-context-aware-term-importance-deep-impact"]], "Learning to rank candidates": [[4, "learning-to-rank-candidates"]], "Learning-to-rank objective": [[4, "learning-to-rank-objective"]], "Links": [[28, "links"]], "LoRA (Low-Rank Adaptation)": [[23, "lora-low-rank-adaptation"]], "Load Balance Consideration": [[2, "load-balance-consideration"]], "Load Balancing": [[2, "load-balancing"]], "Load Balancing Loss": [[2, "load-balancing-loss"]], "Loss-Free Load Balanace": [[2, "loss-free-load-balanace"]], "ME-BERT": [[4, "me-bert"]], "MS MARCO": [[4, "ms-marco"], [5, "ms-marco"]], "MTP": [[2, "mtp"]], "Machine Translation": [[6, "machine-translation"]], "Markov Decision Process (MDP) and Reinforcement learning": [[22, "markov-decision-process-mdp-and-reinforcement-learning"]], "Masked Language Modeling (Masked LM)": [[7, "masked-language-modeling-masked-lm"]], "Mean Average Precision": [[4, "id9"]], "Mean average precision": [[4, "mean-average-precision"]], "Mean reciprocal rank (MRR)": [[4, "mean-reciprocal-rank-mrr"]], "Memory Requirement Breakdown": [[13, "memory-requirement-breakdown"]], "Memory requirement breakdown": [[13, "id1577"]], "Metrics": [[4, "metrics"]], "MiniLM": [[7, "minilm"]], "Minibatch Stochastic Gradient Descent": [[25, "minibatch-stochastic-gradient-descent"]], "Mixed Precision Training": [[21, "mixed-precision-training"]], "MoE Sparse Architectures (WIP)": [[2, null]], "MoE architecture fundamentals": [[2, "moe-architecture-fundamentals"]], "MoE vs Dense Model": [[2, "moe-vs-dense-model"]], "MobileBERT": [[7, "mobilebert"]], "Model Architecture": [[16, "model-architecture"], [16, "id6"], [32, "model-architecture"], [35, "model-architecture"]], "Model Distillation": [[7, "model-distillation"]], "Model Evaluation": [[8, "model-evaluation"]], "Model Fine Tuning": [[10, "model-fine-tuning"]], "Model Finetuning": [[20, "model-finetuning"]], "Model Parameter Estimation": [[8, "model-parameter-estimation"]], "Model Training Objective Functions": [[5, "model-training-objective-functions"]], "Model and Optimizer States": [[21, "model-and-optimizer-states"]], "Model architecture and training": [[4, "model-architecture-and-training"]], "Model configuration of Qwen2 and Mistral, which uses GQA (# KV heads is number of groups )": [[1, "id1595"]], "Model parallelism (tensor parallelism)": [[21, "model-parallelism-tensor-parallelism"]], "Model training objective functions": [[4, "model-training-objective-functions"]], "Modern IR Systems": [[4, "modern-ir-systems"], [5, "modern-ir-systems"]], "Momentum Method": [[25, "momentum-method"]], "Mono T5": [[4, "mono-t5"]], "Mono-BERT (Cross-Encoder) For Point-wise Ranking": [[5, "mono-bert-cross-encoder-for-point-wise-ranking"]], "Mono-BERT And Duo-BERT": [[5, "mono-bert-and-duo-bert"]], "Mono-BERT for point-wise ranking": [[4, "mono-bert-for-point-wise-ranking"]], "More On Perplexity": [[8, "more-on-perplexity"]], "Motivation": [[1, "motivation"], [2, "motivation"], [4, "motivation"], [4, "id58"], [4, "id67"], [4, "id69"], [5, "motivation"], [8, "motivation"], [9, "motivation"], [19, "motivation"], [20, "motivation"], [20, "id8"], [23, "motivation"]], "Motivation and Objective": [[20, "motivation-and-objective"]], "Motivation and Overview": [[22, "motivation-and-overview"], [23, "motivation-and-overview"]], "Motivations": [[4, "motivations"]], "Multi Query Attention (MQA)": [[1, "multi-query-attention-mqa"]], "Multi-Attribute and Multi-task Modeling": [[5, "multi-attribute-and-multi-task-modeling"]], "Multi-Head Attention (MHA)": [[1, "multi-head-attention-mha"]], "Multi-teacher distillation": [[4, "multi-teacher-distillation"]], "Multi-vector Representations": [[5, "multi-vector-representations"]], "Multi-vector representations": [[4, "multi-vector-representations"]], "Multihead Attention with Masks": [[11, "multihead-attention-with-masks"]], "Multilingual Models": [[7, "multilingual-models"]], "Multilingual-BERT (mBERT)": [[7, "multilingual-bert-mbert"]], "Multimodality fundamentals": [[15, null]], "Multiple Token Prediction": [[25, "multiple-token-prediction"]], "Multiple streams and BM25F": [[4, "multiple-streams-and-bm25f"]], "Multistage Retrieval And Ranking Pipeline": [[5, "multistage-retrieval-and-ranking-pipeline"]], "Multistage retrieval and ranking pipeline": [[4, "multistage-retrieval-and-ranking-pipeline"]], "N-pair Dual Loss": [[5, "n-pair-dual-loss"]], "N-pair Loss": [[5, "n-pair-loss"]], "N-pair dual loss": [[4, "n-pair-dual-loss"]], "N-pair loss": [[4, "n-pair-loss"]], "NTK-Aware RoPE": [[1, "ntk-aware-rope"]], "NTK-by-parts and YaRN": [[1, "ntk-by-parts-and-yarn"]], "NV-Embed": [[3, "nv-embed"]], "Natural Language Queries": [[3, "natural-language-queries"]], "Natural Question (NQ)": [[4, "natural-question-nq"], [5, "natural-question-nq"]], "Negative Sampling Methods I: Heuristic Methods": [[5, "negative-sampling-methods-i-heuristic-methods"]], "Negative Sampling Methods II: Model-based Methods": [[5, "negative-sampling-methods-ii-model-based-methods"]], "Negative sampling methods I: heuristic methods": [[4, "negative-sampling-methods-i-heuristic-methods"]], "Negative sampling methods II: model-based methods": [[4, "negative-sampling-methods-ii-model-based-methods"]], "Neural pseudo relevance feedback (NPRF)": [[4, "neural-pseudo-relevance-feedback-nprf"]], "Neural sparse representation learning model": [[4, "neural-sparse-representation-learning-model"]], "Neural text ranking and information retrieval": [[4, null]], "News article generation": [[6, "news-article-generation"]], "Next Sentence Prediction (NSP)": [[7, "next-sentence-prediction-nsp"]], "Noise Contrastive Estimation}": [[12, "noise-contrastive-estimation"]], "Nonlinearity in FFN": [[1, "nonlinearity-in-ffn"]], "Normalized Discounted Cumulative Gain (NDCG)": [[5, "normalized-discounted-cumulative-gain-ndcg"]], "Normalized discounted cumulative gain (NDCG)": [[4, "normalized-discounted-cumulative-gain-ndcg"]], "Notations": [[24, "notations"]], "Note On Bibliography And Software": [[5, "note-on-bibliography-and-software"]], "Note on bibliography and software": [[4, "note-on-bibliography-and-software"]], "Offline computation and indexing for re-ranking and retrieval": [[4, "offline-computation-and-indexing-for-re-ranking-and-retrieval"]], "Online Metrics": [[5, "online-metrics"]], "Online metrics": [[4, "online-metrics"]], "Online query processing": [[4, "online-query-processing"]], "Open-domain Question Answering": [[5, "open-domain-question-answering"]], "Open-domain question answering": [[4, "open-domain-question-answering"]], "Optimization Algorithms": [[25, "optimization-algorithms"]], "Optimization I: negative sampling": [[12, "optimization-i-negative-sampling"]], "Optimization II: down-sampling of frequent words": [[12, "optimization-ii-down-sampling-of-frequent-words"]], "Out Of Vocabulary (OOV) Words and Rare Words": [[8, "out-of-vocabulary-oov-words-and-rare-words"]], "Overall Architecture": [[11, "overall-architecture"]], "Overall architecture": [[4, "overall-architecture"]], "Overall methodology": [[22, "overall-methodology"]], "Overview": [[1, "overview"], [2, "overview"], [4, "overview"], [4, "id20"], [4, "id25"], [4, "id47"], [4, "id74"], [4, "id77"], [4, "id78"], [4, "id92"], [5, "overview"], [5, "id56"], [5, "id64"], [10, "overview"], [10, "id3"], [11, "overview"], [12, "overview"], [13, "overview"], [16, "overview"], [21, "overview"], [22, "overview"], [22, "id19"], [24, "overview"]], "Overview of Information Retrieval": [[5, "overview-of-information-retrieval"]], "Overview of information retrieval": [[4, "overview-of-information-retrieval"]], "Overview of parallel training techniques": [[21, "overview-of-parallel-training-techniques"]], "Pairwise Ranking via Triplet Loss": [[5, "pairwise-ranking-via-triplet-loss"]], "Pairwise ranking objective": [[4, "pairwise-ranking-objective"]], "Pairwise ranking via triplet loss": [[4, "pairwise-ranking-via-triplet-loss"]], "Parameter composition in Transformer models": [[1, "parameter-composition-in-transformer-models"]], "Parameter-Efficient Fine Tuning (PEFT)": [[23, "parameter-efficient-fine-tuning-peft"]], "Parameters in a Transformer": [[1, "id1596"]], "Passage Ranking Task": [[4, "passage-ranking-task"], [5, "passage-ranking-task"]], "Performance Overview": [[6, "performance-overview"]], "Performance comparison among  supervised SOTA neural machine translation models, unsupervised multi-lingual pretrained language models, and GPT-3.": [[6, "id1572"]], "Performance of Step-Back prompting on MMLU tasks.": [[17, "id1571"]], "Phrase representation": [[4, "phrase-representation"]], "Pointwise FeedForward Layer": [[11, "pointwise-feedforward-layer"]], "Pointwise Ranking Objective": [[5, "pointwise-ranking-objective"]], "Pointwise Regression Objective": [[5, "pointwise-regression-objective"]], "Pointwise ranking objective": [[4, "pointwise-ranking-objective"]], "Pointwise regression objective": [[4, "pointwise-regression-objective"]], "Policy iteration": [[24, "policy-iteration"]], "Policy iteration and Value iteration": [[24, "policy-iteration-and-value-iteration"]], "Polyencoder": [[4, "polyencoder"]], "Popularity-based Negative Sampling": [[5, "popularity-based-negative-sampling"]], "Popularity-based negative sampling": [[4, "popularity-based-negative-sampling"]], "Position Encoding and Long Context": [[1, "position-encoding-and-long-context"]], "Position Encodings": [[11, "position-encodings"]], "Position Interpolation for RoPE": [[1, "position-interpolation-for-rope"]], "Practical searching and ranking": [[4, "practical-searching-and-ranking"]], "Pre-trained language models": [[4, "pre-trained-language-models"]], "Pre-training": [[10, "pre-training"]], "Pre-training Tasks": [[7, "pre-training-tasks"]], "Precision And Recall": [[5, "precision-and-recall"]], "Precision and recall": [[4, "precision-and-recall"]], "Preference Data Collection": [[22, "preference-data-collection"]], "Preference Data and Reward Modeling": [[22, "preference-data-and-reward-modeling"]], "Preference Learning": [[33, "preference-learning"]], "Prefix-tuning": [[23, "prefix-tuning"]], "Preliminary: Preference modeling": [[22, "preliminary-preference-modeling"]], "Pretrained Language Models": [[11, "pretrained-language-models"]], "Pretraining": [[6, "pretraining"], [10, "pretraining"], [25, "pretraining"]], "Pretraining performance analysis": [[10, "pretraining-performance-analysis"]], "Principles": [[4, "principles"], [5, "principles"]], "Probabilistic Naive Bayes retrieval": [[4, "probabilistic-naive-bayes-retrieval"]], "Problem statement": [[4, "problem-statement"]], "Product Quantization": [[5, "product-quantization"]], "Product quantization": [[4, "product-quantization"]], "Prompt Compression": [[13, "prompt-compression"]], "Prompt Tuning": [[23, "prompt-tuning"]], "Prompting": [[20, "prompting"], [29, null]], "Prompting Lab": [[36, null]], "Properties of RoPE": [[1, "properties-of-rope"]], "Pseudo relevance feedback": [[4, "pseudo-relevance-feedback"]], "Put It Together": [[7, "put-it-together"]], "QW papers": [[4, "qw-papers"]], "Quantization Fundamentals": [[13, "quantization-fundamentals"]], "Quantization granularities": [[13, "quantization-granularities"]], "Quantization-performance trade-off in language models": [[13, "quantization-performance-trade-off-in-language-models"]], "Quantized matrix multiplication": [[13, "quantized-matrix-multiplication"]], "Query Categorization": [[3, "query-categorization"]], "Query Optimization Overview": [[3, "query-optimization-overview"]], "Query Rewriting": [[4, "id82"]], "Query Understanding & Optimization": [[3, "query-understanding-optimization"]], "Query Understanding And Rewriting": [[5, "query-understanding-and-rewriting"]], "Query and Document Expansion": [[5, "query-and-document-expansion"]], "Query and document expansion": [[4, "query-and-document-expansion"]], "Query expansion": [[4, "query-expansion"]], "Query preprocessing": [[4, "query-preprocessing"]], "Query relaxation": [[4, "query-relaxation"]], "Query rewriting": [[4, "query-rewriting"], [4, "id91"]], "Query scoping": [[4, "query-scoping"]], "Query segmentation": [[4, "query-segmentation"]], "Query similarity from Query-URL bipartite graph method": [[4, "query-similarity-from-query-url-bipartite-graph-method"]], "Query suggestion": [[4, "query-suggestion"]], "Query understanding": [[4, "query-understanding"], [4, "id81"]], "Query understanding and rewriting": [[4, "query-understanding-and-rewriting"], [4, "id75"]], "Query-Doc Ranking": [[3, "query-doc-ranking"]], "Query-document feature": [[4, "query-document-feature"]], "RAFT: Retrieval Augmented Fine Tuning": [[20, "raft-retrieval-augmented-fine-tuning"]], "RAG": [[20, null]], "RAG Challenges in Practice": [[20, "rag-challenges-in-practice"]], "RAG Evaluation": [[20, "rag-evaluation"]], "RAG Frameworks": [[20, "rag-frameworks"]], "RAG Optimization: Document Understanding": [[20, "rag-optimization-document-understanding"]], "RAG Optimization: LLM Understanding & Generation": [[20, "rag-optimization-llm-understanding-generation"]], "RAG Optimization: Query Understanding and Rewriting": [[20, "rag-optimization-query-understanding-and-rewriting"]], "RAG Optimization: Retriever and ReRanker": [[20, "rag-optimization-retriever-and-reranker"]], "RAG Optimizations": [[20, "rag-optimizations"]], "RAG and Agents": [[29, null]], "RAG vs Long Context LLM": [[20, "rag-vs-long-context-llm"]], "RAG vs Prompting and Fine Tuning": [[20, "rag-vs-prompting-and-fine-tuning"]], "RM3": [[4, "rm3"]], "RMS Norm": [[30, "rms-norm"], [31, "rms-norm"], [33, "rms-norm"], [34, "rms-norm"], [36, "rms-norm"]], "RMS Norm (Root Mean Square Norm)": [[1, "rms-norm-root-mean-square-norm"]], "RMSProp": [[25, "rmsprop"]], "Random Negatives and In-batch Negatives": [[5, "random-negatives-and-in-batch-negatives"]], "Random negatives and in-batch negatives": [[4, "random-negatives-and-in-batch-negatives"]], "Rank List Generation": [[3, "rank-list-generation"]], "RankNet": [[4, "ranknet"]], "Ranker": [[4, "ranker"]], "Ranker Distillation": [[3, "ranker-distillation"]], "Ranker Training": [[5, "ranker-training"]], "Ranking features": [[4, "ranking-features"]], "Ranking model training": [[4, "ranking-model-training"]], "Recurrent Neural Language Model": [[9, "recurrent-neural-language-model"]], "Reinforcement learning framework": [[24, "reinforcement-learning-framework"]], "Relevance scoring scheme": [[4, "relevance-scoring-scheme"]], "Retrieval Data Sources": [[20, "id1580"], [20, "id1581"]], "Retrieval Model Enhancement": [[20, "retrieval-model-enhancement"]], "Retrieval Result Quality Control": [[20, "retrieval-result-quality-control"]], "Retrieval results based on exact matching methods and semantic matching methods.": [[5, "id1639"]], "Reward Modeling": [[22, "reward-modeling"]], "RoBERT with different adaptation methods on the language understanding GLUE benchmark.": [[23, "id1587"]], "Robustness To Document Variations": [[5, "robustness-to-document-variations"]], "Robustness to document variations": [[4, "robustness-to-document-variations"]], "Rotary Postion Embedding": [[1, "rotary-postion-embedding"]], "Rotory Embedding": [[30, "rotory-embedding"], [31, "rotory-embedding"], [33, "rotory-embedding"], [34, "rotory-embedding"], [36, "rotory-embedding"]], "SNRM": [[4, "snrm"]], "SVD based word embeddings": [[12, "svd-based-word-embeddings"]], "Sample Efficient: ELECTRA": [[7, "sample-efficient-electra"]], "Scaling Instruction Finetuning": [[23, "scaling-instruction-finetuning"]], "Scaling Law for Fine Tuning": [[23, "scaling-law-for-fine-tuning"]], "Score fusion": [[4, "score-fusion"]], "Scoring": [[4, "scoring"]], "Searcher-document features": [[4, "searcher-document-features"]], "Self-Generated CoT": [[17, "self-generated-cot"]], "Self-Reflective RAG (SELF-RAG)": [[19, "self-reflective-rag-self-rag"]], "Self-attention Variants": [[1, "self-attention-variants"]], "Semantic Clusters As Pseudo Query Embeddings": [[5, "semantic-clusters-as-pseudo-query-embeddings"]], "Semantic Dense Models": [[5, "semantic-dense-models"]], "Semantic clusters as pseudo query embeddings": [[4, "semantic-clusters-as-pseudo-query-embeddings"]], "Semantic match": [[4, "semantic-match"]], "Seq2Seq: T5 and BART": [[10, null]], "Sequence-to-sequence learning": [[4, "sequence-to-sequence-learning"]], "Simple DPO": [[22, "simple-dpo"]], "Simple score interpolation": [[4, "simple-score-interpolation"]], "Single bi-encoder teacher distillation": [[4, "single-bi-encoder-teacher-distillation"]], "Single cross-encoder teacher distillation": [[4, "single-cross-encoder-teacher-distillation"]], "Sites": [[28, "sites"]], "Sliding Window Attention": [[1, "sliding-window-attention"]], "Smooth Quant": [[13, "smooth-quant"]], "Smoothing and Discounting Techniques": [[8, "smoothing-and-discounting-techniques"]], "Smoothing preference label": [[22, "smoothing-preference-label"]], "Software": [[4, "software"], [5, "software"]], "SparTerm": [[4, "sparterm"]], "Sparse IR serving": [[4, "sparse-ir-serving"]], "Special case: unigram language model": [[8, "special-case-unigram-language-model"]], "Speed-Up Hessian Computation": [[13, "speed-up-hessian-computation"]], "Speical Case: Diagonal Hessian Assumption": [[13, "speical-case-diagonal-hessian-assumption"]], "Speller": [[4, "speller"]], "Speller error type": [[4, "speller-error-type"]], "Spelling correction": [[4, "spelling-correction"], [4, "id84"]], "Stacked Decoder layers": [[30, "stacked-decoder-layers"], [31, "stacked-decoder-layers"], [33, "stacked-decoder-layers"], [34, "stacked-decoder-layers"], [36, "stacked-decoder-layers"]], "Standard quantization techniques": [[13, "standard-quantization-techniques"]], "State-action Value function (Q function)": [[24, "state-action-value-function-q-function"]], "Static Hard Negative Examples": [[5, "static-hard-negative-examples"]], "Static hard negative examples": [[4, "static-hard-negative-examples"]], "Statistical Language Models": [[8, "statistical-language-models"]], "Step Back Prompting": [[17, "step-back-prompting"]], "Storage requirement for different components during LLM training using Adam.": [[21, "id1571"]], "Study Results": [[23, "study-results"]], "Subword model": [[12, "subword-model"]], "SuperGLUE": [[6, "superglue"]], "Switch Transformer": [[2, "switch-transformer"]], "T5": [[10, "t5"]], "TERC": [[4, "terc"], [5, "terc"]], "TERC-COVID": [[4, "terc-covid"]], "TF-IDF Vector Space Model": [[5, "tf-idf-vector-space-model"]], "TREC-CAR": [[4, "trec-car"], [5, "trec-car"]], "TREC-deep Learning Track": [[5, "trec-deep-learning-track"]], "TREC-deep learning track": [[4, "trec-deep-learning-track"]], "Table of Contents": [[29, null]], "Techniques to increasing Precision": [[4, "techniques-to-increasing-precision"]], "Techniques to increasing Recall": [[4, "techniques-to-increasing-recall"]], "Temperature-controlled sampling": [[14, "temperature-controlled-sampling"]], "Test Model": [[32, "test-model"], [35, "test-model"]], "Test model": [[31, "test-model"], [33, "test-model"], [34, "test-model"]], "Text Generation Tasks": [[10, "text-generation-tasks"]], "Text Ranking Evaluation Metrics": [[5, "text-ranking-evaluation-metrics"]], "Text ranking evaluation metrics": [[4, "text-ranking-evaluation-metrics"]], "The Decoder Branch": [[11, "the-decoder-branch"]], "The EXTREME Benchmark": [[7, "the-extreme-benchmark"]], "The Encoder Anatomy": [[7, "the-encoder-anatomy"]], "The Encoder Branch": [[11, "the-encoder-branch"]], "The Encoder-decoder Branch": [[11, "the-encoder-decoder-branch"]], "The Error Minimization Framework": [[13, "the-error-minimization-framework"]], "The Memory Requirement For Training LLM": [[21, "the-memory-requirement-for-training-llm"]], "The PPO Algorithm": [[22, "the-ppo-algorithm"]], "The Rise of Large Language Models": [[0, "the-rise-of-large-language-models"]], "The basics": [[14, "the-basics"]], "The exact match framework": [[4, "the-exact-match-framework"]], "The fundamental challenge of LLM inference": [[13, "the-fundamental-challenge-of-llm-inference"]], "The hyperparameter settings of various pretrained BERT configurations.  BERTBase and BERTLarge are the two most commonly used configurations today;": [[7, "id1593"]], "The hypothesis and method": [[23, "the-hypothesis-and-method"]], "The mechanism": [[1, "the-mechanism"]], "The model": [[4, "the-model"], [12, "the-model"]], "TinyBERT": [[7, "tinybert"]], "Token-level Multi-vector Representation": [[5, "token-level-multi-vector-representation"]], "Token-level multi-vector representation": [[4, "token-level-multi-vector-representation"]], "Tokenziation, vocabulary, and weight tying": [[1, "tokenziation-vocabulary-and-weight-tying"]], "Top-k and top-p sampling": [[14, "top-k-and-top-p-sampling"]], "Topic-aware Negative Sampling": [[5, "topic-aware-negative-sampling"]], "Topic-aware negative sampling": [[4, "topic-aware-negative-sampling"]], "Traditional Sparse IR Fundamentals": [[5, "traditional-sparse-ir-fundamentals"]], "Traditional query rewriting": [[4, "traditional-query-rewriting"]], "Traditional sparse IR fundamentals": [[4, "traditional-sparse-ir-fundamentals"]], "Training": [[32, "training"], [33, "training"], [34, "training"], [35, "training"]], "Training Data": [[5, "training-data"]], "Training Data Sampling Strategies": [[5, "training-data-sampling-strategies"]], "Training Entry": [[32, "training-entry"], [35, "training-entry"]], "Training Overview": [[25, "training-overview"]], "Training Process": [[21, "training-process"]], "Training Strategy": [[16, "training-strategy"], [16, "id10"]], "Training data": [[4, "training-data"]], "Training data sampling strategies": [[4, "training-data-sampling-strategies"]], "Transformer Layer": [[32, "transformer-layer"], [35, "transformer-layer"]], "Transformer architectures for retrieval and ranking": [[4, "transformer-architectures-for-retrieval-and-ranking"]], "Transformers": [[4, "transformers"], [11, null]], "Transformers Anatomy": [[11, "transformers-anatomy"]], "Tutorial": [[4, "tutorial"]], "Two Architecture Paradigms": [[5, "two-architecture-paradigms"]], "Two architecture paradigms": [[4, "two-architecture-paradigms"]], "Ultra-high dimensional BERT representation (UHD-BERT)": [[4, "ultra-high-dimensional-bert-representation-uhd-bert"]], "Unigram language model": [[4, "unigram-language-model"]], "Utilizing Knowledge Graph": [[20, "utilizing-knowledge-graph"]], "Validation accuracy on WikiSQL and MultiNLI with different rank r.": [[23, "id1589"]], "Value iteration": [[24, "value-iteration"]], "Vector Quantization": [[5, "vector-quantization"]], "Vector quantization": [[4, "vector-quantization"]], "Vector space model": [[4, "vector-space-model"]], "Vision LLM": [[29, null]], "Vision Language Pretraining": [[16, null]], "Visualization": [[12, "visualization"]], "Where quantization and dequant happen? What is the trade off": [[13, "where-quantization-and-dequant-happen-what-is-the-trade-off"]], "Why Transformers?": [[4, "why-transformers"], [5, "why-transformers"]], "Word Embeddings": [[12, null]], "Word hashing token size and collision numbers as a function of the vocabulary size and the type of letter ngrams.": [[5, "id1640"]], "Word level N grams": [[4, "word-level-n-grams"]], "Word-Embedding based model": [[4, "word-embedding-based-model"]], "Word2Vec": [[12, "word2vec"]], "XLM, XLM-R, And XLM-E": [[7, "xlm-xlm-r-and-xlm-e"]], "ZeRO Via DeepSpeed": [[21, "zero-via-deepspeed"]], "ZeRO-Stage-One": [[21, "zero-stage-one"]], "Zero-shot prompt": [[18, "zero-shot-prompt"]], "\\begin{example} Consider two queries and their retrieved document lists:\n$\n\t\\begin{aligned}\n\t\t&q_{1} \\rightarrow d_{1}, d_{2} \\\\\n\t\t&q_{2} \\rightarrow d_{3}, d_{4}, d_{5}\n\t\\end{aligned}\n\t\n\tAssuming only d_{2}, d_{3}, d_{5} are relevant document given their corresponding query. We have\n\t- \\mathrm{AP} of query 1: \\frac{1}{1} \\times\\left(\\frac{0}{1} \\times 0+\\frac{1}{2} \\times 1\\right)=\\frac{1}{2}$": [[4, "begin-example-consider-two-queries-and-their-retrieved-document-lists-begin-aligned-q-1-rightarrow-d-1-d-2-q-2-rightarrow-d-3-d-4-d-5-end-aligned-assuming-only-d-2-d-3-d-5-are-relevant-document-given-their-corresponding-query-we-have-mathrm-ap-of-query-1-frac-1-1-times-left-frac-0-1-times-0-frac-1-2-times-1-right-frac-1-2"]], "\\star Deriving The MLE": [[8, "star-deriving-the-mle"]], "markmap": [[28, null]], "n-gram Language Model": [[8, "n-gram-language-model"]]}, "docnames": ["docs/Introduction", "docs/chapter_LLM_arch/LLM_dense_architectures", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures", "docs/chapter_application_IR/application_LLM_in_IR", "docs/chapter_application_IR/conversion/neuralNetworkApplicationNLP_IRSearch", "docs/chapter_application_IR/information_retrieval_fundamentals", "docs/chapter_foundation/GPT_series", "docs/chapter_foundation/bert", "docs/chapter_foundation/language_models", "docs/chapter_foundation/neural_language_models", "docs/chapter_foundation/t5", "docs/chapter_foundation/transformers", "docs/chapter_foundation/word_embeddings", "docs/chapter_inference/inference_acceleration", "docs/chapter_inference/inference_fundamentals", "docs/chapter_multimodality/multimodality_fundamentals", "docs/chapter_multimodality/vision_transformers", "docs/chapter_prompt/advanced_prompt", "docs/chapter_prompt/basic_prompt", "docs/chapter_rag/advanced_rag", "docs/chapter_rag/basic_rag", "docs/chapter_training/accelerated_training", "docs/chapter_training/alignment", "docs/chapter_training/finetuning", "docs/chapter_training/reinforcement_learning", "docs/chapter_training/training_fundamentals", "docs/chapter_training/training_lab", "docs/img/chapter_application_IR/ApplicationIRSearch/DataExploration/data_explorer", "docs/img/chapter_application_IR/ApplicationIRSearch/DeepRetrievalModels/KNRM/test", "docs/index", "docs/notebooks/chapter_LLM_arch/annotated_llama", "docs/notebooks/chapter_LLM_arch/annotated_llama_custom", "docs/notebooks/chapter_LLM_training/annotated_instruction_tuning", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_DPO", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_finetuning", "docs/notebooks/chapter_LLM_training/annotated_pretraining", "docs/notebooks/chapter_prompt/prompting_lab", "docs/notebooks/chapter_rag/Graph_Rag", "docs/notebooks/chapter_rag/llamaIndexLearning/test"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["docs/Introduction.md", "docs/chapter_LLM_arch/LLM_dense_architectures.md", "docs/chapter_LLM_arch/LLM_moe_sparse_architectures.md", "docs/chapter_application_IR/application_LLM_in_IR.md", "docs/chapter_application_IR/conversion/neuralNetworkApplicationNLP_IRSearch.md", "docs/chapter_application_IR/information_retrieval_fundamentals.md", "docs/chapter_foundation/GPT_series.md", "docs/chapter_foundation/bert.md", "docs/chapter_foundation/language_models.md", "docs/chapter_foundation/neural_language_models.md", "docs/chapter_foundation/t5.md", "docs/chapter_foundation/transformers.md", "docs/chapter_foundation/word_embeddings.md", "docs/chapter_inference/inference_acceleration.md", "docs/chapter_inference/inference_fundamentals.md", "docs/chapter_multimodality/multimodality_fundamentals.md", "docs/chapter_multimodality/vision_transformers.md", "docs/chapter_prompt/advanced_prompt.md", "docs/chapter_prompt/basic_prompt.md", "docs/chapter_rag/advanced_rag.md", "docs/chapter_rag/basic_rag.md", "docs/chapter_training/accelerated_training.md", "docs/chapter_training/alignment.md", "docs/chapter_training/finetuning.md", "docs/chapter_training/reinforcement_learning.md", "docs/chapter_training/training_fundamentals.md", "docs/chapter_training/training_lab.md", "docs/img/chapter_application_IR/ApplicationIRSearch/DataExploration/data_explorer.ipynb", "docs/img/chapter_application_IR/ApplicationIRSearch/DeepRetrievalModels/KNRM/test.md", "docs/index.md", "docs/notebooks/chapter_LLM_arch/annotated_llama.ipynb", "docs/notebooks/chapter_LLM_arch/annotated_llama_custom.ipynb", "docs/notebooks/chapter_LLM_training/annotated_instruction_tuning.ipynb", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_DPO.ipynb", "docs/notebooks/chapter_LLM_training/annotated_llama_custom_for_finetuning.ipynb", "docs/notebooks/chapter_LLM_training/annotated_pretraining.ipynb", "docs/notebooks/chapter_prompt/prompting_lab.ipynb", "docs/notebooks/chapter_rag/Graph_Rag.ipynb", "docs/notebooks/chapter_rag/llamaIndexLearning/test.ipynb"], "indexentries": {"information retrieval": [[4, "index-0", false], [5, "index-0", false]], "inverted index": [[4, "index-1", false]], "ir": [[4, "index-0", false], [5, "index-0", false]], "neural ir": [[4, "index-0", false], [5, "index-0", false]]}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 32, 33, 35, 36, 37, 38], "0": [1, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "00": [4, 10, 37, 38], "000": [1, 3, 4, 5, 7, 8, 12, 16, 23, 37, 38], "000095367431641": 34, "00051": 5, "000537395477295": 34, "000862121582031": 34, "001": [4, 25], "001102447509766": 34, "00111198425293": 34, "001513957977295": 34, "001770973205566": 34, "00190": 23, "0024333000183105": 34, "002604961395264": 34, "0030306577682495": [32, 35], "003237247467041": 34, "0032548904418945": 34, "0041": 1, "00510": 13, "00555": 1, "005776882171631": 34, "005826950073242": 34, "005913734436035": 34, "006173133850098": 34, "0064697265625": 34, "00651741027832": 34, "006951332092285": 34, "007287502288818": 34, "007312297821045": 34, "00751": 23, "0077738761901855": 34, "007800598628818989": [32, 35], "008021831512451": 34, "00808": 5, "00854": 11, "008838176727295": 34, "009037494659424": 34, "009293556213379": 34, "00df903954ac": [37, 38], "01": [4, 13, 23, 37, 38], "01000001": 1, "01020304050607gener": 4, "010351657867432": 34, "01047420501709": 34, "0109546184539795": 34, "011043071746826": 34, "01108": 7, "01137": 5, "012027263641357": 34, "012099266052246": 34, "013116082176566124": [32, 35], "013998031616211": 34, "014437675476074": 34, "014496803283691": 34, "014517992734909058": [32, 35], "014609336853027": 34, "01462": 12, "014990329742432": 34, "01567663997411728": [32, 35], "016483306884766": 34, "01652": 23, "016759872436523": 34, "017136573791504": 34, "01759": 12, "0175909996032715": 34, "0180": [37, 38], "0184197425842285": 34, "018761157989502": 34, "0189290046691895": 34, "019": [37, 38], "019296646118164": 34, "019469738006592": 34, "019588947296143": 34, "01969": 5, "01_main": [32, 35], "02": [13, 31, 33, 34], "02054": 21, "020560264587402": 34, "020669937133789": 34, "020719528198242": 34, "0208258628845215": 34, "020852088928223": 34, "021": 8, "02116": 7, "021180152893066": 34, "02150": 1, "02155": 22, "021723747253418": 34, "021773338317871": 34, "022000789642334": 34, "022898197174072": 34, "023150444030762": 34, "023197127506136894": [32, 35], "02336311340332": 34, "023693561553955": 34, "023902416229248": 34, "02424": 14, "02440521866083145": [32, 35], "025": 18, "02531": [5, 7], "0253249f": 38, "025716781616211": 34, "02600269578397274": [32, 35], "026512518525123596": [32, 35], "02677": 25, "026836492121219635": [32, 35], "026de08c": [37, 38], "027651309967041": 34, "027662754058838": 34, "0278215408325195": 34, "02880910411477089": [32, 35], "02886047028005123": [32, 35], "0293": [37, 38], "029530048370361": 34, "02984": 7, "03": 13, "03167": 1, "032745361328125": 34, "033027324825525284": [32, 35], "033673286437988": 34, "03374": 25, "03422737121582": 34, "03439474105835": 34, "03444734588265419": [32, 35], "035079002380371": 34, "03599": 5, "036285400390625": 34, "036287613213062286": [32, 35], "036416053771973": [32, 35], "0366": [4, 5], "0369696617126465": 34, "037397384643555": 34, "03740": 21, "037643432617188": 34, "03766665980219841": [32, 35], "037725448608398": 34, "03789590671658516": [32, 35], "038": 6, "03828873857855797": [32, 35], "038869857788086": 34, "04": [4, 8, 37, 38], "040163993835449": 34, "04039938002824783": [32, 35], "04059940576553345": [32, 35], "04085": 5, "041125692427158356": [32, 35], "041174411773682": 34, "0411882400512695": 34, "041816234588623": 34, "042531490325928": 34, "04297": 5, "043063640594482": 34, "04341": 7, "04371192306280136": [32, 35], "0443267822265625": 34, "044668205082416534": [32, 35], "04478645324707": 34, "04554": 5, "04636172950267792": [32, 35], "047027587890625": 34, "047771453857422": 34, "047902584075928": 34, "048016272485256195": [32, 35], "04805": [5, 7, 11], "048269271850586": 34, "04906": 5, "05": [4, 5, 8, 10, 13], "050281047821045": 34, "050431728363037": 34, "05101": 25, "051425457000732": 34, "051654815673828": 34, "05197812244296074": [32, 35], "05202": 1, "052042007446289": 34, "052127838134766": 34, "052281379699707": 34, "0523810386657715": 34, "052631378173828": 34, "052845001220703": 34, "0529069900512695": 34, "05365": 7, "05378653109073639": [32, 35], "054011344909668": [32, 35], "054613832384347916": [32, 35], "05462772026658058": [32, 35], "055233478546143": 34, "055540084838867": 34, "055841445922852": 34, "0558529794216156": [32, 35], "056744575500488": 34, "05726563185453415": [32, 35], "05736": 13, "0578880310058594": 34, "05852453410625458": [32, 35], "05859": 12, "0587334632873535": 34, "0588991753757": [32, 35], "059050846844911575": [32, 35], "059132099151611": 34, "059300899505615": 34, "059329509735107": 34, "05941": 1, "06": [13, 31, 33, 34], "06037088483572006": [32, 35], "06066": 2, "06080": 22, "06117": 17, "061482429504395": 34, "061509609222412": 34, "06174": 21, "061813831329346": 34, "061917304992676": 34, "062714576721191": 34, "062737226486206": 34, "06275": 5, "06347": 22, "06445721536874771": [32, 35], "06446892023086548": [32, 35], "065298080444336": 34, "065533638000488": 34, "066253662109375": 34, "067604064941406": 34, "067690849304199": 34, "067878723144531": 34, "068182945251465": 34, "06825": 1, "068316698074341": 34, "06971258670091629": [32, 35], "06983757019043": 34, "06af60db": 38, "07": [5, 8, 13, 37, 38], "070650100708008": 34, "071258068084717": 34, "071336269378662": 34, "071442127227783": 34, "0717201232910156": [32, 35], "071742057800293": 34, "07186": 5, "07278": 7, "07291": 7, "07339": 13, "073481559753418": 34, "0735877752304077": [32, 35], "074522972106934": 34, "07467": 1, "074995517730713": 34, "07514037191867828": [32, 35], "075766086578369": 34, "076148509979248": 34, "07640326768159866": [32, 35], "076551914215088": 34, "076613426208496": 34, "07666": 5, "0769914910197258": [32, 35], "07708": 5, "078139781951904": 34, "07820": 5, "07834529876709": 34, "078483581542969": 34, "078586578369141": 34, "07909": 1, "079100608825684": 34, "079553604125977": 34, "079935073852539": 34, "08": [4, 10], "08067": 20, "08073": 22, "081141948699951": 34, "081357955932617": 34, "08144": 7, "081643104553223": 34, "081788539886475": 34, "081859588623047": 34, "08191": 5, "082344055175781": 34, "082972049713135": 34, "0829901695251465": 34, "083053112030029": 34, "08328281342983246": [32, 35], "08361": 25, "08375": [5, 20], "084001064300537": 34, "08412479609251022": [32, 35], "084579467773438": 34, "08510": 7, "085297107696533": 34, "085419178009033": 34, "08564770221710205": [32, 35], "0857086181640625": 34, "086000442504883": 34, "08691": [16, 23], "0870": [32, 35], "08730": 10, "08739487081766129": [32, 35], "08747": 23, "08758139610290527": [32, 35], "087961673736572": 34, "088": 8, "0880608558654785": [32, 35], "088583946228027": 34, "08875849843025208": [32, 35], "088858127593994": [32, 35], "09": [13, 22, 38], "09021760523319244": [32, 35], "090518951416016": 34, "091506481170654": 34, "091830253601074": 34, "091935157775879": 34, "091977119445801": 34, "092382431030273": 34, "093469619750977": 34, "093663692474365": 34, "093731641769409": 34, "093860149383545": 34, "093935012817383": 34, "09413014352321625": [32, 35], "094305515289307": 34, "094555854797363": 34, "09466552734375": 34, "094918251037598": 34, "095365524291992": 34, "0959885120391846": 34, "09600830078125": 34, "09685": 23, "09702205657959": 34, "098": [37, 38], "098481178283691": 34, "09864": [1, 30, 31, 33, 34, 36], "098686695098877": 34, "098811626434326": 34, "0994": [32, 35], "099956512451172": [32, 35], "0b": 1, "0m": [23, 37, 38], "0x": [4, 5], "0x0000023000156e50": [37, 38], "1": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "10": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 18, 20, 21, 23, 25, 27, 32, 33, 34, 35, 37, 38], "100": [4, 5, 6, 11, 13, 25, 27, 30, 32, 33, 34, 36], "1000": [1, 4, 5, 38], "10000": [1, 4, 5, 11, 30, 31, 33, 34, 36], "1000000": [31, 33, 34], "10000010": 1, "10001010": 1, "10011000": 1, "10011111": 1, "1007": [37, 38], "1008782386779785": 34, "100k": [1, 4], "100m": 21, "101": [4, 5, 16], "10101100": 1, "101051330566406": 34, "1012": [33, 34], "101280689239502": 34, "1013": [32, 35], "10131": 20, "1016": [37, 38], "10183": 11, "101871013641357": 34, "102": [37, 38], "102067": 5, "102071762084961": 34, "10208554565906525": [32, 35], "1024": [1, 7, 13, 32, 35], "102511882781982": 34, "1027": 27, "10295": [33, 34], "103": [1, 8], "10306": [4, 5], "103277206420898": 34, "10345983505249": 34, "10351": 7, "104": [7, 37, 38], "1045": 9, "10455": [33, 34], "104673862457275": 34, "1048": 9, "104902744293213": 34, "105184078216553": 34, "10520": 32, "10524": [1, 11], "10533": [1, 11], "1054": 27, "10555": 7, "1056838035583496": 34, "105834007263184": 34, "10671": [1, 21], "106828689575195": 34, "10683": 5, "10687": 5, "106971740722656": 34, "10719": 22, "107256889343262": 34, "107507228851318": 34, "107565879821777": 34, "1079": [32, 33, 34], "108": 7, "1081318855285645": 34, "108236312866211": 34, "1082444190979": [32, 35], "10835": 22, "10854959487915": 34, "10866": 22, "10886287689209": 34, "10899": 35, "108m": 7, "109013557434082": 34, "109280109405518": 34, "10985501110553741": [32, 35], "10997": 20, "109997272491455": 34, "10_getting_start": 38, "10a6": 38, "10b": [1, 23], "10k": [4, 8, 21, 38], "10k_sub_quest": 38, "10q": 38, "10q_sub_quest": 38, "10x": [4, 5], "11": [1, 4, 5, 6, 7, 8, 10, 11, 20, 32, 33, 34, 35, 37, 38], "110": [5, 7, 8], "110368728637695": 34, "110491991043091": 34, "1107": [4, 5], "110700607299805": 34, "110k": 7, "110m": 7, "11100010": 1, "11110000": 1, "1113": 27, "11171": [17, 23], "11179701238870621": [32, 35], "112": 21, "1120": 21, "112430095672607": 34, "112819671630859": 34, "112850666046143": 34, "113": 5, "1137": 9, "1139": 25, "113960266113281": 34, "11416": 23, "114251136779785": 34, "1144712045788765": [32, 35], "1147": 25, "114983558654785": [33, 34], "11511": 19, "115427494049072": 34, "1155": 9, "116": 27, "11652": 32, "11692": [7, 11], "117002010345459": 34, "117216110229492": 34, "11755": 20, "11761": 20, "11771243065595627": [32, 35], "1186": [37, 38], "11903": 18, "11916": 18, "1192": [4, 5], "11929": 11, "11942": [7, 11], "11b": 21, "11v2h12l": 38, "11z": 38, "12": [1, 4, 5, 6, 7, 10, 11, 13, 16, 18, 20, 21, 23, 25, 27, 32, 33, 34, 35, 37, 38], "120": [2, 8, 21], "12039041519165": 34, "120830535888672": 34, "120845317840576": 34, "12136": 5, "121431827545166": 34, "12148": 23, "121613502502441": 34, "122": 5, "122198581695557": 34, "122265338897705": 34, "122282028198242": 34, "122321128845215": 34, "1223673820495605": 34, "12254524230957": 34, "1228": 27, "12288": 1, "123": [32, 35], "123189926147461": 34, "123317718505859": 34, "123326778411865": 34, "123955249786377": 34, "12409": 1, "124289035797119": 34, "1246867179870605": 34, "12477972358465195": [32, 35], "125": 23, "125601768493652": 34, "125786542892456": 34, "1258463859558105": 34, "125m": 6, "126089096069336": 34, "1268": 27, "126978397369385": 34, "127": [13, 21, 37, 38], "127451419830322": 34, "128": [1, 4, 7, 21, 32, 33, 34, 35], "1281": [33, 34], "128173351287842": [32, 35], "12888": 16, "129": 5, "12900": 16, "1291": 5, "1291351318359375": 34, "1294450759887695": 34, "12948": 13, "12956428527832": 34, "129610061645508": 34, "1299": 5, "12b": 38, "12df1a233612": [37, 38], "12l": 38, "12z": 38, "12zm": 38, "13": [1, 4, 5, 8, 12, 13, 20, 23, 27, 32, 33, 34, 35, 37, 38], "130": [37, 38], "1301": 12, "130191326141357": 34, "131": 5, "1315": 27, "131k": 1, "132": [4, 27], "13228": 22, "13245": 1, "132767200469971": 34, "132808685302734": 34, "132901668548584": 34, "133650779724121": 34, "134390830993652": 34, "13461": 10, "135": 12, "13567930459976196": [32, 35], "1359076499938965": 34, "136": [5, 37, 38], "13653340935707092": [32, 35], "13719": 32, "137276649475098": 34, "1374053955078125": 34, "1376": [33, 34], "137b": 17, "138185024261475": 34, "138240814208984": 34, "1385064125061035": 34, "139": [37, 38], "13971": 22, "139718532562256": 34, "139926910400391": 34, "13b": [1, 6, 38], "14": [1, 4, 5, 6, 10, 16, 21, 22, 31, 33, 34, 37, 38], "140": [4, 10], "1401": [33, 34], "1402": 12, "14093": 32, "1412": 25, "141721725463867": 34, "141951084136963": 34, "142255783081055": 34, "1424946784973145": 34, "142984390258789": 34, "143166542053223": 34, "143261909484863": 34, "1435980796813965": 34, "14374": [32, 33, 34], "14394": 23, "144": 4, "1441": 11, "14416790008545": [32, 35], "144201278686523": 34, "14424": 5, "144306182861328": 34, "14454984664917": 34, "144584655761719": 34, "1450": 11, "145068168640137": 34, "1457": 27, "14589": [33, 34], "14591908454895": 34, "146": 12, "146424770355225": 34, "14686393737793": 34, "147": [37, 38], "14701": 25, "14734": 22, "1475": 27, "148385047912598": 34, "1493": [33, 34], "15": [1, 3, 4, 5, 7, 10, 12, 18, 24, 27, 37, 38], "1501040756702423": [32, 35], "150128364562988": 34, "1502": 1, "1503": [5, 7], "150716781616211": 34, "1508": 1, "1509199142456055": 34, "151": 27, "151343822479248": 34, "151587963104248": 34, "151601791381836": 34, "151643": [31, 32, 33, 34], "151936": [31, 33, 34], "152644634246826": 34, "152826309204102": 34, "154": [4, 27], "1541220098733902": [32, 35], "154237747192383": 34, "154354572296143": 34, "15440": [33, 34], "154609680175781": 34, "1549": [33, 34], "15538781881332397": [32, 35], "155660629272461": 34, "1558": [33, 34], "15595": 1, "1566009521484375": [32, 35], "158": 27, "158417224884033": 34, "158575057983398": 34, "15884": 19, "1590": 27, "15908": [32, 33, 34], "16": [3, 4, 5, 6, 7, 10, 12, 13, 14, 21, 33, 34, 37, 38], "160": [12, 27], "1602": 5, "160398006439209": 34, "1604": 21, "16051721572876": 34, "1607": [4, 5, 12, 32], "1607208251953125": 34, "1608": 12, "1609": 7, "161": 27, "1610": 14, "1611": 12, "16130": 19, "16138": 7, "162": [27, 37, 38], "162322044372559": 34, "162805080413818": 34, "163": 5, "163131713867188": 34, "16319": [33, 34], "1632": 32, "163222789764404": 34, "1635": [33, 34], "163662910461426": 34, "16411": 32, "16452": 17, "1647": [32, 35], "165": [37, 38], "16555": [32, 33, 34], "1656084060668945": 34, "165675401687622": [32, 35], "1658274382352829": [32, 35], "16613245010376": 34, "1667": 32, "167": [12, 27], "167695999145508": 34, "168": 34, "1681": [32, 33, 34], "16864658892154694": [32, 35], "169183731079102": 34, "169384956359863": 34, "16980576515197754": [32, 35], "16b": 23, "16l7": 38, "16x16": 11, "17": [4, 5, 10, 11, 18, 21, 22, 25, 33, 34, 37, 38], "170": 34, "1704": 5, "1706": 25, "1707": 22, "171": 34, "1710": [1, 21], "1711": 25, "17119836807251": 34, "17193": 23, "172": 34, "172737121582031": 34, "172832489013672": 34, "173": [5, 34], "173192501068115": 34, "173440456390381": 34, "174": 34, "1741": [33, 34], "17463": 1, "1747": 27, "174975395202637": 34, "175": [0, 1, 6, 23, 34], "175256252288818": 34, "1755": [32, 35], "175565719604492": 34, "17556619644165": 34, "17576": 12, "175b": [1, 6, 22], "176": [37, 38], "176111221313477": 34, "176688194274902": 34, "176878452301025": 34, "1769914627075195": 34, "17788": 32, "17809009552002": 34, "178514003753662": 34, "179": [37, 38], "1795573234558105": 34, "179817199707031": 34, "179b": 1, "17bsdp": 21, "18": [4, 5, 6, 7, 11, 25, 33, 34, 37, 38], "1802": 7, "180410385131836": 34, "1806": 10, "180679798126221": 34, "18074893951416": 34, "1809": 7, "1810": [5, 7, 11], "1818265914917": 34, "18223": [1, 25], "182458877563477": 34, "1829": 5, "18290": 22, "183032512664795": 34, "183049201965332": 34, "183134078979492": 34, "1832": 5, "18332052230835": 34, "183322906494141": 34, "183326244354248": 34, "183656692504883": 34, "183904647827148": 34, "183990478515625": [33, 34], "184": 4, "184030055999756": 34, "184084415435791": 34, "1843748092651367": 34, "184566020965576": 34, "18459": 35, "1848344802856445": 34, "184986114501953": 34, "1850": [33, 34], "18514": 32, "185161113739014": 34, "18527889251709": 34, "186308860778809": 34, "1863226890563965": 34, "18638801574707": [32, 35], "186612129211426": 34, "186622142791748": 34, "1872": [37, 38], "18759298324585": 34, "187629699707031": 34, "1877": [1, 6, 8, 11], "188": 12, "188701629638672": 34, "18892765045166": 34, "188948154449463": 34, "1896": [33, 34], "189830780029297": 34, "189905166625977": 34, "18c": 38, "19": [4, 5, 6, 7, 8, 10, 11, 21, 23, 33, 34, 37, 38], "190": 4, "1901": [1, 5, 6, 7, 8, 11], "1902": 23, "1903": 5, "1904": [5, 20], "1905": 5, "1906": 7, "1907": [7, 11], "190706729888916": 34, "1909": [7, 11], "1910": [1, 5, 7, 10, 21], "1911": [1, 7], "192": 1, "192046165466309": 34, "1930": 4, "1931455284357071": [32, 35], "1939": [33, 34], "19411039352417": 34, "19437": 2, "194373607635498": 34, "1946": [37, 38], "1952": 22, "1956353187561035": 34, "195936679840088": 34, "196": 4, "1961": [37, 38], "196247100830078": 34, "1963": 3, "19633081555366516": [32, 35], "19641": [33, 34], "196491241455078": 34, "1966233253479": 34, "1968": 4, "1971": [4, 5], "1972": 4, "19730": 16, "19737": 25, "197397232055664": 34, "19742": 16, "197486877441406": 34, "1975": 4, "1976": 4, "1976746320724487": [32, 35], "1977": 5, "1979": 4, "198": 35, "1980": [4, 27], "1982": 19, "198347806930542": 34, "1984": 20, "198479652404785": 34, "1986": [37, 38], "1986823081970215": 34, "1987": 4, "1988": [], "1988b": 4, "1989": 13, "199": 27, "1990": 4, "199103832244873": 34, "199112892150879": 34, "1992": 4, "1993": [4, 13, 37, 38], "199366569519043": 34, "1994": [4, 8], "199484825134277": 34, "1995": 4, "1998": [4, 20], "1999": [4, 8], "1a": 4, "1b": [4, 19, 23], "1bcf": [37, 38], "1d": 7, "1d5fe2e2902": [37, 38], "1e": [25, 30, 31, 32, 33, 34, 35, 36], "1f60a": 1, "1g": [6, 13], "1i": 6, "1j": 11, "1m": 11, "1mb": 13, "1x": [4, 5], "2": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "20": [1, 4, 5, 6, 7, 8, 10, 11, 12, 16, 22, 25, 27, 37, 38], "200": [4, 8, 20, 38], "2000": [4, 37, 38], "2001": [4, 25], "2002": [1, 5], "2003": [4, 5, 7, 9], "2004": [4, 5, 7, 12], "2006": 4, "2007": [3, 4, 5, 11], "2008": [3, 5, 12], "20080718121858aamfk0v": 4, "2009": 5, "2010": [4, 5, 9, 11, 25], "2011": [4, 25, 37, 38], "2012": [4, 25], "2013": [5, 12, 25, 37, 38], "2014": [4, 5, 12, 25], "2015": [1, 4, 5, 7], "2016": [5, 7, 12, 14, 21, 37, 38], "2017": [1, 4, 5, 7, 8, 11, 12, 21, 22, 25, 37, 38], "2017765045166016": 34, "2018": [4, 5, 6, 7, 8, 10, 11, 37, 38], "2019": [1, 4, 5, 6, 7, 8, 10, 11, 20, 23, 37, 38], "202": [37, 38], "2020": [1, 4, 5, 6, 7, 8, 10, 11, 20, 21, 22, 25, 37, 38], "202093124389648": 34, "2021": [4, 5, 7, 13, 16, 23, 25, 37, 38], "2021a": 4, "2022": [1, 2, 13, 16, 17, 18, 20, 22, 23, 37, 38], "2023": [1, 13, 16, 17, 19, 20, 22, 23, 25, 37, 38], "2023a": 22, "2024": [1, 2, 16, 19, 20, 21, 22, 23, 25, 37, 38], "2024a": 2, "202847957611084": 34, "203221321105957": 34, "2032294273376465": 34, "2033": [32, 33, 34], "2039031982421875": 34, "203961372375488": 34, "204647064208984": 34, "2048": [1, 7, 11, 13, 30, 31, 33, 34, 36], "205238342285156": [33, 34], "205798625946045": 34, "205985069274902": 34, "206247806549072": 34, "20643": [33, 34], "2069501876831055": 34, "2076023817062378": [32, 35], "208010673522949": 34, "2081": 5, "208345413208008": 34, "2084": 5, "208878993988037": 34, "209": 5, "209777355194092": 34, "20_core_compon": 38, "20ac": 1, "20h": 38, "20h20v": 38, "21": [1, 4, 5, 6, 7, 10, 11, 13, 16, 23, 25, 33, 34, 37, 38], "2101": 23, "210110664367676": 34, "2104": [1, 5, 16, 23, 30, 31, 33, 34, 36], "2105": 5, "2106": [5, 7, 23], "21068000793457": 34, "2107": 25, "2108": 1, "2109": [13, 23], "2112": 5, "211876392364502": 34, "2121": 25, "21279782056808472": [32, 35], "2128376960754395": 34, "213296890258789": 34, "213634490966797": 34, "21381": 27, "213995456695557": 34, "215": 6, "2159": 25, "2165975123643875": [32, 35], "217": 8, "217145919799805": 34, "2175068855285645": 34, "217704772949219": 34, "21783": 1, "219": 27, "219264030456543": 34, "219285011291504": 34, "219350337982178": 34, "219789028167725": 34, "21st": 20, "22": [1, 4, 5, 8, 11, 17, 18, 20, 22, 23, 34, 37, 38], "220": [33, 34], "220089912414551": 34, "2201": 18, "2201690673828125": 34, "2203": [1, 17, 22, 23], "220418930053711": 34, "2204294204711914": [32, 35], "2205": 18, "220532178878784": 34, "220764636993408": 34, "220792770385742": 34, "2208": 13, "2209": 20, "2210": 23, "2212": 22, "2213757038116455": 34, "221405029296875": 34, "2214741706848145": [32, 35], "221652030944824": 34, "221750259399414": 34, "221808910369873": 34, "22231": [33, 34], "223": [4, 5, 27], "2233043611049652": [32, 35], "223731994628906": 34, "223905086517334": 34, "2250": [37, 38], "2250871658325195": 34, "22550": [33, 34], "225741386413574": 34, "226": 5, "226304531097412": 34, "226582050323486": 34, "227": 8, "227993965148926": 34, "228": 27, "229344367980957": 34, "229555606842041": 34, "22996433079242706": [32, 35], "22nd": 5, "23": [1, 2, 4, 5, 13, 17, 19, 20, 21, 23, 25, 33, 34, 37, 38], "230": [12, 27], "2302": 22, "2302520275115967": 34, "2303": [1, 25], "2305": [1, 22], "2306": 1, "230792760848999": 34, "2308": [20, 23], "2310": [1, 13, 17, 19, 33, 34], "2311": 17, "2312": [20, 23], "231400489807129": 34, "23215913772583": 34, "232213497161865": 34, "2322254180908203": [32, 35], "2326": [33, 34], "2333": [4, 5], "2334029": 22, "2338": 5, "233859062194824": 34, "234": 4, "234323978424072": 34, "234857439994812": [32, 35], "235097408294678": 34, "235403537750244": 34, "236362934112549": 34, "236627101898193": 34, "23663": 27, "236884117126465": 34, "238": [37, 38], "238468647003174": 34, "238506317138672": 34, "23895448446273804": [32, 35], "23905086517334": 34, "239485263824463": 34, "23l": 38, "23rd": 5, "24": [1, 2, 4, 5, 6, 7, 10, 13, 19, 20, 21, 22, 23, 25, 27, 31, 33, 34, 37, 38], "2401": [2, 19, 22], "2402": [1, 22, 23], "2403": [20, 22], "2404": [19, 22, 25], "2405": [22, 23], "2407": [1, 21], "2408": 20, "2412": 2, "241434097290039": 34, "242073059082031": 34, "242163181304932": 34, "243": 4, "243106842041016": 34, "24321489036083221": [32, 35], "24347": [33, 34], "243719577789307": 34, "244636058807373": 34, "244905471801758": 34, "245": 8, "24505090713501": 34, "2450714111328125": 34, "245612621307373": 34, "246973991394043": 34, "247925281524658": 34, "2480": [33, 34], "249174118041992": 34, "2493443142": 27, "24th": 5, "25": [1, 4, 6, 8, 10, 12, 13, 19, 32, 34, 37, 38], "250": [4, 5], "2500": 25, "250294208526611": 34, "250489711761475": 34, "2514617443084717": 34, "251805305480957": 34, "252415657043457": 34, "252851486206055": 34, "253942489624023": 34, "254053115844727": 34, "254146099090576": 34, "254385948181152": 34, "254650115966797": 34, "254941940307617": 34, "255": [13, 21, 23], "2551": 32, "255387783050537": 34, "255984306335449": 34, "256": [1, 4, 5, 7, 11, 27, 32, 33, 34, 35], "256246566772461": 34, "256918340921402": [32, 35], "257": 1, "257620811462402": 34, "258242607116699": 34, "259": 27, "259034156799316": 34, "259069442749023": 34, "25th": 12, "26": [4, 5, 6, 10, 12, 34, 35, 37, 38], "26035213470459": 34, "260522842407227": 34, "260662078857422": 34, "26072883605957": 34, "261": 27, "262": 35, "262142658233643": 34, "262190818786621": 34, "26226806640625": 34, "262915134429932": 34, "263815879821777": 34, "263994216918945": 34, "264": [32, 33, 34], "264045238494873": 34, "264111042022705": 34, "264615058898926": 34, "266002655029297": 34, "26678991317749": 34, "267": 8, "267117977142334": 34, "267175197601318": 34, "2679": 32, "268042087554932": 34, "268439769744873": 34, "2689290046691895": 34, "269": [18, 27], "269332408905029": 34, "269647121429443": 34, "269782066345215": 34, "26th": 5, "27": [3, 4, 5, 6, 13, 17, 27, 34, 37, 38], "270": 27, "2701": 32, "2702107429504395": 34, "270448684692383": 34, "271": [33, 34, 35], "271264553070068": 34, "271533966064453": 34, "272322654724121": 34, "2724": 27, "272527694702148": 34, "272828102111816": 34, "273": 35, "273373603820801": 34, "273721694946289": 34, "27378": [33, 34], "273829936981201": 34, "27408504486084": 34, "2745": 35, "2747355103492737": [32, 35], "2748712301254272": [32, 35], "275448322296143": 34, "275712490081787": 34, "275812149047852": 34, "276309013366699": 34, "277": 4, "277144908905029": 34, "277264356613159": 34, "2779080867767334": 34, "278": [8, 27], "278239727020264": 34, "279": [32, 33, 34], "279453992843628": 34, "279878616333008": 34, "2799654006958": [33, 34], "27a6": 38, "27h": 38, "28": [1, 4, 5, 6, 8, 21, 23, 34, 37, 38], "280029296875": 34, "280559539794922": 34, "281369686126709": 34, "281500816345215": 34, "284355640411377": 34, "284381866455078": 34, "284786701202393": 34, "2848913073539734": [32, 35], "28593635559082": 34, "286657810211182": 34, "286722183227539": 34, "286881446838379": 34, "28696480": [37, 38], "287": [5, 35], "2870": 27, "287336826324463": 34, "288": 6, "28824520111084": 34, "288344383239746": 34, "288504600524902": 34, "288642406463623": 34, "289": 27, "289977550506592": 34, "28th": 11, "29": [4, 5, 6, 7, 23], "290078163146973": 34, "290414333343506": 34, "29051": [32, 33, 34], "29083251953125": 34, "29171895980835": 34, "292008399963379": 34, "292236328125": 34, "292308330535889": 34, "292393684387207": 34, "293": 13, "29322": [37, 38], "29323148727417": 34, "29353666305542": 34, "2936": 35, "293612957000732": 34, "294384956359863": 34, "294795036315918": 34, "294926166534424": 34, "295": [37, 38], "29543": 35, "29562": 32, "295699119567871": 34, "296": 5, "296192169189453": 34, "297027826309204": 34, "297110557556152": 34, "2976996898651123": 34, "298": [4, 5, 37, 38], "2980282306671143": 34, "298332691192627": 34, "298480033874512": 34, "299": 13, "29th": 13, "2_": 11, "2a": 4, "2b": [4, 21], "2b5669c2": 38, "2bsd": 21, "2bsdp": 21, "2bypt": 21, "2c": 4, "2c7": 38, "2d": [1, 4, 12, 30, 36], "2d_": 11, "2e": 4, "2f": 4, "2fc7077e": [37, 38], "2g": 4, "2gd_": 1, "2h": [21, 38], "2h7": 38, "2hp": 21, "2i": 1, "2j": 11, "2l": 38, "2m": 11, "2v8l": 38, "2x": 5, "3": [0, 1, 3, 5, 7, 8, 9, 10, 11, 12, 13, 17, 19, 20, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "30": [4, 5, 6, 7, 11, 34, 38], "300": [4, 5, 27, 38], "30039644241333": 34, "300551414489746": 34, "3006774187088013": [32, 35], "300681114196777": 34, "3008": 22, "300i": 38, "301": [37, 38], "301499366760254": 34, "30162525177002": 34, "302": [27, 37, 38], "3021": 22, "302224636077881": 34, "302529811859131": 34, "302533149719238": 34, "303577899932861": 34, "303918361663818": 34, "304": [32, 33, 34], "304293155670166": 34, "305261135101318": 34, "3055548667907715": 34, "30568265914917": 34, "305816173553467": 34, "305967330932617": 34, "30621": [4, 5], "30665": [32, 33, 34], "306757926940918": 34, "307093143463135": 34, "3072": 1, "308": [4, 5], "3082857131958": [33, 34], "30828776955604553": [32, 35], "30832594633102417": [32, 35], "308478832244873": 34, "309": 8, "30929644": [37, 38], "309408664703369": 34, "309920787811279": 34, "30_manual_orchestr": 38, "30k": [4, 5], "31": [4, 5, 6, 13, 21, 34, 37, 38], "3102": 27, "310380458831787": 34, "311": [32, 33, 34], "3110": 32, "3111": [5, 12], "31115": [32, 33, 34], "311150074005127": 34, "31174373626709": 34, "311887741088867": 34, "3119": [5, 12], "311979293823242": [32, 35], "312523365020752": 34, "312560081481934": 34, "313": [5, 27], "31392": [33, 34], "314": 35, "315": [4, 32, 33, 34], "315019607543945": 34, "315254211425781": 34, "3153": [37, 38], "315401077270508": 34, "315445423126221": 34, "31577205657959": [33, 34], "316": 27, "316316604614258": 34, "317086696624756": 34, "317536354064941": 34, "3179033994674683": [32, 35], "3184404373168945": 34, "319": [4, 5, 27], "3196fd91": [37, 38], "31v20h4": 38, "31v4h": 38, "32": [1, 4, 5, 6, 13, 21, 34, 37, 38], "320345878601074": 34, "3208274245262146": [32, 35], "3208323121070862": [32, 35], "3213835": 27, "321924686431885": 34, "3219523429870605": 34, "3223795890808105": 34, "322475433349609": 34, "323": [5, 33, 34], "3230046033859253": [32, 35], "323247909545898": 34, "324": 22, "324112892150879": 34, "324937343597412": 34, "325": 5, "325492858886719": 34, "325699806213379": 34, "326": [4, 35], "326104164123535": 34, "326220512390137": 34, "326286792755127": 34, "3267621994018555": 34, "326879024505615": 34, "326934814453125": 34, "327077388763428": 34, "327323913574219": 34, "327679634094238": 34, "32768": [1, 31, 33, 34], "328179359436035": 34, "329": 5, "32k": 1, "32mextract": [37, 38], "33": [1, 4, 5, 6, 7, 8, 11, 18, 22, 34, 37, 38], "330": 27, "3309": [33, 34], "330907344818115": 34, "33094": [33, 34], "331": 27, "3313188552856445": 34, "331404447555542": 34, "331404685974121": 34, "331676006317139": 34, "33185669779777527": [32, 35], "332029819488525": 34, "332251071929932": 34, "332863807678223": 34, "333367824554443": 34, "333590984344482": 34, "333754062652588": 34, "333774089813232": 34, "333951950073242": 34, "334": 7, "33411979675293": 34, "334537982940674": 34, "334575653076172": 34, "3347": 35, "335": [20, 27], "335203170776367": 34, "3354811668396": 34, "335762023925781": 34, "336": 20, "336148262023926": 34, "336493492126465": 34, "336531639099121": 34, "337": 27, "337359428405762": 34, "3376": 27, "337612152099609": 34, "338": 27, "3380939960479736": 34, "3383": [32, 33, 34], "34": [4, 5, 6, 34, 37, 38], "340": [4, 7], "340113162994385": 34, "340m": 7, "341": 4, "341320037841797": 34, "341635704040527": [33, 34], "342": 32, "342960357666016": 34, "343040943145752": 34, "3431472182273865": [32, 35], "3432": [33, 34], "343332290649414": 34, "343361854553223": 34, "3435": [32, 35], "345": [5, 22, 33, 34], "3463053703308105": 34, "347463607788086": 34, "3481526374816895": 34, "34901": [32, 33, 34], "349497318267822": 34, "3495795726776123": 34, "3496479988098145": 34, "34bsd": 21, "35": [4, 5, 6], "3511956036090851": [32, 35], "3517656326293945": 34, "3518853187561035": 34, "352": [4, 5], "3524281978607178": 34, "3535": [33, 34], "3537": [33, 34], "353724956512451": 34, "3540425300598145": 34, "3543524742126465": 34, "355349540710449": 34, "3554": 32, "356051445007324": 34, "357344627380371": 34, "357487678527832": 34, "3576202392578125": 34, "358": [32, 33, 34], "3584": 21, "359": 8, "359533786773682": 34, "35969877243042": 34, "36": [4, 5, 12, 13, 34, 37, 38], "360": 27, "360662937164307": 34, "361": [4, 27], "362": [4, 5], "362468719482422": 34, "362699031829834": 34, "362935543060303": 34, "363485336303711": 34, "363903999328613": 34, "364670753479004": 34, "365195274353027": 34, "366": 35, "366093635559082": 34, "366409778594971": 34, "366528511047363": 34, "366771697998047": 34, "367": [4, 5], "367013": 27, "367886066436768": 34, "368297576904297": 34, "36879": [33, 34], "369": [27, 33, 34], "369438171386719": 34, "37": [2, 4, 5, 6, 23, 37, 38], "370": 27, "370241641998291": 34, "370524883270264": 34, "370950222015381": 34, "371190547943115": 34, "37131962180137634": [32, 35], "371455669403076": 34, "371676445007324": 34, "371853351593018": 34, "371891021728516": 34, "37199068069458": 34, "372": [4, 5], "372015953063965": 34, "3722": 12, "3724923133850098": 34, "372688293457031": 34, "372903347015381": 34, "373": [4, 5], "3731765747070312": 34, "373385906219482": 34, "373404502868652": 34, "374": [32, 33, 34], "374007225036621": 34, "37417459487915": 34, "374730110168457": 34, "375204563140869": 34, "3765709400177": 34, "37682580947876": 34, "377189636230469": 34, "3781": 12, "378183364868164": 34, "378776550292969": 34, "3796772956848145": 34, "379730224609375": 34, "38": [4, 5, 6, 12, 37, 38], "380": 27, "380285739898682": 34, "380952835083008": 34, "381": [37, 38], "38142": [33, 34], "3818368911743164": 34, "382": [4, 5, 32, 33, 34], "3821120262146": 34, "38214": [32, 33, 34], "383841037750244": 34, "384125709533691": 34, "385": 12, "38566": 32, "385810375213623": 34, "3863539695739746": 34, "386f": [37, 38], "387": [34, 37, 38], "387298583984375": 34, "387340068817139": 34, "388": 34, "3883811235427856": [32, 35], "3887": 5, "389": [33, 34], "3896": 5, "38f": [4, 5], "39": [2, 4, 5, 6, 22, 23], "390": [8, 34], "3900": [32, 37, 38], "390007495880127": 34, "39061975479126": 34, "390718460083008": [32, 35], "391116142272949": 34, "391934394836426": 34, "392": 27, "392367839813232": 34, "392545": [37, 38], "393157005310059": 34, "393226623535156": 34, "3936262130737305": 34, "393649101257324": 34, "393858432769775": 34, "393913745880127": 34, "394": [8, 27, 34], "3943068981170654": 34, "394356727600098": [33, 34], "394460201263428": 34, "394814491271973": 34, "395": 34, "39547872543335": 34, "395797729492188": 34, "396": 34, "396156311035156": 34, "396198272705078": 34, "396443367004395": 34, "3968892097473145": 34, "3981733322143555": 34, "398224353790283": 34, "398374557495117": 34, "398658752441406": 34, "3988": [33, 34], "399": 12, "399399518966675": 34, "399779796600342": 34, "399806499481201": 34, "3a": 22, "3a6": 38, "3b": 21, "3bsdp": 21, "3d": 1, "3l12": 38, "3m": [4, 5, 23], "3m0": 38, "3rd": 8, "3x": [4, 5], "4": [0, 1, 3, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "40": [1, 4, 6, 7, 13, 18, 23, 27, 32, 33, 34, 37, 38], "400": [4, 38], "40000": 4, "400i": 38, "400m": 16, "401310443878174": 34, "40156105160713196": [32, 35], "40158": [33, 34], "402266025543213": 34, "40275764465332": 34, "403815269470215": 34, "4044294357299805": 34, "405b": 1, "406094074249268": 34, "4070963859558105": 34, "407286643981934": 34, "407567024230957": 34, "408": [37, 38], "408968448638916": 34, "4092": [33, 34], "4096": [1, 13, 21], "409931182861328": 34, "40_python_sdk": 38, "40bd": [37, 38], "40k": [4, 5], "40th": 5, "41": [6, 10], "410": 6, "4107441902160645": 34, "411169052124023": 34, "41145658493042": 34, "412205457687378": 34, "413370132446289": 34, "413440227508545": 34, "4138765335083": 34, "41429328918457": 34, "4145": 32, "415234088897705": 34, "41815683245658875": [32, 35], "418442249298096": 34, "418704986572266": 34, "419": 32, "41a7": [37, 38], "41st": 5, "42": [4, 5, 7, 38], "4208574295043945": 34, "421682357788086": 34, "42185115814209": 34, "4221187233924866": [32, 35], "422640323638916": 34, "423": 35, "423009395599365": 34, "423011779785156": 34, "423229217529297": 34, "423436641693115": 34, "4235": [37, 38], "424270153045654": 34, "424302339553833": 34, "4244": 32, "425": [4, 5], "425178527832031": 34, "425512790679932": 34, "426880836486816": 34, "427": 27, "42734432220459": 34, "427750110626221": 34, "42807": [33, 34], "428111553192139": 34, "428226947784424": 34, "428523063659668": 34, "4287636280059814": 34, "429": [27, 32, 33, 34, 37, 38], "429275512695312": 34, "429739475250244": 34, "429806232452393": 34, "42l12": 38, "42l13": 38, "42l19": 38, "42nd": 5, "43": [4, 5, 13], "430": [37, 38], "431": [37, 38], "431405067443848": 34, "431438446044922": 34, "4315948486328125": 34, "432": [33, 34, 37, 38], "432180404663086": 34, "4324140548706055": 34, "432761192321777": 34, "432821750640869": 34, "433": [37, 38], "4338": [37, 38], "434": [37, 38], "4340": [33, 34], "434049606323242": 34, "4341": [37, 38], "434146881103516": 34, "434628486633301": 34, "435": [37, 38], "4353928565979": 34, "436": [37, 38], "43606948852539": 34, "436637878417969": 34, "436718463897705": 34, "437": [37, 38], "437107086181641": 34, "437134265899658": 34, "4378": 32, "438": [35, 37, 38], "438089370727539": 34, "438453674316406": 34, "438752174377441": 34, "439": [27, 37, 38], "43989896774292": 34, "439957618713379": 34, "43rd": 5, "44": [4, 8, 13, 23, 34, 38], "440": [37, 38], "440547466278076": 34, "4411": 7, "441150665283203": 34, "441350936889648": 34, "4415": [37, 38], "4421": 7, "442394733428955": 34, "4426798820495605": [32, 35], "442732810974121": 34, "4431843757629395": 34, "443197250366211": 34, "443287372589111": 34, "444087982177734": 34, "445369243621826": 34, "44551944732666": 34, "44568920135498": [33, 34], "445786476135254": 34, "44595": [32, 33, 34], "44614315032959": 34, "446750640869141": 34, "4469170570373535": 34, "4486": 32, "4496119022369385": 34, "44975471496582": 34, "44th": 5, "45": [4, 6, 20, 23, 37, 38], "450": 27, "451141357421875": 34, "4517886638641357": 34, "452328205108643": 34, "452475070953369": 34, "452916622161865": 34, "453": 5, "453352451324463": 34, "453845024108887": 34, "455": [4, 5], "455920219421387": [33, 34], "456425189971924": 34, "456601619720459": 34, "45728063583374": 34, "458": [4, 5, 32, 33, 34], "458085536956787": 34, "458860397338867": 34, "459051609039307": 34, "459372520446777": 34, "459793090820312": 34, "459e": [37, 38], "45c10": 38, "46": [10, 34], "460000": 4, "461446285247803": 34, "4618144035339355": 34, "462": [4, 5], "4624552726745605": 34, "4628005027770996": 34, "4628641605377197": 34, "462956428527832": 34, "4637": [33, 34], "46475347876548767": [32, 35], "465144634246826": 34, "4653306007385254": 34, "4658331871032715": 34, "466": 5, "466038227081299": 34, "466475486755371": 34, "466663837432861": 34, "468654155731201": 34, "46910417079925537": [32, 35], "46e4": [37, 38], "47": [31, 33, 34], "4701": [37, 38], "470743179321289": 34, "471054553985596": 34, "471277713775635": 34, "471698522567749": 34, "4721360206604": 34, "472388744354248": 34, "472402095794678": 34, "472513198852539": 34, "4728546142578125": 34, "473038673400879": 34, "4736328125": 34, "474020481109619": 34, "474560022354126": 34, "475": [8, 35], "4750": 35, "4750823974609375": 34, "4755": 32, "475765228271484": 34, "475982666015625": 34, "476": 32, "476668834686279": 34, "476725101470947": 34, "476774215698242": [33, 34], "477248191833496": 34, "477256774902344": 34, "477426528930664": 34, "4774370193481445": 34, "47752046585083": 34, "477724552154541": 34, "4789605140686035": 34, "479019641876221": 34, "479202747344971": 34, "4797074794769287": 34, "4797680377960205": 34, "479838848114014": 34, "48": [4, 5, 8, 18, 21, 34, 37, 38], "480766296386719": 34, "480937957763672": 34, "481202602386475": 34, "481714248657227": 34, "481831073760986": 34, "481995105743408": 34, "483189582824707": 34, "483315467834473": 34, "483484745025635": 34, "483814716339111": 34, "483890056610107": 34, "484647274017334": 34, "485343933105469": 34, "485445499420166": 34, "485818862915039": 34, "4864": [31, 33, 34], "486827850341797": 34, "487637042999268": 34, "487700462341309": 34, "487936019897461": 34, "488248825073242": 34, "488309383392334": 34, "488674640655518": 34, "489042282104492": 34, "489135265350342": 34, "489388465881348": 34, "489965438842773": 34, "48e3": [37, 38], "49": [6, 37, 38], "490474700927734": 34, "49088": [32, 33, 34], "49103": [33, 34], "491201877593994": 34, "491785049438477": 34, "492624759674072": 34, "493218898773193": 34, "4936649799346924": 34, "493767261505127": 34, "494001865386963": 34, "495570659637451": 34, "495635032653809": 34, "495880603790283": 34, "496494293212891": 34, "496853351593018": 34, "497350692749023": 34, "497448921203613": 34, "4975152611732483": [32, 35], "498": [4, 5, 32], "4981274604797363": [32, 35], "498323440551758": 34, "498516082763672": 34, "498530387878418": 34, "499092102050781": 34, "499148368835449": 34, "499700": 4, "4997334480285645": 34, "49c0": [37, 38], "49d2": [37, 38], "49f6": [37, 38], "4b92": [37, 38], "4bsdp": 21, "4d": [11, 30, 36], "4d0a": 38, "4e43": [37, 38], "4h": 21, "4h4v4": 38, "4m": 22, "4m0": 38, "4o": [36, 38], "4v": 38, "4x": 13, "5": [5, 6, 8, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "50": [1, 4, 5, 7, 13, 16, 18, 32, 33, 34, 37, 38], "500": [1, 4, 7, 12, 16, 23], "500000": 4, "500061988830566": 34, "500189781188965": 34, "500576972961426": 34, "500579357147217": 34, "5009": 32, "500k": [4, 5, 25], "500m": 20, "5017807483673096": 34, "501925468444824": 34, "502203643321991": [32, 35], "50257": [32, 35], "502859115600586": 34, "503": [4, 5], "503620147705078": 34, "50405740737915": 34, "504574775695801": 34, "5048041343688965": 34, "504852771759033": 34, "505090713500977": 34, "505105972290039": 34, "507336616516113": 34, "507905960083008": 34, "508": [32, 33, 34, 35], "508111953735352": 34, "508213996887207": 34, "509119033813477": 34, "509369850158691": 34, "509552001953125": 34, "50_llamactl": 38, "50b": 25, "50m": 22, "50th": 18, "51": [6, 10, 18, 27], "510": [32, 33, 34], "510037422180176": 34, "510807991027832": 34, "510921478271484": 34, "512": [1, 3, 4, 5, 7, 11, 37, 38], "5129594802856445": 34, "512974739074707": 34, "5140": 1, "515994071960449": 34, "516447067260742": 34, "516720771789551": 34, "51699161529541": [33, 34], "51749": [33, 34], "517505168914795": 34, "517650604248047": 34, "517978191375732": 34, "518763065338135": 34, "518989562988281": 34, "519045352935791": 34, "51907205581665": 34, "519378185272217": 34, "5197012424468994": 34, "52": [4, 6, 13, 23, 38], "520": 5, "52064323425293": 34, "521": [8, 27], "5216474533081055": 34, "521772861480713": [32, 35], "522157669067383": 34, "5231332778930664": 34, "523230075836182": 34, "523402214050293": 34, "524458408355713": 34, "5248": [37, 38], "525": [33, 34], "525822639465332": 34, "526": 35, "526586055755615": 34, "5270466804504395": 34, "528031826019287": 34, "528431415557861": 34, "528918743133545": 34, "529": 27, "529574394226074": 34, "529670000076294": 34, "529696226119995": 34, "5297532081604": 34, "529804706573486": 34, "53": [6, 10, 13, 23, 37, 38], "530": [4, 5], "530302047729492": 34, "5303852558135986": 34, "531440258026123": 34, "531777381896973": 34, "531828880310059": [32, 35], "532500267028809": 34, "532714605331421": 34, "533547401428223": 34, "535": 5, "535629749298096": 34, "535632133483887": 34, "5358526110649109": [32, 35], "53585433959961": 34, "535881042480469": 34, "536": 1, "536715030670166": 34, "53681755065918": 34, "537": [27, 32, 33, 34], "537608623504639": 34, "537712097167969": 34, "538330078125": 34, "538795471191406": [33, 34], "539457321166992": 34, "539644241333008": 34, "539986610412598": 34, "54": [6, 13, 37, 38], "540": 0, "5420756340026855": 34, "543970584869385": 34, "544000625610352": 34, "544711589813232": 34, "54485559463501": 34, "545587062835693": 34, "545934677124023": [32, 35], "546802282333374": 34, "547": 5, "5471502542495728": [32, 35], "549046039581299": 34, "5498576164245605": 34, "549989223480225": 34, "54cbf61d": [37, 38], "55": [4, 6, 13], "550": [4, 35], "550424575805664": 34, "550425052642822": 34, "5504891872406006": 34, "5507609844207764": [32, 35], "5514726638793945": 34, "551836967468262": 34, "552192687988281": 34, "552657604217529": 34, "552811145782471": 34, "5529890060424805": 34, "553": [33, 34], "5534721612930298": [32, 35], "554015159606934": 34, "5544586181640625": 34, "5545": 32, "554964065551758": 34, "5555013418197632": [32, 35], "55605697631836": [32, 35], "556525230407715": 34, "5571": [33, 34], "557234048843384": 34, "557378768920898": [33, 34], "558029651641846": 34, "559053421020508": 34, "559063911437988": 34, "5597606897354126": [32, 35], "55c11": 38, "56": [4, 5, 6, 10, 13, 38], "56008243560791": 34, "5603532791137695": 34, "5610265731811523": [32, 35], "56149673461914": 34, "56154203414917": 34, "562791347503662": 34, "5628833770751953": 34, "5643": [33, 34], "565061569213867": [33, 34], "56566047668457": 34, "566010475158691": 34, "566425323486328": 34, "566890716552734": 34, "568009376525879": 34, "568994998931885": 34, "569": 8, "569152355194092": 34, "56923770904541": 34, "5693602561950684": 34, "569487571716309": 34, "569583892822266": 34, "569966316223145": 34, "57": [4, 5, 6, 13], "571550369262695": 34, "571666240692139": 34, "572741508483887": 34, "573783874511719": 34, "574258804321289": 34, "574467658996582": 34, "57578182220459": 34, "576030731201172": 34, "57619571685791": 34, "576348304748535": 34, "576384544372559": 34, "577573776245117": 34, "5776": 7, "57779598236084": 34, "5788": 7, "579033374786377": 34, "579311370849609": 34, "5797553062438965": 34, "58": [6, 13, 32, 33, 34, 37, 38], "580028533935547": 34, "580134868621826": 34, "580226898193359": 34, "580467224121094": 34, "580507755279541": 34, "581": 5, "581442832946777": 34, "581953048706055": 34, "58283": [33, 34], "58307a52": [37, 38], "583113193511963": 34, "583437442779541": 34, "583615779876709": 34, "5837": [33, 34], "584": 1, "584530353546143": 34, "584754943847656": 34, "584958076477051": 34, "584d": [37, 38], "585": 27, "5854703783988953": [32, 35], "585550308227539": 34, "586": 18, "5864": 27, "586897850036621": 34, "5871": [33, 34], "587782382965088": 34, "588257312774658": 34, "589232444763184": 34, "59": [4, 5, 10, 38], "590230464935303": 34, "590473175048828": 34, "590849876403809": [32, 35], "5909385681152344": 34, "5911970138549805": 34, "591366767883301": 34, "5918143ce249": [37, 38], "592565059661865": 34, "592731475830078": 34, "593": 27, "594": 27, "5949": [32, 33, 34], "5954437255859375": 34, "5963003635406494": [32, 35], "596868991851807": 34, "597": 27, "597620487213135": 34, "5977479219436646": [32, 35], "5978": [33, 34], "597959041595459": 34, "598532199859619": 34, "598954200744629": 34, "599": 27, "5998": [5, 11], "5a21": [37, 38], "5b": [1, 4, 5, 21, 31, 32, 33, 34, 38], "5bsdp": 21, "5c0": 38, "5e": [32, 33, 34, 35], "5h18v2h3z": 38, "5h18v2h3zm0": 38, "5s7": 38, "5v": 38, "5x": 17, "6": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "60": [4, 5, 6, 8, 32, 33, 34, 37, 38], "600": [4, 8], "60009": [33, 34], "600272178649902": 34, "600544452667236": 34, "60056209564209": 34, "6008": [5, 11], "601119041442871": 34, "601291179656982": 34, "602296352386475": 34, "602899551391602": 34, "60315465927124": 34, "603550434112549": 34, "603623867034912": 34, "604100227355957": 34, "60424": [33, 34], "604459285736084": 34, "6048583984375": 34, "605": 27, "6051": 32, "60521936416626": 34, "6053457260131836": [32, 35], "605682849884033": 34, "605772018432617": 34, "6057915687561035": [32, 35], "6067054271698": 34, "606869220733643": 34, "607332706451416": 34, "608583450317383": [33, 34], "608859539031982": 34, "60928201675415": 34, "6098673343658447": 34, "609960079193115": 34, "61": [4, 5, 10, 37, 38], "610466957092285": 34, "6105570793151855": 34, "611": 13, "6119120121002197": 34, "613434791564941": 34, "614": 32, "614431858062744": 34, "614804267883301": 34, "6153844594955444": [32, 35], "6168": [33, 34], "616897106170654": 34, "617480754852295": 34, "6194265484809875": [32, 35], "62": [4, 5, 6, 10], "6206157207489014": 34, "621312618255615": 34, "621826648712158": 34, "6219611167907715": 34, "622305870056152": 34, "622346878051758": 34, "622471332550049": 34, "622495174407959": 34, "622593879699707": 34, "622760057449341": [32, 35], "624054431915283": 34, "624549865722656": 34, "625": 27, "625117301940918": 34, "625831127166748": 34, "626": 13, "62721586227417": 34, "628": 8, "628726005554199": 34, "628757476806641": 34, "629382610321045": 34, "629907608032227": 34, "62a38c14ef93": [37, 38], "63": [4, 5, 6, 13], "630148887634277": [33, 34], "630690574645996": 34, "632315635681152": 34, "632775783538818": 34, "633367538452148": 34, "633436679840088": 34, "634267807006836": 34, "634389877319336": 34, "634511470794678": 34, "635364055633545": 34, "6356282234191895": 34, "635852336883545": 34, "636819839477539": 34, "636826515197754": 34, "636929512023926": 34, "6371138095855713": 34, "637344837188721": 34, "6378068923950195": 34, "6382832527160645": 34, "638418674468994": 34, "64": [1, 4, 5, 13, 21, 23, 27, 37, 38], "6400299072265625": 34, "640043258666992": 34, "6411399841308594": 34, "641413688659668": 34, "641853332519531": 34, "64230489730835": 34, "6428487300872803": 34, "642920017242432": 34, "643113613128662": 34, "643775939941406": 34, "6444194316864014": 34, "646": 8, "646106719970703": 34, "6462178230285645": 34, "646474838256836": 34, "64660120010376": 34, "647436618804932": 34, "64829683303833": 34, "6485166549682617": 34, "648794651031494": 34, "64k": 21, "65": [4, 5, 6], "650116920471191": 34, "6505937576293945": 34, "65060": [33, 34], "6517698764801025": 34, "65182113647461": 34, "6522207260131836": 34, "6524": [33, 34], "6527": [33, 34], "653": [32, 33, 34], "653111457824707": [32, 35], "6534948348999023": 34, "653968811035156": 34, "656194686889648": 34, "658": 27, "659289360046387": 34, "66": [4, 37, 38], "66028356552124": 34, "661034107208252": [32, 35], "661935806274414": 34, "662009239196777": 34, "663405895233154": 34, "6638": [33, 34], "664598226547241": 34, "664869785308838": 34, "6651949882507324": 34, "665449619293213": 34, "666153430938721": 34, "666990756988525": 34, "667112112045288": 34, "667187213897705": 34, "667201995849609": 34, "667232513427734": 34, "667469024658203": [32, 35], "668": 27, "668609619140625": 34, "668902397155762": 34, "669": 8, "67": [4, 8, 10], "670968532562256": 34, "671": [2, 27], "671119213104248": 34, "671813488006592": 34, "6721017360687256": 34, "6727049350738525": 34, "673074245452881": 34, "673221111297607": 34, "673618316650391": 34, "673720836639404": 34, "674612998962402": 34, "6747": [33, 34], "675": [32, 33, 34], "675600528717041": 34, "675665378570557": 34, "6758": 32, "675980091094971": 34, "676620960235596": 34, "677322864532471": 34, "678": [33, 34], "678136348724365": 34, "678229808807373": 34, "678469657897949": 34, "679088592529297": 34, "68": [4, 5, 6, 13, 23], "680325984954834": 34, "680359840393066": 34, "6811306476593018": 34, "681352615356445": 34, "681512355804443": 34, "681833744049072": 34, "681835651397705": 34, "682058334350586": 34, "683": [27, 35], "6833784580230713": 34, "6834278106689453": 34, "683590888977051": 34, "684218883514404": 34, "684447288513184": 34, "684568405151367": 34, "6858339309692383": 34, "685907363891602": 34, "686": [33, 34], "687262058258057": 34, "6873087882995605": 34, "68833065032959": 34, "688720703125": 34, "688923716545105": [32, 35], "68g": 13, "69": [4, 5, 10, 17, 23, 38], "69024658203125": 34, "690933227539062": 34, "690967559814453": 34, "6910786628723145": 34, "6914448738098145": 34, "691554069519043": 34, "692015171051025": 34, "692304611206055": 34, "692431449890137": 34, "692702293395996": 34, "692835807800293": 34, "694700717926025": 34, "6950": [33, 34], "6956562995910645": 34, "695700645446777": 34, "6958794593811035": 34, "696816921234131": 34, "696834564208984": [32, 35], "697": [33, 34], "697264671325684": 34, "6973631381988525": 34, "697608232498169": 34, "69783878326416": 34, "6980": 25, "698017597198486": 34, "699291229248047": 34, "69l": 38, "69l12": 38, "69l23": 38, "69v4h": 38, "6_45": [37, 38], "6a6": 38, "6b": 22, "6ce7567c": 38, "6h18v2h3zm0": 38, "6m8": 38, "6t": 1, "6th": 5, "6x": [4, 5], "7": [4, 5, 6, 8, 10, 12, 13, 17, 18, 20, 21, 22, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "70": [4, 5, 6, 8, 13, 23], "700": [4, 5, 25, 32, 38], "700i": 38, "700k": [4, 5], "701747894287109": 34, "702801704406738": 34, "7028074264526367": 34, "703210353851318": 34, "703780651092529": 34, "704662322998047": 34, "704864501953125": 34, "704891681671143": 34, "704917907714844": 34, "704999923706055": 34, "705": [33, 34], "7060208320617676": 34, "706062316894531": 34, "706840991973877": 34, "707007884979248": 34, "7073099613189697": [32, 35], "7074978351593018": 34, "707741737365723": 34, "707758903503418": [33, 34], "707916498184204": 34, "708553314208984": 34, "709282875061035": 34, "7093892097473145": 34, "70b": 21, "71": [4, 5, 6, 13, 21], "710": [37, 38], "710177421569824": 34, "71079158782959": 34, "711": 27, "7111575603485107": 34, "711648464202881": 34, "712862968444824": 34, "712878227233887": 34, "713091850280762": 34, "713352203369141": 34, "713385581970215": 34, "714572906494141": 34, "715023994445801": 34, "715595006942749": 34, "715723037719727": 34, "71601676940918": 34, "716200351715088": 34, "717043399810791": 34, "717501163482666": 34, "718": [37, 38], "718930721282959": 34, "719274520874023": 34, "719524383544922": 34, "72": [4, 6, 13], "720107078552246": 34, "7206292152404785": 34, "721": 27, "722000598907471": 34, "722191333770752": 34, "7227935791015625": 34, "723069190979004": 34, "723470687866211": [32, 35], "723588466644287": 34, "723733425140381": 34, "723975658416748": 34, "723995208740234": 34, "724527359008789": 34, "725409030914307": 34, "726780652999878": 34, "727088212966919": 34, "727319717407227": 34, "727591514587402": 34, "728212833404541": 34, "728569984436035": 34, "729640483856201": 34, "72987174987793": 34, "72b": [1, 21, 23], "73": [4, 10, 23], "730113983154297": 34, "7304390668869019": [32, 35], "73057746887207": 34, "7306365966796875": 34, "7311224937438965": 34, "73159122467041": 34, "731667518615723": 34, "732223510742188": 34, "732889175415039": 34, "734208822250366": 34, "735": 8, "7354": [33, 34], "73932409286499": 34, "739846706390381": 34, "74": [5, 8, 13, 23, 37, 38], "740163803100586": 34, "74027681350708": 34, "741073131561279": 34, "741084098815918": 34, "741124629974365": 34, "741174697875977": 34, "741250038146973": 34, "741294860839844": 34, "741503715515137": 34, "7415623664855957": [32, 35], "741562366485596": 34, "7417104244232178": 34, "742": 27, "743686199188232": 34, "745245933532715": 34, "7454066276550293": 34, "745575428009033": 34, "747305393218994": 34, "747768878936768": 34, "747809410095215": 34, "748711585998535": 34, "7493696212768555": 34, "74m": 6, "75": [4, 5, 10, 14], "750854969024658": 34, "751248836517334": 34, "75154972076416": 34, "751e9282": [37, 38], "752": [33, 34], "75210428237915": 34, "75229549407959": [33, 34], "752303123474121": 34, "752645969390869": 34, "75282621383667": 34, "7530999183654785": 34, "753459453582764": 34, "754215717315674": 34, "754348278045654": 34, "754844903945923": 34, "755044937133789": 34, "755195617675781": 34, "755681991577148": 34, "756224632263184": 34, "7571fd0e": [37, 38], "757355690002441": 34, "7589945793151855": 34, "7592775821685791": [32, 35], "759560585021973": 34, "76": [4, 6, 10, 37, 38], "7600": [32, 33, 34], "760083198547363": 34, "7603330612182617": 34, "7606987953186035": 34, "761293649673462": 34, "761895179748535": 34, "7626": [33, 34], "7630279064178467": 34, "763137340545654": 34, "76379919052124": 34, "763954162597656": 34, "763996601104736": 34, "76458215713501": 34, "764934539794922": 34, "765582084655762": [33, 34], "765937805175781": 34, "766097545623779": 34, "766164302825928": 34, "766860485076904": 34, "7668848037719727": 34, "767918109893799": 34, "767960786819458": 34, "768": [6, 7, 13, 27, 32, 35], "768507957458496": 34, "7687": [37, 38], "7694032192230225": 34, "769754409790039": 34, "77": [4, 10], "7702178955078125": 34, "7712979316711426": 34, "772399663925171": 34, "772454738616943": 34, "77386999130249": 34, "774710655212402": 34, "774909019470215": 34, "774920463562012": 34, "775512218475342": 34, "7771": [33, 34], "778233051300049": 34, "7789058685302734": 34, "779604434967041": 34, "779975414276123": 34, "78": [6, 8, 17, 18, 34, 37, 38], "7802093029022217": 34, "78045129776001": 34, "7807536125183105": 34, "781039237976074": 34, "78139591217041": 34, "781938552856445": [33, 34], "784018039703369": 34, "784379005432129": 34, "785": [32, 33, 34], "785065174102783": 34, "785312175750732": [32, 35], "785589694976807": 34, "785794258117676": 34, "785893201828003": 34, "7861552238464355": 34, "786230087280273": 34, "7864863872528076": 34, "7880635261535645": 34, "7880818843841553": 34, "78818941116333": 34, "788674831390381": 34, "79": [6, 17, 34], "790492057800293": 34, "79287338256836": 34, "793": 27, "79330587387085": 34, "79390287399292": 34, "793996810913086": [33, 34], "795068740844727": 34, "7956585884094238": [32, 35], "795717716217041": 34, "796220779418945": [32, 35], "796965599060059": 34, "797081470489502": 34, "797332763671875": 34, "79794979095459": 34, "798689842224121": 34, "798949718475342": 34, "799320697784424": 34, "799370288848877": 34, "799619197845459": 34, "79gb": 21, "79l": 38, "79l5": 38, "7b": [1, 6, 13, 21, 25], "7b431dcd": [37, 38], "7c9d": [37, 38], "7croboto": 38, "7h2l3": 38, "7x": [4, 5], "8": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 18, 20, 21, 23, 25, 27, 32, 33, 34, 35, 37, 38], "80": [1, 4, 6, 7, 10, 13, 17, 20, 36], "800": [4, 5, 7], "800738334655762": 34, "801295280456543": 34, "802": 27, "802001953125": 34, "803051471710205": 34, "80307149887085": 34, "8037070035934448": [32, 35], "804": 27, "8040966987609863": 34, "805547714233398": 34, "806467056274414": 34, "806612491607666": 34, "807": [4, 5], "807152271270752": 34, "807299613952637": 34, "80978536605835": 34, "80f": [4, 5], "81": [4, 5, 10, 13], "810": 27, "810102939605713": 34, "810388565063477": 34, "8105340003967285": 34, "810624122619629": 34, "811124563217163": 34, "811209678649902": 34, "8114094734191895": 34, "8117189407348633": 34, "812191009521484": 34, "8126726150512695": 34, "8128983974456787": 34, "81308650970459": 34, "81414794921875": 34, "814231872558594": 34, "8145": [33, 34], "8146843910217285": 34, "815140247344971": 34, "8156819343566895": 34, "8167617321014404": 34, "816813945770264": 34, "8174004554748535": 34, "817617416381836": 34, "8177027702331543": 34, "8192": 21, "8197818994522095": 34, "819911003112793": 34, "819949626922607": 34, "81d6": 38, "82": [4, 5, 6, 13, 17, 34], "820557594299316": 34, "8216": 35, "8216800689697266": [32, 35], "821797847747803": 34, "821817398071289": 34, "822120189666748": 34, "8225502967834473": 34, "823371648788452": [32, 35], "823562145233154": 34, "823636054992676": 34, "824": 5, "824695587158203": [32, 35], "825289726257324": 34, "825384616851807": 34, "826181888580322": 34, "8262834548950195": 34, "826323509216309": 34, "8265886306762695": 34, "82674": 32, "826778411865234": [33, 34], "827072620391846": 34, "828341007232666": 34, "828f0e0ce7c3": [37, 38], "829176425933838": 34, "829235553741455": 34, "8292932510375977": 34, "829486131668091": 34, "82970666885376": 34, "83": [6, 10, 13], "830827236175537": 34, "831056118011475": 34, "831080675125122": 34, "831615447998047": 34, "832583427429199": 34, "833148002624512": 34, "833350658416748": 34, "833383560180664": 34, "8344197273254395": 34, "835850715637207": 34, "835949420928955": 34, "835978031158447": 34, "836": [5, 23], "836061954498291": 34, "836536407470703": 34, "8368377685546875": 34, "837181568145752": 34, "8372912406921387": 34, "837329864501953": 34, "837427139282227": 34, "838168621063232": 34, "8385039567947388": [32, 35], "8390822410583496": 34, "8393359184265137": 34, "839694976806641": 34, "83f73b43": 38, "84": [4, 10, 13, 38], "843852519989014": 34, "845158576965332": [33, 34], "8457": 27, "845762729644775": 34, "8462512493133545": 34, "846373081207275": 34, "847": [33, 34], "8480": [33, 34], "848109722137451": 34, "8482837677001953": 34, "848433494567871": 34, "849096417427063": [32, 35], "85": [4, 5, 10, 17, 23], "850433349609375": 34, "850610256195068": 34, "851036548614502": 34, "85136079788208": 34, "852": 27, "852313041687012": 34, "852490425109863": 34, "852870941162109": 34, "853": 27, "853394985198975": 34, "853605031967163": 34, "853939533233643": 34, "8541741371154785": 34, "8544": 32, "854536056518555": 34, "854578495025635": 34, "854784965515137": 34, "857": 5, "857684373855591": 34, "8582260608673096": 34, "858340263366699": 34, "85955286026001": 34, "85ec": [37, 38], "86": [4, 6, 13, 23], "860": 5, "86091": [32, 33, 34], "8609557151794434": 34, "861074447631836": 34, "861825942993164": 34, "861833095550537": [32, 35], "862": [33, 34], "862744331359863": [32, 35], "862921714782715": 34, "863290309906006": 34, "863368034362793": 34, "8637996912002563": [32, 35], "864298343658447": 34, "8648743629455566": 34, "865966796875": 34, "866605758666992": [32, 35], "866785049438477": 34, "867308616638184": 34, "868498802185059": 34, "87": [4, 5, 6, 10, 13, 23], "8703227043151855": 34, "8712005615234375": [32, 35], "871994972229004": 34, "872298240661621": 34, "872332572937012": 34, "872432708740234": 34, "872669696807861": 34, "87325382232666": 34, "873578071594238": 34, "8736047744750977": 34, "87380313873291": 34, "8748": 16, "8751044273376465": 34, "876048564910889": 34, "876171588897705": 34, "8763": 16, "876376628875732": 34, "87647533416748": 34, "8772687911987305": 34, "878566741943359": 34, "879708290100098": 34, "88": [4, 10, 13, 27], "880929946899414": 34, "881252765655518": 34, "882": [33, 34], "882725715637207": 34, "883283615112305": 34, "883755207061768": 34, "884": [37, 38], "884681701660156": 34, "884730815887451": 34, "88575": [33, 34], "885791301727295": 34, "885951042175293": 34, "886054039001465": 34, "886f": [37, 38], "887": 8, "8876073360443115": 34, "8876633644104": 34, "8881": [33, 34], "888261795043945": 34, "888372898101807": 34, "888976573944092": 34, "889030933380127": 34, "889654159545898": [32, 35], "889729976654053": 34, "89": [4, 10, 13, 23, 38], "890717029571533": 34, "890924453735352": 34, "892027854919434": 34, "892342567443848": 34, "892409324645996": 34, "8928182125091553": 34, "8931796550750732": 34, "893668174743652": 34, "894": [32, 33, 34], "89480447769165": 34, "895185947418213": 34, "8953351974487305": 34, "895663738250732": 34, "895957946777344": 34, "896": [1, 21, 31, 33, 34], "896338701248169": 34, "897386074066162": 34, "897405624389648": 34, "897862672805786": 34, "8983609676361084": 34, "898429870605469": 34, "899875164031982": 34, "899890422821045": 34, "8a4": 38, "8aa8": [37, 38], "8b": [4, 5, 38], "8bit": [4, 5], "8k": 38, "8l11": 38, "8z": 38, "9": [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 21, 22, 23, 25, 26, 27, 32, 33, 34, 35, 37, 38], "90": [4, 6, 10, 17, 23, 32, 35, 37, 38], "900": [4, 5], "900402545928955": 34, "90108060836792": 34, "90164852142334": 34, "90189790725708": 34, "9022767543792725": 34, "903525352478027": 34, "90477180480957": 34, "9049072265625": 34, "9050904512405396": [32, 35], "9056620597839355": 34, "906172513961792": 34, "9063": [33, 34], "90633487701416": 34, "906378746032715": 34, "906666278839111": 34, "9074": 35, "91": [4, 13, 23], "910447120666504": 34, "911383628845215": 34, "911465644836426": [32, 35], "91188907623291": 34, "912365198135376": 34, "912549018859863": 34, "9133124351501465": 34, "913785934448242": 34, "9140095710754395": 34, "9142746925354": 34, "914324760437012": 34, "914765357971191": 34, "916": [33, 34], "9162068367004395": 34, "916520118713379": 34, "91668176651001": 34, "917107582092285": 34, "917119979858398": 34, "917527198791504": 34, "918045997619629": 34, "918137550354004": 34, "918391704559326": 34, "918561935424805": 34, "9189252853393555": 34, "9197351932525635": 34, "92": [4, 5, 6, 13, 18, 38], "920": 4, "920042514801025": 34, "9200592041015625": 34, "9204912185668945": 34, "920564889907837": 34, "921731472015381": 34, "9226": [37, 38], "922638893127441": 34, "92359733581543": 34, "9241669178009033": 34, "9244496822357178": 34, "924680709838867": 34, "924805164337158": 34, "924842834472656": 34, "924886226654053": 34, "925065279006958": 34, "925262928009033": 34, "92586088180542": 34, "927282333374023": [33, 34], "927736759185791": 34, "928682327270508": 34, "9287333488464355": 34, "9288668632507324": 34, "929": 8, "929883003234863": 34, "92l10": 38, "93": [6, 10, 13, 18], "930153846740723": 34, "930305480957031": 34, "931658744812012": 34, "931668281555176": 34, "932027578353882": 34, "932221412658691": 34, "932360649108887": 34, "9330551624298096": 34, "934": 27, "9340012073516846": 34, "934217929840088": 34, "934983253479004": [33, 34], "935726165771484": 34, "936": 32, "9394731521606445": 34, "939565896987915": 34, "94": 4, "9410641193389893": 34, "9412453174591064": 34, "941544532775879": 34, "9419379234313965": 34, "94294548034668": 34, "943296194076538": 34, "9441943168640137": 34, "946": 27, "94623327255249": 34, "946823835372925": 34, "947456359863281": [33, 34], "948013305664062": 34, "9481024742126465": 34, "948268890380859": 34, "948304653167725": 34, "9484546184539795": 34, "948454856872559": 34, "948586463928223": 34, "949153900146484": 34, "95": 6, "950": 27, "950073719024658": 34, "9502949714660645": 34, "950989246368408": 34, "951192378997803": 34, "951941967010498": 34, "952410697937012": 34, "952450275421143": 34, "95388650894165": 34, "95413064956665": 34, "954265594482422": 34, "9543941020965576": 34, "954722881317139": 34, "955": 27, "955168724060059": 34, "955503463745117": [32, 35], "9562225341796875": 34, "9569365978240967": 34, "956958293914795": 34, "9570159912109375": 34, "959106922149658": 34, "959136009216309": 34, "9597320556640625": 34, "95d43e88c7c1": [37, 38], "96": [1, 4, 6, 12], "96026611328125": 34, "961142539978027": 34, "961429595947266": 34, "961651802062988": [33, 34], "9625": [33, 34], "963241577148438": 34, "964029312133789": [33, 34], "9645": [32, 33, 34], "965": 27, "9658665657043457": 34, "966070652008057": 34, "966353416442871": 34, "9665141105651855": 34, "967166423797607": 34, "967503786087036": 34, "968055009841919": [32, 35], "968337297439575": 34, "969112873077393": 34, "969647169113159": 34, "96h2": 38, "97": [4, 7, 37, 38], "970147609710693": 34, "9703688621521": 34, "970599412918091": 34, "9712347984313965": 34, "9737207889556885": 34, "9738078117370605": 34, "9749789237976074": 34, "975": [33, 34], "975719928741455": 34, "976319313049316": [32, 35], "977041721343994": 34, "97719144821167": 34, "977738380432129": 34, "978": [37, 38], "978025436401367": 34, "979550361633301": 34, "98": [4, 13, 37, 38], "980317115783691": 34, "981": [37, 38], "9820597171783447": 34, "9838547706604": 34, "9840877056121826": 34, "985": 5, "985239267349243": 34, "9856": [33, 34], "985677719116211": 34, "98590087890625": 34, "9863040447235107": 34, "9869866371154785": 34, "987048387527466": 34, "98706579208374": 34, "9870753288269043": [32, 35], "988": 5, "988377571105957": 34, "988438606262207": 34, "988609313964844": 34, "9887170791625977": [32, 35], "988809585571289": 34, "988922595977783": 34, "988944053649902": 34, "99": [4, 13], "992218255996704": 34, "992305278778076": 34, "99277925491333": 34, "9927866458892822": 34, "9929": 5, "993241786956787": 34, "9939": 5, "9949235916137695": 34, "995843887329102": 34, "995906829833984": 34, "9966230392456055": 34, "997178077697754": 34, "9978317618370056": [32, 35], "998691082000732": 34, "999": 25, "999240875244141": 34, "999532699584961": 34, "999742269515991": 34, "999855995178223": 34, "9998772144317627": 34, "9bsdp": 21, "9fd33479": [37, 38], "9gb": 21, "9m": 23, "9z": 38, "9zm20": 38, "A": [0, 1, 2, 3, 5, 7, 8, 9, 10, 12, 13, 16, 18, 19, 21, 22, 24, 25, 30, 33, 36, 37, 38], "AND": 4, "ANDs": 4, "AT": 7, "And": [4, 13, 19, 20, 21, 22], "As": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 25, 37, 38], "At": [2, 4, 5, 6, 11, 13, 14, 16, 20, 21, 22, 23, 24], "Be": 20, "Being": [4, 12], "But": [4, 5, 8, 12, 18, 21, 22], "By": [0, 1, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 17, 20, 22, 25, 30, 36, 37, 38], "For": [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 37, 38], "IN": [37, 38], "IT": [13, 20, 37, 38], "If": [1, 2, 4, 5, 6, 7, 8, 11, 13, 14, 17, 19, 20, 21, 22, 24, 30, 36, 37, 38], "In": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "It": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 36, 37, 38], "Its": [4, 16], "No": [8, 13, 18, 37, 38], "Not": [12, 19, 21, 25], "OR": [4, 11], "ORs": 4, "Of": [4, 38], "On": [1, 4, 6, 7, 11, 12, 18, 20, 21, 22, 23, 24, 25, 38], "One": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 20, 22, 23, 24, 25, 37, 38], "Or": 24, "Such": [1, 4, 5, 12, 19, 20, 22, 37, 38], "That": [1, 4, 5, 6, 7, 10, 12, 13, 22, 24, 25], "The": [2, 3, 5, 6, 9, 10, 16, 17, 18, 19, 20, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "Their": [1, 4, 7, 19, 37, 38], "Then": [4, 5, 7, 8, 13, 17, 25], "There": [3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 19, 20, 25, 30, 31, 33, 34, 36, 37, 38], "These": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 25, 37, 38], "To": [1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 16, 17, 19, 20, 22, 23, 25, 36, 38], "With": [1, 2, 4, 5, 7, 10, 11, 12, 13, 17, 19, 20, 21, 22, 24, 25, 37, 38], "_": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "_0": [22, 23], "_1": [1, 2, 4, 5, 11, 30, 31, 33, 34, 36], "_2": [2, 4, 11], "__analyt": 38, "__config": 38, "__drawer": 38, "__getitem__": [32, 33, 34, 35], "__init__": [30, 31, 32, 33, 34, 35, 36], "__len__": [32, 33, 34, 35], "__main__": [31, 32, 33, 34, 35], "__md_analyt": 38, "__md_get": 38, "__md_hash": 38, "__md_scope": 38, "__md_set": 38, "__name__": [31, 32, 33, 34, 35], "__nav_1": 38, "__nav_1_5": 38, "__nav_1_5_label": 38, "__nav_1_8": 38, "__nav_1_8_label": 38, "__nav_1_label": 38, "__nav_2": 38, "__nav_2_3": 38, "__nav_2_3_2": 38, "__nav_2_3_2_label": 38, "__nav_2_3_label": 38, "__nav_2_4": 38, "__nav_2_4_label": 38, "__nav_2_5": 38, "__nav_2_5_label": 38, "__nav_2_6": 38, "__nav_2_6_label": 38, "__nav_2_8": 38, "__nav_2_8_2": 38, "__nav_2_8_2_label": 38, "__nav_2_8_label": 38, "__nav_2_9": 38, "__nav_2_9_2": 38, "__nav_2_9_2_label": 38, "__nav_2_9_3": 38, "__nav_2_9_3_label": 38, "__nav_2_9_4": 38, "__nav_2_9_4_label": 38, "__nav_2_9_5": 38, "__nav_2_9_5_label": 38, "__nav_2_9_label": 38, "__nav_2_label": 38, "__nav_3": 38, "__nav_3_label": 38, "__nav_4": 38, "__nav_4_10": 38, "__nav_4_10_label": 38, "__nav_4_11": 38, "__nav_4_11_label": 38, "__nav_4_12": 38, "__nav_4_12_label": 38, "__nav_4_13": 38, "__nav_4_13_label": 38, "__nav_4_14": 38, "__nav_4_14_label": 38, "__nav_4_15": 38, "__nav_4_15_label": 38, "__nav_4_16": 38, "__nav_4_16_label": 38, "__nav_4_17": 38, "__nav_4_17_label": 38, "__nav_4_18": 38, "__nav_4_18_label": 38, "__nav_4_19": 38, "__nav_4_19_label": 38, "__nav_4_2": 38, "__nav_4_20": 38, "__nav_4_20_label": 38, "__nav_4_21": 38, "__nav_4_21_label": 38, "__nav_4_22": 38, "__nav_4_22_label": 38, "__nav_4_23": 38, "__nav_4_23_label": 38, "__nav_4_24": 38, "__nav_4_24_label": 38, "__nav_4_25": 38, "__nav_4_25_label": 38, "__nav_4_26": 38, "__nav_4_26_label": 38, "__nav_4_27": 38, "__nav_4_27_label": 38, "__nav_4_28": 38, "__nav_4_28_label": 38, "__nav_4_29": 38, "__nav_4_29_label": 38, "__nav_4_2_label": 38, "__nav_4_3": 38, "__nav_4_30": 38, "__nav_4_30_label": 38, "__nav_4_31": 38, "__nav_4_31_label": 38, "__nav_4_32": 38, "__nav_4_32_label": 38, "__nav_4_33": 38, "__nav_4_33_label": 38, "__nav_4_34": 38, "__nav_4_34_label": 38, "__nav_4_35": 38, "__nav_4_35_label": 38, "__nav_4_36": 38, "__nav_4_36_label": 38, "__nav_4_37": 38, "__nav_4_37_label": 38, "__nav_4_38": 38, "__nav_4_38_label": 38, "__nav_4_39": 38, "__nav_4_39_label": 38, "__nav_4_3_label": 38, "__nav_4_4": 38, "__nav_4_4_label": 38, "__nav_4_5": 38, "__nav_4_5_label": 38, "__nav_4_6": 38, "__nav_4_6_label": 38, "__nav_4_7": 38, "__nav_4_7_label": 38, "__nav_4_8": 38, "__nav_4_8_label": 38, "__nav_4_9": 38, "__nav_4_9_label": 38, "__nav_4_label": 38, "__nav_5": 38, "__nav_5_10": 38, "__nav_5_10_5": 38, "__nav_5_10_5_label": 38, "__nav_5_10_label": 38, "__nav_5_11": 38, "__nav_5_11_label": 38, "__nav_5_13": 38, "__nav_5_13_label": 38, "__nav_5_2": 38, "__nav_5_2_2": 38, "__nav_5_2_2_label": 38, "__nav_5_2_label": 38, "__nav_5_3": 38, "__nav_5_3_label": 38, "__nav_5_4": 38, "__nav_5_4_2": 38, "__nav_5_4_2_label": 38, "__nav_5_4_4": 38, "__nav_5_4_4_label": 38, "__nav_5_4_5": 38, "__nav_5_4_5_label": 38, "__nav_5_4_6": 38, "__nav_5_4_6_label": 38, "__nav_5_4_label": 38, "__nav_5_5": 38, "__nav_5_5_label": 38, "__nav_5_6": 38, "__nav_5_6_label": 38, "__nav_5_7": 38, "__nav_5_7_10": 38, "__nav_5_7_10_label": 38, "__nav_5_7_2": 38, "__nav_5_7_2_label": 38, "__nav_5_7_3": 38, "__nav_5_7_3_label": 38, "__nav_5_7_4": 38, "__nav_5_7_4_label": 38, "__nav_5_7_5": 38, "__nav_5_7_5_label": 38, "__nav_5_7_6": 38, "__nav_5_7_6_label": 38, "__nav_5_7_9": 38, "__nav_5_7_9_label": 38, "__nav_5_7_label": 38, "__nav_5_8": 38, "__nav_5_8_label": 38, "__nav_5_9": 38, "__nav_5_9_label": 38, "__nav_5_label": 38, "__nav_6": 38, "__nav_6_4": 38, "__nav_6_4_label": 38, "__nav_6_5": 38, "__nav_6_5_label": 38, "__nav_6_label": 38, "__nav_7": 38, "__nav_7_10": 38, "__nav_7_10_label": 38, "__nav_7_11": 38, "__nav_7_11_label": 38, "__nav_7_12": 38, "__nav_7_12_11": 38, "__nav_7_12_11_label": 38, "__nav_7_12_label": 38, "__nav_7_13": 38, "__nav_7_13_label": 38, "__nav_7_14": 38, "__nav_7_14_label": 38, "__nav_7_15": 38, "__nav_7_15_label": 38, "__nav_7_16": 38, "__nav_7_16_label": 38, "__nav_7_17": 38, "__nav_7_17_label": 38, "__nav_7_18": 38, "__nav_7_18_label": 38, "__nav_7_19": 38, "__nav_7_19_label": 38, "__nav_7_2": 38, "__nav_7_20": 38, "__nav_7_20_label": 38, "__nav_7_21": 38, "__nav_7_21_label": 38, "__nav_7_22": 38, "__nav_7_22_label": 38, "__nav_7_23": 38, "__nav_7_23_label": 38, "__nav_7_24": 38, "__nav_7_24_label": 38, "__nav_7_25": 38, "__nav_7_25_label": 38, "__nav_7_26": 38, "__nav_7_26_label": 38, "__nav_7_27": 38, "__nav_7_27_label": 38, "__nav_7_28": 38, "__nav_7_28_label": 38, "__nav_7_29": 38, "__nav_7_29_label": 38, "__nav_7_2_label": 38, "__nav_7_3": 38, "__nav_7_30": 38, "__nav_7_30_label": 38, "__nav_7_31": 38, "__nav_7_31_label": 38, "__nav_7_32": 38, "__nav_7_32_1": 38, "__nav_7_32_1_label": 38, "__nav_7_32_2": 38, "__nav_7_32_2_label": 38, "__nav_7_32_3": 38, "__nav_7_32_3_label": 38, "__nav_7_32_4": 38, "__nav_7_32_4_label": 38, "__nav_7_32_5": 38, "__nav_7_32_5_label": 38, "__nav_7_32_6": 38, "__nav_7_32_6_label": 38, "__nav_7_32_7": 38, "__nav_7_32_7_label": 38, "__nav_7_32_label": 38, "__nav_7_33": 38, "__nav_7_33_label": 38, "__nav_7_34": 38, "__nav_7_34_label": 38, "__nav_7_3_label": 38, "__nav_7_4": 38, "__nav_7_4_label": 38, "__nav_7_5": 38, "__nav_7_5_label": 38, "__nav_7_6": 38, "__nav_7_6_label": 38, "__nav_7_7": 38, "__nav_7_7_label": 38, "__nav_7_8": 38, "__nav_7_8_label": 38, "__nav_7_9": 38, "__nav_7_9_label": 38, "__nav_7_label": 38, "__nav_8": 38, "__nav_8_3": 38, "__nav_8_3_label": 38, "__nav_8_5": 38, "__nav_8_5_label": 38, "__nav_8_label": 38, "__nav_9": 38, "__nav_9_label": 38, "__palett": 38, "__palette_0": 38, "__palette_1": 38, "__palette_2": 38, "__search": 38, "__tabbed_": 38, "__toc": 38, "_d": 2, "_execution_engin": 34, "_f": 1, "_get_batch_logp": 33, "_h": 1, "_i": [1, 2, 4, 5, 8, 11, 12], "_j": [1, 11], "_k": [12, 23, 25], "_m": 11, "_mkdocstr": 38, "_n": 14, "_prepare_4d_causal_attention_mask_with_cache_posit": [30, 36], "_q": [4, 13], "_r": 4, "_static": 38, "_t": [2, 4, 12, 14], "_tensor": 34, "_tied_weights_kei": [30, 31, 33, 34, 36], "_update_causal_mask": [30, 36], "_v": 23, "_w": 13, "_x": 13, "a21a738": [37, 38], "a3a5": [37, 38], "a3e27ab0": [37, 38], "a3f1": [37, 38], "a94e91d": [37, 38], "a_": [1, 4, 5, 6, 7, 22], "a_0": [22, 24], "a_1": 24, "a_q": 4, "a_r": 4, "a_t": [22, 24], "aakanksha": [17, 23], "aapo": 25, "aaron": 5, "aayog": [37, 38], "ab": [1, 2, 5, 7, 11, 13, 17, 18, 21, 22, 23], "ab1d8deded01": [37, 38], "abbrevi": 4, "abcd": 10, "abdelrahman": 10, "abdomen": 4, "abhimanyu": 1, "abhinav": 1, "abiiti": [5, 20], "abil": [0, 1, 2, 4, 5, 6, 7, 9, 12, 20, 22, 23, 25, 38], "abl": [4, 5, 6, 7, 8, 11, 12, 21, 22, 38], "ablat": [7, 13, 17], "abnorm": 4, "abolut": 1, "about": [1, 4, 5, 6, 7, 13, 17, 19, 20, 22, 23, 36, 37, 38], "abov": [1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 18, 20, 22, 23, 24, 25, 30, 36, 38], "absenc": [4, 5, 22], "absmax": 13, "absolut": [4, 5, 7, 8, 13, 21], "absorb": 6, "abstract": [3, 4, 5, 10, 17, 24, 38], "ac": [37, 38], "ac08b3e72275": [37, 38], "academ": [4, 5, 37, 38], "acc": [10, 23], "accademia": [], "acceler": [0, 1, 4, 5, 11, 29], "accent": [4, 38], "accept": [4, 5, 10, 37, 38], "access": [0, 4, 5, 11, 13, 20, 36, 37, 38], "accid": [4, 5], "accident": [4, 5], "accommod": [4, 13], "accomplish": [4, 5, 6, 11, 18, 19, 21, 22], "accord": [4, 5, 13, 14, 20, 21, 24], "accordingli": [4, 6], "account": [1, 4, 5, 7, 30, 31, 33, 34, 36, 37, 38], "accountabilityprocess": [37, 38], "accredit": [37, 38], "accum": 13, "accumul": [4, 5, 13, 21, 25, 38], "accumulate_grad": 34, "accur": [1, 2, 3, 4, 5, 7, 8, 10, 13, 17, 18, 19, 20, 23, 25, 36, 37, 38], "accuraci": [0, 4, 5, 8, 13, 17, 19, 20, 21, 37, 38], "accuracy_in_clinical_document": [37, 38], "acero": 5, "acheiv": 4, "achiev": [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 22, 23, 30, 31, 33, 34, 36], "achin": [1, 2, 10, 11], "aci": [37, 38], "acid": [4, 5], "acklei": 4, "acl2023": [19, 20], "acm": [5, 11, 20], "acquir": [1, 6, 7, 25], "acquisit": 2, "acronym": 20, "across": [0, 1, 2, 4, 5, 6, 7, 11, 12, 13, 16, 17, 18, 20, 21, 23, 25, 30, 31, 33, 34, 36, 37, 38], "act": [1, 2, 4, 11, 18, 22, 23, 32, 35, 37, 38], "action": [4, 5, 16, 18, 19, 22, 36, 38], "actit": 21, "activ": [1, 2, 4, 5, 6, 7, 11, 13, 20, 37, 38], "activeloop": 38, "actor": 4, "actual": [4, 5, 7, 8, 12, 13, 20, 22, 23], "ad": [1, 2, 3, 6, 7, 8, 11, 13, 14, 16, 19, 20, 22, 23, 25, 37, 38], "ad54": [37, 38], "adam": [4, 5, 10, 23], "adamw": [32, 33, 34, 35], "adap": 23, "adapt": [1, 2, 4, 5, 6, 7, 11, 14, 16, 18, 20, 22, 38], "adaptor": 23, "adc": [4, 5], "add": [1, 2, 4, 5, 7, 10, 11, 13, 14, 16, 20, 22, 23, 25, 30, 31, 33, 34, 36, 38], "addeventlisten": 38, "addison": 5, "addit": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 25, 36], "addition": [2, 21, 22], "additional_kwarg": [37, 38], "addon": 38, "address": [1, 2, 4, 5, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 37, 38], "adept": 23, "adequaci": 20, "adher": [4, 20], "adhocretrievaldemob": 4, "adhocretrievaldemogoogl": 4, "adiabat": 4, "aditya": [7, 16], "adject": [4, 8, 12], "adjust": [1, 2, 4, 5, 7, 12, 13, 20, 25, 36], "administr": [37, 38], "administrative_data": [37, 38], "admiss": [37, 38], "admit": [4, 17], "adopt": [1, 4, 5, 6, 7, 10, 11, 16, 20, 21, 22, 37, 38], "adpt": 23, "advanc": [0, 1, 2, 3, 4, 6, 7, 8, 11, 12, 16, 22, 29, 37, 38], "advanced_ingestion_pipelin": 38, "advanced_prompt": 38, "advanced_rag_with_llamapars": 38, "advanced_retriev": 38, "advanced_text_to_sql": 38, "advantag": [1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 25, 37, 38], "advent": [0, 7, 37, 38], "adventur": [6, 38], "adverb": 12, "adversari": 7, "advertis": 4, "advic": [4, 37, 38], "advis": 4, "advisor": [], "aer": 8, "affect": [1, 4, 5, 8, 20, 22, 25], "affili": [37, 38], "affin": [2, 13], "afflin": 13, "afford": [4, 21], "aforement": 2, "africa": [37, 38], "after": [1, 3, 4, 5, 7, 8, 11, 12, 13, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "afterend": 38, "ag": [1, 3, 4, 5, 29, 37, 38], "again": [4, 5, 13, 22], "against": [4, 5, 7, 20, 22], "agarw": [16, 22], "agenc": 19, "agent": [3, 22, 24, 37, 38], "agent_around_query_pipeline_with_hyde_for_pdf": 38, "agent_build": 38, "agent_runn": 38, "agent_runner_rag_control": 38, "agent_search": 38, "agent_search_retriev": 38, "agentic_rag_using_vertex_ai": 38, "agentic_rag_with_llamaindex_and_vertexai_managed_index": 38, "agentic_strategi": 38, "agentop": 38, "agents_coa": 38, "agents_lat": 38, "agents_llm_compil": 38, "aggreg": [4, 5, 12, 21, 37, 38], "aggress": [1, 4, 13, 23, 25], "aghajanyan": 7, "agi": 0, "agnost": [4, 5, 6, 7, 10], "ago": [], "ago0": 4, "agre": 20, "agreement": [4, 5, 8], "ahm": [1, 5], "ahmad": 4, "ahz": 1, "ai": [1, 2, 4, 5, 8, 12, 20, 22, 29, 37, 38], "ai2019learn": 4, "ai21": 38, "aid": [4, 5, 19, 37, 38], "aidan": [5, 11], "aigc": 16, "aim": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 16, 17, 19, 20, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "aimcallback": 38, "ain": 12, "ainsli": 1, "aiohappyeyebal": [37, 38], "aiohttp": [37, 38], "aiosign": [37, 38], "airbyt": 38, "airbyte_cdk": 38, "airbyte_gong": 38, "airbyte_hubspot": 38, "airbyte_salesforc": 38, "airbyte_shopifi": 38, "airbyte_strip": 38, "airbyte_typeform": 38, "airbyte_zendesk_support": 38, "airlin": 4, "airtabl": 38, "airtrain": 38, "airtrainai": 38, "aisearch": 38, "aitchison": 23, "aixin": 2, "aka": 38, "akari": 19, "akc": 4, "al": [1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 16, 21, 22, 23, 37, 38], "alarm": 4, "albeit": [37, 38], "alben": 21, "albert": [1, 11, 23], "alberti": 5, "alcohol": [4, 5], "aldo": 23, "alec": [6, 8, 10, 11, 16, 22, 25], "aleph": 38, "alephalpha": 38, "alessandro": 5, "alex": [5, 19, 22, 23], "alexand": [11, 20], "alexandr": 1, "alexandra": 1, "alexei": 11, "alexi": 7, "alg": 24, "algebra": 22, "algolia": 38, "algorithm": [1, 4, 5, 12, 19, 21], "aliaksei": 5, "alibaba": 38, "alibabacloud": 38, "alibabacloud_aisearch": 38, "alibabacloud_aisearch_rerank": 38, "alibabacloud_opensearch": 38, "alibabacloudopensearchindexdemo": 38, "alic": 19, "align": [0, 1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 16, 18, 20, 23, 24, 25, 29, 30, 36], "alik": 4, "all": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 30, 31, 33, 34, 36, 37, 38], "all_logit": 33, "all_logp": 33, "allan": [5, 22], "alleg": 8, "allen": 23, "aller": 6, "allerg": [4, 5], "allergi": [37, 38], "allevi": [1, 2, 4, 5, 8, 9, 11, 20], "allgath": 21, "alloc": [2, 4, 13, 37, 38], "allow": [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 24, 25, 37, 38], "allow_unreach": 34, "allowed_speci": 35, "allreduc": 21, "almeida": 22, "almost": [4, 37, 38], "alon": [4, 6, 7, 11, 23, 36], "along": [1, 4, 5, 6, 20, 24, 30, 31, 33, 34, 36, 37, 38], "aloud": 18, "alpaca_data": [32, 33, 34], "alpha": [1, 2, 4, 5, 7, 12, 14, 23, 25, 38], "alpha_0": 25, "alpha_1": 2, "alpha_2": 2, "alpha_k": 25, "alphabet": [4, 5], "alreadi": [4, 5, 20, 23, 24, 30, 36, 37, 38], "also": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 36, 37, 38], "alt": 38, "altdj": 1, "alter": 4, "altern": [4, 5, 7, 8, 12, 14, 20, 24, 37, 38], "although": [1, 4, 5, 7, 9, 11, 12, 20, 21, 22, 23, 24, 25], "alwai": [2, 4, 5, 6, 8, 18, 21, 38], "am": [4, 7], "amanda": [1, 6, 8, 11, 16, 22], "amaz": [4, 18], "amazon": [4, 38], "amazon_product_extract": 38, "amazonaw": [6, 8, 11], "amazonneptunevectordemo": 38, "ambigu": [3, 4, 5, 6, 19, 20, 22], "amen": [4, 10, 11], "amend": [37, 38], "america": [4, 12, 37, 38], "american": [3, 4], "amir": 5, "amodei": [6, 8, 10, 11, 22, 25], "among": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 23, 37, 38], "amount": [0, 1, 4, 5, 6, 7, 8, 11, 13, 14, 16, 20, 21, 22, 23, 25, 38], "amp": 38, "amper": 21, "an": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 32, 33, 34, 36, 37, 38], "anaconda3": [27, 34, 37, 38], "analog": 4, "analys": 4, "analysi": [4, 5, 7, 12, 13, 20, 22, 37, 38], "analyt": [11, 22, 37, 38], "analyticdb": 38, "analyticdbdemo": 38, "analyz": [1, 2, 3, 4, 11, 13, 19, 20, 38], "anastomos": [37, 38], "anastomot": [37, 38], "anasw": 7, "anatomi": [6, 37, 38], "anc": [4, 5], "ancenegativesamplingdemo": 4, "anchor": [4, 5], "andi": 22, "andrea": 23, "andrei": 23, "andrej": 12, "andrew": [5, 23, 25], "angel": 3, "angestellt": 4, "angl": [1, 4, 20], "angola": 12, "angular": [4, 5], "ani": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 18, 19, 20, 23, 37, 38], "anim": 4, "animos": 10, "anisotrop": 5, "ankur": 5, "ann": [1, 4, 5, 8, 22, 37, 38], "ann_18_02_05": [37, 38], "anna": 22, "annot": [4, 5, 8, 16, 19, 20, 22, 23, 29, 37, 38], "annotated_typ": [37, 38], "announc": 38, "annual": [12, 20, 37, 38], "anonym": 4, "anoth": [1, 4, 5, 7, 8, 9, 11, 12, 20, 25], "anserini": [4, 5], "answer": [1, 3, 7, 10, 11, 12, 16, 17, 18, 19, 20, 23, 25, 36, 37, 38], "answer_and_context_relev": 38, "answer_relev": 38, "ant": [37, 38], "anthrop": [22, 38], "anthropic_ag": 38, "anthropic_haiku": 38, "anthropic_multi_mod": 38, "anthropic_prompt_cach": 38, "antic": 4, "anticip": 4, "antoin": 5, "anton": 20, "antonym": 4, "anyio": [37, 38], "anyon": [], "anyscal": 38, "anyth": [4, 37, 38], "anytim": [37, 38], "anywai": 4, "anywher": [37, 38], "apache_kafka": 38, "apart": [1, 4, 5], "api": 38, "api_kei": [37, 38], "api_refer": 38, "apifi": 38, "apiserv": 38, "apolog": 19, "apostroph": 4, "app": 38, "appar": [3, 12], "appeal": [1, 4], "appear": [4, 5, 8, 9, 12, 13, 14, 19], "append": [4, 5, 27, 32, 33, 34, 35], "appendix": 25, "appetit": 4, "appl": [7, 12, 37, 38], "appli": [1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 16, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "applic": [0, 1, 4, 5, 7, 8, 10, 11, 12, 14, 19, 20, 23, 24, 25, 36, 37, 38], "applicationmaintain": [37, 38], "applicationnlp_irsearch": [4, 5], "apply_rotary_pos_emb": [30, 31, 33, 34, 36], "apporach": 14, "appreci": 4, "approach": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 24, 25, 35, 38], "approch": 22, "appropri": [2, 4, 5, 8, 20, 32, 33, 34, 36, 37, 38], "approv": 4, "approx": [4, 5, 8, 11, 12, 13, 21, 24, 25], "approx1": 12, "approxim": [1, 8, 12, 13, 22, 23], "apr": [37, 38], "april": [37, 38], "apurva": 19, "aquarium": 4, "ar": [0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "arab": 1, "arang": [16, 30, 31, 32, 33, 34, 35, 36], "arango": 38, "arango_db": 38, "arbitrari": [4, 7, 20, 30, 36], "arbitrarili": [6, 8, 24], "arc": 6, "arcco": [4, 5], "archectur": 23, "archit": 22, "architectur": [0, 3, 6, 9, 10, 12, 13, 20, 21, 23, 25, 36], "architur": 23, "area": [2, 4, 17, 20], "aren": 4, "arg": [4, 5, 24, 30, 31, 33, 34, 36, 38], "arg_pack": 38, "argentina": 4, "argentinian": 4, "argentino": 4, "argentinocompar": 4, "argilla": 38, "argmax": [2, 12, 14, 20], "argmax_": [], "argmin": 12, "argu": 22, "arguabl": [37, 38], "argument": [1, 4, 38], "ari": 5, "aria": 38, "aris": [0, 4, 5, 7, 20], "arithemat": 6, "arithmet": [1, 17, 21], "ariz": 38, "arize_phoenix": 38, "arize_phoenix_query_engin": 38, "arizona": [4, 5], "arka": 22, "arm": 4, "armand": 12, "armen": 7, "arnold": 5, "arora": 12, "around": [4, 5, 8, 12, 20, 37, 38], "arrai": [1, 3, 4, 7, 11, 12, 23, 24], "arrang": 4, "arriv": [4, 12, 17, 19, 21, 22], "ars": 20, "art": [0, 2, 4, 5, 6, 8, 10, 11, 19, 38], "arthur": 1, "articl": [4, 5, 7, 8, 11, 13, 16, 20, 38], "artifici": [0, 1, 8, 20], "artist": [4, 19], "artperform": 11, "arun": 5, "arvind": [1, 6, 8, 11], "arxiv": [1, 2, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 38], "as_query_engin": [37, 38], "as_retriev": [37, 38], "asai": 19, "asana": 38, "asap": 4, "ascend": [4, 5], "ascii": 1, "ashish": [5, 11], "ashwin": 14, "asia": [37, 38], "asian": [37, 38], "asid": 4, "ask": [1, 4, 5, 6, 10, 16, 17, 18, 19, 20, 25, 36, 38], "askel": [1, 6, 8, 11, 16, 22], "asker": 4, "aspect": [2, 4, 5, 9, 11, 18, 19, 20, 23, 25, 36, 37, 38], "aspel": 4, "assembl": 12, "assemblyai": 38, "assert": [32, 33, 35], "assess": [4, 6, 19, 20, 22, 23, 37, 38], "assesse": [37, 38], "assessor": [37, 38], "asset": [6, 8, 11, 37, 38], "assign": [2, 4, 5, 8, 22, 37, 38], "assignmodel": 4, "assist": [0, 4, 5, 20, 22, 23, 36, 38], "associ": [2, 3, 4, 5, 7, 11, 12, 14, 20, 22, 24, 25, 37, 38], "assum": [5, 7, 8, 11, 12, 13, 20, 21, 22, 24, 25, 30, 36], "assumpt": [4, 5, 7, 9, 17, 23], "assur": [4, 37, 38], "ast18": 7, "astana": 12, "astonish": 4, "astra": 38, "astra_db": 38, "astradbindexdemo": 38, "asymmetr": [4, 5, 13], "async": [37, 38], "async_ingestion_pipelin": 38, "asynchron": [4, 5], "asyncindexcreationdemo": 38, "asyncio": [37, 38], "atari": 24, "athen": 12, "athena": 38, "athlet": 4, "atla": 38, "atom": [3, 12, 20], "att": [11, 32, 35], "attach": [4, 10], "attain": [37, 38], "attariyan": 23, "attempt": [4, 6, 18, 37, 38], "attend": [1, 3, 4, 5, 7, 11, 13, 16, 30, 36], "attent": [2, 3, 4, 5, 6, 7, 8, 10, 16, 20, 21, 23], "attentent": [4, 5], "attention_bia": [30, 36], "attention_dropout": [30, 31, 33, 34, 36], "attention_logit": [32, 35], "attention_mask": [30, 36], "attention_sc": [30, 31, 33, 34, 36], "attention_weight": [32, 35], "attentionweight": 1, "attitud": [37, 38], "attn": 7, "attn_output": [30, 31, 33, 34, 36], "attn_weight": [30, 31, 33, 34, 36], "attnet": 1, "attornei": 4, "attr": [37, 38], "attract": [4, 7, 8], "attribut": [4, 19, 37, 38], "au": 6, "audio": [8, 36], "audit": [20, 37, 38], "aug": 6, "augment": [0, 3, 4, 5, 7, 19, 36, 38], "australian": [37, 38], "auth": [37, 38], "authent": [37, 38], "author": [3, 4, 5, 7, 17, 20, 22, 37, 38], "auto": [4, 6, 10, 11, 20, 25, 38], "auto_merg": 38, "auto_merging_retriev": 38, "auto_prev_next": 38, "auto_retriev": 38, "auto_vs_recursive_retriev": 38, "autocomplet": 38, "autoencod": 4, "autograd": 34, "autom": [17, 20, 38], "automat": [4, 5, 6, 7, 9, 13, 16], "automobil": [4, 5], "automodelforcausallm": [31, 33, 34], "autonom": 38, "autoref": 4, "autoregress": [10, 13, 16, 23, 25], "autoretriev": 38, "autotoken": [32, 33, 34], "autr": 6, "auxiliari": [2, 6, 7], "auxillari": 22, "avail": [0, 4, 5, 7, 16, 20, 22, 24, 25, 37, 38], "avdl": 4, "averag": [1, 2, 3, 5, 12, 16, 17, 22, 25], "average_log_prob": 33, "avg": 23, "avgdl": [4, 5], "avil": 25, "avirup": 19, "avocado": 4, "avoid": [2, 4, 5, 7, 14, 16, 18, 19, 20, 21, 22, 25, 27, 37, 38], "aw": 38, "awadb": 38, "awadbdemo": 38, "awai": [4, 5, 6, 12, 22, 37, 38], "awar": [13, 16, 20], "awb": 5, "awesom": 3, "awsdocdb": 38, "awsdocdbdemo": 38, "aww": 19, "ax": 27, "axi": [16, 27], "azadeh": 5, "azalia": 22, "azcognit": 38, "azcognitive_search": 38, "azhar": 22, "azstorag": 38, "azstorage_blob": 38, "azur": [4, 38], "azure_code_interpret": 38, "azure_cv": 38, "azure_devop": 38, "azure_infer": 38, "azure_openai": 38, "azure_openai_multi_mod": 38, "azure_speech": 38, "azure_transl": 38, "azureaisearch": 38, "azureaisearchindexdemo": 38, "azurecosmosdbmongodbvcoredemo": 38, "azurecosmosdbnosqldemo": 38, "azurecosmosmongo": 38, "azurecosmosmongovcor": 38, "azurecosmosnosql": 38, "azuredocstoredemo": 38, "azureopenai": 38, "azzolini": [37, 38], "b": [1, 2, 4, 5, 7, 9, 10, 12, 13, 14, 18, 20, 21, 24, 25, 33, 37, 38], "b02e": [37, 38], "b0e6799a25ad": [37, 38], "b130": [37, 38], "b13b": [37, 38], "b_": [1, 4, 11, 12], "b_1": [1, 7, 11], "b_2": [1, 7, 11], "b_i": 2, "b_j": 2, "b_x": 9, "b_y": 9, "ba": [4, 25], "babak": 13, "babi": 7, "back": [3, 4, 5, 6, 7, 19, 20, 23, 38], "backbon": [4, 5], "backend": 38, "backoff": [4, 8], "backpropag": [4, 21], "backpropg": 6, "backpropog": 21, "backslash": 20, "backtick": 20, "backup": [37, 38], "backward": [4, 7, 21, 24, 32, 33, 34, 35, 38], "bacteria": 4, "bad": [4, 6, 18, 19, 25], "badr": 25, "bag": [4, 5, 12], "bagel": 38, "bagelautoretriev": 38, "bagelindexdemo": 38, "bai": 22, "bai2020sparterm": 4, "bai2022constitut": [], "baidu": [21, 38], "baiduvectordb": 38, "baiduvectordbindexdemo": 38, "bajaj": 7, "bakalov": 20, "balanc": [0, 1, 4, 5, 7, 13, 20, 22, 24, 25], "ball": [24, 25], "bamford": 1, "band": 4, "bandwidth": [1, 13, 21], "bangladesh": [37, 38], "bank": [6, 8, 12, 37, 38], "banknot": 8, "bao": [2, 7], "baosong": [1, 11, 21], "baptist": [22, 25], "bar": 4, "bark": 4, "barla": 5, "barret": [1, 2, 23], "barri": [1, 4], "bart": [11, 29], "base": [1, 2, 3, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 20, 21, 22, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "baselin": [1, 4, 5, 8, 13, 19, 22], "basemodeloutputwithpast": [30, 36], "basi": [4, 12, 20, 37, 38], "basic": [0, 5, 7, 8, 12, 19, 25, 29, 37, 38], "basic_ag": 38, "basic_flow": 38, "basic_strategi": 38, "bat": 24, "batch": [1, 2, 3, 7, 11, 13, 16, 21, 22, 30, 31, 32, 33, 34, 35, 36], "batch_ev": 38, "batch_siz": [30, 31, 32, 33, 34, 35, 36], "batchevalrunn": 38, "batra": 14, "battl": 38, "bb58": [37, 38], "bcc16": [4, 5], "bcca": [37, 38], "bce": [6, 22], "bd03": [37, 38], "bdvj03": 9, "beam": [4, 5, 13, 22], "bear": 4, "beat": 4, "beautifulsoup4": [37, 38], "becam": 0, "becaus": [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 19, 20, 21, 22, 23, 25], "becom": [1, 2, 4, 5, 9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 25, 30, 36, 37, 38], "bed": [4, 37, 38], "bedrock": [25, 38], "bedrock_convers": 38, "bedrock_converse_ag": 38, "bedrock_retriev": 38, "bedroom": 9, "been": [0, 1, 3, 4, 5, 6, 7, 8, 11, 16, 20, 22, 23, 37, 38], "befor": [1, 4, 5, 6, 7, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 30, 31, 33, 34, 36], "beforehand": [16, 24], "began": 0, "begin": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 22, 24, 25, 37, 38], "beginn": 38, "begun": [37, 38], "behav": [20, 22], "behavior": [1, 4, 5, 6, 7, 19, 20, 22, 23], "behind": [3, 4, 5, 8, 14, 18, 20, 25, 38], "bei": 2, "beichen": [1, 25], "beihong": 5, "beij": [4, 5, 12], "being": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 18, 19, 20, 22, 30, 31, 33, 34, 36, 37, 38], "beingoptim": 4, "beings": 8, "beir": 38, "beirevalu": 38, "belief": 20, "believ": 8, "belinkov": 4, "belkada": 13, "bell": [4, 20], "bellman": 24, "belong": [4, 5], "below": [1, 4, 5, 8, 12, 13, 19, 20, 30, 32, 33, 34, 36, 37, 38], "belvi": [37, 38], "bench": 38, "benchmark": [6, 10, 11, 13, 17, 20, 25, 38], "bend": 4, "benderski": 5, "benefici": [1, 4, 5, 20], "benefit": [1, 3, 4, 5, 7, 13, 17, 18, 20, 21, 23, 25, 30, 31, 33, 34, 36, 37, 38], "bengio": [5, 9], "benjamin": [1, 6, 8, 11, 25], "bennett": 5, "bentlei": 5, "berant": 5, "berkelei": 19, "berlin": [12, 22], "berlitz": 8, "berri": 4, "bert": [1, 6, 10, 11, 12, 13, 20, 29], "bert4rec": 11, "besid": [1, 4, 5, 10, 11, 18, 20, 22, 25, 37, 38], "best": [2, 4, 5, 6, 17, 19, 20, 22, 25, 38], "beta": [4, 5, 8, 22, 23, 33, 38], "beta_": 8, "beta_i": 22, "beta_j": 22, "better": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 16, 18, 19, 20, 22, 23, 24, 25, 37, 38], "between": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 37, 38], "beyer": 11, "beyond": [1, 4, 5, 7, 17, 20, 21, 22, 37, 38], "bf": 19, "bf16": 21, "bfloat16": [13, 21, 31, 33, 34], "bge": 38, "bge_m3": 38, "bgem3demo": 38, "bgjm17": 12, "bhaskar": 5, "bi": [2, 20], "bia": [1, 2, 4, 5, 12, 13, 17, 20, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36], "biao": [1, 23], "bias": [1, 2, 4, 5, 9, 22, 23, 25], "bibliograph": 4, "bid": [4, 5], "bidirect": [3, 4, 5, 7, 10, 11, 16], "biencod": 4, "big": [3, 4, 5, 7, 8, 12, 19, 37, 38], "bigger": [0, 6, 23], "bigger_s": 27, "biggest": [7, 13], "bigram": [4, 5, 8], "bilibili": 38, "bilinear": 27, "bilingu": 7, "bill": [37, 38], "billion": [0, 1, 2, 4, 5, 6, 11, 13, 21, 25], "bin": 23, "binar": 4, "binari": [4, 5, 6, 7, 11, 12, 16, 22, 38], "bing": [2, 4, 5, 21, 38], "bing_search": 38, "binghai": 22, "bingxuan": 2, "binom": 22, "binwidth": 27, "binyuan": [1, 21], "biographi": 4, "biometrika": 22, "birch": 1, "bird": 7, "birth": [37, 38], "bit": [1, 4, 5, 6, 13, 21], "bitbucket": 38, "bitcoin": [4, 5], "bitlion": 25, "bitwis": 4, "bkk": 22, "black": [4, 38], "blankevoort": 13, "blaze": 4, "blend": [3, 4, 6], "blendfilt": 3, "bleu": [6, 20], "blind": 4, "blindli": 23, "blob": 38, "block": [1, 2, 4, 6, 11, 12, 20, 21, 22, 30, 31, 33, 34, 36], "blog": [4, 6, 8, 10, 11, 20, 38], "blood": [4, 20], "bloomberggpt": 25, "blow": 4, "blue": [2, 3, 4, 17], "blunsom": 7, "blur": 38, "bm": [4, 5], "bm25": [20, 38], "bm25_retriev": 38, "bm25model": [4, 5], "bm42": 38, "bmatrix": [1, 11], "bmod": 1, "bmr": [1, 6, 8, 11], "bnb21": 13, "bo": [1, 21], "boar": 4, "board": [8, 37, 38], "boarddoc": 38, "bob": 19, "bochao": 2, "bodi": [4, 5, 18, 20, 36, 38], "boil": [4, 5], "bojanowski": 12, "bold": [8, 19], "boldsymbol": [1, 4, 7, 13, 22], "bolt": [37, 38], "bondarenko": 13, "book": [4, 5, 11, 12, 25], "bookcorpu": [6, 11, 25], "bookmark": 4, "books1": 6, "books2": 6, "bookscorpu": [6, 7], "bool": [30, 32, 33, 35, 36], "boolean": 4, "boost": [1, 4, 6, 7, 23, 37, 38], "boostrap": 23, "bootstrap": 16, "bord": 5, "bore": [14, 18], "bori": 21, "borrow": [4, 8], "bos_token_id": [31, 33, 34], "bosco": 4, "bosma": [18, 23], "boss": [19, 20], "boston": [5, 37, 38], "bot": 5, "both": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 36, 37, 38], "bottl": 11, "bottleneck": [2, 4, 5, 7, 11, 16, 23, 37, 38], "bottom": [1, 4, 5, 7, 16, 27, 38], "bought": 7, "bound": [1, 4, 5, 11, 12, 13, 21, 24], "boundari": [0, 1, 4, 5, 12, 20], "bow": 4, "box": [6, 38], "bradlei": [19, 22], "brahma": 23, "brain": [4, 5, 13], "braintrust": 38, "bran": 4, "branch": [4, 5, 20, 37, 38], "branches_and_loop": 38, "brand": 4, "brauen": 4, "brave": 38, "brave_search": 38, "brazil": [37, 38], "breadown": 13, "breadth": 19, "break": [1, 3, 4, 5, 12, 13, 18, 19, 20, 32, 33, 34, 35], "breakout": 24, "breakpoint": 20, "breakthrough": 0, "breath": 4, "bred": 4, "breed": [4, 27], "bressand": 1, "brevet": 6, "breviti": [2, 4, 14], "brewer": 4, "brian": [16, 23], "brick": 24, "bridg": [4, 7, 16, 20, 23, 25], "brief": [4, 23, 37, 38], "briefli": 16, "bring": [1, 4, 5, 6, 9], "british": 8, "broad": [4, 5, 6, 14, 18, 20, 22, 23, 25], "broadcast": [21, 30, 31, 33, 34, 36], "broaden": 4, "broader": 3, "broadli": [4, 7, 17, 25], "brockman": 25, "broke": [], "bromlei": 4, "brother": 12, "brought": [0, 4, 5, 37, 38], "brown": [1, 4, 6, 8, 11, 25], "brows": 4, "browser": 4, "bruce": 5, "bruch": 5, "bruna": 23, "brush": 4, "brute": [4, 5, 14], "bryan": 10, "bsd": 21, "bsdp": 21, "bsz": [30, 31, 33, 34, 36], "bt": 22, "bt52": 22, "bu": [4, 5], "bucket": [4, 12], "bucklei": 4, "budget": [0, 2, 7], "buffer": [21, 32, 35, 38], "bui": 4, "build": [1, 2, 5, 7, 8, 11, 12, 19, 20, 22, 24, 37, 38], "builder": 38, "building_a_chatbot": 38, "building_rag_from_scratch": 38, "built": [4, 5, 20, 22], "bullet": 20, "bullmastiffexplor": 4, "bundl": 38, "bur10": 5, "burda": 25, "burden": [1, 16, 20, 37, 38], "burg": [4, 5], "burges2005learn": 4, "burget": 9, "burr": 6, "busi": 4, "buttcher": 5, "butter": 4, "button": 38, "byproduct": [37, 38], "byte": [13, 21], "byvb1zve6j": 38, "c": [1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 16, 19, 33, 34, 37, 38], "c4": [11, 25], "c_": [1, 4, 5], "c_0": 8, "c_1": [4, 5, 8], "c_2": 8, "c_3": 8, "c_4": 8, "c_5": 8, "c_6": 8, "c_i": [4, 5, 8], "c_k": [4, 5], "ca": 20, "cabl": 4, "cacciator": [37, 38], "cach": [1, 4, 5, 9, 21, 30, 36, 37, 38], "cache_posit": [30, 36], "caffein": [4, 5], "cai": 2, "caim": [10, 16], "caishuang": 22, "cake": [4, 19], "cal": 4, "calcuat": 13, "calcul": [1, 3, 4, 5, 7, 11, 12, 13, 16, 18, 21, 24, 30, 36, 38], "calibr": [4, 5], "california": 12, "call": [2, 4, 5, 6, 7, 8, 11, 12, 16, 19, 21, 24, 25, 27, 34, 36, 37, 38], "call_llm_with_full_text": 36, "callan": [4, 5], "callback": 38, "callowai": 8, "calvin": 4, "cambieri": [37, 38], "cambodia": 12, "cambodian": 12, "cambridg": 5, "came": [37, 38], "camel": 38, "camera": [37, 38], "cameron": 22, "campo": 5, "can": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 30, 31, 33, 34, 36, 37, 38], "canada": 12, "canadian": [37, 38], "cancel": 22, "cancer": 4, "candid": [3, 5, 6, 8, 13, 14, 16, 22, 23], "cane": 4, "cannot": [0, 1, 3, 4, 5, 6, 10, 12, 13, 14, 16, 20, 21, 22, 23], "canon": [4, 38], "canonic": 4, "cao": [5, 7], "cap": [1, 4, 5, 12], "capabl": [0, 1, 4, 5, 6, 7, 10, 11, 13, 16, 17, 18, 20, 23, 25], "capac": [1, 2, 3, 4, 5, 6, 7, 11, 22], "capfilt": 16, "capit": [3, 4, 5, 12, 22], "caption": [4, 8, 16, 20, 24, 38], "captur": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 19, 20, 22, 23, 37, 38], "car": [20, 23], "carb": 4, "carbohydr": [4, 5], "carbonel": 20, "card": 38, "cardin": [4, 5, 14], "care": [2, 4, 20, 37, 38], "carefulli": [4, 6, 14, 22, 23], "carignan": 17, "carlo": [4, 5, 21], "carnegi": [], "carolina": [4, 5], "carpineto": 4, "carri": [4, 5, 8, 17, 24, 37, 38], "carrol": 22, "cartesian": [4, 5], "cartoon": 4, "caruana": 5, "casa": 1, "case": [1, 2, 4, 5, 6, 7, 11, 12, 14, 17, 20, 21, 23, 24, 25, 30, 36, 37, 38], "caslon": 7, "cassandra": 38, "cassandraindexdemo": 38, "cast": [4, 10], "castro": 23, "casual": 8, "cat": [4, 9, 30, 31, 33, 34, 36], "catastroph": [16, 23, 25], "catch": [4, 38], "categor": [4, 5, 11], "categori": [4, 5, 6, 11, 20, 37, 38], "caus": [1, 4, 5, 7, 8, 13, 14, 19, 20, 23], "causal": [11, 16, 19, 30, 36], "causal_mask": [30, 36], "causallmoutputwithpast": [30, 36], "caveat": [4, 5], "cb753cb8dfd3": [37, 38], "cbow": 16, "cc": [1, 4, 12], "ccc": 4, "cccc": 12, "ccccc": 4, "ccccccc": 1, "cd": [4, 10], "cdk": 38, "cdn": 38, "cdot": [1, 2, 4, 5, 7, 8, 9, 11, 12, 13, 14, 22, 23, 25, 30, 31, 33, 34, 36], "cdpo": 22, "ce": [4, 5, 8], "ceil": 21, "cell": [4, 5, 34, 37, 38], "cellular": [37, 38], "center": [1, 4, 12, 20, 25, 37, 38], "centr": [37, 38], "central": [4, 5, 11, 12, 19, 37, 38], "centroid": [4, 5], "centrust": 8, "ceo": [3, 4], "cer": [37, 38], "cereal": 4, "cerebra": 38, "cernock\u00fd": 9, "cert": [37, 38], "certain": [1, 2, 3, 4, 5, 7, 8, 12, 13, 17, 19, 20, 21, 25], "certainli": [4, 18], "certif": [37, 38], "certifi": [37, 38], "cfce": [37, 38], "cfgh20": 5, "cfwb17": [4, 5], "cg": [4, 5], "cg98": 20, "cg99": 8, "ch": [4, 5, 24], "ch02": [32, 35], "chain": [8, 14, 17, 20, 21, 23, 38], "chairman": 8, "challeng": [0, 1, 2, 6, 7, 8, 9, 11, 14, 16, 17, 18, 19, 21, 23, 25, 37, 38], "chan": [4, 5], "chanc": [4, 5, 13, 25], "chang": [1, 4, 5, 6, 7, 8, 11, 12, 13, 20, 22, 23, 24, 32, 35, 37, 38], "chang2020pr": 4, "changelog": 38, "changer": 0, "changhua": 11, "channel": 4, "chantai": 4, "chao": [19, 22], "chaoui": [37, 38], "chaplot": 1, "chapter": [1, 4, 11, 23, 25, 32, 35, 37, 38], "chapter_foundation_def_pretrained_lm_transformer_bert_encoder_lay": 7, "chapter_foundation_fig_language_model_feedforward_model": 9, "chapter_foundation_fig_word_embedding_word2vec_visu": 12, "chapter_inference_eq_inference_acceleration_gptq_error_minimization_objective_matrix_form": 13, "chapter_rag_fig_promptagator_demo": [], "chapter_rag_fig_rag_knowledge_base_demo": [], "chapter_rag_fig_rag_llm_ft_data_sourc": [], "charact": [1, 4, 7, 8, 12, 18, 20, 36], "character": [4, 5, 24], "characterist": [1, 2, 4, 5, 8, 20], "charcodeat": 38, "charcter": 22, "charl": 5, "charset": [37, 38], "chart": [20, 37, 38], "chat": [4, 5, 36, 38], "chat_engin": 38, "chat_engine_best": 38, "chat_engine_condense_plus_context": 38, "chat_engine_condense_quest": 38, "chat_engine_condense_question_stream_respons": 38, "chat_engine_context": 38, "chat_engine_openai": 38, "chat_engine_person": 38, "chat_engine_react": 38, "chat_engine_repl": 38, "chat_memory_buff": 38, "chat_prompt": 38, "chat_stor": 38, "chatbot": [20, 38], "chatbot_sec": 38, "chatcompletionmessag": 36, "chatgpt": [3, 38], "chatgpt_plugin": 38, "chatmessag": [37, 38], "chatprompttempl": [37, 38], "chaudhari": 7, "chauffer": 4, "chaumond": 7, "chd": 7, "cheap": [1, 4], "cheaper": [7, 13, 20, 37, 38], "cheapli": 19, "cheapter": 5, "cheatham": [], "chec": [37, 38], "check": [4, 5, 20, 37, 38], "checkbox": 38, "checker": [4, 5], "checkpoint": [1, 4, 5, 22, 30, 31, 32, 33, 34, 35], "chees": 4, "chelsea": 22, "chemic": 17, "chemistri": 17, "chen": [1, 2, 5, 7, 8, 11, 12, 17, 19, 21, 22, 23, 25], "cheng": [2, 5, 17, 19, 20], "chengda": 2, "chenggang": 2, "chengqi": 2, "chenxin": 1, "chenyan": 5, "chenyu": [2, 22], "chern": 5, "cherri": 23, "chess": 25, "chest": 4, "chi": [7, 17, 18, 23], "chicago": 12, "chief": 4, "chieh": 5, "child": [4, 6, 8, 10, 11, 20, 25], "childcar": [37, 38], "children": [4, 20, 37, 38], "chin": 13, "china": [4, 5, 12, 37, 38], "chines": [1, 4, 7, 25], "chip": 4, "chiyuan": 21, "chl": 23, "cho": [5, 20], "choi2021improv": 4, "choic": [2, 4, 5, 7, 12, 14, 20, 23, 36], "cholesterol": 4, "chong": [2, 22], "choos": [4, 5, 7, 8, 14, 22, 24, 25, 37, 38], "chose": [4, 6], "chosen": [2, 4, 12, 14, 16, 22, 33], "chosen_logp": 33, "chosen_reward": 33, "choudhuri": 4, "chowdheri": [17, 23], "chri": [1, 5, 16], "christian": [1, 9], "christiano": 22, "christoph": [5, 7, 8, 22, 25], "chroma": 38, "chroma_auto_retriev": 38, "chroma_autoretriev": 38, "chroma_metadata_filt": 38, "chromademo": 38, "chromafireworksnom": 38, "chromaindexdemo": 38, "chromamultimodaldemo": 38, "chromosom": [4, 5], "chronolog": [19, 37, 38], "chuck": 21, "chung": 23, "chunk": [13, 19, 35, 38], "chunk_overlap": [37, 38], "chunk_siz": [37, 38], "chunker": 38, "chunyuan": 16, "church": 4, "cinema": 18, "cin\u00e9ma": 6, "circ": 19, "circumst": 13, "citat": [19, 20, 38], "citation_query_engin": 38, "citationqueryengin": 38, "cite": [4, 12, 14, 20], "citi": [4, 7, 12, 22], "citizen": [37, 38], "ckg": 7, "cklm19": 7, "cl": [4, 5, 7, 10, 16], "claim": 20, "clarifai": 38, "clariti": 20, "clark": [5, 7, 16], "class": [3, 4, 5, 6, 7, 10, 12, 16, 19, 23, 30, 31, 32, 33, 34, 35, 36, 38], "classfici": 5, "classic": [7, 8, 12, 18, 22, 25], "classicrepresentationlearn": 4, "classif": [3, 4, 5, 6, 7, 10, 11, 12, 16, 20, 21, 22, 37, 38], "classifi": [4, 5, 7, 10, 12, 16, 18, 36], "classroom": 7, "clean": [16, 20], "cleaner": 20, "cleanlab": 38, "cleanlab_tlm_rag": 38, "clear": [1, 5, 6, 11, 19, 20, 37, 38], "clearli": [4, 5, 6, 12, 22, 25, 37, 38], "clearn": 25, "cleverest": 6, "cli": [37, 38], "click": [4, 5, 37, 38], "clickhous": 38, "clickhouseindexdemo": 38, "clicknum": 4, "clickthrough": [4, 5], "client": [36, 38], "clin": [37, 38], "clinic": [37, 38], "clinical_data": [37, 38], "clinical_govern": [37, 38], "clinician": [37, 38], "clip": [13, 38], "clipboard": 38, "cllm20": 7, "clone": [22, 26, 30, 33, 36], "close": [1, 4, 5, 7, 8, 12, 19, 20, 21, 22, 37, 38], "closer": [0, 4, 5, 12], "closest": [4, 19], "cloth": [4, 12], "cloud": [4, 5, 20, 37, 38], "cloudflar": 38, "cloudflare_workersai": 38, "club": 4, "clubth": 4, "cluett": 8, "cluster": [9, 19], "cm": 27, "cms10": [4, 5], "cmu": [], "cmy": 5, "cnn": [10, 11], "cnndssm": 4, "co": [1, 4, 5, 7, 8, 9, 11, 12, 20, 30, 31, 33, 34, 36], "coa": 38, "coa_ag": 38, "coach": 4, "coars": [4, 5, 20], "coat": 4, "coco": 5, "coconut": 4, "code": [7, 11, 18, 20, 25, 30, 32, 35, 36, 37, 38], "code_hierarchi": 38, "code_interpret": 38, "codebook": [4, 5], "codebookmemorysavingdemo": 4, "codebookmemorysavingdemoproductquant": 4, "codecook": [4, 5], "codestr": 38, "codex": 25, "codi": 13, "coeffici": [4, 16, 22, 25], "coexist": 12, "coffe": [4, 5, 19], "cogniswitch": 38, "cogniswitch_ag": 38, "cogniswitch_query_engin": 38, "cognit": 4, "cogswel": 14, "coher": [1, 6, 7, 8, 11, 20, 36, 38], "cohere_citation_chat": 38, "cohere_custom_rerank": 38, "cohere_multi_mod": 38, "cohere_rerank": 38, "cohere_retriever_ev": 38, "cohereai": 38, "coherererank": 38, "cohes": [4, 5, 12, 14], "cohort": 4, "coil": 5, "coilembed": 4, "coilindexingmethod": 4, "col": [4, 5], "cola": 13, "colber": 4, "colbert": [27, 38], "colbert_rerank": 38, "colbertl2": [4, 5], "colbertrerank": 38, "coldest": [4, 5], "colect": 22, "colin": [5, 10, 22, 23], "collabor": [2, 4, 19, 38], "collaps": 2, "collat": [37, 38], "collate_fn": [32, 33, 34], "collect": [4, 5, 6, 8, 16, 17, 19, 20, 21, 24, 27, 37, 38], "colleg": [4, 37, 38], "collin": 5, "collis": [4, 24], "collison": 12, "collobert": 12, "colloc": 4, "coloni": 22, "color": [1, 3, 4, 16, 38], "colorama": [37, 38], "coloss": 25, "colpali": 38, "colpali_rerank": 38, "colpalirerank": 38, "column": [12, 13, 36], "com": [4, 6, 8, 11, 21, 32, 33, 34, 35, 38], "combat": 1, "combin": [2, 3, 4, 5, 7, 9, 10, 11, 12, 19, 20, 21, 22, 23, 36, 37, 38], "comcast": 4, "come": [1, 3, 4, 5, 7, 8, 11, 16, 17, 19, 20, 30, 36, 38], "comment": [4, 6, 34], "commerc": [4, 5], "commerci": 4, "commnic": 21, "common": [1, 2, 4, 5, 7, 11, 12, 14, 17, 18, 20, 24, 25, 37, 38], "commoncrawl": [7, 25], "commonli": [1, 3, 4, 5, 11, 12, 14, 16, 20, 22], "commonsens": [6, 17], "commun": [0, 2, 4, 5, 8, 18, 19, 25, 37, 38], "communi": [37, 38], "comorbid": [37, 38], "compact": [4, 5, 7, 9, 37, 38], "compact_accumul": 38, "compact_and_refin": 38, "compani": [1, 3, 4, 12, 20, 37, 38], "compar": [1, 2, 3, 4, 5, 8, 9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 30, 31, 33, 34, 36, 37, 38], "comparis": [1, 13], "comparison": [1, 5, 7, 8, 9, 17, 18, 19, 20, 21, 22, 25, 38], "compat": 1, "compel": 20, "compens": [4, 12], "compet": [12, 37, 38], "competit": [4, 16, 23], "competitor": [4, 5], "compil": [4, 38], "complaint": [4, 37, 38], "complement": [4, 5], "complementari": [4, 19, 20], "complet": [2, 4, 5, 6, 7, 8, 10, 11, 12, 18, 20, 21, 22, 23, 32, 33, 34, 36, 37, 38], "completion_prompt": 38, "complex": [0, 1, 2, 3, 4, 5, 11, 12, 13, 17, 18, 19, 21, 22, 24, 25, 38], "compli": [37, 38], "complianc": 20, "compliant": 20, "complic": [4, 24, 37, 38], "compon": [1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 17, 20, 23, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38], "component_wise_evalu": 38, "components_of_llamaindex": 38, "componentwis": 1, "compos": [4, 8, 17, 38], "composable_memori": 38, "composable_retriev": 38, "composit": [4, 13, 25], "composition": [5, 12], "compound": 4, "comprehens": [0, 3, 4, 5, 6, 7, 10, 20, 22, 23, 37, 38], "compress": [2, 4, 5, 7, 11, 20], "compris": [3, 4, 5, 24], "compromis": [1, 7, 13, 23], "comput": [0, 2, 6, 8, 9, 12, 16, 18, 20, 21, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "computatio": 13, "computation": [4, 5, 13, 20, 23, 25], "compute_batch_loss": [32, 33, 34, 35], "computeris": [37, 38], "con": [4, 5, 13, 23, 37, 38], "concat": [1, 9, 11, 23, 30, 31, 33, 34, 36], "concaten": [4, 5, 6, 7, 9, 12, 16, 20, 23, 30, 31, 33, 34, 36], "concatin": 5, "concentr": [4, 5, 22], "concept": [0, 3, 4, 5, 8, 12, 16, 17, 18, 19, 22, 25, 37, 38], "conceptu": [3, 4, 20], "concern": [4, 5, 19], "concis": [19, 20, 23], "conclud": [37, 38], "conclus": [1, 16, 18, 20, 36, 37, 38], "concret": [4, 5], "concurr": [4, 38], "concurrent_execut": 38, "conda": 26, "condens": [4, 5, 38], "condense_plus_context": 38, "condense_quest": 38, "condit": [1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 20, 24, 37, 38], "conduct": [4, 7, 13, 20, 23, 37, 38], "conf": 9, "confer": [4, 5, 7, 11, 12, 13, 16, 20, 22, 25], "confid": [4, 5, 6, 14, 19], "confidenti": [37, 38], "config": [21, 30, 31, 32, 33, 34, 35, 36, 38], "config_dict": [32, 35], "configur": [4, 5, 6, 13, 25], "confirm": 19, "conflict": [19, 20], "confluenc": 38, "confus": 4, "conglomer": 8, "conneau": 7, "connect": [1, 2, 3, 4, 7, 8, 9, 11, 16, 19, 20, 22, 24, 30, 31, 33, 34, 36, 37, 38], "connector": 38, "consecut": [1, 4, 7, 8, 20, 24, 37, 38], "consent": [37, 38], "consequ": [4, 7, 13], "conserv": [4, 22], "consid": [1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 19, 21, 22, 23, 25, 37, 38], "consider": [1, 4, 7, 8, 20], "consist": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "consol": 23, "consolid": [2, 8], "const": 22, "constant": [1, 2, 4, 5, 7, 11, 13, 16, 22, 23, 25], "constantli": [0, 4, 5], "constitu": [4, 5, 8, 12], "constitut": [4, 22], "constrain": [1, 3, 4, 5], "constraint": [0, 3, 4, 5, 8, 13, 14, 21, 22, 25], "constrast": 22, "construct": [1, 5, 7, 8, 9, 11, 12, 18, 19, 20, 22, 23, 25, 38], "consult": [4, 37, 38], "consum": [4, 5, 13, 20, 21, 23, 37, 38], "consumpt": [4, 5, 21], "contact": 4, "contain": [1, 4, 5, 6, 7, 8, 9, 13, 16, 20, 22, 24, 30, 31, 33, 34, 36, 37, 38], "contamin": 23, "content": [3, 4, 5, 17, 20, 21, 22, 23, 36, 37, 38], "content__inn": 38, "contest": 4, "context": [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 21, 22, 24, 25, 32, 35, 37, 38], "context_length": [32, 35], "context_msg": [37, 38], "context_relev": 38, "context_str": [37, 38], "context_vec": [32, 35], "context_window": [37, 38], "contextu": [6, 7, 11, 13, 19, 20, 36, 38], "contextual_retriev": 38, "contextualencod": 7, "contexu": 11, "contigu": [13, 21, 30, 31, 32, 33, 34, 35, 36], "contin": 22, "conting": [37, 38], "continu": [0, 1, 2, 4, 5, 6, 11, 12, 13, 19, 20, 22, 23, 24, 37, 38], "contract": [12, 24], "contradict": [7, 10], "contrari": [4, 25], "contrast": [3, 4, 5, 6, 7, 16, 21, 22, 24], "contribut": [2, 4, 5, 6, 10, 11, 12, 13, 17, 19, 23, 25, 32, 33, 34, 37, 38], "contributing_llamadataset": 38, "control": [4, 5, 6, 7, 8, 11, 16, 19, 22, 24, 25, 27, 38], "control_plan": 38, "controlnet": 16, "conv": 4, "convai2": 10, "convei": 4, "conveni": [4, 11, 24, 37, 38], "convens": 13, "convent": 4, "converg": [1, 4, 6, 7, 13, 21, 25], "convers": [4, 6, 7, 16, 25, 38], "convert": [4, 6, 8, 10, 11, 12, 13, 14, 16, 20, 22], "convex": 25, "convknrm": [4, 5], "convolut": [4, 5, 7, 13], "cookbook": 38, "cool": 4, "cooper": [4, 19], "coordin": [4, 19, 37, 38], "copi": [4, 5, 21, 30, 31, 33, 34, 36, 37, 38], "copyright": [37, 38], "core": [1, 3, 4, 5, 9, 11, 13, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "cormack": 5, "cornerston": [1, 25, 37, 38], "corollari": [37, 38], "corpora": [4, 5, 7, 8, 12, 25], "corpu": [3, 4, 5, 7, 8, 10, 11, 12, 20, 22, 25, 35, 36, 38], "corrado": [5, 12], "correct": [5, 7, 16, 17, 18, 20, 22, 25, 38], "corrective_rag": 38, "corrective_rag_pack": 38, "correctli": [4, 5, 25, 30, 36], "correctness_ev": 38, "corrector": 4, "correl": [4, 37, 38], "correpond": [4, 5], "correspond": [1, 2, 5, 6, 7, 8, 10, 11, 12, 16, 20, 21, 22, 23, 25, 33, 34], "correspondingli": 2, "corrupt": [7, 10, 11], "corso": 4, "cose": 20, "cosin": [4, 5, 7, 11, 16, 30, 31, 33, 34, 36], "cosmo": 38, "cosmosdb": 38, "cossim": 16, "cossimilar": 7, "cost": [1, 2, 3, 4, 5, 12, 14, 16, 18, 19, 20, 21, 23, 25, 30, 31, 33, 34, 36, 37, 38], "cost_analysi": 38, "costli": [4, 5, 12, 20], "cot": [20, 23, 38], "cot\u00e9": 6, "couchbas": 38, "couchbasevectorstoredemo": 38, "couchdb": 38, "could": [1, 3, 4, 5, 7, 9, 11, 12, 13, 16, 19, 20, 23, 25, 37, 38], "count": [4, 5, 6, 8, 9, 16, 27, 38], "counter": [4, 9, 38], "counterpart": [2, 21, 24], "countersign": [37, 38], "countersunk": 3, "counti": 4, "countri": [3, 4, 20, 22, 37, 38], "countrywid": [37, 38], "coupl": [4, 5, 37, 38], "courag": 4, "cours": [4, 19, 37, 38], "court": [37, 38], "courvil": 5, "covari": 1, "cover": [0, 1, 4, 5, 7, 8, 12, 16, 20, 22, 23, 24, 25], "coverag": [4, 23], "coverg": 1, "covid": [37, 38], "cowork": 19, "cp39": [37, 38], "cpp": 38, "cpu": [32, 33, 34, 35, 38], "cql": 5, "cr": 4, "cracker": 4, "craft": [16, 17, 20, 23], "crandal": 14, "crash": [4, 5, 8], "craswel": 5, "craswell2020overview": 4, "crawl": [4, 5, 6, 11, 25], "cream": 4, "creat": [1, 3, 4, 5, 8, 11, 16, 19, 20, 21, 23, 24, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38], "create_data_load": [32, 33, 34, 35], "create_graph": 34, "createel": 38, "creation": [20, 36, 38], "creation_d": [37, 38], "creativ": [0, 4, 14, 37, 38], "creativecommon": [37, 38], "credit": [37, 38], "crewai": 38, "crewai_llamaindex": 38, "crf": 4, "crimin": [37, 38], "crisp": [4, 37, 38], "criteria": [4, 5, 13, 20, 22, 25], "criterion": [13, 17, 20], "critic": [1, 4, 5, 6, 11, 13, 14, 19, 20, 23, 24], "critiqu": 19, "croft": [4, 5], "croft2010search": 4, "cross": [2, 3, 6, 7, 10, 12, 13, 16, 19, 20, 22, 25, 38], "cross_encoder_finetun": 38, "cross_entropi": [32, 33, 34, 35], "cross_entropy_loss": 16, "crossentropi": [2, 7], "crossorigin": 38, "crowd": 7, "crucial": [0, 1, 2, 4, 5, 7, 11, 13, 16, 20, 22, 23, 25, 30, 36, 37, 38], "crush": 4, "crust": 4, "crutch": [37, 38], "crystal": [4, 5], "css": 38, "cssc": 4, "ctj": 25, "ctr": [4, 5], "cuda": [32, 33, 34, 35], "cue": [4, 5], "cuisin": [3, 4, 5], "cumbersom": [4, 5], "cumul": 24, "cunxiang": 20, "cup": [1, 4, 12], "curat": [3, 25], "currenc": 12, "current": [1, 4, 5, 6, 7, 13, 20, 21, 22, 24, 25, 37, 38], "curriculum": 25, "currilumn": 5, "curs": [4, 5, 8, 9], "curv": [4, 20], "cusp": 0, "custom": [1, 4, 5, 20, 22, 23, 37, 38], "custom_ag": 38, "custom_collate_fn": [32, 33, 34], "custom_embed": 38, "custom_llm": 38, "custom_model": [31, 33, 34], "custom_modul": 38, "custom_prompt_synthes": 38, "custom_query_engin": 38, "customiz": 4, "customizatio": [], "customretriev": 38, "cut": [1, 4, 14], "cute": 4, "cv": [4, 12, 38], "cvi": 25, "cw08": 12, "cwct23": 1, "cxzg16": 21, "cy": 4, "cycl": [37, 38], "cypher": [37, 38], "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 20, 21, 22, 23, 27, 30, 31, 33, 34, 36, 38], "d1033338": 27, "d1350520": 27, "d140227": 27, "d1439360": 27, "d213890": 27, "d2286511": 27, "d2342771": [4, 27], "d304123": 27, "d3048094": [4, 27], "d312959": 27, "d3233725": [4, 27], "d508131": 27, "d69114": 27, "d_": [1, 5, 6, 7, 8, 11, 13, 22, 23], "d_0": 11, "d_1": [3, 4, 5, 11, 19], "d_2": [4, 5, 11], "d_3": [4, 5], "d_e": 16, "d_f": 23, "d_h": 13, "d_head": [32, 35], "d_i": [3, 4, 5, 8, 16, 20], "d_j": [4, 20], "d_k": [1, 4, 5, 11, 20], "d_m": [3, 4, 5], "d_model": [1, 6, 32, 35], "d_n": [4, 5, 11, 19], "d_q": 4, "d_t": 16, "d_v": 11, "d_x": 13, "da": [4, 5, 10, 19], "dad": 38, "dad_jok": 38, "dahl": 25, "dai": [2, 4, 5, 19, 20, 23, 37, 38], "daili": [4, 5, 37, 38], "daj24": 1, "dakota": [4, 5], "dale": [17, 18, 23], "dalf": 2, "damag": [4, 13, 23], "damai": 2, "damiani": [37, 38], "danc": 12, "dane": 4, "danger": [4, 37, 38], "dani": 5, "daniel": [4, 5, 22], "danqi": [5, 7, 11, 22], "dario": [6, 8, 10, 11, 22, 25], "dark": [4, 38], "darren": 19, "dash": 22, "dasha": 23, "dashscop": 38, "dashscope_ag": 38, "dashscope_embed": 38, "dashscope_multi_mod": 38, "dashscope_rerank": 38, "dashvector": 38, "dashvectorindexdemo": 38, "dashvectorreaderdemo": 38, "data": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 16, 18, 19, 23, 24, 37, 38], "data2": [32, 33, 34], "data_connector": 38, "data_load": [32, 33, 34, 35], "data_stor": [37, 38], "databas": [4, 5, 20, 37, 38], "databasereaderdemo": 38, "databrick": 38, "databricksvectorsearchdemo": 38, "dataclass": [37, 38], "dataclasses_json": [37, 38], "datafram": 38, "datalay": 38, "dataload": [32, 33, 34, 35], "dataset": [0, 1, 2, 3, 6, 10, 11, 16, 17, 20, 22, 23, 25, 32, 33, 34, 35, 37, 38], "dataset_gener": 38, "date": [3, 4, 5, 11, 20, 36, 37, 38], "dateutil": [37, 38], "daughter": 4, "davi": 4, "david": [5, 6, 8, 10, 11, 13, 14, 21, 25], "daxiang": 5, "daxin": 5, "daya": 2, "db": [9, 38], "db7a12aa1b4d": [37, 38], "dbk": 11, "dblp": 9, "dc19": [4, 5], "dc7238350598": 38, "dca": 1, "dcbert": 4, "dcg": [4, 5], "dclt18": [4, 5, 7, 11], "dded": 12, "ddot": [1, 11], "ddz": 2, "de": [1, 4, 5, 6, 9, 12, 13, 23, 25, 37, 38], "deal": [1, 4], "dean": [5, 7, 12, 17, 23], "death": [4, 5, 37, 38], "debug": [20, 38], "debut": 7, "dec": 16, "dec_attn": [30, 31, 33, 34, 36], "dec_featur": [30, 31, 33, 34, 36], "dec_hidden": [30, 31, 33, 34, 36], "decad": [4, 5, 8], "decai": 1, "decathlon": 10, "decent": 6, "decentr": [37, 38], "decid": [3, 4, 5, 10, 19, 20, 22, 38], "decis": [4, 5, 6, 18, 20, 37, 38], "deck": 38, "decod": [1, 2, 3, 4, 6, 7, 10, 16, 17, 20, 22, 29, 32, 35], "decoder_lay": [30, 31, 33, 34, 36], "decoderlay": 11, "decompos": [2, 4, 7, 11, 12, 13, 20], "decomposit": [3, 8, 12, 19, 20], "decond": 11, "decor": 38, "decoupl": [4, 5, 25], "decreas": [1, 2, 4, 5, 8, 11, 22, 25], "dedic": [3, 25, 37, 38], "deduc": 20, "deem": [4, 5], "deep": [0, 1, 6, 7, 8, 11, 12, 13, 20, 21, 22, 25, 38], "deep_memori": 38, "deepai": 20, "deepct": [4, 5], "deepcttermimportancedemo": 4, "deeper": [1, 9, 19], "deepev": 38, "deepimpact": 4, "deepinfra": 38, "deeplak": 38, "deeplake_deepmemory_retriev": 38, "deeplake_multimodal_retriev": 38, "deeplakeindexdemo": 38, "deeplakeread": 38, "deeplearn": 21, "deepli": 7, "deeplmpact": 4, "deepmemori": 38, "deepnet": 1, "deepnorm": 1, "deepseekmo": 2, "deerwest": 4, "def": [18, 30, 31, 32, 33, 34, 35, 36, 37, 38], "default": [4, 5, 27, 30, 36, 38], "default_cyph": [37, 38], "default_templ": [37, 38], "defaultdict": 27, "defect": [], "defenc": [37, 38], "defer": [4, 5], "defin": [1, 4, 5, 7, 8, 11, 12, 14, 20, 22, 24, 27, 36, 37, 38], "definit": [4, 5, 8, 12, 19, 24, 37, 38], "deflect": 24, "defragment": 21, "degener": 4, "degrad": [1, 13, 22, 23, 25], "degre": [4, 5, 8, 19, 22], "dehghani": [5, 11, 23], "dejian": 2, "deleg": 19, "delet": [4, 6, 10, 11, 13], "deli": 2, "deliber": 6, "delic": [4, 5], "delimit": [4, 5, 6, 20], "deliv": [4, 5, 11, 23, 37, 38], "deliveri": [37, 38], "delphic": 38, "delta": [4, 13, 23, 24, 25], "delta_": 4, "delv": 0, "demand": [4, 5, 19, 20, 37, 38], "demeonstr": 22, "demo": 38, "demograph": [37, 38], "demonstr": [0, 1, 4, 5, 6, 7, 8, 11, 13, 14, 16, 17, 18, 22, 25, 37, 38], "demostr": 38, "deng": [2, 5], "deni": 8, "denker": 13, "denni": [7, 17, 18, 23], "denois": [10, 11], "denomer": 8, "denomin": [4, 5, 8, 12, 14], "denorm": 13, "denot": [2, 3, 4, 5, 7, 12, 13, 14, 19, 21, 23, 24], "dens": [0, 7, 9, 11, 12, 38], "dense_x_retriev": 38, "densiti": [3, 20, 27], "depart": [37, 38], "depend": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 22, 23, 25], "depict": [2, 4, 20, 30, 36], "deploi": [1, 2, 4, 5, 7, 11, 13, 23, 38], "deplot": 38, "deplotread": 38, "deploy": [4, 5, 37, 38], "deposit": 12, "deprec": [37, 38], "deprecated_term": 38, "depth": [1, 2, 18, 19, 20, 36, 38], "deq": 13, "derelict": [37, 38], "deriv": [1, 2, 4, 5, 11, 12, 13, 20, 22, 24, 25], "descend": 4, "descendingli": 14, "descent": [6, 9, 12, 23], "descreas": [1, 22], "describ": [4, 5, 6, 10, 12, 16, 18, 20, 21, 30, 31, 32, 33, 34, 36], "describr": 20, "descrip": [37, 38], "descript": [3, 4, 5, 6, 7, 8, 10, 16, 20, 23, 37, 38], "descriptor": 4, "desig": 21, "design": [1, 2, 3, 4, 5, 6, 7, 10, 11, 21, 22, 23, 24, 25, 37, 38], "desipt": 21, "desir": [1, 2, 4, 5, 13, 14, 18, 20, 22, 23], "desm": 4, "despit": [4, 5, 20, 22, 37, 38], "destroi": [21, 24], "detach": [32, 33, 34, 35], "detail": [1, 3, 4, 7, 10, 11, 13, 14, 17, 18, 19, 20, 21, 22, 25, 30, 36, 37, 38], "detect": [4, 5, 6, 7, 18, 20], "deterior": 13, "determin": [2, 4, 5, 7, 8, 10, 11, 13, 19, 20, 21, 22, 24], "determinist": [2, 8, 14, 22, 24], "dettmer": 13, "dev": [4, 5], "devbal": 2, "develop": [0, 1, 2, 4, 5, 7, 8, 12, 13, 20, 21, 23, 25, 37, 38], "devendra": 1, "deviat": [1, 13, 22], "devic": [2, 4, 7, 13, 30, 31, 32, 33, 34, 35, 36, 38], "devicelevel": [], "devlin": [4, 5, 7, 10, 11, 23], "devoid": [4, 5], "devop": 38, "df": 19, "df_program": 38, "dgcwcsnxhu": 38, "dhariw": [1, 6, 8, 11, 22, 25], "dhruv": 14, "dhs11": 25, "di": [1, 4, 11], "diabet": 4, "diag": [37, 38], "diagno": [37, 38], "diagnoal": 13, "diagnos": [20, 38], "diagnosi": [20, 37, 38], "diagon": [30, 32, 35, 36], "diagram": [4, 10, 19, 22], "dialect": 19, "dialog": [4, 14, 16, 38], "dialog__inn": 38, "dialogu": [10, 16, 22, 36], "diamo": 21, "diaz": 5, "dichotomi": 4, "dict": [30, 36], "dict_item": [37, 38], "dictat": 4, "dictionari": [3, 4, 12, 20], "did": [3, 4, 6, 19, 20], "didn": [4, 19], "die": 4, "diederik": 25, "diego": 1, "diet": 4, "dietz": 5, "diff": 38, "diff_private_simple_dataset": 38, "diffcult": 19, "differ": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 22, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "differenti": [2, 4, 5, 13, 20], "difficult": [4, 6, 7, 11, 14, 16, 20, 23, 25, 37, 38], "difficulti": [1, 3, 4, 5, 7, 9, 20], "digest": [4, 5], "digi": [37, 38], "digit": [0, 37, 38], "dilemma": 24, "dili": [37, 38], "dilut": [3, 20], "dim": [4, 13, 21, 30, 31, 32, 33, 34, 35, 36], "dimens": [1, 2, 3, 4, 5, 7, 11, 12, 13, 16, 20, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "dimension": [1, 2, 5, 7, 8, 9, 11, 12, 13, 20, 23, 25], "dimensionaltii": 9, "diment": 1, "diminish": [0, 3, 4, 5, 20], "ding": [2, 5], "diogo": 22, "dir": 38, "dir_graph": [37, 38], "dir_vector": [37, 38], "direct": [3, 4, 5, 6, 7, 8, 9, 10, 12, 16, 18, 20, 22, 23, 24, 25, 37, 38], "directli": [1, 2, 3, 4, 5, 7, 8, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 37, 38], "director": 8, "directori": 38, "dirichlet": 4, "dirk": 11, "dirtyjson": [37, 38], "disabl": 38, "disadvantag": [4, 5, 12, 13, 14], "disagr": 11, "disagre": 20, "disambigu": [3, 4], "disanc": 1, "disc": 7, "discard": [2, 5, 7, 12, 14, 17, 19, 21, 23], "discharg": [37, 38], "discharge_summari": [37, 38], "discographi": 4, "discontinu": 4, "discord": 38, "discord_thread_manag": 38, "discorddemo": 38, "discount": [14, 24], "discourag": 22, "discov": [4, 5, 25, 38], "discover": 20, "discover_llamaindex": 38, "discoveri": [0, 4], "discrep": [4, 5, 7], "discret": [], "discrimin": [4, 5, 7, 16, 22], "discuss": [0, 1, 5, 7, 8, 11, 12, 21, 25], "diseas": [4, 37, 38], "disease_a": [37, 38], "disease_b": [37, 38], "disjoint": 10, "disk": 13, "dispar": [13, 19], "dispatch": [2, 37, 38], "displac": 7, "displai": [4, 5, 37, 38], "disposit": 4, "disproportion": 13, "dissatisfact": 4, "dissatisfi": 4, "dissect": 3, "dissimilar": [4, 5, 12], "distanc": [1, 3, 8, 9, 12, 22], "distance_comput": 4, "distant": [4, 5], "distil": [0, 11, 20, 38], "distilbert": [4, 5, 7, 11], "distinct": [1, 2, 4, 5, 20, 22], "distinguish": [4, 5, 7, 11, 12, 16, 22], "distort": [4, 7], "distract": 20, "distractor": 20, "distribut": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 20, 22, 24, 25, 30, 31, 33, 34, 36, 37, 38], "distro": [37, 38], "disturb": 2, "div": 38, "dive": 4, "diverg": [4, 5, 7], "divers": [2, 3, 4, 6, 7, 10, 11, 14, 17, 19, 22, 23, 25], "divid": [1, 4, 12, 13, 20, 25, 27], "divis": [1, 19, 25], "divisor": 21, "dl": 4, "dlbz22": 13, "dm": 10, "dmitri": 5, "dna": [4, 5], "dnn": [4, 5, 11, 21], "do": [1, 4, 5, 6, 7, 8, 11, 12, 17, 18, 19, 20, 21, 22, 27, 30, 36, 37, 38], "doc": [1, 4, 11, 21, 27, 38], "doc2queri": [4, 5, 20], "doc_2_queri": 27, "doc_dict": 27, "doc_len": 27, "docarrai": 38, "docarrayhnswindexdemo": 38, "docarrayinmemoryindexdemo": 38, "docder": 11, "docexpansionarch": 4, "docl": 38, "doclingreaderdemo": 38, "docs_readm": 38, "docsearch": 38, "docstor": 38, "docstoredemo": 38, "docstr": [30, 36, 38], "docstring_walk": 38, "doct5queri": [4, 5], "doctor": [4, 37, 38], "doctrain": 27, "doctttttqueri": [4, 5], "doctyp": 38, "docuemnt": 20, "docugami": 38, "docugami_kg_rag": 38, "document": [1, 3, 6, 7, 8, 10, 11, 12, 18, 19, 25, 36, 37, 38], "document360": 38, "document_length_ms_marco": 27, "document_manag": 38, "document_management_pipelin": 38, "document_summari": 38, "documents_and_nod": 38, "doe": [4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 37, 38], "doesn": [4, 16, 21], "dog": [4, 5, 9, 12, 27], "dogcatch": 12, "dogo": [4, 27], "doi": [37, 38], "doll": 25, "dollar": 12, "domain": [0, 2, 6, 11, 17, 20, 22, 23, 25, 38], "domainqa": 4, "domcontentload": 38, "domest": 4, "domiant": 13, "domin": [3, 4, 5, 7, 11, 25], "don": [1, 4, 7, 8, 20, 38], "donald": 5, "done": [4, 19, 20, 21, 22, 25, 37, 38], "dong": [1, 2, 5, 7, 25], "dongdong": 1, "dongji": 2, "dongxu": 16, "dongyu": 20, "doolei": 22, "door": [4, 5], "dosovitskii": 11, "dot": [1, 2, 4, 5, 7, 11, 16, 19, 30, 31, 33, 34, 36], "doteq": 24, "dou": 22, "doubl": 38, "doubt": [37, 38], "douz": 5, "down": [1, 3, 4, 5, 7, 13, 18, 19, 20, 21, 25, 30, 31, 33, 34, 36], "down_proj": [30, 31, 32, 33, 34, 35, 36], "downgrad": 38, "download": [4, 37, 38], "downloading_llama_dataset": 38, "downstream": [1, 4, 6, 7, 10, 11, 20, 23], "downweight": [12, 22], "dpi": 27, "dpo": [20, 29], "dpop": 22, "dr": 4, "dramat": [0, 4, 13, 25], "drastic": [4, 5, 11], "drave": [], "draw": [4, 11, 12, 20], "drawback": [1, 3, 4, 5, 7, 9, 12, 13, 14, 18, 20, 22, 36], "drawer": 38, "drawn": [4, 5, 22], "dress": 4, "drew": [6, 11], "drift": 4, "drive": [0, 4, 11, 38], "driven": [0, 4, 5, 24, 37, 38], "driver": [37, 38], "drop": [2, 4, 5, 11, 13], "drop_last": [32, 33, 34, 35], "dropbox": [], "dropout": [4, 5, 7, 21, 30, 31, 32, 33, 34, 35, 36], "drown": 4, "dtype": [30, 31, 33, 34, 36], "du": [1, 2, 6, 7, 11, 23, 25], "dub": 4, "dubei": 1, "ducharm": 9, "duchi": 25, "duckdb": 38, "duckdb_retriev": 38, "duckdbdemo": 38, "duckduckgo": 38, "duct": [37, 38], "due": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 17, 18, 20, 23, 37, 38], "duet": 5, "duli": [37, 38], "dum04": 12, "dumai": 12, "duobert": [4, 5], "duobertarch": 4, "duplic": [20, 37, 38], "durat": [13, 37, 38], "dure": [1, 2, 4, 5, 6, 7, 10, 11, 12, 13, 16, 17, 19, 20, 22, 23, 24, 25, 32, 35, 37, 38], "durm": 11, "dutch": [4, 8], "duti": [37, 38], "dvrc17": [4, 5], "dwell": [4, 5], "dy": 1, "dynam": [1, 2, 11, 13, 20, 21, 24, 25], "dynamo": 38, "dynamodb": 38, "dynamodbdocstoredemo": 38, "dysfunct": 4, "dz": [4, 5], "dzm": 20, "e": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "e2e_evalu": 38, "e_": [4, 5, 7, 8, 9, 11, 16, 22, 24], "e_0": [7, 11], "e_1": [7, 9, 11], "e_2": [7, 11], "e_d": [4, 5], "e_i": [2, 7, 11], "e_l": [7, 11], "e_n": [7, 11], "e_q": [4, 5], "e_t": 9, "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "earli": [1, 4, 5, 8, 13, 25, 29], "earlier": 4, "earn": [1, 2, 10, 11, 37, 38], "earnings_call_transcript": 38, "earth": [4, 5, 22], "earthquak": [4, 5], "easi": [4, 5, 6, 12, 13, 16, 20, 21, 37, 38], "easier": [4, 5, 7, 18, 19, 20, 22, 32, 35, 38], "easiest": 12, "easili": [4, 5, 6, 8, 12, 14, 19, 20, 37, 38], "eat": [4, 5, 12], "eb91": 38, "econom": [37, 38], "economi": [37, 38], "ecosystem": 38, "ed": [17, 18, 23], "ed4": [37, 38], "edg": [4, 18, 19, 20, 36], "edgar": 17, "edit": [4, 22, 30, 36, 37, 38], "editor": 9, "edouard": [7, 12], "educ": [37, 38], "edunov": 5, "edward": [23, 25], "ef96": [37, 38], "effeci": 9, "effect": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 25, 30, 36, 37, 38], "efff": [37, 38], "effici": [0, 1, 2, 3, 9, 11, 12, 13, 14, 16, 20, 21, 22, 25, 37, 38], "efficieni": 21, "effiect": 23, "effort": [3, 4, 5, 7, 8, 11, 20, 25, 37, 38], "efron": 4, "ega": 12, "egg": 4, "eh": 7, "ehealth": [37, 38], "eid": 6, "eiffel": [3, 4], "eight": [6, 11], "ein": 11, "eisenstein": 5, "either": [4, 5, 7, 12, 18, 24, 30, 36], "eival": 4, "el": 1, "elabor": 4, "elad": 25, "elast": 4, "elasticsearch": 38, "elasticsearch_auto_retriev": 38, "elasticsearch_demo": 38, "elasticsearchindexdemo": 38, "elec": [37, 38], "elect": [37, 38], "electron": [7, 37, 38], "electronic_medical_record": [37, 38], "eleg": 23, "elegxo": 4, "element": [2, 3, 4, 5, 6, 13, 14, 18, 20, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38], "elev": 4, "eli5": 10, "elicit": 18, "elif": 18, "elimin": [3, 7, 13], "ell": [6, 7], "ell_": 7, "ellen": 5, "ellipsi": 38, "els": [4, 14, 18, 19, 30, 32, 33, 34, 35, 36], "elsen": 21, "elsewher": 13, "em": 4, "emac": 19, "email": [4, 38], "email_data_extract": 38, "emb": [4, 16, 17, 30, 31, 33, 34, 36, 38], "emb_dropout": [32, 35], "embark": 0, "embd": 7, "embed": [6, 9, 10, 11, 13, 16, 17, 19, 20, 22, 23, 25, 29, 32, 35, 37, 38], "embed_dim": [30, 31, 33, 34, 36], "embed_model": [37, 38], "embed_token": [30, 31, 33, 34, 36], "embedding_rec": 38, "emerg": [0, 1, 4, 6, 8, 11, 13, 23, 25, 37, 38], "emin": [5, 23], "emlo": 7, "emoji": 1, "emotion_prompt": 38, "emotionprompt": 38, "emphas": [1, 4, 12], "emphasi": [4, 5], "empir": [4, 5, 8, 12, 22, 23, 25], "emploi": [2, 4, 5, 7, 11, 12, 13, 16, 17, 20, 21, 22, 25], "employ": [4, 20], "employe": [4, 19], "empow": [4, 5], "empower": 4, "empti": 4, "emptyset": 1, "emr": [37, 38], "en": [4, 6, 38], "enabl": [1, 2, 4, 5, 6, 7, 10, 11, 12, 13, 16, 19, 20, 21, 22, 23, 25, 37, 38], "encod": [2, 6, 10, 12, 16, 20, 23, 30, 31, 32, 33, 34, 35, 36, 38], "encodd": 16, "encoderlaly": [7, 11], "encoderlay": [7, 11], "encompass": [13, 37, 38], "encount": [4, 20, 27, 37, 38], "encourag": [2, 4, 5, 12, 14, 16, 17, 18, 22, 37, 38], "encourg": 22, "encyclopedia": 25, "end": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 19, 20, 21, 22, 23, 24, 25, 37, 38], "end_char_idx": [37, 38], "endoftext": 35, "endpoint": 38, "endto": 4, "energet": [], "energi": [4, 5, 13], "enforc": [4, 5, 16, 38], "engag": [2, 4, 21], "engin": [5, 6, 13, 17, 19, 20, 23, 25, 34, 38], "england": [37, 38], "english": [1, 4, 5, 6, 7, 8, 10, 11, 16, 21, 25], "enhanc": [0, 1, 2, 5, 11, 17, 18, 19, 21, 22, 23, 25, 36, 38], "enjoi": [8, 20], "enlarg": 22, "enlist": [37, 38], "enorm": [1, 11, 21], "enough": [4, 7, 8, 19, 20, 21, 22, 25, 30, 31, 33, 34, 36], "enrich": [5, 7, 12, 20], "enrish": 20, "ensembl": [22, 38], "ensemble_query_engin": 38, "ensemble_retriev": 38, "ensur": [1, 2, 3, 4, 5, 8, 14, 16, 20, 22, 23, 25, 30, 36, 37, 38], "entail": [6, 7, 10], "entangl": 4, "enter": [4, 11, 20, 38], "enterpris": 38, "entertain": [18, 36], "entir": [1, 4, 5, 6, 10, 13, 16, 20, 35, 37, 38], "entiti": [4, 5, 7, 8, 11, 16, 19, 20, 22, 37, 38], "entityextractionclim": 38, "entorpi": 8, "entri": [4, 5, 7, 11, 12, 33, 34, 37, 38], "entropi": [2, 4, 5, 6, 7, 10, 12, 22, 25], "enumer": [33, 37, 38], "env": [27, 34, 37, 38], "environ": [13, 22, 24, 37, 38], "environment": 0, "enyu": 22, "enzym": [4, 5], "eo": [11, 14, 22], "eoq": 4, "eos_token_id": [31, 33, 34], "ep": [30, 31, 32, 33, 34, 35, 36], "epeat": 24, "epic": [37, 38], "epidem": [37, 38], "epidemiolog": [37, 38], "epineurium": 4, "episod": 22, "epoch": [4, 32, 33, 34, 35], "epsilla": 38, "epsillaindexdemo": 38, "epsilon": [1, 4, 22, 24], "epstein": 5, "eq": [4, 13], "equal": [1, 2, 4, 5, 7, 8, 11, 12, 21, 25, 37, 38], "equat": [4, 5, 12, 13, 22, 23, 24], "equip": [0, 4], "equiv": 4, "equival": [4, 5, 7, 8, 10, 13, 21, 22, 24, 25, 30, 31, 33, 34, 36], "er": 12, "era": [0, 11, 13], "erat": 4, "erhang": 2, "eric": [5, 22], "erich": 21, "ericmitchel": 22, "erik": 5, "ermon": 22, "error": [5, 7, 12, 17, 18, 19, 20, 37, 38], "escap": 25, "esearch": [2, 10, 38], "esm": 4, "especi": [1, 4, 5, 8, 11, 13, 18, 20, 21, 23, 25, 37, 38], "essai": 19, "essenc": [4, 23, 24], "essenti": [3, 4, 5, 8, 12, 20, 22, 25, 29, 37, 38], "est": [4, 5], "establish": [4, 8, 20, 22, 25, 37, 38], "estim": [4, 5, 6, 19, 21, 22, 25], "et": [1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 16, 21, 22, 37, 38], "eta": [37, 38], "etc": [1, 4, 5, 6, 11, 12, 13, 14, 16, 19, 20, 22, 25, 37, 38], "ethic": 12, "etreiv": 4, "euclidean": [4, 5, 12], "eural": [1, 6, 8, 11], "euro": 1, "eva": 16, "eval": [4, 5, 38], "eval_query_engine_tool": 38, "evalu": [1, 2, 6, 12, 19, 23, 25, 37, 38], "evaluating_evaluators_with_llamadataset": 38, "evaluating_rag_system": 38, "evaluating_with_llamadataset": 38, "evaluator_benchmark": 38, "evalut": 20, "evapor": 38, "evaporate_program": 38, "even": [0, 1, 2, 4, 5, 6, 7, 8, 11, 13, 14, 16, 19, 20, 22, 25, 37, 38], "evenli": [2, 4, 5], "event": [3, 4, 5, 8, 16, 19, 20, 37, 38], "event_handl": 38, "event_typ": 38, "eventu": [2, 4, 12, 21], "ever": [0, 4, 8, 20], "everi": [1, 2, 4, 5, 7, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 37, 38], "everlyai": 38, "everyon": [4, 37, 38], "everyth": [], "everywher": 4, "evid": [4, 5, 37, 38], "evok": 17, "evolut": [8, 19, 23], "evolv": [4, 5, 20, 23], "ex": 19, "exa": 38, "exacerb": [], "exact": [13, 20], "exactli": [4, 8, 20], "examin": [0, 1, 4, 6, 20, 25, 37, 38], "exampifi": 1, "exampl": [3, 6, 7, 8, 9, 10, 11, 13, 14, 16, 18, 19, 21, 22, 23, 25, 37, 38], "example_documents_msmarco": 4, "example_queries_msmarco": [4, 5], "examplifi": 5, "exapns": 4, "exce": [22, 37, 38], "exceed": [6, 13], "excel": [4, 5, 6, 19, 20, 37, 38], "excellet": 20, "except": [4, 5, 6, 7, 12, 21, 36, 37, 38], "exceptiongroup": [37, 38], "excess": [4, 20], "exchang": [2, 4], "excit": [0, 4], "exclu": 4, "exclud": [4, 7, 11, 18, 37, 38], "excluded_embed_metadata_kei": [37, 38], "excluded_llm_metadata_kei": [37, 38], "exclus": [11, 23, 37, 38], "excus": 4, "execut": [4, 13, 23, 37, 38], "exercis": [1, 4, 7, 36], "exhibit": [0, 4, 11, 13, 20, 22], "exist": [1, 4, 5, 7, 8, 16, 18, 20, 22, 23, 25, 32, 33, 34, 35, 37, 38], "existing_answ": [37, 38], "existing_data": 38, "exp": [3, 4, 5, 7, 8, 12, 14, 16, 22], "expand": [0, 3, 4, 5, 6, 23, 30, 31, 33, 34, 36, 38], "expans": [3, 12, 13, 20], "expbal": 2, "expect": [2, 3, 4, 5, 6, 7, 12, 20, 22, 23, 24], "expedit": [37, 38], "expenditur": [37, 38], "expens": [4, 5, 9, 11, 12, 13, 18, 20, 25, 37, 38], "experi": [1, 4, 5, 16, 18, 23, 30, 31, 33, 34, 36, 37, 38], "experienc": [4, 5], "experiment": [4, 16, 25, 38], "expert": [0, 2, 4, 17, 36, 37, 38], "expertis": [2, 20], "explain": [4, 12, 16, 18, 19, 20, 22], "explan": [1, 13, 20], "explicit": [4, 5, 12, 18, 20, 22, 25], "explicitli": [0, 4, 5, 7, 19, 20, 22, 24], "explod": 1, "exploit": [4, 9, 24, 37, 38], "explor": [0, 1, 4, 5, 7, 9, 10, 17, 20, 23, 24, 25, 37, 38], "expon": 21, "exponenti": [0, 4, 8, 22, 25, 37, 38], "expos": [11, 21, 22], "exposur": 11, "express": [4, 5, 6, 12, 13, 20, 23, 24, 38], "extend": [4, 5, 7, 9, 16, 23, 38], "extens": [1, 3, 4, 6, 11, 14, 18, 23, 25, 37, 38], "extent": [12, 22, 37, 38], "extern": [0, 4, 5, 19, 20, 22, 36], "extra": [1, 4, 5, 6, 20, 23], "extract": [4, 5, 6, 8, 10, 11, 16, 20, 36, 37, 38], "extract_entities_from_pdf": [37, 38], "extractor": [4, 38], "extrapol": [1, 4, 37, 38], "extrem": [4, 5, 6, 13, 21, 25], "extropol": 1, "ey": 4, "f": [1, 2, 4, 5, 7, 8, 12, 13, 22, 25, 30, 31, 32, 33, 34, 35, 37, 38], "f1": 10, "f16": 13, "f_": [3, 4, 5, 25], "f_1": 13, "f_2": 13, "f_i": 2, "f_j": 2, "f_q": 4, "f_r": 4, "f_u": 25, "fabian": 25, "fabric": [37, 38], "face": [3, 4, 5, 12, 13, 20, 22, 38], "facebook": [7, 12], "facet": [20, 37, 38], "facil": 13, "facilit": [4, 5, 7, 12, 37, 38], "fact": [1, 3, 4, 5, 6, 8, 11, 13, 16, 17, 19, 20, 22, 24], "factoid": [4, 5], "factor": [0, 1, 2, 4, 5, 7, 11, 12, 13, 14, 17, 21, 22, 23, 24, 25, 37, 38], "factual": [1, 6, 17, 19, 20, 22, 25], "faecboek": 4, "fail": [4, 5, 8, 14, 19, 21, 22, 23], "failth": 20, "failur": [1, 4, 13, 20, 22], "fair": 4, "fairli": [4, 5], "faisal": 22, "faiss": [4, 5, 38], "faissdemo": 38, "faissindexdemo": 38, "fait": 6, "faith": [20, 38], "faithful": 38, "faithfulness_ev": 38, "falcon": 25, "falkordb": 38, "fall": [4, 5, 6, 11, 25, 37, 38], "fallback": 38, "fals": [7, 16, 24, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "famili": [7, 11, 38], "familiar": [4, 37, 38], "famou": 38, "fan": 5, "fandong": 23, "fang": [4, 5, 7], "fangyun": 2, "faq": 38, "far": [1, 4, 5, 8, 12, 22, 25, 38], "fashion": [4, 5, 12], "fast": [1, 4, 5, 25], "fastemb": 38, "faster": [2, 4, 7, 13, 21, 25], "fastest": 13, "fasttext": [4, 5, 12], "fat": 4, "fatal": [4, 5], "fatti": [4, 5], "favor": [4, 17, 20, 22], "favorit": 4, "fb74": [37, 38], "fbf77": [4, 5], "fc": 16, "feasibl": [4, 5, 37, 38], "feasibli": 13, "featur": [1, 2, 5, 7, 8, 11, 12, 13, 16, 20, 22, 23, 37, 38], "feb": 9, "februari": 20, "fed": [4, 5, 6, 7, 10, 11, 12, 16, 20, 23, 25], "federico": 1, "fedu": [2, 23], "feed": [1, 4, 7, 10, 11, 13, 16, 20, 25], "feedback": [5, 18, 22, 38], "feedback__not": 38, "feedforward": [1, 9, 21, 32, 35], "feedfoward": [30, 31, 32, 33, 34, 35], "feedli": 38, "feedly_rss": 38, "feel": [4, 10, 36], "fei": [1, 11], "feishu": 38, "feishu_doc": 38, "feishu_wiki": 38, "felix": 5, "fell": 4, "femal": 4, "feng": [2, 5], "fernando": 5, "fetch": [4, 5], "few": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 16, 17, 20, 23, 25], "fewer": [2, 4, 5, 13], "ff": [7, 11, 32, 35], "ffd": 23, "ffn": [2, 7, 11, 13, 16, 21, 23], "fi": 4, "fibonacci": 18, "fibonacci_50th": 18, "fibroid": 4, "ficat": 4, "fiction": 22, "field": [0, 4, 5, 8, 20, 25, 37, 38], "fifth": [37, 38], "fig": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23, 24, 25, 37, 38], "figsiz": 27, "figur": [2, 4, 5, 13, 20, 25, 27], "file": [20, 27, 32, 33, 34, 35, 37, 38], "file_nam": [37, 38], "file_path": [32, 33, 34, 35, 37, 38], "file_s": [37, 38], "file_typ": [37, 38], "filenam": 38, "filenodeprocessor": 38, "filesystem": 38, "filip": [5, 22], "fill": [4, 5, 10, 30, 36], "fill_valu": [30, 36], "filter": [3, 4, 5, 6, 16, 19, 20, 23, 25, 37, 38], "final": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 30, 36], "final_norm": [32, 35], "financ": 38, "financi": [20, 37, 38], "financial_data": [37, 38], "finchat": 38, "find": [0, 1, 3, 4, 5, 7, 10, 13, 14, 17, 19, 20, 22, 23, 37, 38], "fine": [0, 1, 2, 4, 5, 8, 11, 13, 16, 18, 22, 25, 38], "fine_tun": 38, "finer": [2, 17], "finetin": 20, "finetun": [3, 11, 16, 18, 22, 25, 29, 38], "finetune_corpus_embed": 38, "finetune_embed": 38, "finetune_embedding_adapt": 38, "finetune_llm_judg": 38, "finetune_llm_judge_single_grading_correct": 38, "finfo": [30, 36], "fingertip": [37, 38], "finish": [4, 13], "finit": [4, 5, 13, 22], "finkel": 5, "finn": 22, "firat": [7, 23], "fire": 20, "firebas": 38, "firebase_realtimedb": 38, "firestor": 38, "firestoredemo": 38, "firestorevectorstor": 38, "firework": 38, "fireworks_cookbook": 38, "firm": 4, "firmli": 4, "first": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "firstelementchild": 38, "firstli": 22, "fisch": 5, "fish": [4, 20], "fit": [4, 5, 13, 20, 21, 22, 23, 38], "five": [4, 5], "fix": [1, 2, 4, 5, 7, 9, 10, 11, 12, 13, 14, 16, 17, 20, 22, 23, 24, 38], "fixed_rec": 38, "fixedwidth": 4, "fl": [37, 38], "flag": 38, "flag_embedding_rerank": 38, "flagembeddingrerank": 38, "flail": 4, "flan": 23, "flant5": 16, "flare": 38, "flare_query_engin": 38, "flasch": 11, "flash": [30, 36], "flat": [3, 4, 5, 25], "flat_logit": [32, 33, 34, 35], "flat_target": [32, 33, 34, 35], "flatten": [32, 33, 34, 35], "flavor": 21, "flexibl": [2, 4, 5, 7, 11, 18, 20, 23, 38], "flier": 4, "flight1ess": 7, "flip": [4, 22], "float": [1, 4, 5, 13, 30, 31, 33, 34, 36], "float16": [13, 21, 30, 31, 33, 34, 36], "float32": [13, 21, 30, 31, 33, 34, 36], "floattensor": [30, 31, 33, 34, 36], "floor": 8, "flop": [4, 13], "flor": 4, "florenc": [], "florian": 1, "flow": [1, 3, 4, 16, 36, 38], "fluctuat": 1, "fluenci": 14, "fluent": 8, "fluffi": 4, "fluid": [4, 5], "fly": [5, 22], "flyout": 38, "fmt": [7, 23], "focu": [0, 1, 4, 5, 8, 13, 20], "focus": [0, 2, 4, 5, 7, 11, 19, 20, 22, 23, 37, 38], "fold": [4, 5, 7], "folder": 38, "follow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "font": [27, 38], "fontsiz": 27, "food": [4, 5, 8], "fool": 6, "footer": [36, 38], "footer__button": 38, "footer__direct": 38, "footer__inn": 38, "footer__link": 38, "footer__titl": 38, "footnot": 12, "footnotes": 4, "footprint": [1, 11, 13, 21, 37, 38], "foral": [4, 6, 13, 24, 25], "forc": [4, 5, 7, 14, 16, 22, 38], "forecast": [0, 20], "forexampl": 4, "forget": [16, 23, 25], "forgett": [18, 36], "form": [1, 3, 4, 5, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 30, 36, 37, 38], "formal": [4, 5, 7, 8, 9, 12, 14, 20, 24], "format": [4, 5, 6, 10, 13, 17, 18, 20, 21, 36, 37, 38], "format_input": [32, 33, 34], "former": [4, 8, 16, 37, 38], "formul": [2, 4, 5, 6, 10, 12, 22, 23], "formula": [1, 4, 5, 8, 11, 12, 13, 21, 30, 31, 33, 34, 36], "forrank": 4, "forth": [4, 38], "forum": 25, "forward": [0, 4, 6, 7, 11, 13, 14, 18, 20, 21, 22, 30, 31, 32, 33, 34, 35, 36, 38], "forword": 14, "found": [0, 1, 3, 4, 5, 6, 7, 12, 13, 19, 20, 37, 38], "foundat": [0, 1, 4, 5, 8, 11, 17, 22], "founder": 4, "four": [1, 2, 4, 5, 6, 10, 20, 37, 38], "fourier": 4, "fp16": 21, "fp32": [13, 21, 30, 31, 33, 34, 36], "fp8": 21, "fr": 6, "frac": [1, 2, 5, 7, 8, 9, 11, 12, 13, 14, 16, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36], "fraction": [2, 4, 5, 20, 21], "fractur": [37, 38], "fraemwork": 22, "fragment": [4, 5, 13, 20, 21, 37, 38], "frame": [4, 11], "framework": [6, 7, 8, 10, 12, 14, 16, 19, 22, 25, 36, 37, 38], "franc": [3, 12, 22], "francisco": 7, "frank": [4, 25], "fraser": 22, "free": [1, 4, 6, 7, 22, 36, 38], "freedom": [37, 38], "freez": [16, 23], "frei": 4, "french": [4, 6, 7], "freq": [30, 31, 33, 34, 36], "frequenc": [1, 4, 5, 7, 8, 9, 12, 20, 30, 31, 33, 34, 36], "frequent": [1, 4, 5, 7, 8, 9, 16, 20, 25, 38], "fresh": 20, "friction": [], "friedman": 5, "friend": [4, 8], "friendli": [23, 38], "fro": 12, "from": [0, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "from_default": [37, 38], "from_docu": [37, 38], "from_pretrain": [31, 32, 33, 34], "fromstein": 8, "fromth": 20, "front": 8, "frontier": 0, "frozen": [16, 22, 23], "frozenlist": [37, 38], "fruit": 7, "fsdp": [30, 36], "fsspec": [37, 38], "ft": [20, 23], "fu": [2, 22, 23], "fucong": 2, "fuli": 2, "full": [4, 5, 8, 10, 13, 14, 20, 21, 22, 23, 25, 30, 36, 38], "full_stack_project": 38, "fulli": [1, 2, 3, 4, 5, 11, 16, 19, 20, 23, 30, 31, 33, 34, 36], "fullstack_app_guid": 38, "fullstack_with_delph": 38, "fullyconnect": 4, "fun": 7, "funciton": [1, 22], "function": [1, 2, 3, 6, 7, 9, 12, 13, 14, 16, 22, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "function_cal": 36, "function_calling_ag": 38, "function_map": [37, 38], "function_program": 38, "functool": [32, 33, 34], "fund": [12, 19], "fundament": [0, 3, 6, 7, 8, 11, 23, 29, 37, 38], "fung": 5, "furhter": 17, "furna": 4, "further": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 22, 23, 24, 25, 36, 37, 38], "furthermor": [4, 11, 37, 38], "furu": [1, 7], "fuse": [4, 5, 11, 13], "fusi": 17, "fusion": [5, 7, 16, 38], "fusion_retriev": 38, "futagi": 4, "futur": [0, 4, 6, 11, 25, 30, 36], "fuyu": 38, "fuzheng": 5, "fuzzi": 38, "fuzzy_cit": 38, "fzs22": 2, "g": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 37, 38], "g_": [1, 2, 4, 25], "g_0": 25, "g_i": 13, "g_t": 24, "ga": [4, 12, 17], "gabriel": [16, 25], "gain": [0, 6, 7, 12, 13, 21, 22, 23, 24, 37, 38], "gal": 5, "gallon": 7, "game": [0, 4, 23, 24], "gamma": [2, 4, 5, 24, 30, 31, 33, 34, 36], "gan": 7, "ganesh": 21, "gao": [2, 4, 5, 7, 20, 22], "gao2021compl": 4, "gao2021unsupervis": 4, "gao2021your": 4, "gap": [4, 7, 16, 20, 22, 23, 25, 37, 38], "gar": 12, "garanti": 6, "garc": 7, "garcia": 21, "garciajsvaldes17": 7, "gardner": 7, "gate": [1, 2, 4, 30, 31, 33, 34, 36], "gate_proj": [30, 31, 33, 34, 36], "gather": [4, 5, 13, 19, 21, 33], "gatsbi": 38, "gaudi": 38, "gaug": [8, 24], "gaurav": 23, "gaussian": 4, "gautier": 22, "gb": [3, 4, 7, 13, 21], "gbcb16": [4, 5], "gbm": 4, "gc": 38, "gca": 27, "gdc21": [4, 5], "gdn": 38, "gdollarg": 25, "gdp": [3, 4], "gdpr": 20, "ge": 2, "gelli": [11, 23], "gelu": [4, 32, 35], "gement": [37, 38], "gementinpat": [37, 38], "gemini": [1, 20, 38], "gemma": 38, "gen": [4, 19, 37, 38], "genai": 38, "gender": 4, "gene": [4, 5], "genearl": 9, "gener": [0, 1, 2, 5, 7, 8, 9, 11, 14, 16, 18, 19, 21, 23, 25, 27, 30, 36, 37, 38], "generalis": 7, "generalist": [3, 17, 20], "generalz": 22, "generationmixin": [30, 36], "genet": [4, 5], "geng": 5, "geniu": 38, "genius": [], "genr": [4, 6], "genserp": 3, "genuin": [4, 8], "geo": 16, "geoffrei": [5, 7, 25], "geograph": 22, "geometr": 4, "georg": [11, 25, 37, 38], "geq": [7, 24], "german": [4, 10], "germani": 22, "gesellschaft": 4, "gesmundo": 23, "get": [4, 5, 6, 8, 9, 10, 11, 13, 14, 17, 19, 25, 27, 30, 31, 33, 34, 36, 37, 38], "get_encod": [32, 33, 34, 35], "get_logp": 33, "get_prompt": [37, 38], "getattribut": 38, "getelementbyid": 38, "getenv": 36, "getitem": 38, "getting_start": 38, "gfp": [4, 5], "gg": 38, "ghajar": 5, "ghazvininejad": 10, "ghosh": 5, "gianna": 1, "giant": 19, "gibberish": 14, "gigachat": 38, "gigant": 4, "gimpel": [7, 11], "ginsburg": 21, "girish": [1, 6, 8, 11, 16], "girozier": 25, "girshick": [5, 25], "git": 26, "gitano": 8, "gitbook": 38, "github": [4, 13, 25, 38], "github_issue_analysi": 38, "githubrepositoryreaderdemo": 38, "githubusercont": [32, 33, 34, 35], "gitlab": 38, "giurgiu": 23, "give": [1, 4, 5, 7, 8, 9, 13, 18, 20, 21, 22, 24, 30, 31, 33, 34, 36, 37, 38], "given": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 36, 37, 38], "gl14": 12, "glanc": [4, 24], "glass": 4, "glean": 3, "glitch": [37, 38], "global": [4, 5, 12, 19, 20, 37, 38], "global_step": [32, 33, 34, 35], "globerson": 5, "gloeckl": 25, "glove": 7, "glu": [1, 30, 31, 33, 34, 36], "glucos": [4, 5], "glue": [11, 13], "glycem": 4, "gmail": 38, "gmail_openai_ag": 38, "gnu_aspel": 4, "go": [1, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 22, 24, 30, 31, 33, 34, 36, 37, 38], "goal": [0, 4, 5, 6, 8, 10, 12, 14, 16, 20, 24, 37, 38], "god": 20, "goe": [1, 4, 5, 12, 37, 38], "gogh": 38, "goh": 16, "goir": 5, "gol17": 8, "golbandi": 5, "gold": [3, 4, 8, 20], "goldberg": [8, 12], "golden": 20, "goldi": 22, "goldstein": 20, "gomez": [5, 11], "gong": [1, 2, 38], "gonzalez": [13, 20], "good": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 16, 20, 22, 37, 38], "goodfellow": 5, "goodman": [7, 8, 11], "googl": [1, 4, 5, 7, 20, 38], "google_palm": 38, "googleapi": 38, "googlechatdemo": 38, "googledemo": 38, "googledocsdemo": 38, "googledrivedemo": 38, "googlemapstextsearchreaderdemo": 38, "googlesheetsdemo": 38, "googletagmanag": 38, "gordon": 5, "gorilla": 8, "got": 4, "gotten": [], "gou": [2, 5], "gouvern": 6, "govern": [0, 6, 8, 37, 38], "goyal": [7, 10, 11, 22, 25], "gpt": [0, 1, 8, 10, 11, 13, 16, 17, 19, 20, 22, 29, 36, 37, 38], "gpt2": [32, 33, 34, 35], "gpt3": [6, 23], "gpt4": 38, "gpt4o_mm_structured_output": 38, "gpt4v": 38, "gpt4v_experiments_cot": 38, "gpt4v_multi_modal_retriev": 38, "gpt_model": 36, "gpt_repo": 38, "gptpretraindataset": 35, "gpu": [4, 5, 11, 13, 19, 23, 38], "gqa": [21, 30, 31, 33, 34, 36], "gr": 5, "grad": [], "grad_fn": [32, 35], "grad_tensor": 34, "grad_tensors_": 34, "grad_vari": 34, "grade": [4, 5, 23, 38], "gradient": [1, 2, 4, 5, 6, 7, 9, 12, 21, 22, 23, 34, 38], "gradio": 38, "gradio_agent_chat": 38, "gradio_react_agent_chatbot": 38, "gradual": [1, 6, 11, 24, 25], "graham": [7, 20], "grai": [4, 25], "graident": 21, "grain": [2, 4, 5, 7, 8, 13, 16, 17, 20, 38], "grainger": 4, "gram": [5, 9, 14], "grammar": [4, 5, 8, 9, 12, 14], "grammat": [4, 5], "granddaught": 12, "grandson": 12, "granular": [1, 4, 5], "graph": [5, 21, 37, 38], "graph_stor": [37, 38], "graphdatabas": [37, 38], "graphdb": 38, "graphdb_cyph": 38, "graphql": 38, "graphrag": 38, "graphrag_v1": 38, "graphrag_v2": 38, "graphwidget": [37, 38], "grasp": [1, 11], "grave": [7, 12], "gre": 12, "great": [4, 5, 6, 11, 12, 38], "greater": [3, 4, 5, 8, 11, 12, 13, 21, 37, 38], "greatli": [1, 4, 5, 18], "greec": 12, "greedi": [17, 24], "greedili": 14, "greenlet": [37, 38], "greg": [5, 12, 25], "gregari": 12, "gregori": [13, 21], "gression": 4, "grid": [27, 38], "grip": 18, "groom": [4, 8], "groq": 38, "gross": 4, "ground": [2, 3, 4, 5, 16, 17, 18, 19, 20, 22, 23], "groundtruth": 22, "groundwork": 4, "group": [2, 4, 5, 8, 13, 20, 21, 30, 31, 32, 33, 34, 35, 36, 37, 38], "groupwis": 5, "grow": [1, 4, 5, 6, 11, 12, 13, 20, 37, 38], "grown": [37, 38], "growth": [0, 4], "gsh23": 22, "gsl": [4, 5], "gsm8k": 18, "gstatic": 38, "gt": [22, 38], "gtag": 38, "gu": [2, 18, 19, 20, 23], "guadalup": 7, "guan": 2, "guangbo": 2, "guangju": 22, "guant": 2, "guarante": [4, 5, 12, 14, 19, 20], "guarate": 20, "guard": 38, "guardrail": 38, "guardrailsdemo": 38, "guess": 4, "guestrin": 21, "gui": 6, "guid": [0, 1, 4, 5, 12, 16, 17, 18, 20, 21, 22, 37, 38], "guidanc": 38, "guidance_pydantic_program": 38, "guidance_sub_quest": 38, "guidelin": [20, 37, 38], "guideline_ev": 38, "guillaum": [1, 7], "gun": 4, "guo": [2, 5], "guo2016deep": 4, "guowei": 2, "gurevych": 4, "guru": 38, "gut": 10, "gutenberg": 25, "guterman": 8, "guu": [20, 23], "guu2020retriev": 4, "guzm": 7, "gxg": 20, "h": [1, 2, 4, 5, 7, 9, 11, 13, 16, 17, 21, 23, 24, 30, 31, 33, 34, 36, 37, 38], "h1": [18, 36, 38], "h11": [37, 38], "h2": 38, "h3": 38, "h_": [4, 5, 6, 7, 9, 13], "h_0": [4, 5, 6], "h_1": [4, 5, 7], "h_2": 4, "h_3": 4, "h_4": 4, "h_5": 4, "h_6": 4, "h_7": 4, "h_8": 4, "h_9": 4, "h_i": 25, "h_l": 6, "h_n": [4, 5, 7], "h_t": [4, 7, 9], "ha": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "hack": [37, 38], "hacker": 19, "had": [0, 4, 6, 19], "haddad": 5, "haddow": 1, "haifeng": 5, "haiku": [36, 38], "hajishirzi": 19, "hakan": 12, "half": [1, 7, 13, 21, 30, 31, 33, 34, 36], "hall": 20, "hallaci": 16, "hallmark": 38, "halluci": 17, "hallucin": [1, 3, 19, 20, 22], "hambro": 22, "hame": 5, "han": [2, 5], "hanburi": 5, "hand": [1, 4, 5, 7, 8, 11, 12, 17, 18, 20, 22, 23, 24, 25, 37, 38], "handl": [1, 2, 4, 5, 9, 13, 18, 19, 20, 23], "handle_torch_funct": 34, "handler": 38, "hang": 5, "hangbo": 7, "hannaneh": 19, "hanwei": 2, "hao": [2, 13], "haocheng": 2, "haofen": 20, "haoqi": 5, "haoran": 23, "haotian": 16, "haowei": 2, "happen": [4, 5, 7, 16, 17, 19, 22], "happi": [4, 20], "harar": 12, "hard": [1, 3, 6, 12, 14, 20, 21, 22, 37, 38], "harder": [4, 5, 7], "hardli": [4, 8], "hardwar": [0, 13, 21, 37, 38], "harm": [20, 22, 23], "harmless": 22, "harmon": 4, "harper": 4, "harri": [4, 25], "harsh": 4, "harsha": 17, "harvard": [], "has_torch_function_unari": 34, "hash": [4, 12, 38], "hasn": 4, "hassibi": 13, "hat": [4, 5, 7, 14, 22, 23, 25], "hate": [4, 6, 10], "hatena": 38, "hatena_blog": 38, "have": [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 36, 37, 38], "hazan": 25, "hdmi": 4, "he": [1, 2, 4, 5, 7, 9, 11, 20, 21, 22, 25, 30, 36], "he2016learn": 4, "head": [2, 3, 4, 5, 6, 7, 10, 11, 13, 18, 20, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "head_1": 11, "head_dim": [30, 31, 32, 33, 34, 35, 36], "head_h": 11, "head_i": 11, "header": [20, 36, 38], "header__button": 38, "header__ellipsi": 38, "header__inn": 38, "header__opt": 38, "header__titl": 38, "header__top": 38, "headerlink": 38, "health": [4, 37, 38], "health_record": [37, 38], "healthcar": [37, 38], "healthcare_provid": [37, 38], "healthi": 4, "heard": [4, 6], "heart": [4, 5, 14], "heat": 13, "heath": 4, "heavi": 25, "heavili": [7, 11, 12, 20, 25], "heck": 5, "heewoo": 25, "height": [4, 38], "heigold": 11, "held": [4, 21], "helix": 4, "hello": [18, 32, 35, 36], "help": [1, 4, 5, 6, 7, 11, 18, 19, 20, 21, 22, 23, 25, 36, 37, 38], "helper": 38, "hemoglobin": 4, "henc": [4, 5, 37, 38], "henceforth": 4, "heng": 17, "henighan": 25, "henriqu": 25, "her": [4, 5, 12, 37, 38], "herd": 1, "here": [0, 1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38], "hereaft": 4, "herebi": 19, "herv": 5, "hess": 25, "heterogen": [4, 5, 20], "heurist": [11, 14, 20], "hfill": 4, "hg19": [4, 5], "hgj": 23, "hh": 22, "hhg": [4, 5], "hi": [4, 5, 6, 19, 37, 38], "hickman": [37, 38], "hidden": [1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 38], "hidden_act": [31, 33, 34], "hidden_s": [30, 31, 33, 34, 36], "hidden_st": [30, 31, 33, 34, 36], "hidn": 7, "hierach": 20, "hierarch": [20, 38], "hierarchi": [4, 19, 38], "high": [1, 2, 5, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 37, 38], "higher": [1, 2, 3, 4, 5, 8, 13, 14, 17, 18, 19, 20, 22, 23, 25, 38], "highest": [1, 2, 3, 4, 5, 14, 16, 20, 22], "highli": [1, 2, 3, 4, 7, 20, 22], "highlight": [4, 5, 13, 17, 18, 19, 36, 38], "highperform": 4, "highwai": [4, 5], "hill": 4, "hilton": 22, "hin12": 25, "hinder": [2, 22, 37, 38], "hing": [4, 12, 37, 38], "hingeloss": 4, "hinrich": [5, 8], "hinton": [5, 7, 25], "hippa": [37, 38], "hire": 22, "hiros": 9, "histogram": 4, "histopathologi": [37, 38], "histor": [4, 5, 6, 20, 25], "histori": [4, 5, 16, 23, 37, 38], "history1995th": 4, "history_sheet": [37, 38], "histplot": 27, "hit": 24, "hive": 38, "hkk": 25, "hkm": 4, "hline": [4, 12], "hlt24": 22, "hmm": 4, "hnsw": [4, 5, 38], "hnswlib": 38, "hnswlibindexdemo": 38, "hofst": 5, "hofstatter2020improv": 4, "hofstatter2021effici": 4, "hofstatterli": 5, "hoi": 16, "hold": 4, "holder": [37, 38], "hole": 4, "holidai": 4, "holist": 19, "hologr": 38, "hologresdemo": 38, "home": [27, 37, 38], "homework": 8, "homogen": 4, "homonym": 4, "honeyh": 38, "honeyhivellamaindextrac": 38, "hong": [5, 22], "honghui": 2, "hongkun": [7, 23], "honglei": 5, "hongyin": 5, "hongyu": 1, "honour": [37, 38], "hop": [3, 17, 19, 20], "hope": [4, 5, 22], "hopefulli": [4, 25], "horizon": 22, "horizont": 25, "hors": 12, "hospit": [37, 38], "hospital_information_system": [37, 38], "host": 38, "hot": [4, 5, 7, 12, 13], "hotel": [3, 4, 5], "hotpotqadistractor": 38, "hottest": [4, 5], "hou": [1, 4, 23, 25], "houlsbi": 23, "hour": [4, 5, 19, 25], "hourglass": 4, "hous": 22, "houston": 21, "how": [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 37, 38], "howev": [0, 1, 2, 3, 4, 5, 6, 7, 9, 14, 16, 18, 20, 21, 22, 23, 24, 25, 36, 37, 38], "hr": 7, "href": 38, "hslw19": [4, 5], "hspace": 27, "hsw": 23, "hsw93": 13, "html": [4, 9, 18, 20, 21, 36, 38], "html_tag_read": 38, "http": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 20, 21, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38], "httpcore": [37, 38], "httpx": [37, 38], "htut": [4, 5], "hu": [2, 7, 20, 23], "hua": [5, 19], "huaixiu": 17, "huajian": 2, "huang": [1, 2, 5, 7, 22, 23], "huanyu": 20, "huazuo": 2, "hub": 38, "hubspot": 38, "huehn": 4, "hug": 38, "huge": [1, 4, 5, 7, 8, 12, 21, 38], "huggingfac": [30, 31, 32, 33, 34, 35, 38], "huggingface_api": 38, "huggingface_camel": 38, "huggingface_f": 38, "huggingface_itrex": 38, "huggingface_openvino": 38, "huggingface_optimum": 38, "huggingface_optimum_intel": 38, "huggingface_stablelm": 38, "hugo": [5, 22], "hui": [1, 2, 5, 21], "huiqiang": 13, "huishuai": [1, 11], "hullucil": 20, "human": [0, 1, 4, 5, 7, 8, 12, 14, 17, 18, 20, 22, 23, 25, 37, 38], "human_in_the_loop_story_craft": 38, "humeau": [4, 5], "humeau2019poli": 4, "hundr": [0, 1, 4, 5, 6, 12, 19, 25], "hungari": 23, "hunspel": 4, "hunt": 4, "hurdl": [37, 38], "hurt": [1, 7], "hutter": 25, "hv": 7, "hvd15": [4, 5, 7], "hwp": 38, "hybrid": [5, 16, 20, 38], "hyde": 38, "hydequerytransformdemo": 38, "hydro": 8, "hygien": [37, 38], "hyken": 4, "hyper": [1, 2, 4, 5, 14], "hyperbol": 4, "hyperlink": 4, "hypermet": 13, "hypernym": 4, "hyperparamet": [1, 4, 5, 8, 22, 25, 38], "hyperplan": [4, 5], "hyperspher": [4, 5], "hyphen": 4, "hypothes": [1, 4, 14, 23, 30, 31, 33, 34, 36], "hypothesi": [1, 4, 5, 6, 7, 10, 14], "hypothet": 22, "hyung": 23, "i": [0, 2, 3, 6, 7, 8, 9, 10, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "i8": 13, "i_": [4, 16], "i_1": [4, 5, 7, 11], "i_d": [4, 5], "i_f": 16, "i_k": [4, 5], "i_n": [7, 11], "i_p": [7, 11], "i_q": [4, 5], "ian": 5, "ib": 7, "ibarra": 7, "ibm": [12, 38], "ibm_watsonx": 38, "ibuprofen": 20, "ic": [4, 12, 19], "iceberg": 38, "ich": 11, "ici": [4, 5], "icon": 38, "id": [4, 5, 30, 31, 33, 34, 36, 37, 38], "id_": [37, 38], "idaa": 24, "idaho": [4, 5], "idcg": [4, 5], "idea": [1, 3, 4, 5, 7, 8, 9, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 25], "ideal": [4, 5, 12, 17, 20, 21], "iden": 4, "ident": [4, 11, 37, 38], "identi": 4, "identif": [0, 4], "identifi": [3, 4, 5, 11, 13, 19, 20, 36, 37, 38], "idf": [4, 12], "idl": 2, "idna": [37, 38], "idrissi": 25, "idx": [32, 33, 34, 35], "ieee": [5, 13, 21], "ient": [37, 38], "ientpatientdischarg": [37, 38], "iffals": 4, "ific": [37, 38], "ignit": 20, "ignor": [4, 5, 12, 13, 20, 21, 30, 32, 33, 34, 36], "ignore_idx": [32, 33, 34], "ii": [3, 13, 22], "iisel": 19, "iisup": 19, "ij": [1, 4, 8, 11, 12, 13], "ijsrp": [37, 38], "ik": 1, "iks16": 12, "il": 6, "ill": [37, 38], "illia": [5, 11], "illinoi": 12, "illiter": [37, 38], "illustr": [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 16, 17, 18, 19, 20, 22, 23, 25, 30, 31, 32, 33, 34, 35], "ilya": [5, 6, 8, 10, 11, 12, 25], "im": 4, "imag": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 20, 22, 23, 25, 37, 38], "image_encod": 16, "image_to_image_retriev": 38, "imagenet": 25, "imagin": [37, 38], "imaginari": 8, "imbal": [2, 7, 21], "imbecil": 6, "imc": [37, 38], "imdb": 38, "imdb_review": 38, "imf": 12, "img": 38, "imit": 22, "immeasur": [37, 38], "immedi": [4, 5, 24], "impact": [0, 1, 5, 6, 7, 8, 13, 14, 19, 20, 22, 23, 25, 37, 38], "impacthardnegativeonretriev": 4, "impair": 2, "imper": [37, 38], "imperfect": [4, 20, 22], "implement": [2, 4, 7, 13, 19, 21, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "impli": [1, 4, 7, 10, 12, 13], "implic": [0, 1, 4, 13, 21], "implicit": [4, 7, 12, 20], "implicitli": [4, 5, 20, 24], "impor": 4, "import": [0, 1, 3, 7, 8, 10, 11, 12, 13, 19, 20, 23, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "importantli": [4, 12], "impos": [4, 7, 14, 23, 38], "imposs": [4, 5, 7], "impossibli": 12, "impract": [4, 5, 8], "impress": [4, 5, 6, 11, 18, 25, 36], "improv": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 23, 25, 36, 37, 38], "imshow": 27, "inaccru": 22, "inaccur": 16, "inaccuraci": 9, "inaccurci": 13, "inadvert": 23, "inan": 12, "inappropri": [20, 22], "inbatchdistil": 4, "inbatchneg": 4, "inc": [4, 5, 25], "inch": [3, 4], "includ": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 37, 38], "include_embed": [37, 38], "include_text": [37, 38], "inclus": [23, 37, 38], "incom": [4, 37, 38], "incomplet": [3, 20, 22], "inconsist": [9, 23], "inconveni": [4, 37, 38], "incopor": 20, "incorpo": 14, "incorpor": [2, 3, 4, 5, 7, 14, 19, 20, 25, 36, 37, 38], "incorrect": [1, 4, 12, 16, 17, 19, 20, 22], "incorrectli": [8, 22], "increas": [0, 1, 2, 5, 6, 7, 8, 9, 11, 13, 17, 18, 19, 20, 21, 22, 23, 25, 37, 38], "increasingli": [0, 1, 4, 13, 20, 37, 38], "increment": [4, 17, 23], "incres": 1, "incrimin": [37, 38], "inculc": [37, 38], "incur": [4, 21, 23], "inde": [4, 12, 24], "indent": 4, "independ": [2, 4, 5, 6, 7, 10, 12, 13, 19, 20, 22, 25], "index": [1, 2, 7, 11, 12, 24, 33, 37, 38], "index_guid": 38, "index_stor": 38, "india": [37, 38], "indian": [37, 38], "indic": [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 20, 23, 30, 33, 36, 37, 38], "indici": 22, "indigo": 38, "indirectli": [4, 16], "indiscrimin": [], "indispens": [4, 8, 37, 38], "individu": [1, 2, 3, 4, 5, 7, 12, 19, 22], "indoor": [37, 38], "induc": 4, "induct": 12, "industri": [0, 4, 8, 11, 19, 20, 23], "ineffect": 23, "ineffici": [4, 5, 7, 13, 22, 25], "inefficien": [37, 38], "inexact": [4, 5, 20], "inexpens": [4, 5], "inf": [11, 14, 32, 35], "infer": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 17, 20, 21, 22, 25, 38], "infer_retrieve_rerank": 38, "inferenc": 13, "inferior": [4, 5, 24], "inflow": 4, "influenc": [4, 13, 23, 37, 38], "influenti": [7, 11, 23], "inform": [0, 1, 2, 3, 6, 7, 10, 11, 12, 13, 16, 19, 20, 22, 25, 36, 37, 38], "infrastructur": [4, 13, 37, 38], "infrequ": [4, 5], "infti": [4, 5, 8, 11, 22, 24, 25], "ing": 4, "ingest": 38, "ingestion_gdr": 38, "ingestion_pipelin": 38, "ingrati": 4, "ingredi": 4, "inher": [4, 5, 20, 22], "iniit": 25, "init": 1, "init8": 38, "initi": [1, 3, 4, 5, 6, 7, 10, 11, 13, 16, 20, 22, 24, 25, 30, 36, 37, 38], "initializer_rang": [31, 33, 34], "initil": 23, "inject": [4, 20, 30, 36], "inmemori": 38, "inner": [1, 4, 5, 7, 11, 13], "innov": [0, 2, 4, 7, 19], "inpati": [37, 38], "inpatient_record": [37, 38], "input": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 38], "input_batch": [32, 33, 34, 35], "input_chunk": 35, "input_dtyp": [30, 31, 33, 34, 36], "input_embed": [32, 35], "input_fil": [37, 38], "input_id": [30, 31, 32, 33, 34, 35, 36], "input_idx": [32, 35], "input_layernorm": [30, 31, 33, 34, 36], "input_mask": 33, "input_tensor": [30, 36], "input_text": [32, 33, 34], "inputs_emb": [30, 31, 33, 34, 36], "insensit": [1, 21], "insert": [4, 5, 7, 10, 19], "insertadjacentel": 38, "insid": 12, "insight": [1, 3, 4, 19, 37, 38], "inspect": [37, 38], "inspir": [6, 17, 19, 20, 25], "inst": 23, "instabl": [1, 22, 23], "instal": [4, 37, 38], "instanc": [1, 4, 5, 11, 14, 20, 23, 37, 38], "instant": 38, "instead": [1, 4, 5, 7, 8, 12, 13, 14, 17, 19, 20, 22, 23, 25], "institut": [37, 38], "instruct": [3, 6, 19, 20, 21, 22, 25, 33, 34, 37, 38], "instructblip": 16, "instructgpt": [18, 22, 23], "instruction_data": [33, 34], "instruction_plus_input": [32, 33, 34], "instruction_text": [32, 33, 34], "instructiondataset": [32, 33, 34], "instructor": 38, "instrument": 38, "insturct": 20, "insuffici": [4, 5, 7, 20], "insur": [4, 37, 38], "int": [4, 5, 13, 30, 31, 32, 33, 34, 35, 36, 37, 38], "int16": 13, "int32": 13, "int4": 13, "int64": [30, 31, 33, 34, 36], "int8": 21, "int_": [4, 5], "intak": [37, 38], "intang": [37, 38], "integ": [1, 4, 5, 7, 11, 12, 13, 21], "integr": [2, 4, 5, 8, 17, 20, 23, 37, 38], "intel": [12, 38], "intellectu": 4, "intellig": [0, 1, 4, 5, 6, 7, 8, 38], "intend": [4, 7, 8, 11, 14, 22, 37, 38], "intens": [3, 4, 5, 13, 17, 20, 37, 38], "intensifi": 13, "intent": [3, 4, 5, 18, 20, 22, 23, 37, 38], "intention": 7, "intents": 20, "inter": [1, 7, 8, 11, 20, 22], "interact": [0, 1, 5, 11, 12, 16, 18, 19, 20, 23, 24, 38], "intercom": 38, "interconnect": [19, 20], "interconnected": 19, "interest": [4, 5, 6, 11, 20], "interf": 4, "interfac": [4, 16, 38], "interfer": 2, "interleaf": 19, "interleav": [4, 19], "intermedi": [1, 2, 4, 5, 11, 13, 18, 21, 24, 38], "intermediate_s": [30, 31, 33, 34, 36], "intermedid": 25, "intermitt": 19, "intern": [1, 3, 4, 5, 7, 11, 12, 13, 16, 19, 20, 21, 22, 25, 37, 38], "internet": [1, 4, 16, 37, 38], "interoper": [37, 38], "interplai": 0, "interpol": [18, 27], "interpolat": 1, "interpret": [1, 3, 4, 5, 7, 8, 18, 20, 22, 23, 24, 38], "intersect": 4, "interspeech": 9, "interspeech2010": 9, "interst": [4, 5], "intertwin": 36, "interv": [4, 6], "intervent": [37, 38], "intra": [1, 37, 38], "intract": [4, 8], "intric": [1, 22], "intricaci": 0, "intrins": [6, 20], "intro": 38, "introduc": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 24], "introduct": [11, 38], "introspect": 38, "introspective_agent_toxicity_reduct": 38, "intuit": [1, 3, 4, 5, 6, 8, 11, 13, 17, 23, 25], "intut": 20, "intutivi": 1, "inv": [30, 31, 33, 34, 36], "inv_freq": [30, 31, 33, 34, 36], "inv_freq_expand": [30, 31, 33, 34, 36], "invalid": [37, 38], "invalu": 0, "invari": 1, "invent": [3, 11, 20], "invers": [1, 4, 5, 8, 12, 25, 30, 36], "invert": [7, 20, 30, 36], "invest": [0, 4, 37, 38], "investig": [3, 4, 5, 6, 37, 38], "invit": 10, "invok": [1, 20], "involv": [1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 36], "invovl": 20, "io": [4, 13, 37, 38], "ioff": 1, "ion": [13, 20], "ionic": 38, "ionic_shop": 38, "iou": 12, "iowa": 4, "ip": 4, "ipad": 4, "ipex": 38, "ipex_llm": 38, "ipex_llm_gpu": 38, "iphon": 3, "ipo": [8, 22, 33], "ipykernel": 27, "ipykernel_60922": 27, "ipykernel_launch": 27, "ipynb": 38, "ipython": [37, 38], "ir": 29, "iran": 12, "irr": [37, 38], "irrelev": [4, 5, 7, 12, 16, 19, 20], "irrelv": 20, "irreplac": 20, "irrespect": [12, 25], "irrespons": 19, "irrit": [4, 5], "is15": 1, "is_avail": [32, 33, 34, 35], "is_caus": [30, 31, 33, 34, 36], "is_chat_model": [37, 38], "isca": 9, "isn": [4, 20, 37, 38], "isnext": 7, "isol": [2, 4], "isola": 5, "isr": [37, 38], "isrel": 19, "issn": [37, 38], "issu": [1, 2, 4, 5, 11, 12, 13, 19, 20, 21, 22, 25, 37, 38], "issup": 19, "issup\u548cisuse\u7b49": [], "ist": [10, 37, 38], "isus": 19, "italian": [4, 5, 37, 38], "itc": 16, "itch": 4, "item": [4, 5, 21, 22, 32, 33, 34, 35, 37, 38], "iter": [1, 2, 4, 5, 10, 13, 14, 16, 23, 25, 38], "itg": 16, "itlian": [4, 5], "itm": 16, "itrex": 38, "its": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 37, 38], "itself": [4, 5, 6, 7, 11, 13, 17, 21, 22, 36], "iv": [7, 10, 18, 22, 23], "ivf": [4, 5], "ivfadc": 4, "iwasawa": 18, "iyyer": 7, "izacard": 22, "j": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 22, 23, 24, 37, 38], "j_": [4, 5], "j_i": [4, 5], "j_n": [4, 5], "j_p": [4, 5], "jaap": 5, "jaccard": 4, "jack": 16, "jacki": [4, 5], "jackson": [22, 25], "jacob": [5, 7, 11, 22, 23, 25], "jade": 20, "jae": 16, "jaguar": 38, "jaguarindexdemo": 38, "jaim": 20, "jain": 20, "jakob": [5, 11], "jame": [1, 4, 22, 25], "jami": 5, "jan": [9, 22], "jang2021ultra": 4, "januari": [4, 5], "japan": 3, "japanes": 4, "jare": [1, 6, 8, 11, 25], "jargon": [20, 21], "jason": [4, 5, 12, 17, 18, 23], "jastrzebski": 23, "jauhri": 1, "jaundic": 4, "jauvin": 9, "java": 4, "javascript": 38, "jc": 5, "jdiq": 5, "jdjegou19": [4, 5], "je": 6, "jean": 9, "jeff": [5, 7, 12, 21, 22, 23], "jeffrei": [6, 8, 10, 11, 12, 22, 25], "jejun": [37, 38], "jelli": 4, "jennimaria": 5, "jerom": 5, "jerri": 25, "jgbm16": 12, "jheng": 5, "ji": [1, 2, 20, 25], "jia": [19, 20, 25], "jiafeng": 5, "jialin": 5, "jian": [1, 2, 5, 11, 25], "jianfeng": 5, "jiang": [1, 5, 7, 11, 13, 22, 25], "jianlin": 1, "jianmo": 20, "jianzhong": 2, "jiao": [5, 7], "jiaq": 20, "jiaqi": 2, "jiashi": 2, "jiawei": [2, 20], "jiaxuan": 22, "jiayang": 20, "jie": 23, "jimmi": [5, 20, 25], "jin": [2, 5, 22], "jina": 38, "jina_embed": 38, "jinaai": 38, "jinaai_embed": 38, "jinaai_rerank": 38, "jinarerank": 38, "jing": [5, 20], "jingang": 5, "jingchang": 2, "jingfei": [7, 11], "jingyang": 2, "jingyaogong": 26, "jinhao": [1, 25], "jinliu": 20, "jira": 38, "jiter": [37, 38], "jiwoo": 22, "jo": 4, "job": [4, 19], "joblib": [37, 38], "joe": 23, "john": [4, 13, 22, 25], "johnson": [4, 5, 7], "join": [8, 27, 36, 38], "joint": [4, 5, 7, 8, 9, 16, 23, 38], "jointli": [1, 4, 11, 16, 23], "jointqasummari": 38, "joke": 38, "joliett": 6, "jon": 5, "jonah": 21, "jonathan": [5, 17, 19], "jone": [4, 5, 11, 22], "jong": [1, 16], "joplin": 38, "jose": 20, "joseph": [5, 13, 20, 25], "joshi": [7, 11], "joshua": [1, 8, 19], "joulin": 12, "journal": [5, 7, 8, 9, 25], "journei": 0, "joydeep": 5, "jsdelivr": 38, "jsm": 1, "json": [32, 33, 34, 37, 38], "json_query_engin": 38, "jsonalayz": 38, "jsonalyz": 38, "jsonalyze_query_engin": 38, "jsonpatch": [37, 38], "jsonpoint": [37, 38], "jstor": 22, "judg": [4, 5, 38], "judgement": [4, 38], "judgment": [4, 19], "juic": 12, "jul": [25, 37, 38], "juli": [3, 4, 5], "julien": 7, "jump": 6, "jumpstart": 25, "jun": [1, 11, 25, 37, 38], "junaid": 5, "june": 20, "junji": [1, 2, 7, 25], "junlong": 2, "junnan": 16, "junxiao": 2, "junyi": [1, 25], "jurafski": 4, "jurisdict": [37, 38], "just": [1, 4, 5, 6, 7, 8, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 30, 36, 37, 38], "justif": [4, 20], "justifi": [4, 12], "jwl": 13, "jy": 7, "k": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "k_": [1, 2, 4, 5, 19], "k_1": [4, 5], "k_emb": [30, 31, 33, 34, 36], "k_i": 1, "k_n": 1, "k_proj": [30, 31, 33, 34, 36], "k_r": 2, "kadavath": 22, "kafka": 38, "kai": [1, 2, 5, 11, 12, 16, 23], "kaig": 2, "kaim": [5, 25], "kaiser": [5, 11], "kaltura": 38, "kaltura_esearch": 38, "kamp": 5, "kamyar": 5, "kang": 2, "kangxiang": 20, "kansa": [4, 5], "kaplan": [1, 6, 8, 11, 25], "karafi\u00e1t": 9, "karen": 4, "karkhani": 22, "karpukhin": 5, "karpukhin2020dens": 4, "karthik": [6, 8, 11], "kartikai": 7, "katarina": 22, "kate": 7, "katherin": [5, 10], "katz": 25, "kazakhstan": 12, "kb": [37, 38], "kb14": 25, "kd": [4, 5, 7], "kdb": 38, "kdbai": 38, "kdbai_advanced_rag_demo": 38, "keep": [1, 2, 4, 5, 8, 14, 16, 20, 23, 37, 38], "keepdim": [30, 31, 32, 33, 34, 35, 36], "keeper": 4, "keerthi": [37, 38], "kei": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "keikichi": 9, "keith": 20, "kelton": 22, "kelvin": [20, 23], "kenton": [5, 7, 11], "kentucki": [4, 5], "kept": [4, 5, 18, 36, 37, 38], "kernel": [1, 4, 7], "kernion": 22, "keskar": 10, "keskar2019ctrl": 14, "kevin": [7, 11, 23], "kexin": 2, "key_sequence_length": [30, 36], "key_stat": [30, 31, 33, 34, 36], "key_value_length": [30, 36], "keyboard": 4, "keyboardinterrupt": 34, "keyphras": 20, "keyvalu": 3, "keyword": [4, 5, 19, 20, 37, 38], "kg": [20, 38], "kg_index": [37, 38], "kg_node": [37, 38], "kg_rag_query_engin": [37, 38], "kg_retriev": [37, 38], "kgr": 18, "khalifa": [37, 38], "khamlichi": [37, 38], "khandelw": 7, "khashayar": 12, "khattab": [4, 5], "khennou": [37, 38], "khosravi": 12, "khudanpur": 9, "kia": 8, "kibela": 38, "kid": [], "kihyuk": 5, "kill": [4, 5], "kim": 16, "kind": [4, 7, 38], "kindli": 4, "king": [4, 17], "kingma": [4, 25], "kitten": 4, "kj": 1, "kl": [4, 7, 22], "klau": 7, "klimov": 22, "klist": [37, 38], "klz": 13, "kmh": 25, "kn": 38, "kneser": 8, "knew": [], "knn": 17, "knolwedg": 20, "know": [4, 6, 8, 13, 19, 20, 22, 24], "knowl": 4, "knowledg": [0, 2, 3, 6, 7, 11, 12, 17, 18, 23, 24, 25, 36, 37, 38], "knowledge_graph": 38, "knowledge_graph_query_engin": 38, "knowledge_graph_rag_query_engin": 38, "knowledgegraphindex": [37, 38], "knowledgpt": 20, "known": [4, 5, 7, 8, 11, 12, 13, 17, 20, 22, 23, 24], "knrm": 5, "kobayashi": 9, "koda": 38, "koda_retriev": 38, "kojima": 18, "kolesnikov": 11, "kong": 1, "konko": 38, "kor": 4, "korean": 1, "kouguzm": [4, 5], "kpr": [4, 5], "krikun": 7, "kristina": [5, 7, 11], "kuai": 2, "kuchaiev": 21, "kukich": 4, "kullback": [4, 5], "kumar": 5, "kun": [1, 25], "kundu": 22, "kurt": 5, "kusner": 7, "kuula": 20, "kuzu": 38, "kv": [30, 31, 33, 34, 36], "kv_store": 38, "kvstore": 38, "kw": [1, 11], "kw_i": 11, "kwanza": 12, "kwarg": [30, 36, 37, 38], "kwargsforcausallm": [30, 36], "kwiatkowski": 5, "kwin": 24, "kwok": [4, 5], "kwon": 13, "kwout": 24, "kwret": 24, "kyrola": 25, "kyunghyun": [5, 20], "kz20": [4, 5], "l": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36], "l2": [4, 5], "l2_normal": 16, "l_": [4, 5, 7, 13, 16, 22], "l_2": [4, 5], "l_n": 25, "l_q": [4, 13], "l_r": 4, "la": [1, 5], "lab": [29, 33], "label": [6, 7, 10, 11, 12, 16, 17, 20, 23, 24, 25, 27, 30, 33, 36, 38], "label_smooth": 33, "labelledbi": 38, "labelledevaluatordataset": 38, "labelledragdataset": 38, "labels": 27, "labor": 19, "laboratori": [37, 38], "lachaux": [1, 5, 22], "lack": [1, 3, 4, 5, 7, 8, 13, 18, 20, 22, 23, 25, 36, 37, 38], "lacroix": [1, 22], "lacuna": [37, 38], "ladi": 4, "lagrang": [8, 13], "lagrangian": 13, "lake": 38, "lambda": [1, 2, 4, 8, 13, 20, 22, 25], "lambda_": 4, "lambda_i": 8, "lambdaloss": 4, "lambdamart": [4, 5], "lambdarank": [4, 5], "lamda": 17, "lampl": [1, 7], "lan": [1, 7, 11], "lancedb": 38, "lancedbindexdemo": 38, "land": [4, 5], "landmark": [37, 38], "landscap": 0, "lang": 38, "langaug": [30, 31, 33, 34, 36], "langchain": [37, 38], "langchain_cor": [37, 38], "langchain_text_splitt": [37, 38], "langchainoutputparserdemo": 38, "langfus": 38, "langfusecallbackhandl": 38, "langfusemistralposthog": 38, "langl": [1, 4, 5, 22], "langsmith": [37, 38], "languag": [1, 2, 5, 12, 14, 17, 18, 19, 20, 22, 25, 29, 38], "languageunsupervis": [6, 8, 11], "languga": 25, "lanka": [37, 38], "lantern": 38, "lanternautoretriev": 38, "lanternindexdemo": 38, "laplac": 8, "laptop": [3, 4, 38], "larc21": [16, 23], "larg": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 30, 36, 37, 38], "large_language_model": 38, "larger": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 21, 22, 23, 25], "largest": [4, 6, 11, 21, 37, 38], "larnguag": 8, "laroussilh": 23, "larri": 5, "larson": [17, 19], "lasso": 4, "last": [1, 3, 4, 5, 6, 7, 10, 19, 22, 27, 30, 31, 33, 34, 36, 37, 38], "last_accessed_d": [37, 38], "last_hidden_st": [30, 36], "last_modified_d": [37, 38], "lat": 38, "late": [4, 5], "latenc": [1, 2, 4, 5, 19, 20, 23], "latent": [2, 3, 4, 5, 9, 12, 25], "later": [4, 5, 24], "latest": [1, 4, 5, 8], "lats_ag": 38, "latter": 4, "launch": 4, "laura": 5, "laurenc": 23, "lavaud": 1, "lavrenko2017relev": 4, "lavril": [1, 22], "law": [0, 2, 8, 17, 20, 22, 25, 37, 38], "lawyer": 4, "lax": 4, "layer": [2, 3, 4, 5, 6, 9, 10, 12, 13, 16, 17, 20, 21, 22, 23, 25], "layer_idx": [30, 31, 33, 34, 36], "layer_output": [30, 36], "layer_st": [30, 31, 33, 34, 36], "layernorm": [1, 7, 11, 30, 31, 32, 33, 34, 35, 36], "layerwis": 7, "layout": [4, 20, 21], "lb": 14, "lc": 4, "lc19": 7, "lcc": 4, "lccc": 4, "lcccc": 4, "lceil": 4, "lcg": [7, 11], "ldot": [1, 2, 3, 4, 5, 6, 7, 8, 12, 14, 19, 23, 25], "lds89": 13, "le": [1, 5, 7, 8, 17, 18, 23], "lead": [1, 2, 3, 4, 5, 11, 12, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 36], "leader": 6, "leak": [37, 38], "leakag": 16, "lean": 2, "leap": 0, "lear": 25, "learn": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 16, 19, 20, 21, 23, 29, 38], "learnabl": [1, 7, 16, 23, 30, 31, 33, 34, 36], "learner": [1, 6, 7, 8, 10, 11, 23], "learning_r": [32, 33, 34, 35], "learningcan": 4, "learnt": 4, "least": [1, 4, 5, 13, 17, 22, 37, 38], "leav": [4, 5, 20], "leben": 4, "lebensversicherungsgesellschaftsangestellt": 4, "lebr\u00f3n": 1, "lecong": 2, "lectur": [5, 8], "lecun": 13, "led": [0, 4, 5, 7, 23], "ledel": 5, "ledger": 4, "lee": [1, 5, 7, 10, 11, 14, 16, 17, 22, 23], "lee2020learn": 4, "lee2021phras": 4, "left": [1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 19, 20, 22, 23, 24, 25, 27, 38], "leftarrow": [5, 24, 25], "leftto": 4, "legaci": [37, 38], "legal": [25, 37, 38], "legal_data": [37, 38], "legend": 27, "legisl": [37, 38], "legitim": 22, "lei": 2, "leibler": [4, 5], "leik": 22, "leimao": 13, "lemma": 24, "lemmat": [4, 12], "lemon": 4, "len": [7, 27, 32, 33, 34, 35, 38], "length": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 20, 21, 22, 23, 27, 30, 32, 35, 36], "lengthi": [4, 5, 19, 20, 38], "lengyel": 1, "leo": 22, "leonardo": 19, "leq": [1, 4, 5, 8, 12, 13, 24], "leqslant": 2, "lesion": [37, 38], "less": [1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 18, 20, 22, 23, 37, 38], "lesson": 4, "lester": [16, 23], "let": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 18, 20, 22, 23, 24, 25, 33], "letc21": [4, 5], "letter": [1, 4], "level": [0, 2, 3, 6, 7, 8, 11, 12, 13, 17, 20, 22, 23, 24, 37, 38], "lever": 4, "leverag": [3, 4, 5, 7, 11, 13, 16, 19, 20, 21, 22, 23, 36, 37, 38], "levi": [5, 7, 10, 11, 12], "lewi": [1, 5, 7, 10, 11, 13], "lex": 4, "lexi": 4, "lexic": [3, 4, 5, 12, 20], "lexicon": 4, "leyi": 2, "lfloor": [1, 13], "lh17": 25, "li": [1, 2, 4, 5, 7, 10, 11, 12, 13, 16, 17, 20, 23, 25, 38], "liabil": [37, 38], "liang": [2, 5, 12, 20, 23], "liangjian": 1, "lianmin": 13, "lib": [27, 34, 37, 38], "liber": 4, "librari": [4, 5, 37, 38], "licens": [37, 38], "lie": [1, 6], "life": [4, 23], "lifeng": 7, "lift": [4, 38], "light": [2, 38], "lighter": 7, "lightn": [4, 5], "lightweight": [4, 5, 16, 19, 22], "liguist": 25, "like": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 37, 38], "likehood": 22, "likelihood": [1, 4, 5, 6, 7, 8, 12, 14, 17, 22, 25], "likert": 22, "likewis": 6, "lilac": 38, "lili": [5, 13], "lilianweng": 13, "lim_": [8, 24], "limit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 18, 20, 22, 23, 24, 25, 37, 38], "lin": [2, 4, 5, 11, 13, 20], "lin2021batch": 4, "lincoln": 4, "lindgren": 5, "lindorm": 38, "lindormdemo": 38, "line": [4, 5, 7, 20, 22, 27, 34, 36, 37, 38], "linear": [1, 3, 4, 5, 6, 7, 10, 11, 12, 16, 21, 25, 30, 31, 32, 33, 34, 35, 36, 38], "linearli": [1, 4, 5, 7, 9, 13, 16, 21, 30, 31, 33, 34, 36], "ling": 19, "lingl": 23, "lingpeng": 1, "lingual": [7, 25], "linguist": [1, 4, 5, 7, 8, 10, 12, 16, 23], "link": [4, 8, 12, 19, 20, 37, 38], "linkedin": [4, 38], "linli": 25, "linlin": 7, "linq": 5, "lior": 12, "lipani": 23, "lisa": 23, "lisp": 19, "list": [1, 5, 10, 14, 16, 19, 20, 27, 30, 31, 32, 33, 34, 35, 37, 38], "listen": 6, "listwis": [3, 4, 5], "lite": [7, 11], "litellm": 38, "liter": [4, 6], "literalai": 38, "literatur": [4, 22, 25, 37, 38], "lithophil": 4, "liti": 7, "litig": [37, 38], "litong": 2, "littl": [4, 5, 13, 25], "liu": [1, 2, 5, 7, 10, 11, 16, 17, 22, 23, 25], "liu2021pr": 4, "live": [4, 9, 19, 38], "liver": [4, 5], "liwei": [1, 11], "liyu": 2, "ljz20": [4, 5], "lkb20": 7, "ll": [4, 5, 7, 11, 13, 19, 23, 25], "ll21": 23, "llama": [1, 25, 29, 32, 35, 37, 38], "llama2": [22, 38], "llama3": [1, 38], "llama3_cookbook": 38, "llama3_cookbook_groq": 38, "llama3_cookbook_ollama_repl": 38, "llama7b": 13, "llama_2": 38, "llama_2_llama_cpp": 38, "llama_2_rap_battl": 38, "llama_api": 38, "llama_cloud": [37, 38], "llama_cloud_index": 38, "llama_cpp": 38, "llama_dataset": 38, "llama_dataset_metadata": 38, "llama_debug": 38, "llama_deploi": 38, "llama_extract": 38, "llama_guard_moder": 38, "llama_hub": 38, "llama_index": [37, 38], "llama_index_agent_openai": [37, 38], "llama_index_cli": [37, 38], "llama_index_cor": [37, 38], "llama_index_embeddings_openai": [37, 38], "llama_index_indices_managed_llama_cloud": [37, 38], "llama_index_legaci": [37, 38], "llama_index_llms_openai": [37, 38], "llama_index_multi_modal_llms_openai": [37, 38], "llama_index_program_openai": [37, 38], "llama_index_question_gen_openai": [37, 38], "llama_index_readers_fil": [37, 38], "llama_index_readers_llama_pars": [37, 38], "llama_pack": 38, "llama_pack_ollama": 38, "llama_pack_resum": 38, "llama_packs_exampl": 38, "llama_pars": [37, 38], "llamaattent": [30, 31, 33, 34, 36], "llamacloud": 38, "llamaconfig": [30, 31, 33, 34, 36], "llamacpp": 38, "llamadataset": 38, "llamadebughandl": 38, "llamadecoderlay": [30, 31, 33, 34, 36], "llamafil": 38, "llamaforcausallm": [30, 31, 33, 34, 36], "llamahub": 38, "llamaindex": 38, "llamaindext": 38, "llamalogobrowsertab": 38, "llamamlp": [30, 31, 33, 34, 36], "llamamodel": [30, 31, 33, 34, 36], "llamapack": 38, "llamapars": 38, "llamapretrainedmodel": [30, 36], "llamarmsnorm": [30, 31, 33, 34, 36], "llamarotaryembed": [30, 31, 33, 34, 36], "llamasquareblack": 38, "llava": 38, "llava_complet": 38, "llava_demo": 38, "llava_multi_modal_tesla_10q": 38, "llg": 10, "llion": [5, 11], "lll": 7, "lllr": 4, "llm": [2, 6, 11, 16, 17, 19, 37, 38], "llm_book": [], "llm_compil": 38, "llm_env": 26, "llm_judg": 38, "llm_predictor": 38, "llm_program": 38, "llm_question_gen": 38, "llm_rail": 38, "llm_rerank": 38, "llm_text_complet": 38, "llmlingua": 13, "llmrail": 38, "llmrerank": 38, "lloyd": [4, 5], "llsh23": 16, "llustrat": [3, 20], "llwl24": 16, "llxh22": 16, "llxl21": [4, 5], "lm": [4, 16, 18, 19, 21, 23, 38], "lm_head": [30, 31, 32, 33, 34, 35, 36], "lmformatenforc": 38, "lmformatenforcer_pydantic_program": 38, "lmformatenforcer_regular_express": 38, "lmstudio": 38, "ln": [1, 8, 12], "lny21": [4, 5], "lo": [3, 37, 38], "load": [1, 4, 5, 13, 21, 31, 32, 33, 34, 37, 38], "load_and_search": 38, "load_data": [37, 38], "load_index_from_storag": [37, 38], "load_medical_records_data": [37, 38], "load_state_dict": [31, 33, 34], "loader": 38, "loan": [], "local": [1, 4, 5, 11, 12, 16, 19, 20, 25, 38], "local_model": 38, "localai": 38, "localhost": [37, 38], "localstorag": 38, "locat": [3, 4, 5, 7, 9, 13, 20, 25, 37, 38], "log": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 16, 22, 23, 25, 33, 38], "log10": 27, "log_": [4, 5], "log_2": [4, 5], "log_softmax": 33, "logarithm": [4, 5], "logdiscount": 4, "logic": [1, 4, 5, 8, 9, 11, 17, 18, 20], "logist": [4, 12, 37, 38], "logit": [4, 5, 7, 12, 14, 16, 22, 30, 31, 32, 33, 34, 35, 36], "logo": 38, "logsigmoid": 33, "london": 3, "long": [0, 3, 4, 8, 9, 11, 13, 14, 22, 25, 30, 36, 37, 38], "long_context_reord": 38, "long_context_test": 38, "long_rag_pack": 38, "longcontextreord": 38, "longer": [1, 4, 5, 7, 8, 9, 11, 13, 14, 17, 22, 23], "longest": [32, 33, 34], "longllmlingua": 38, "longpr": 23, "longrag": 38, "longtensor": [30, 31, 33, 34, 36], "look": [4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 22], "lookup": [4, 5], "loop": 38, "loophol": [37, 38], "loos": [4, 5], "lopez": 25, "lose": [4, 12, 21, 22], "loshchilov": 25, "loss": [3, 6, 7, 8, 10, 11, 12, 13, 16, 20, 21, 25, 30, 32, 33, 34, 35, 36], "loss_funct": [30, 36], "loss_i": 16, "loss_kwarg": 33, "loss_mark": 33, "loss_mask": 33, "loss_t": 16, "lost": [4, 5, 10, 20], "lot": [4, 16, 20, 37, 38], "lott": 4, "lou": [16, 23], "loui": 5, "love": [4, 7, 12], "low": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 19, 20, 21, 22, 25, 38], "low_level": 38, "lower": [2, 4, 5, 7, 8, 12, 13, 14, 20, 21, 22, 23, 37, 38], "lower_level": 38, "lowercas": 8, "lowest": [14, 20], "loyal": 4, "lpg_index_guid": 38, "lr": [32, 33, 34, 35], "lsa": [4, 5, 12], "lstm": [4, 5, 7], "lt": 38, "ltr": [4, 38], "lty": 11, "lu": [1, 2, 5, 20, 22, 23], "luan": [4, 5, 6, 8, 10, 11, 20], "luan2021spars": 4, "luca": 11, "lucen": [4, 5], "lucil": 1, "lucki": 12, "luckiest": 12, "lukasz": 25, "luke": [7, 10, 11, 13, 22], "luk\u00e1": 9, "luo": [2, 23], "luong": 7, "luxuri": 24, "luyu": 5, "lvert": 24, "lwlq21": [4, 5], "ly": [4, 5], "lyft": 38, "lyl21": [4, 5], "lym": 23, "lyme": 4, "lysandr": 7, "lyu": 11, "lzy24": [16, 23], "l\u00e9lio": 1, "m": [1, 2, 3, 6, 7, 8, 10, 11, 12, 13, 19, 21, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "m12": 38, "m13": 38, "m14": 38, "m3": 38, "m365": 4, "m4": 38, "m9": 38, "m_": [4, 7, 12, 13, 21, 25], "m_1": 7, "m_k": 25, "m_m": 7, "m_t": 7, "ma": [1, 2, 4, 5, 7, 12, 20, 22], "ma2021pr": 4, "maarten": [18, 23], "mac": 12, "machel": 18, "macherei": 7, "machin": [1, 4, 5, 7, 8, 9, 10, 11, 12, 14, 16, 21, 22, 25], "machineri": 4, "macintosh": 12, "macrometa": 38, "macrometa_gdn": 38, "macrothal": 4, "maddi": 22, "made": [4, 5, 6, 8, 10, 14, 19, 20, 37, 38], "magazin": [], "magnitud": [1, 4, 13, 25], "mahal": 3, "maher": 4, "mai": [1, 3, 4, 5, 7, 13, 14, 18, 19, 20, 22, 23, 24, 25, 37, 38], "main": [2, 4, 5, 6, 20, 21, 32, 33, 34, 35, 36, 37, 38], "main__inn": 38, "mainli": [1, 2, 4, 5, 7, 13, 20, 21], "mainstream": [1, 13], "maintain": [1, 2, 4, 5, 7, 13, 20, 21, 37, 38], "maintainentc": 23, "mainten": [20, 23, 37, 38], "major": [1, 4, 5, 6, 7, 11, 12, 13, 16, 17, 37, 38], "majumd": 5, "make": [1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 36, 38], "make_com": 38, "makedemo": 38, "makedir": [37, 38], "makhzani": 4, "male": 4, "malkov": 5, "malonei": [37, 38], "malpractic": [37, 38], "mammal": [4, 5], "man": [5, 6, 7, 8, 12, 22, 37, 38], "manag": [0, 3, 4, 5, 7, 11, 13, 19, 20, 37, 38], "manage_retrieval_benchmark": 38, "mandar": [7, 11], "mandatori": [37, 38], "mangadex": 38, "mangoapp": 38, "mangoapps_guid": 38, "mani": [1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 17, 20, 21, 23, 24, 25, 37, 38], "manifest": [], "manifold": 4, "manisha": 5, "manlei": 22, "mann": [1, 6, 8, 11], "manner": [0, 4, 5, 7, 10, 19, 20, 24, 37, 38], "mantissa": 21, "manual": [4, 7, 16, 17, 20, 37, 38], "manual_se": [32, 33, 34, 35], "manufactur": [3, 23], "map": [1, 4, 5, 7, 8, 11, 12, 13, 20, 21, 23, 24, 38], "mappign": 23, "mar": [22, 37, 38], "mar94": 8, "marc": 5, "marcinkiewicz": 8, "margin": [4, 5, 17, 20, 22, 23, 38], "mari": [1, 5, 8, 22, 23], "mariadb": 38, "marineri": 22, "maritalk": 38, "marjan": 10, "mark": [1, 6, 7, 11, 25, 37, 38], "markdown": [20, 37, 38], "markdown_el": 38, "marker": [4, 5, 7, 37, 38], "market": [4, 20, 38], "marketwatch": 4, "markings10learn": 4, "markov": 8, "marku": 13, "marshmallow": [37, 38], "marten": 25, "martin": [4, 9], "martinet": 22, "marvin": 38, "marvinmetadataextractordemo": 38, "mask": [1, 4, 5, 10, 16, 21, 30, 32, 33, 34, 35, 36, 38], "mask_bool": [32, 35], "mask_fil": [], "mask_length": [30, 36], "masked_fil": [30, 32, 33, 34, 35, 36], "maskedmultiheadattent": 11, "mass": [4, 6, 8], "massiv": [0, 1, 4, 6, 7], "master": 21, "masteri": 20, "masterpiec": 18, "mastiff": 4, "match": [1, 6, 7, 8, 16, 17, 19, 20, 21, 23, 30, 31, 33, 34, 36, 37, 38], "matchmedia": 38, "matei": [5, 20], "matena": [5, 10], "materi": [20, 25, 37, 38], "math": [1, 12, 30, 31, 32, 33, 34, 35, 36], "mathbb": [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 22, 23, 24, 25], "mathbf": [1, 2, 4, 5, 6, 7, 10, 13, 14, 17, 19, 23, 25], "mathcal": [1, 2, 3, 4, 5, 6, 7, 8, 12, 14, 19, 22, 23, 24], "mathemat": [1, 4, 5, 18, 22, 23, 25], "mathemati": 22, "mathrm": [2, 5, 7, 8, 10, 13, 19, 22, 23, 25], "matmul": [30, 31, 33, 34, 36], "matplotlib": 27, "matric": [1, 3, 7, 9, 11, 12, 13, 23, 30, 31, 33, 34, 36], "matrix": [1, 4, 6, 7, 8, 10, 11, 12, 21, 23, 24, 25, 30, 36], "matryoshka": 38, "matsuo": 18, "matt": 7, "matter": [4, 5, 7, 25, 30, 36], "matthew": 7, "matthia": 11, "matthij": 5, "matur": 4, "max": [4, 5, 7, 11, 12, 13, 20, 22, 23, 24], "max_": [12, 13, 22, 24], "max_a": 24, "max_ae_": 24, "max_font_s": 27, "max_length": [32, 33, 34, 35], "max_position_embed": [30, 31, 33, 34, 36], "max_seq_len": [30, 31, 33, 34, 36], "max_seq_len_cach": [30, 31, 33, 34, 36], "max_triplets_per_chunk": [37, 38], "max_val": 13, "max_window_lay": [31, 33, 34], "maxdcg": 4, "maxheap": 4, "maxim": [0, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 22, 24], "maximum": [1, 4, 5, 8, 12, 13, 14, 24, 38], "maxsim": 4, "maxsimilar": [4, 5], "mayb": 4, "maynard": 4, "mb": [37, 38], "mbart": 6, "mbb": [37, 38], "mbox": 38, "mboxreaderdemo": 38, "mc": [4, 5], "mc19": [4, 5], "mccandlish": 25, "mccann": 10, "mccd13": 12, "mckinnon": 22, "mcrank": 4, "md": 38, "mdc17": [4, 5], "me": [7, 10, 18, 19, 20, 36], "mean": [2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36], "meaning": [4, 5, 8, 14, 20, 37, 38], "meaningless": 4, "meant": [4, 19], "meanwhil": [2, 3, 4, 5], "measur": [4, 5, 6, 11, 12, 20, 22], "mebert": 4, "mechan": [2, 4, 5, 7, 9, 11, 13, 16, 20, 23, 37, 38], "mechnism": 13, "med": [4, 16], "medal": 20, "medi": [37, 38], "media": [4, 12, 25, 38], "medic": [4, 17, 20, 37, 38], "medical_record": [37, 38], "medicin": [4, 17, 25, 37, 38], "medico": [37, 38], "medico_legal_data": [37, 38], "medium": [7, 25, 37, 38], "medium_s": 27, "medprompt": 17, "medqa": 17, "meet": [4, 5, 9, 14, 20, 23, 37, 38], "meetup": 4, "megatron": 21, "mei": 22, "melani": [1, 6, 8, 11], "melvin": 7, "mem0": 38, "mem0memori": 38, "member": 14, "memgraph": 38, "memo": 38, "memor": [3, 4, 5, 8], "memori": [1, 2, 4, 5, 7, 11, 12, 30, 36, 38], "memotec": 8, "meng": [2, 22, 23], "mengzhou": 22, "menopaus": 4, "mensch": 1, "mental": [37, 38], "mentez": 6, "mention": [4, 5, 7, 9, 18, 19, 20, 25, 36, 37, 38], "merg": [1, 4, 5, 16, 37, 38], "merit": [37, 38], "mesnil": 5, "mesomorph": 4, "mess": 4, "messag": [4, 36, 38], "message_consum": 38, "message_publish": 38, "message_queu": 38, "message_templ": [37, 38], "messagerol": [37, 38], "met": 25, "meta": [1, 4, 5, 19, 22, 38], "meta__inn": 38, "metadata": [4, 20, 22, 37, 38], "metadata_extract": 38, "metadata_replac": 38, "metadata_seper": [37, 38], "metadata_str": [37, 38], "metadata_templ": [37, 38], "metadataextraction_llmsurvei": 38, "metadataextractionsec": 38, "metadatareplacementdemo": 38, "metal": 38, "metalindexdemo": 38, "metaphon": 4, "metaphor": 38, "metat": 20, "method": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 20, 21, 22, 24, 30, 36, 38], "methodolog": 23, "methodologi": [4, 5, 25], "meticul": [37, 38], "metric": [0, 6, 20, 22, 38], "metzler": 5, "mha": [13, 21], "mi": 22, "miaojun": 2, "mice": 12, "michael": [4, 5, 10, 11, 14, 20, 21], "michiel": 1, "micikeviciu": 21, "microservic": 38, "microsoft": [1, 4, 5, 12, 19, 38], "microsoft_onedr": 38, "microsoft_outlook": 38, "microsoft_sharepoint": 38, "mid": [2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 22, 23, 25], "mid1": 11, "mid2": 11, "middl": [1, 4, 11, 20, 21, 23, 37, 38], "might": [1, 2, 4, 5, 7, 8, 12, 13, 19, 20, 22, 23], "migrain": 4, "mike": [1, 7, 10, 11, 13], "mikolov": [5, 8, 9, 12], "mikolovkbck10": 9, "mildew": 4, "mile": [4, 23], "milk": 7, "miller": [4, 22], "million": [1, 4, 5, 6, 8, 11, 12, 16, 20, 25], "millisecond": 4, "milton": 22, "milvu": 38, "milvushybridindexdemo": 38, "milvusindexdemo": 38, "milvusoperatorfunctiondemo": 38, "milvusread": 38, "milvusreaderdemo": 38, "mimetyp": [37, 38], "mimic": [4, 18, 22], "mimick": 7, "min": [1, 4, 5, 13, 23, 25, 30, 36, 38], "min_": [7, 13], "min_dtyp": [30, 36], "min_length": 14, "min_val": 13, "mind": 4, "minder": 11, "mine": [4, 5, 12, 20], "ming": [5, 7, 11, 20], "mingchuan": 2, "mingda": [7, 11], "minghua": 2, "minghui": 2, "mingm": 2, "minh": 7, "mini": [4, 5, 7, 16, 36, 38], "minibatch": [16, 21], "minigpt4": 38, "minim": [2, 4, 5, 6, 7, 8, 12, 22, 25, 29, 37, 38], "minimind": 26, "minimum": [4, 5, 11, 13, 20, 25, 37, 38], "minio": 38, "minor": 7, "mip": [4, 5], "mir": 5, "mirac": 23, "miracul": [], "mirhoseini": 22, "mirror": 4, "miscellan": 4, "misconcept": 20, "mishkin": [16, 22], "mishra": [17, 23], "mislead": [19, 20], "mismatch": [4, 5, 7, 25], "miss": [4, 5, 7, 12, 20, 37, 38], "mission": [37, 38], "missouri": [4, 5], "misspel": [4, 5], "mistak": [4, 5, 37, 38], "mistakenli": [4, 19], "mistral": 38, "mistral_ag": 38, "mistral_multi_mod": 38, "mistral_r": 38, "mistralai": 38, "mistralai_fine_tun": 38, "mistralr": 38, "mistyp": 4, "misunderstand": 4, "mit": [5, 8], "mit23": 22, "mitchel": 22, "mitig": [1, 2, 4, 5, 9, 11, 13, 14, 17, 20, 21, 22, 25, 37, 38], "mitra": 5, "mitra2016du": 4, "mix": [4, 5, 6, 7, 12, 13, 18, 20, 36], "mixedbread": 38, "mixedbread_rerank": 38, "mixedbreadai": 38, "mixedbreadai_rerank": 38, "mixedbreadairerank": 38, "mixtur": [0, 2, 16, 20, 23, 38], "mixture_of_ag": 38, "mkb": 9, "mkdoc": 38, "mkxs18": 10, "ml": [4, 37, 38], "mla": 2, "mlflow": 38, "mllm": 16, "mlm": [4, 7, 11], "mlp": [3, 4, 5, 16, 30, 31, 33, 34, 36], "mlp_bia": [30, 31, 33, 34, 36], "mlx": [8, 38], "mm": [4, 5], "mm_agent": 38, "mmlm": 7, "mmr": 20, "mna": 21, "mncc16": 5, "mnist": [4, 5], "mnli": [10, 13, 23], "mnt": [], "mobil": [3, 4, 37, 38], "moco": 5, "modal": [4, 5, 16, 20, 37, 38], "mode": [4, 22, 37, 38], "model": [14, 17, 18, 19, 25, 29, 37, 38], "model_config": [31, 32, 33, 34, 35], "model_nam": [31, 33, 34], "model_output": 33, "model_typ": [31, 33, 34], "modelscop": 38, "moder": [2, 38], "modern": [0, 1, 8, 11, 12, 13, 21], "modest": [4, 13], "modi": 19, "modif": [1, 4, 16, 20, 25], "modifi": [4, 5, 6, 8, 10, 11, 12, 20, 22], "modul": [1, 2, 3, 4, 5, 6, 13, 16, 20, 23, 24, 27, 30, 31, 32, 33, 34, 35, 36, 38], "module_guid": 38, "module_usag": 38, "modulelist": [30, 31, 33, 34, 36], "moe": 29, "moham": 10, "mohammad": 7, "mohit": 7, "mold": 4, "molossian": 4, "moment": [4, 10, 25], "momentum": [5, 21, 37, 38], "mon": 22, "mona": 23, "mondaydotcom": 38, "monei": [], "monetari": 12, "mongodb": 38, "mongodb_atlas_bm25_retriev": 38, "mongodb_retrieval_strategi": 38, "mongodbatlasvectorsearch": 38, "mongodbatlasvectorsearchragfirework": 38, "mongodbatlasvectorsearchragopenai": 38, "mongodemo": 38, "mongodocstoredemo": 38, "monitor": [2, 4, 20, 37, 38], "mono": 38, "monobert": [4, 5], "monobertarch": 4, "monolingu": [6, 7], "monolith": 22, "monont": 1, "monoton": [1, 4, 5, 25], "monounsatur": 4, "monster": 38, "monsterapi": 38, "mont": [4, 5], "montana": [4, 5], "month": [4, 5], "mood": 4, "mor": 25, "morbid": [37, 38], "more": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 36, 37, 38], "moreat": 4, "moreov": [3, 4, 5, 8, 11, 18, 19], "morocco": [37, 38], "morphem": 12, "morpholog": [4, 5, 12], "morron": 23, "mortal": [37, 38], "most": [1, 2, 4, 5, 6, 8, 11, 12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 27, 34, 37, 38], "mostafa": [5, 11, 23], "mostli": [4, 5, 8, 14, 23, 37, 38], "mother": 19, "motiv": [6, 7, 10, 11, 13, 16, 18, 25], "motorist": [4, 5], "mou": 5, "mountain": 3, "mous": 12, "move": [4, 13, 22, 24, 25], "movement": [4, 25], "movi": [4, 5, 6, 7, 20, 36], "mr": 8, "mrpc": 13, "mrr": [5, 20], "msc": [4, 5, 12], "mschutze99": 8, "mse": [4, 7], "msmarco": [4, 5, 27], "mt": 38, "mt_bench_human_judg": 38, "mt_bench_single_grad": 38, "mtp": [], "mu": [1, 4, 5, 24, 25], "mu_": 4, "much": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 38], "multi": [2, 3, 7, 10, 11, 12, 13, 16, 17, 18, 19, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "multi_doc_auto_retriev": 38, "multi_doc_together_hybrid": 38, "multi_document_ag": 38, "multi_mod": 38, "multi_modal_llm": 38, "multi_modal_pydant": 38, "multi_modal_rag_evalu": 38, "multi_modal_rag_nom": 38, "multi_modal_rag_system": 38, "multi_modal_retriev": 38, "multi_modal_video_rag": 38, "multi_modal_videorag_videodb": 38, "multi_step": 38, "multi_step_query_engin": 38, "multi_strategy_workflow": 38, "multi_ten": 38, "multi_tenancy_rag": 38, "multiarith": 18, "multiclass": 4, "multicolumn": 4, "multidict": [37, 38], "multidoc": 38, "multidoc_autoretriev": 38, "multihead": [1, 21, 23], "multiheadattent": [7, 11, 32, 35], "multihop": 3, "multilingu": [1, 4, 5, 25], "multimedia": [4, 12], "multimod": [16, 38], "multinomi": 4, "multion": 38, "multipl": [1, 2, 3, 5, 6, 7, 10, 11, 12, 16, 17, 19, 20, 21, 23, 38], "multipli": [1, 2, 4, 5, 8, 9, 11, 13, 14, 21, 25], "multiprocessor": 13, "multirow": 4, "multistageretrievalrankingbert": 4, "multistep": 38, "multitask": [6, 8, 10, 11, 12, 23], "multivari": 5, "murtadha": 1, "muscl": [4, 5], "music": 4, "must": [4, 5, 7, 16, 20, 21, 22, 37, 38], "mutual": [4, 12], "mxc24": 22, "my": [10, 18, 19, 20, 36], "my18": [4, 5], "myaeng": 4, "myle": [7, 11], "mymag": 38, "mypi": [37, 38], "mypy_extens": [37, 38], "myscal": 38, "myscaleindexdemo": 38, "myscalereaderdemo": 38, "mysteri": [], "m\u00f6chte": 11, "n": [1, 2, 6, 7, 9, 11, 12, 13, 14, 16, 18, 19, 22, 23, 24, 25, 26, 32, 33, 34, 36, 37, 38], "n1": [11, 37, 38], "n10": [37, 38], "n12": [37, 38], "n2": [11, 37, 38], "n45": [37, 38], "n45medic": [37, 38], "n529": [37, 38], "nOT": [37, 38], "n_": [1, 4, 5, 7, 8, 12], "n_d": 21, "n_pair_loss": 4, "n_q": [4, 5], "n_r": 2, "n_rep": [30, 31, 33, 34, 36], "n_t": [4, 5], "na": [4, 37, 38], "nabbrevi": [37, 38], "nabh": [37, 38], "nabil": [37, 38], "nabl": [37, 38], "nabla": 25, "nabla_": [22, 25], "naccess": [37, 38], "naccount": [37, 38], "nadapt": [37, 38], "nadav": 5, "nadopt": [37, 38], "nadvanc": [37, 38], "nag": [37, 38], "nagel": 13, "nagement": [37, 38], "nahb": 8, "naidu": 22, "naiv": [5, 12, 19, 21], "najork": 5, "nakamura": 9, "nalisnick": 5, "nall": [37, 38], "nalli": 4, "nalwai": [37, 38], "naman": [7, 10, 11, 20, 22], "name": [1, 3, 4, 5, 7, 8, 11, 16, 19, 20, 22, 25, 27, 37, 38], "nameerror": 27, "namongst": [37, 38], "nan": [7, 21, 23, 37, 38], "nanalog": [37, 38], "nanc": [37, 38], "nand": [37, 38], "nandroid": [37, 38], "nanosecond": 4, "nanswer": [37, 38], "napr": [37, 38], "narang": [5, 10, 17, 21, 23], "narasimhan": [6, 8, 11], "nare": [37, 38], "narea": [37, 38], "narrow": [4, 5, 7, 14, 22, 25], "nassess": [37, 38], "nasti": 4, "nation": [4, 12, 37, 38], "nativ": 38, "natur": [0, 1, 7, 8, 9, 10, 11, 12, 14, 16, 18, 20, 22, 23, 36, 37, 38], "natura": 6, "naudit": [37, 38], "nausea": 4, "nav": 38, "nav__button": 38, "nav__contain": 38, "nav__icon": 38, "nav__item": 38, "nav__link": 38, "nav__list": 38, "nav__titl": 38, "nav__toggl": 38, "navig": [0, 5, 20, 24, 38], "na\u00efv": 4, "nb": 38, "nba": [4, 5], "nbe": [37, 38], "nbecom": [37, 38], "nbesid": [37, 38], "nbetween": [37, 38], "nbsp": [4, 5], "nc19": [4, 5], "ncabl": [37, 38], "ncal": [37, 38], "ncare": [37, 38], "ncasualti": [37, 38], "ncate": [37, 38], "nccl": 21, "nce": 12, "nchanc": [37, 38], "nchina": [37, 38], "nci": [37, 38], "nclinic": [37, 38], "nclinicam": [37, 38], "ncome": [37, 38], "ncommon": [37, 38], "nconnect": [37, 38], "nconsid": [37, 38], "ncours": [37, 38], "ncqa": [37, 38], "ncreatico": [37, 38], "ncredit": [37, 38], "ncumbersom": [37, 38], "ncurrent": [37, 38], "ndaili": [37, 38], "ndard": [37, 38], "ndata": [37, 38], "ndcg": 20, "ndeath": [37, 38], "ndepart": [37, 38], "ndestroi": [37, 38], "ndevelop": [37, 38], "ndigit": [37, 38], "ndirect": [37, 38], "ndischarg": [37, 38], "ndischargeemerg": [37, 38], "ndischargemor": [37, 38], "ndocument": [37, 38], "ndoi": [37, 38], "ne": 6, "neach": [37, 38], "nearbi": [4, 5, 11, 12], "nearest": [12, 13], "nearli": [4, 5, 12, 23], "neas": [37, 38], "nebula": 38, "nebulagraph": 38, "nebulagraph_query_engin": 38, "necess": 20, "necessari": [1, 3, 4, 5, 8, 13, 14, 17, 19, 21, 25, 30, 31, 33, 34, 36, 37, 38], "necessarili": [4, 5, 14], "necessarymeet": 4, "necessit": 20, "need": [0, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "neelakantan": [1, 6, 8, 11], "neg": [1, 3, 7, 8, 14, 16, 18, 20, 22, 25, 36], "negat": 4, "negativesamplingstrategi": 4, "neh": [37, 38], "nei": 8, "neighbor": 12, "neil": 23, "neither": [10, 20, 37, 38], "nelectron": [37, 38], "nemr": [37, 38], "nenabl": [37, 38], "nendless": 36, "neo4j": [37, 38], "neo4j_metadata_filt": 38, "neo4j_query_engin": 38, "neo4jvector": 38, "neo4jvectordemo": 38, "neptun": 38, "neq": [4, 5, 12, 13, 23], "ner": [4, 37, 38], "ner_pii": 38, "neri": [37, 38], "nership": [37, 38], "nespeci": [37, 38], "nest": [20, 37, 38], "nest_asyncio": [37, 38], "net": [4, 21, 38], "nethic": [37, 38], "netowk": 9, "networ": 12, "network": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 16, 20, 21, 25, 30, 31, 32, 33, 34, 35, 38], "networkx": [37, 38], "neubig": 7, "neumann": 7, "neural": [0, 1, 2, 5, 7, 8, 11, 12, 14, 16, 21, 22, 25, 29], "neurologist": 4, "neuron": [2, 4, 5], "neutral": [7, 10, 18, 36], "neutrino": 38, "nevada": [4, 5], "nevalu": [37, 38], "neven": [37, 38], "never": [4, 5, 19, 37, 38], "nevertheless": [4, 22], "new": [0, 1, 3, 4, 5, 7, 8, 10, 11, 13, 14, 16, 18, 19, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "newest": 4, "newli": [10, 23], "newlin": 8, "newman": 19, "newsi": 4, "nexcel": [37, 38], "nexclud": [37, 38], "nexecut": [37, 38], "nexpect": [37, 38], "next": [1, 4, 6, 8, 9, 11, 13, 14, 19, 20, 21, 22, 23, 24, 25, 38], "nextrapol": [37, 38], "nfig": [37, 38], "nfinanci": [37, 38], "nfollow": [37, 38], "nfor": [37, 38], "nform": [37, 38], "nformat": [1, 6, 8, 11, 37, 38], "nformul": [37, 38], "nfour": [37, 38], "nfrom": [37, 38], "ngentli": [37, 38], "ngiven": [37, 38], "ngo": [37, 38], "ngood": [37, 38], "ngram": 4, "ngroup": [37, 38], "ngrow": [37, 38], "nguyen": 5, "nha": [37, 38], "nhealth": [37, 38], "nheavi": [37, 38], "nhi": [37, 38], "nhistor": [37, 38], "nhospit": [37, 38], "nhowev": [37, 38], "ni": [2, 20, 37, 38], "nice": 1, "nichola": [17, 25], "nick": [1, 5, 6, 8, 11], "nicolo": 17, "nidentifi": [37, 38], "nie": [1, 2, 5, 25], "nient": [37, 38], "niki": [5, 11], "nile": 38, "nilevectorstor": 38, "nim": 38, "nimag": [37, 38], "nimport": [37, 38], "nimprov": [37, 38], "nin": [37, 38], "ninadequ": [37, 38], "ninclud": [37, 38], "nincom": [37, 38], "nincreas": [37, 38], "nindia": [37, 38], "nindic": [37, 38], "nindirectli": [37, 38], "nine": 23, "ninfluenc": [37, 38], "ninform": [37, 38], "ning": [2, 37, 38], "niniti": [37, 38], "ninpati": [37, 38], "nintern": [37, 38], "ninvestig": [37, 38], "nip": 5, "niqu": 4, "nirm": 4, "nisan": 22, "nit": [37, 38], "niti": [37, 38], "nitish": 10, "nitrat": 4, "nixon": 4, "nj": 11, "nl": 38, "nl_sql_tabl": 38, "nlayer": 36, "nlegal": [37, 38], "nlegibl": [37, 38], "nlegibli": [37, 38], "nlg": 11, "nli": 23, "nlp": [0, 1, 4, 5, 6, 7, 8, 10, 11, 12, 20, 23, 37, 38], "nltk": [4, 37, 38], "nlu": [11, 14], "nlvr2": 16, "nlz": 17, "nm": 11, "nmai": [37, 38], "nmaintain": [37, 38], "nmana": [37, 38], "nmandat": [37, 38], "nmateri": [37, 38], "nmaterialsclin": [37, 38], "nmedic": [37, 38], "nmedico": [37, 38], "nmember": [37, 38], "nmendou": [37, 38], "nminimum": [37, 38], "nmodel": [37, 38], "nmore": [37, 38], "nmost": [37, 38], "nn": [4, 5, 30, 31, 32, 33, 34, 35, 36, 38], "nnation": [37, 38], "nncoder": [], "nnear": [37, 38], "nnecessarili": [37, 38], "nness": [37, 38], "nnever": [37, 38], "nnew": [37, 38], "nnific": [37, 38], "nnosi": [37, 38], "nnot": [37, 38], "nnurs": [37, 38], "no_grad": [30, 31, 33, 34, 36], "noah": [1, 16, 22, 23], "noam": [1, 2, 5, 10, 11], "node": [2, 4, 19, 20, 21, 37, 38], "node_label_map": [37, 38], "node_pars": [37, 38], "node_parser_semantic_chunk": 38, "node_postprocessor": 38, "nof": [37, 38], "nogueira": [5, 20], "nogueira2020docu": 4, "nois": [1, 4, 5, 7, 10, 16, 20], "noisi": [4, 5, 10, 16, 20, 22], "nomic": 38, "nomin": 8, "non": [1, 3, 7, 8, 11, 12, 13, 14, 19, 20, 23, 25, 37, 38], "nonc": [37, 38], "noncommerci": 4, "none": [4, 5, 27, 30, 31, 33, 34, 36, 37, 38], "nonetheless": 4, "nonexecut": 8, "nonlinear": [7, 11, 13, 23], "nonneg": 4, "nonperform": 7, "nonrelev": [4, 5], "nonsens": 18, "nonsmooth": 1, "nonzero": [2, 4], "noordhui": 25, "nopd": [37, 38], "nopen": [37, 38], "noper": [37, 38], "nor": [37, 38], "nordli": 4, "norganis": [37, 38], "nori": 17, "norigin": [37, 38], "norm": [4, 32, 35], "norm1": [32, 35], "norm2": [32, 35], "norm_x": [32, 35], "normal": [2, 6, 7, 8, 11, 12, 13, 19, 20, 21, 22, 23, 27, 30, 31, 33, 34, 36, 37, 38], "normalis": 4, "norouzi": 7, "north": [4, 5, 37, 38], "norvig": 4, "norwai": 12, "notabl": [4, 7, 11, 12, 13, 23, 24], "notat": [4, 14, 21, 22, 23], "notdiamond": 38, "note": [1, 2, 7, 8, 9, 10, 11, 12, 13, 17, 20, 21, 22, 24, 25, 30, 31, 33, 34, 36, 37, 38], "notebook": 38, "noth": [9, 18, 30, 36], "notic": [4, 5, 6, 37, 38], "notin": [4, 13], "notion": [4, 38], "notiondemo": 38, "notnext": 7, "notsotini": 4, "notwithstand": 4, "nougat": 38, "nougat_ocr": 38, "noun": [4, 5, 8, 12], "nout": [37, 38], "noutpati": [37, 38], "nov": 8, "novel": [0, 1, 2, 4, 6, 7, 11], "novelti": 20, "novic": 4, "now": [1, 4, 5, 6, 8, 11, 12, 13, 14, 18, 19, 20, 21, 24, 25, 37, 38], "nowadai": [4, 5, 20], "nown": [37, 38], "np": [4, 16, 27], "npairloss": 4, "npakistan": [37, 38], "npaper": [37, 38], "nparamed": [37, 38], "npatient": [37, 38], "npersonnel": [37, 38], "nphysic": [37, 38], "npire": [37, 38], "npm": 38, "npmc6220686": [37, 38], "npmc6442402": [37, 38], "npmj": 38, "npoint": [37, 38], "npopular": [37, 38], "npost": [37, 38], "npower": [37, 38], "npre": [37, 38], "npredict": [37, 38], "npresent": [37, 38], "nprocess": [37, 38], "nproduct": [37, 38], "nprofession": [37, 38], "nprogramm": [37, 38], "nprogress": [37, 38], "nproport": [37, 38], "npublic": [37, 38], "nqualiti": [37, 38], "nqueri": [37, 38], "nr": [4, 5], "nreal": [37, 38], "nrecommend": [37, 38], "nrecord": [37, 38], "nreduc": [37, 38], "nrefer": [37, 38], "nreferencescons": [37, 38], "nrefin": [37, 38], "nreflect": [37, 38], "nregard": [37, 38], "nregion": [37, 38], "nregul": [37, 38], "nreiter": [37, 38], "nrelat": [37, 38], "nrequir": [37, 38], "nresearch": [37, 38], "nresourc": [37, 38], "nrespons": [37, 38], "nreview": [37, 38], "nright": [37, 38], "nrm": 4, "nrr": 4, "nscan": [37, 38], "nshort": [37, 38], "nsi": [37, 38], "nsign": [37, 38], "nsn18": [4, 5], "nsome": [37, 38], "nsp": 11, "nspecimen": [37, 38], "nspectiv": [37, 38], "nstand": [37, 38], "nstatist": [37, 38], "nstatutori": [37, 38], "nstorag": [37, 38], "nstore": [37, 38], "nsuch": [37, 38], "nsultat": [37, 38], "nsuper": [37, 38], "nsurger": [37, 38], "nsystem": [37, 38], "ntain": [37, 38], "ntal": [37, 38], "ntechnologi": [37, 38], "ntem": [37, 38], "nternat": [1, 11, 16], "nthan": [37, 38], "nthat": [37, 38], "nthe": [37, 38], "nthei": [37, 38], "ntheir": [37, 38], "nthere": [37, 38], "nthi": [37, 38], "nthose": [37, 38], "ntice": [37, 38], "ntive": [37, 38], "nto": [37, 38], "ntransfer": [37, 38], "ntranspar": [37, 38], "ntreatment": [37, 38], "ntronic": [37, 38], "nuanc": [1, 4, 11, 20, 25], "nucleu": [4, 5], "nudg": 38, "num": 2, "num_attention_head": [30, 31, 33, 34, 36], "num_epoch": [32, 33, 34, 35], "num_head": [30, 31, 32, 33, 34, 35, 36], "num_hidden_lay": [30, 31, 33, 34, 36], "num_key_value_group": [30, 31, 33, 34, 36], "num_key_value_head": [30, 31, 33, 34, 36], "num_lay": [32, 35], "num_logits_to_keep": [30, 36], "num_output": [37, 38], "num_token": [32, 35], "num_work": [32, 33, 34, 35], "number": [0, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 17, 18, 20, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "numel": [32, 33, 34, 35], "numer": [3, 4, 5, 8, 12, 13, 20, 22, 30, 31, 33, 34, 36], "numpi": [27, 37, 38], "numref": 12, "nundi": [37, 38], "nupdat": [37, 38], "nupload": [37, 38], "nurs": [37, 38], "nuse": [37, 38], "nut": 4, "nutil": [37, 38], "nutrient": 4, "nutrit": [4, 38], "nv": [], "nvalu": [37, 38], "nvascular": [37, 38], "nvice": [37, 38], "nvide": [37, 38], "nvidia": [3, 13, 21, 38], "nvidia_ag": 38, "nvidia_nim": 38, "nvidia_output_pars": 38, "nvidia_rerank": 38, "nvidia_sub_question_query_engin": 38, "nvidia_tensorrt": 38, "nvidia_text_complet": 38, "nvidia_triton": 38, "nvidiarerank": 38, "nvirus": [37, 38], "nw": [37, 38], "nward": [37, 38], "nware": [37, 38], "nwe": [4, 37, 38], "nwell": [37, 38], "nwere": [37, 38], "nwhen": [37, 38], "nwhere": [37, 38], "nwhich": [37, 38], "nwide": [37, 38], "nwith": [37, 38], "nwjo": [37, 38], "nword": [37, 38], "nworkforc": [37, 38], "nycl19": [4, 5], "nylc19": [4, 5, 20], "nzg": [4, 5], "o": [1, 3, 4, 5, 7, 8, 11, 12, 13, 14, 21, 23, 32, 33, 34, 35, 36, 37, 38], "o_": [4, 5, 7], "o_1": 11, "o_bia": [31, 33, 34], "o_m": 11, "o_n": 11, "o_p": 11, "o_proj": [30, 31, 33, 34, 36], "oat": 4, "object": [2, 6, 7, 11, 12, 13, 16, 19, 22, 23, 25, 37, 38], "object_index": 38, "objectbox": 38, "objectboxindexdemo": 38, "observ": [4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 23, 24, 25, 38], "observatori": [37, 38], "obsidian": 38, "obsidianreaderdemo": 38, "obsolet": [4, 19, 20, 24], "obtain": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 20, 21, 22, 24, 30, 31, 33, 34, 36, 37, 38], "obviou": [4, 16, 19], "obvious": 8, "oc": 4, "occasion": 4, "occup": 4, "occupi": [4, 5, 13], "occur": [4, 5, 6, 7, 8, 12, 13, 20], "occurr": [4, 5, 8, 9, 12, 20], "oceanbas": 38, "oceanbasevectorstor": 38, "oci": 38, "oci_genai": 38, "ocr": [16, 20, 38], "octoai": 38, "odd": [1, 4, 11, 22], "odot": [4, 25], "ofdistribut": 22, "ofelia": 7, "off": [2, 4, 5, 14, 19, 20, 23, 27, 38], "offer": [2, 4, 5, 6, 7, 8, 13, 16, 18, 20, 21, 23, 24, 25, 37, 38], "offic": [4, 8, 37, 38], "offici": [4, 5], "offlin": [5, 20, 22], "offset": [1, 4, 5, 7, 10, 13], "ofir": [1, 12], "often": [0, 1, 4, 5, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 37, 38], "ofth": [4, 5], "ofword": 4, "oil": [4, 23], "ok": 4, "okai": 18, "okapi": [4, 5], "oklahoma": [4, 5], "olatunji": 21, "old": [8, 19], "older": 4, "oldest": 4, "oleg": 22, "oleksii": 21, "olga": 5, "oliveira": 25, "olivia": 5, "ollama": 38, "ollama_cookbook": 38, "ollama_embed": 38, "ollama_gemma": 38, "ollama_query_engin": 38, "olp": [37, 38], "olymp": 20, "olympu": 22, "omar": 5, "omegaconf": [31, 32, 33, 34, 35], "omer": [5, 7, 10, 11, 12], "omit": [1, 4, 11], "onc": [4, 5, 25, 37, 38], "ondemand": 38, "ondemand_load": 38, "ondemandloadertool": 38, "one": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 30, 31, 33, 34, 35, 36, 37, 38], "onedr": 38, "oner": 4, "ones": [0, 4, 5, 8, 12, 19, 20, 22, 30, 31, 32, 33, 34, 35, 36, 37, 38], "onfer": [1, 11, 16], "ongo": [4, 5, 25, 37, 38], "onli": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 20, 21, 23, 25, 30, 31, 33, 34, 36, 37, 38], "onlin": [16, 19, 20, 22, 25], "onogo": 25, "onset": [4, 37, 38], "onto": [4, 12, 23, 37, 38], "onu": [37, 38], "oov": [4, 5, 12], "op": [37, 38], "open": [0, 1, 6, 8, 20, 22, 23, 25, 27, 32, 33, 34, 35, 38], "openai": [0, 1, 6, 8, 10, 11, 22, 36, 37, 38], "openai_ag": 38, "openai_agent_context_retriev": 38, "openai_agent_lengthy_tool": 38, "openai_agent_parallel_function_cal": 38, "openai_agent_query_cookbook": 38, "openai_agent_query_plan": 38, "openai_agent_retriev": 38, "openai_agent_tool_call_pars": 38, "openai_agent_with_query_engin": 38, "openai_api_kei": [36, 37, 38], "openai_assistant_ag": 38, "openai_assistant_query_cookbook": 38, "openai_fine_tun": 38, "openai_fine_tuning_funct": 38, "openai_forced_function_cal": 38, "openai_json_vs_function_cal": 38, "openai_legaci": 38, "openai_lik": 38, "openai_multi_mod": 38, "openai_pydantic_program": 38, "openai_retrieval_benchmark": 38, "openai_sub_quest": 38, "openaiembed": [37, 38], "openalex": 38, "openapi": 38, "openbookqa": 6, "opend": 38, "openehr": [37, 38], "openinfer": 38, "openinferencecallback": 38, "openllm": 38, "openllmetri": 38, "openqa": [4, 5], "openrout": 38, "opensearch": 38, "opensearchdemo": 38, "openvino": 38, "openvino_multimod": 38, "openvino_rerank": 38, "oper": [1, 2, 3, 4, 5, 7, 9, 11, 13, 19, 20, 24, 25, 30, 31, 33, 34, 36, 37, 38], "operative_not": [37, 38], "operatornam": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 20, 22, 23, 25, 30, 31, 33, 34, 36], "opik": 38, "opikcallback": 38, "opinion": 4, "opportun": [2, 9, 37, 38], "opportunti": 20, "oppos": [1, 4, 8], "opposit": [4, 12, 20], "opt": [13, 16], "optic": [8, 20], "optim": [0, 1, 2, 4, 5, 7, 9, 10, 11, 13, 14, 16, 22, 23, 24, 32, 33, 34, 35, 38], "optimis": 22, "optimizerdemo": 38, "optimum": 38, "optimum_intel": 38, "optimumintelllm": 38, "option": [4, 5, 8, 9, 14, 17, 25, 30, 31, 32, 33, 34, 35, 36, 38], "oracl": 38, "oracleai": 38, "oracleai_demo": 38, "oracledb": 38, "oral": [37, 38], "orallamav": 38, "orang": [4, 17], "orchestr": 38, "order": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 20, 25, 30, 31, 33, 34, 36, 37, 38], "ordinari": [4, 7], "oreget": 4, "oreilly_course_cookbook": 38, "org": [1, 2, 4, 5, 7, 8, 11, 12, 13, 17, 18, 21, 22, 23, 30, 31, 33, 34, 36, 37, 38], "organ": [4, 5, 8, 11, 13, 19, 20, 37, 38], "orhan": [7, 23], "ori": 5, "orient": 20, "orig": [32, 35], "origin": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 37, 38], "original_inv_freq": [30, 31, 33, 34, 36], "original_max_seq_len": [30, 31, 33, 34, 36], "oriol": [5, 7], "orjson": [37, 38], "orthogon": 4, "oslo": 12, "oss_ingestion_retriev": 38, "ot": [4, 5, 37, 38], "other": [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 30, 36, 37, 38], "otherwis": [2, 4, 5, 7, 8, 13, 37, 38], "otim": [1, 13, 30, 31, 33, 34, 36], "ott": [7, 11], "otuput": 11, "ou": [2, 11, 12], "our": [0, 2, 4, 5, 6, 7, 8, 10, 13, 18, 20, 22, 24, 25, 37, 38], "ournal": [2, 10], "out": [3, 4, 5, 6, 7, 10, 11, 12, 13, 16, 17, 19, 20, 21, 22, 24, 34, 37, 38], "out_vec": [32, 35], "outbound": 4, "outcom": [19, 20, 21, 22], "outcompet": 17, "outdat": 20, "outer": 13, "outlier": 13, "outlin": [4, 22], "outlook": 38, "outnumb": [4, 5], "outpati": [37, 38], "outpatient_record": [37, 38], "outperform": [0, 4, 6, 7, 12, 22], "output": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38], "output_attent": [30, 36], "output_hidden_st": [30, 36], "output_pars": [37, 38], "outsid": [13, 22], "ouyang": 22, "over": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 19, 20, 23, 25, 30, 31, 33, 34, 36, 37, 38], "overal": [1, 2, 5, 7, 12, 13, 14, 18, 19, 20, 21, 36, 37, 38], "overbear": 4, "overcom": [1, 11, 12, 13, 21, 22], "overestim": 8, "overfit": [7, 8, 11, 22, 23, 25], "overflow": [2, 21], "overgener": 22, "overhead": [1, 4, 5, 13, 30, 31, 33, 34, 36], "overlai": 38, "overlap": [3, 4, 5, 20], "overli": 4, "overlin": 4, "overload": [2, 4], "overoptim": 22, "oversight": [37, 38], "overst": 0, "overview": [7, 19, 20, 37, 38], "overwijk": 5, "owj": 22, "own": [1, 4, 5, 11, 13, 19, 20, 25, 37, 38], "owner": 4, "ownership": [37, 38], "p": [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 17, 18, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "p9124": [37, 38], "p_": [1, 2, 4, 5, 7, 8, 12, 13, 14, 21, 22, 23, 25], "p_0": 14, "p_1": 23, "p_2": 23, "p_i": [2, 4, 14], "p_j": [2, 4], "p_k": 23, "p_l": 23, "p_n": 12, "p_t": 4, "p_v": 23, "p_x": 13, "pa": [6, 7, 37, 38], "pack": [4, 38], "packag": [4, 27, 34, 37, 38], "pact": 4, "pad": [4, 5, 7, 8, 11, 30, 32, 33, 34, 36], "pad_token_id": [30, 31, 32, 33, 34, 36], "padding_idx": [30, 31, 33, 34, 36], "padding_mask": [30, 36], "padmask": [7, 11], "page": [3, 4, 5, 6, 16, 18, 20, 22, 23, 30, 31, 33, 34, 36, 37, 38], "page_label": [37, 38], "page_path": 38, "pagedattent": 13, "pai": [4, 20], "paid": [], "paiea": 38, "pain": 4, "paint": 19, "pair": [1, 7, 9, 11, 12, 16, 20, 22, 23, 25], "pairwis": [3, 16, 22, 38], "pairwise_comparison": 38, "pairwise_ev": 38, "pakistan": [37, 38], "pal": 22, "palett": 38, "palm": [0, 4, 38], "palomaki": 5, "pamela": [16, 22], "pan": [1, 2, 20, 37, 38], "pancrea": [4, 37, 38], "pancreat": 4, "panda": [27, 37, 38], "pandas_ai": 38, "pandas_query_engin": 38, "pandem": [37, 38], "panel": 38, "panel_chatbot": 38, "pang": 5, "panpan": 2, "paper": [1, 3, 5, 6, 8, 11, 16, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "paper_medical_record": [37, 38], "paper_record": [37, 38], "paperswithcod": 6, "par": [1, 30, 31, 33, 34, 36], "paradigm": [6, 10, 11, 21, 23, 24], "paraemt": [13, 21], "paragraph": [4, 5, 6, 7, 8, 12, 20], "paragrpah": 20, "paral": 21, "parallel": [1, 4, 7, 11, 13, 16, 25, 38], "parallel_execut": 38, "parallel_execution_ingestion_pipelin": 38, "paralleliz": 11, "param": [1, 23, 38], "param_optim": 38, "paramed": [37, 38], "paramet": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 20, 21, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "parameter": [4, 5, 7, 9, 22, 23], "paramountci": [37, 38], "paramt": 13, "paraphras": [3, 4], "parent": 20, "parenthes": 4, "parfum": 6, "pari": [3, 12, 22], "parikh": 5, "parmar": [5, 11], "pars": [4, 37, 38], "parser": 38, "parsimoni": 4, "part": [0, 4, 5, 6, 7, 8, 10, 11, 13, 16, 19, 20, 21, 22, 23, 25, 27, 30, 32, 35, 36, 37, 38], "parti": [10, 37, 38], "partial": [4, 5, 8, 13, 19, 32, 33, 34], "particip": [4, 5, 37, 38], "participl": 12, "particular": [1, 2, 4, 5, 7, 17, 18, 20, 22, 25, 37, 38], "particularli": [1, 3, 4, 5, 10, 11, 13, 14, 17, 20, 22, 23, 24, 25, 36], "partit": [2, 4, 5, 21, 22], "pascal": 9, "pass": [3, 4, 5, 6, 7, 11, 13, 14, 16, 21, 22, 34], "passag": [3, 11, 19, 20, 37, 38], "passage2queri": 4, "passagequeri": 4, "passio": 38, "passio_nutrition_ai": 38, "passiv": 4, "password": [37, 38], "past": [1, 4, 8, 12, 13, 20, 30, 36, 37, 38], "past_key_valu": [30, 36], "past_present": 38, "patch": 4, "patent": 6, "patentsview": 38, "path": [17, 19, 32, 33, 34, 35, 37, 38], "pathnam": 38, "pathwai": 38, "pathway_retriev": 38, "pathwayreaderdemo": 38, "patient": [37, 38], "patient_clinical_data": [37, 38], "patient_demographic_data": [37, 38], "patient_inform": [37, 38], "patil": 20, "patit": 21, "patrick": [5, 11], "pattern": [1, 2, 4, 5, 8, 9, 11, 14, 20, 22, 37, 38], "pauciti": [37, 38], "paul": [5, 22], "paul_graham": [], "paul_graham_essai": [], "pauliu": 21, "pave": [4, 5], "pavillion": 4, "payal": 7, "paz": 25, "pca": 12, "pd": 27, "pdate": 23, "pdb": 38, "pdf": [4, 6, 8, 11, 20, 22, 30, 31, 33, 34, 36, 37, 38], "pdf_marker": 38, "pdf_path": [37, 38], "pdf_tabl": 38, "pe": [1, 7, 11], "peac": 4, "peak": [4, 5], "pear": 12, "pebblo": 38, "peer": [37, 38], "peft": [20, 25], "pegasu": 11, "pei": [2, 11], "peilin": 5, "peiyi": 2, "peiyu": [1, 25], "pellat": 23, "penal": [2, 4, 14, 20, 22, 25], "penalti": [4, 14, 22], "peng": [2, 11, 20], "penguin": 7, "penn": [6, 8], "pennington2014glov": 12, "penntre": 8, "peopl": [4, 8, 20], "per": [4, 5, 7, 11, 21, 37, 38], "per_token_logp": 33, "perceiv": [4, 5, 16, 24, 37, 38], "percentag": [7, 20], "percept": 20, "perci": 23, "pereira": 4, "perfect": [4, 5, 20, 22], "perfectli": 20, "perform": [0, 1, 2, 3, 4, 5, 7, 8, 11, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "perfum": 6, "perhap": [4, 37, 38], "period": [1, 37, 38], "perk": 8, "perman": [4, 38], "permiss": [37, 38], "permit": [4, 37, 38], "permut": [4, 10, 11, 30, 31, 33, 34, 36], "perplex": [0, 6, 23, 38], "persist": [30, 31, 33, 34, 36, 37, 38], "persist_dir": [37, 38], "person": [20, 37, 38], "personnel": [37, 38], "perspect": [1, 3, 5, 8, 12, 13, 14, 19, 20, 22, 23], "perus": [37, 38], "pet": 23, "peter": [5, 7, 10, 22], "petrov": 23, "pgvecto": 38, "pgvecto_r": 38, "pgvector": 38, "pgvector_sql": 38, "pgvector_sql_query_engin": 38, "pgvectorsdemo": 38, "pharmaci": [37, 38], "pharmacist": 4, "phase": [4, 5, 6, 8, 10, 12, 20, 23, 25], "phd": [], "phenomena": 4, "phenomenon": [7, 12, 13, 22], "phenomonon": 22, "phi": [4, 22, 23], "phi_": 4, "phi_0": 23, "phil": 7, "philadelphia": 7, "philip": 5, "phillip": [5, 23], "philz": 19, "phoenix": 38, "phone": [3, 4, 37, 38], "phonet": 4, "photo": [4, 16, 37, 38], "photograph": [37, 38], "phrase": [3, 5, 8, 12, 16, 20, 23], "physic": [4, 6, 8, 17, 24, 25], "pi": [1, 4, 5, 11, 22, 24], "pi_": [22, 24], "pi_logratio": 33, "pi_r": 22, "piao": 2, "pick": [4, 5, 11, 12], "pictur": [16, 37, 38], "piec": [3, 4, 7, 19, 20, 36], "pierr": [1, 8], "pieter": 25, "pigeon": 10, "pii": 38, "pile": 1, "pileup": [4, 5], "pilferag": [37, 38], "pill": 4, "pillow": [37, 38], "pilot": 4, "pin": [37, 38], "pinecon": 38, "pinecone_auto_retriev": 38, "pinecone_existing_data": 38, "pinecone_metadata_filt": 38, "pineconedemo": 38, "pineconeindexdemo": 38, "ping": 5, "pink": 4, "pinpoint": 3, "pinto": 25, "pioneer": [0, 2, 4, 5, 22], "piotr": [12, 25], "pip": [37, 38], "pipelin": [3, 20, 21, 22, 25, 38], "pipeshift": 38, "piqa": 6, "pit": 4, "pivot": [37, 38], "pixtral": 38, "piyush": [7, 11], "pizza": 4, "pkd": 22, "place": [4, 5, 11, 22, 23, 30, 36, 38], "placehold": [37, 38], "plai": [1, 4, 5, 7, 11, 20, 22, 24, 25, 37, 38], "plain": [4, 37, 38], "plan": [19, 37, 38], "plane": 12, "planet": 22, "planning_workflow": 38, "plant": 4, "plastic": 4, "plateau": [4, 5, 6], "platform": [4, 25, 37, 38], "platitud": 4, "plausibl": [1, 4, 20], "playground": 38, "plc": 8, "plcae": [30, 36], "pleas": 4, "plm": 23, "plot": [18, 36], "plt": 27, "plu": [4, 5, 6, 7, 10, 11, 13, 16, 18, 19, 20, 22, 30, 31, 33, 34, 36, 38], "plugin": 38, "plural": [8, 12], "pmcid": [37, 38], "pmi": 12, "pmid": [37, 38], "pmlr": [1, 5, 7, 11, 16, 22], "png": [27, 38], "pni": 7, "po": [5, 7], "point": [1, 7, 11, 13, 20, 21, 22, 23, 24, 37, 38], "pointwis": [1, 12, 21], "poli": [4, 5], "polic": [37, 38], "polici": [33, 37, 38], "policy_chosen_logp": 33, "policy_evalu": 24, "policy_improv": 24, "policy_rejected_logp": 33, "policy_t": 24, "policyst": 24, "polit": [4, 22], "polo": 4, "polosukhin": [5, 11], "polysem": 4, "polysemi": [4, 5, 12], "polyunsatur": 4, "pond": 25, "pont": 4, "pool": [3, 4, 5, 13, 16, 23], "poor": [4, 5, 9, 12, 20, 22, 37, 38], "poorli": [4, 5, 8, 19, 22], "popul": [3, 22, 37, 38], "popular": [3, 7, 8, 11, 12, 13, 23, 25, 38], "pormpt": 18, "portabl": [37, 38], "portion": [7, 11, 13, 21], "portit": 25, "portkei": 38, "pos_emb": [32, 35], "pos_embed": [32, 35], "poscia": [37, 38], "pose": [4, 5, 12, 13], "posit": [2, 6, 7, 10, 12, 13, 16, 17, 18, 20, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 38], "position_embed": [30, 31, 33, 34, 36], "position_id": [30, 31, 33, 34, 36], "position_ids_expand": [30, 31, 33, 34, 36], "posot": 4, "possess": [4, 23, 37, 38], "possibl": [0, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 19, 20, 21, 23], "possibli": [4, 12, 20], "post": [1, 4, 6, 11, 13, 25, 37, 38], "post1": [37, 38], "post3": [37, 38], "post_attention_layernorm": [30, 31, 33, 34, 36], "post_init": [30, 36], "poster": [37, 38], "posterior": [4, 5], "postgr": 38, "postgresml": 38, "postgresmldemo": 38, "postgresql": 38, "posthog": 38, "postnorm": 1, "postprocessor": 38, "potenti": [0, 1, 3, 4, 5, 11, 13, 16, 18, 19, 20, 21, 23, 37, 38], "pound": 4, "pour": 6, "pow": [30, 31, 33, 34, 36], "power": [0, 1, 2, 4, 5, 7, 11, 13, 16, 20, 23, 37, 38], "ppl": 10, "pr": 22, "prabhakar": 5, "prac": [37, 38], "practic": [0, 1, 2, 5, 7, 12, 13, 14, 21, 23, 25, 37, 38], "practis": 21, "practition": [37, 38], "prafulla": [1, 6, 8, 11, 22, 25], "prais": 4, "prajit": 1, "pranav": [1, 6, 8, 11], "prank": 4, "pre": [1, 3, 5, 6, 8, 9, 11, 12, 14, 16, 17, 18, 20, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 38], "preced": [1, 6, 7, 8, 9, 10, 11, 13, 14, 16, 19, 20, 25], "precis": [1, 2, 3, 8, 13, 18, 19, 20], "preconnect": 38, "pred": [4, 7], "predecessor": [0, 2], "predefin": [4, 5, 20, 38], "predibas": 38, "predic": 19, "prediciton": [30, 31, 33, 34, 36], "predict": [0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 16, 19, 20, 22, 23, 30, 31, 33, 34, 36, 37, 38], "predictor": [4, 22, 38], "predominantli": 25, "prefer": [4, 5, 20, 23, 25, 29, 38], "preference_loss": 33, "prefil": 13, "prefix": [4, 10, 12, 16], "preganc": 20, "pregnanc": 20, "pregnant": 20, "premai": 38, "premis": [6, 7, 10], "prenorm": 1, "preoper": [37, 38], "prepar": [4, 5, 20, 37, 38], "prepend": [4, 5, 23], "preprint": [1, 2, 5, 7, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25], "preprocess": [8, 10, 16, 17, 20, 38], "preprocessreaderdemo": 38, "prescript": [37, 38], "presenc": [4, 5, 25], "present": [1, 2, 3, 4, 5, 6, 7, 12, 18, 20, 25, 30, 31, 32, 33, 34, 35, 38], "present_key_valu": [30, 36], "preserv": [4, 11, 12, 13, 20, 23], "presid": [3, 4, 37, 38], "presidio": 38, "presoftmax": 1, "press": [1, 5, 8, 12], "pressur": [4, 17, 20], "pretain": 7, "pretrain": [2, 4, 5, 18, 20, 22, 23, 29, 32], "pretrained_model_nam": [33, 34], "pretti": [4, 19, 30, 36], "prev": 38, "prev_next": 38, "prevent": [11, 13, 14, 16, 22, 25, 30, 36, 37, 38], "preventdefault": 38, "prevers": 1, "previou": [1, 4, 5, 9, 11, 12, 13, 20, 21, 22, 23, 30, 31, 33, 34, 36, 37, 38], "previous": [0, 4, 10, 11, 13, 18, 20, 25], "prevnextpostprocessordemo": 38, "prf": 4, "prfarch": 4, "price": 3, "primari": [4, 5, 11, 23, 25, 38], "primarili": [1, 4, 5, 6, 22], "prime": [1, 2, 4, 5, 7, 8, 12, 24], "princip": [2, 12], "principl": [0, 8, 9, 13, 14, 17, 20, 24], "print": [18, 22, 27, 32, 33, 34, 35, 36, 37, 38], "print_formatted_respons": 36, "print_response_stream": [37, 38], "printbibliographi": 4, "prior": [4, 5, 6, 7, 8, 21, 23, 37, 38], "priori": 4, "priorit": 20, "privaci": [37, 38], "privat": [20, 23, 37, 38], "priviat": 20, "priya": 25, "pro": [4, 5, 7, 13, 23, 37, 38], "prob": [4, 11], "probabilist": [5, 6, 8, 9, 14], "probabilti": 14, "probabl": [2, 4, 5, 6, 7, 8, 9, 11, 12, 14, 20, 22, 24, 25, 33], "probe": 6, "probirsec": 4, "problem": [1, 2, 5, 7, 10, 13, 14, 17, 18, 19, 20, 21, 24, 25, 38], "problemat": [4, 5, 8, 22], "proc": [37, 38], "proce": [4, 13], "procedur": [4, 5, 7, 10, 11, 24, 37, 38], "proceed": [5, 11, 12, 13, 20], "process": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 25, 30, 36, 37, 38], "procur": [37, 38], "prod_": [4, 8, 14, 22, 23], "produc": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36], "product": [1, 2, 7, 11, 13, 14, 20, 21, 30, 31, 33, 34, 36, 38], "production_rag": 38, "profession": [0, 4, 7, 20, 37, 38], "profil": [4, 37, 38], "profit": [37, 38], "profound": [0, 4, 5, 6], "program": [4, 19, 20, 24, 36, 37, 38], "progress": [4, 5, 16, 22, 23, 37, 38], "progress_sheet": [37, 38], "prohibit": [4, 5, 7, 24, 25], "proj": [16, 37, 38], "projeciton": 23, "project": [1, 2, 4, 5, 7, 9, 10, 12, 13, 16, 21, 23, 25, 30, 31, 33, 34, 36, 38], "projector": 12, "projet": [30, 31, 33, 34, 36], "prometheu": 38, "prometheus2_cookbook": 38, "prometheus_evalu": 38, "promin": 11, "promis": [0, 20, 22], "promot": [2, 4, 7, 20, 37, 38], "prompt": [0, 1, 3, 6, 11, 16, 19, 22, 25, 38], "prompt_mixin": 38, "prompt_optim": 38, "prompt_typ": [37, 38], "prompt_with_complet": [32, 33, 34], "promptag": 20, "promptlay": 38, "promptlayerhandl": 38, "prompts_dict": [37, 38], "prompts_rag": 38, "prompttempl": [37, 38], "prompttyp": [37, 38], "prone": 19, "pronoun": 20, "pronounc": 23, "pronunci": 4, "proof": [4, 24], "propag": [1, 20], "propcach": [37, 38], "proper": [4, 5, 7, 37, 38], "properit": 1, "properli": [8, 20, 22, 23], "properti": [4, 5, 7, 11, 38], "property_graph": 38, "property_graph_advanc": 38, "property_graph_bas": 38, "property_graph_custom_retriev": 38, "property_graph_neo4j": 38, "propog": 1, "proport": [4, 5, 7, 8, 12, 25, 37, 38], "proportion": 4, "propos": [1, 3, 4, 5, 7, 9, 10, 12, 16, 17, 19, 20, 22, 23, 30, 31, 33, 34, 36, 37, 38], "proposit": 7, "proprieti": [], "propto": 4, "prospect": [37, 38], "protect": [4, 37, 38], "protein": 4, "prototyp": [4, 38], "prove": [1, 4, 5, 9, 37, 38], "proven": [0, 4], "provid": [0, 1, 3, 4, 5, 6, 7, 9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 36, 37, 38], "provision": [37, 38], "proxi": [3, 5, 22], "proxim": [4, 22], "pseudo": 8, "pseudoqueryembed": 4, "pseudorelev": 4, "psi": [4, 21], "psi_": [4, 5], "psl22": 1, "psychic": 38, "psychicdemo": 38, "pt": [32, 33, 34], "ptb": [4, 5, 8], "pth": [32, 35], "ptq": 13, "ptx": 22, "pub": [37, 38], "public": [1, 20, 25, 37, 38], "publicli": [16, 37, 38], "publish": [4, 5, 7, 8, 11, 37, 38], "puesedo": 5, "pull": [4, 5, 12], "puma": 4, "pump": 4, "punctuat": [4, 5, 7, 8], "punish": 4, "punk": 4, "punt": 8, "puppiesth": 4, "puppyhood": 4, "pure": [2, 4], "purpl": 38, "purpos": [4, 5, 7, 10, 16, 17, 18, 20, 25], "pursuant": [37, 38], "pursuit": [0, 4], "purview": [37, 38], "push": [0, 4, 5, 10, 12, 38], "put": [4, 5, 12, 20, 22, 38], "putting_it_all_togeth": 38, "puzzl": 1, "pw16": 12, "pxid": 38, "py": [27, 34], "py2": [37, 38], "py3": [37, 38], "pydant": [37, 38], "pydantic_cor": [37, 38], "pydantic_program": 38, "pydantic_query_engin": 38, "pydantic_tree_summar": 38, "pydanticextractor": 38, "pypars": [37, 38], "pypdf": [37, 38], "pypdf2": [37, 38], "pypi": 38, "pyplot": 27, "pythagorean": 38, "python": [4, 5, 18, 20, 26, 34, 37, 38], "python3": 27, "python_fil": 38, "python_sdk": 38, "pytorch_latest": [34, 37, 38], "pytz": [37, 38], "pyyaml": [37, 38], "q": [1, 2, 3, 4, 5, 6, 11, 13, 16, 20, 21, 22, 23, 25, 27, 30, 31, 33, 34, 36, 37, 38], "q_": [5, 13, 24], "q_0": 23, "q_1": [4, 5], "q_and_a": 38, "q_emb": [30, 31, 33, 34, 36], "q_i": [1, 4, 5], "q_ik": 1, "q_j": 4, "q_l": [4, 5], "q_len": [30, 31, 33, 34, 36], "q_m": [1, 4, 5], "q_max": 13, "q_n": [4, 5], "q_proj": [30, 31, 33, 34, 36], "q_t": 4, "qa": [4, 5, 10, 16, 20, 23, 38], "qat": 13, "qdl": [4, 5], "qdrant": 38, "qdrant_bm42": 38, "qdrant_hybrid": 38, "qdrant_metadata_filt": 38, "qdrant_using_qdrant_filt": 38, "qdrantdemo": 38, "qdrantindexdemo": 38, "qi": [7, 19], "qiancheng": 2, "qianfan": 38, "qianhui": 13, "qianwen": 20, "qianyu": 20, "qid": 4, "qihao": 2, "qime": 25, "qin": [5, 7, 23], "qing": 14, "qingyang": 16, "qingyao": 5, "qinyu": 2, "qiu": [1, 2, 5, 13, 20], "qiu2020pretrain": 7, "qiushi": 2, "qk": 1, "qkv": 1, "qkv_bia": [31, 32, 33, 34, 35], "qnli": 13, "qp": 4, "qq": 13, "qqp": 13, "qrel": 27, "qrw": 4, "qsx": 7, "qtr": [4, 5], "qu": [2, 5], "quad": [1, 4, 5, 13, 19, 22, 24], "quadrant": 20, "quadrat": [1, 11, 21], "qualiti": [1, 2, 3, 4, 5, 6, 8, 12, 14, 16, 17, 18, 19, 21, 23, 24, 25, 36, 37, 38], "quan": 5, "quandari": [37, 38], "quantat": 13, "quantifi": 4, "quantiti": [4, 5, 6, 8, 16, 21, 22], "quarter": 4, "quebec": 8, "queen": 4, "quel": 6, "quelqu": 6, "quentin": 23, "queri": [0, 2, 7, 11, 13, 16, 19, 21, 30, 31, 32, 33, 34, 35, 36, 37, 38], "querstion": 20, "query_dict": 27, "query_engin": [37, 38], "query_fus": 38, "query_len": 27, "query_length": [30, 36], "query_length_ms_marco": 27, "query_pipelin": 38, "query_pipeline_ag": 38, "query_pipeline_async": 38, "query_pipeline_memori": 38, "query_pipeline_panda": 38, "query_pipeline_rout": 38, "query_pipeline_sql": 38, "query_plan": 38, "query_respons": 38, "query_sequence_length": [30, 36], "query_st": [30, 31, 33, 34, 36], "query_str": [37, 38], "query_transform": 38, "query_transform_cookbook": 38, "query_understanding_ag": 38, "query_word_cloud": 27, "querydocu": 4, "queryengin": 38, "queryexpansionarch": 4, "querylengthdoclengthmsmarco": 4, "queryselector": 38, "queryselectoral": 38, "quesion": 19, "question": [0, 1, 3, 7, 10, 11, 12, 16, 17, 18, 19, 20, 22, 23, 25, 36, 37, 38], "question_answ": [37, 38], "question_gen": 38, "questiongener": 38, "queue": 5, "quick": [4, 18], "quickli": [4, 5, 6, 20, 25, 38], "quickstart": 38, "quietli": 4, "quip": 38, "quirk": 4, "quit": [4, 5, 6, 7, 12, 37, 38], "qun": 7, "quoc": [1, 7, 17, 18, 23], "quora": [4, 5], "quot": [4, 38], "qw": [1, 11], "qw_i": 11, "qwen": [1, 31, 32, 33, 34, 38], "qwen2": [21, 23, 31, 32, 33, 34], "r": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 19, 20, 22, 24, 25, 30, 32, 33, 34, 35, 36, 37, 38], "r1": 23, "r1000": 4, "r2": [23, 38], "r200": 4, "r50": 4, "r_": [1, 4, 5, 22, 24], "r_0": [4, 5, 22], "r_1": [3, 4], "r_2": 4, "r_i": [3, 4], "r_j": 3, "r_l": 22, "r_m": 3, "r_n": [4, 5], "r_q": [4, 5], "r_t": 24, "ra": [37, 38], "rabbitmq": 38, "race": 0, "radford": [6, 8, 10, 11, 16, 22, 25], "radio": [37, 38], "radiologi": [37, 38], "radiu": 4, "radlinski": 5, "radu": [7, 11], "rafael": 22, "rafailov": 22, "raffel": [5, 10], "raft": 38, "raft_dataset": 38, "rag": [0, 25, 36, 38], "rag_ag": 38, "rag_cli": 38, "rag_cli_loc": 38, "rag_evalu": 38, "rag_fusion_query_pipelin": 38, "rag_learn": [], "ragatouil": 38, "ragatouille_retriev": 38, "ragcheck": [20, 38], "ragdataset_submission_templ": 38, "raghavan": 5, "rag\u4e0d\u4ec5\u5173\u6ce8\u68c0\u7d22\u7684\u51c6\u786e\u6027": [], "rag\u7684\u4f18\u52bf\u5728\u4e8e\u5176\u80fd\u591f\u6309\u9700\u68c0\u7d22": [], "rag\u8fd8\u901a\u8fc7\u5f15\u5165\u53cd\u601dtoken\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u63a7\u6027": [], "rag\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5b9e\u73b0": [], "rai": 22, "rail": 38, "rain": [4, 5], "rais": [0, 4], "rajbhandari": 21, "rake": 8, "ralph": 22, "ram": [3, 5], "ramachandran": 1, "ramamurthi": 5, "ramelson": [37, 38], "ramesh": 16, "ramet": [37, 38], "rami": [16, 23], "ramprasath": 14, "random": [7, 8, 10, 23, 24, 25], "randomli": [4, 5, 7, 10, 11, 14, 24], "rang": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 18, 20, 21, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 38], "rangan": 5, "rangl": [1, 4, 5, 18, 22], "rank": [7, 12, 13, 16, 19, 20, 21, 22, 29, 37, 38], "rank0": 21, "ranker": 20, "rankgpt": 38, "rankgpt_rerank": 38, "rankllm": 38, "rankllm_rerank": 38, "ranknet": [3, 5], "rap": 38, "raphael": 5, "rapid": [4, 5, 6, 12], "rapidli": [4, 12], "raptor": 38, "rare": [1, 4, 5, 7, 9, 12, 13, 14, 20, 25], "rasbt": [32, 35], "raslei": 21, "raspberri": 4, "rate": [1, 4, 5, 7, 17, 20, 24, 32, 35, 37, 38], "rategi": 4, "rather": [1, 3, 4, 5, 6, 7, 11, 12, 13, 18, 20], "rathnayak": [37, 38], "ratio": [4, 5, 8, 11, 12, 21, 22, 23, 25], "rational": [3, 4, 5, 7, 17, 20], "raw": [1, 4, 5, 7, 19, 20, 32, 33, 34, 35], "raxa": [37, 38], "rayyan": 38, "rbf": 4, "rc": 27, "rceil": [4, 13], "re": [0, 1, 3, 5, 8, 9, 12, 13, 17, 20, 22, 25, 30, 31, 33, 34, 36, 37, 38], "reach": [1, 4, 5, 6, 7, 14, 17, 20, 24], "react": 38, "react_ag": 38, "react_agent_finetun": 38, "react_agent_with_query_engin": 38, "reaction": [4, 5], "read": [4, 5, 6, 7, 12, 13, 24, 32, 33, 34, 35, 38], "read_text_data": [32, 33, 34, 35], "reader": [3, 4, 5, 37, 38], "readi": 7, "readili": 20, "readm": 38, "readthedoc": 38, "readwis": 38, "real": [0, 4, 5, 7, 8, 20, 22, 23, 24, 37, 38], "realist": [4, 6, 11], "realiz": [2, 4, 5, 7, 12, 19, 24, 25], "realli": [4, 19], "realtim": 20, "realtimedb": 38, "reaons": 20, "reason": [1, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 22, 23, 25, 34, 38], "reasongin": 1, "recal": [3, 9, 20, 24, 38], "recalcul": [13, 21], "receiv": [2, 4, 5, 12, 21, 24, 37, 38], "recenc": 38, "recencypostprocessordemo": 38, "recent": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 23, 27, 34, 37, 38], "recip": 4, "reciproc": [5, 38], "reciprocal_rerank_fus": 38, "recis": 21, "recogn": [4, 11, 20, 37, 38], "recognit": [4, 7, 8, 11, 16, 20], "recommend": [11, 23, 37, 38], "recomposit": 19, "recomput": 13, "reconcil": [4, 5], "reconstruct": [4, 5, 10, 11], "record": [4, 5, 20, 37, 38], "recov": [1, 4, 10], "recruit": [37, 38], "rectifi": 4, "recurisve_retriever_nodes_braintrust": 38, "recurs": [36, 38], "recursive_retriev": 38, "recursive_retriever_ag": 38, "recursive_retriever_nod": 38, "red": 4, "reddit": [1, 25, 38], "redefin": 0, "redfield": 5, "redi": 38, "redis_ingestion_pipelin": 38, "redisdocstoreindexstoredemo": 38, "redisindexdemo": 38, "redistribut": 8, "redo": 21, "redpajama": 25, "reduc": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "reduced_error": [37, 38], "reducescatt": 21, "reduct": [1, 4, 5, 7, 13, 17, 21], "redund": [2, 13, 20, 21], "ref": [22, 32, 33, 34], "ref_logratio": 33, "ref_model": 33, "refe": 3, "refer": [4, 5, 7, 13, 14, 16, 20, 21, 22, 23, 37, 38], "reference_chosen_logp": 33, "reference_fre": 33, "reference_output": 33, "reference_rejected_logp": 33, "referr": [37, 38], "referrerpolici": 38, "refin": [3, 4, 5, 6, 19, 20, 37, 38], "refine_templ": [37, 38], "refinedweb": 25, "reflect": [4, 8, 12, 22, 37, 38], "reformul": [4, 20], "refresh": [5, 20], "refsect": 4, "refus": [20, 36], "reg": 12, "regard": [4, 6, 11, 20, 23, 37, 38], "regardless": [2, 4, 5, 17], "regatta": 8, "regex": [37, 38], "region": [5, 25, 37, 38], "register_buff": [30, 31, 32, 33, 34, 35, 36], "regress": [6, 10, 11, 12, 25], "regul": [4, 5, 20, 37, 38], "regular": [1, 4, 5, 7, 11, 12, 13, 22, 23, 25, 37, 38], "regularli": [37, 38], "regulatori": 20, "reid": 18, "reimer": 4, "reinforc": [18, 29], "reival": 4, "reject": [19, 20, 22], "rejected_logp": 33, "rejected_reward": 33, "reka": 38, "rel": [1, 4, 5, 6, 12, 13, 17, 20, 25, 37, 38], "rel_": 4, "rel_q": [4, 5], "relat": [0, 3, 4, 5, 7, 8, 10, 12, 14, 19, 20, 21, 22, 23, 25, 37, 38], "related": 4, "related_to": [37, 38], "relationship": [1, 3, 4, 5, 7, 9, 10, 11, 16, 19, 25, 37, 38], "relative_score_dist_fus": 38, "relax": 5, "relearn": 4, "releas": [4, 5], "relev": [2, 3, 5, 6, 7, 12, 16, 17, 19, 20, 36, 37, 38], "relevancy_ev": 38, "reli": [1, 2, 4, 5, 7, 11, 18, 20, 22, 23, 24], "reliabl": [1, 3, 4, 8, 19, 20, 23, 25], "relianc": 4, "relik": 38, "relu": [1, 4, 11, 13], "relyt": 38, "relytdemo": 38, "remain": [1, 2, 4, 5, 6, 8, 11, 13, 17, 22, 23, 25, 37, 38], "remark": [0, 1, 2, 4], "remedi": [4, 8, 25], "rememb": 4, "reminisc": 7, "remot": [37, 38], "remote_depth": 38, "remov": [1, 3, 4, 5, 7, 8, 10, 13, 16, 20, 22, 23], "ren": [1, 2, 5, 25], "renaiss": 19, "renard": 1, "renji": 7, "rent": [], "renz": [16, 23], "reorder": [20, 38], "rep": 4, "repeat": [1, 4, 14, 24, 25, 30, 31, 33, 34, 36, 37, 38], "repeat_interleav": [30, 31, 33, 34, 36], "repeat_kv": [30, 31, 33, 34, 36], "repel": [4, 5], "repetit": [4, 5, 14], "repl": 38, "repl4nlp": 5, "replac": [4, 5, 7, 8, 10, 16, 22, 37, 38], "repli": 16, "replic": [4, 38], "replicate_multi_mod": 38, "repo": 38, "repond": [], "repons": [22, 23], "report": [1, 2, 4, 5, 8, 21, 37, 38], "repositori": [37, 38], "repres": [0, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25], "represen": 4, "represent": [1, 3, 6, 7, 9, 10, 11, 12, 13, 16, 20, 21, 22, 23, 25, 38], "representationss": 12, "reprocess": 13, "reproduc": [4, 5], "reproduct": [4, 5, 37, 38], "repurpos": 2, "request": [4, 5, 13, 20, 21, 22, 32, 33, 34, 35, 37, 38], "requests_toolbelt": [37, 38], "requir": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 30, 36, 37, 38], "rerank": [3, 4, 5, 38], "rescal": [1, 4, 11, 14], "research": [0, 2, 4, 5, 7, 9, 10, 11, 12, 13, 16, 19, 20, 21, 25, 37, 38], "researchcov": [6, 8, 11], "resembl": [4, 5, 7, 16], "reserv": [13, 21], "reset": 7, "reshap": [0, 4, 5, 30, 31, 33, 34, 36], "resid": [1, 4, 13, 20, 37, 38], "residu": [1, 4, 11, 21, 30, 31, 33, 34, 36], "resil": [37, 38], "resnet": 16, "resnetd": 16, "resolv": [4, 20, 38], "resourc": [0, 2, 4, 7, 19, 20, 21, 23, 25, 37, 38], "respect": [4, 5, 7, 11, 12, 13, 20, 21, 22, 23, 24], "respond": [1, 4, 18, 20, 24], "respons": [1, 2, 3, 4, 5, 14, 16, 17, 18, 19, 20, 24, 25, 32, 33, 34, 35, 36, 37, 38], "response_graph_rag": [37, 38], "response_mod": [37, 38], "response_synthes": [37, 38], "response_synthesi": 38, "response_vector_rag": [37, 38], "rest": [4, 5, 8, 10, 13, 21], "restaur": [3, 4, 5], "restaurat": [4, 5], "restera": 6, "restor": [7, 20], "restrict": [1, 4, 5, 11, 18, 38], "result": [1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 25, 37, 38], "resum": 38, "resume_screen": 38, "ret": 4, "retain": [1, 2, 4, 5, 8, 11, 20, 21, 23, 30, 31, 33, 34, 36, 37, 38], "retain_graph": 34, "retent": [37, 38], "retrain": [7, 13, 18, 20, 22, 37, 38], "retreiv": 4, "retri": 38, "retriev": [0, 6, 7, 16, 17, 36, 37, 38], "retrievalrerankingtask": 4, "retrievel": 3, "retriever_ev": 38, "retriever_mod": [37, 38], "retriever_rout": 38, "retrieverankingarch": 4, "retrieverrouterqueryengin": 38, "retro": [37, 38], "retrospect": [37, 38], "retry_engine_weavi": 38, "retry_polici": 38, "retryqueri": 38, "return": [0, 1, 4, 5, 18, 20, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38], "return_dict": [30, 36], "return_direct_ag": 38, "return_tensor": [32, 33, 34], "reus": [4, 5, 13], "reveal": [4, 8, 11, 12, 13, 20, 22], "revers": [4, 5], "review": [1, 4, 5, 7, 12, 22, 23, 36, 37, 38], "revis": [37, 38], "revisit": [4, 5], "revolut": 0, "revolution": [0, 1, 20], "revolutionari": 0, "reward": [4, 14], "reweigh": 4, "rewon": [6, 8, 10, 11, 25], "rewrit": [3, 37, 38], "rewritten": [4, 5, 20], "rfloor": 1, "rfou": [16, 23], "rhetor": 4, "rho": 25, "rho_1": 25, "rho_2": 25, "rho_i": 25, "rhodesian": 4, "rial": 12, "ricciardi": [37, 38], "rice": 4, "rich": [4, 5, 7, 11, 14, 22], "richard": [4, 10, 12, 17], "richer": [4, 5], "rico": 1, "ride": 6, "ridgeback": 4, "right": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 20, 22, 23, 24, 25, 27, 37, 38], "rightarrow": [5, 8, 22], "rigor": [37, 38], "ring": [4, 21], "ringallreduc": 21, "ringreducescatt": 21, "rio": 12, "risd": [], "rise": [37, 38], "risk": [2, 4, 5, 13, 21, 22, 23, 37, 38], "risteski": 12, "river": [3, 12], "rkh": 16, "rl": [23, 24], "rlhf": 18, "rm": [22, 32, 35], "rms_norm_ep": [30, 31, 33, 34, 36], "rmsnorm": [1, 30, 31, 33, 34, 36], "rnn": [9, 11], "rnss18": [6, 8, 11], "ro": [6, 23], "road": [4, 5], "rob_bas": 23, "robert": [5, 10, 22], "roberta": [7, 11], "roberts2020trec": 4, "robertson": [4, 5], "robertson2009probabilist": 4, "robinson": 23, "roboto": 38, "robust": [1, 2, 10, 17, 20, 22], "robustli": [7, 11], "roc71": [4, 5], "rocchio": [4, 5], "rocess": [1, 6, 8, 11], "rocketqa": 5, "rockset": 38, "rocksetdb": 38, "rocksetindexdemo": 38, "rodrigo": [5, 20], "roform": 1, "role": [0, 1, 4, 5, 7, 11, 19, 20, 22, 24, 25, 36, 37, 38], "roll": [5, 37, 38], "romanc": 6, "romano": 4, "rome": 12, "ronan": 12, "rong": [1, 25], "room": [4, 5, 9, 37, 38], "root": [4, 5, 7, 12, 38], "rope": [30, 31, 33, 34, 36], "rope_init_fn": [30, 31, 33, 34, 36], "rope_kwarg": [30, 31, 33, 34, 36], "rope_theta": [30, 31, 33, 34, 36], "rosenberg": 5, "ross": [5, 25], "rotari": [30, 31, 32, 33, 34, 35, 36], "rotary_emb": [30, 31, 33, 34, 36], "rotat": [1, 7, 10, 11, 30, 31, 33, 34, 36], "rotate_half": [30, 31, 33, 34, 36], "roug": 23, "roughli": [1, 4, 8, 25], "round": [4, 13, 20, 22], "rout": [2, 38], "router": [2, 38], "router_and_subquestion_queryengin": 38, "router_finetun": 38, "router_query_engin": 38, "router_retriev": 38, "routerqueryengin": 38, "routin": [37, 38], "row": [3, 4, 11, 12, 13], "rozi": [22, 25], "rqh": 20, "rr": 4, "rr_": 4, "rr_q": 4, "rrrh20": 21, "rsj": 4, "rsl": [4, 5], "rsm": 22, "rsqrt": [30, 31, 33, 34, 36], "rsr": [4, 5, 10], "rss": 38, "rte": 13, "rtn": 13, "ru": 20, "ruan": 2, "ruben": 8, "ruder": 7, "rudolph": 8, "rui": 22, "ruibin": [1, 11], "ruin": 4, "ruiqi": [2, 5], "ruisong": 2, "ruiyang": [1, 5, 25], "ruizh": 2, "rule": [1, 4, 5, 7, 8, 9, 12, 14, 20, 21, 25, 37, 38], "rumor": 8, "run": [4, 5, 9, 12, 13, 17, 18, 20, 22, 23, 34, 37, 38], "run_backward": 34, "rungpt": 38, "runji": 2, "runllm": 38, "runner": 38, "runtim": [8, 12, 13], "runtimewarn": 27, "runxin": 2, "ruofei": 5, "ruoyu": 2, "russo": 19, "ruwas": 21, "ruyi": 2, "rvert": 24, "rvert_": 24, "rw": 4, "rwc": [6, 8, 10, 11], "rwe": 4, "rx": 2, "ryan": 22, "ryder": [1, 6, 8, 11], "rz09": [4, 5], "rzl17": 1, "s13584": [37, 38], "s2": 38, "s3": [6, 8, 11, 38], "s_": [2, 4, 5, 7, 9, 13, 22, 24], "s_0": 24, "s_1": [4, 5, 24], "s_2": [4, 5], "s_3": [4, 5], "s_4": [4, 5], "s_5": [4, 5], "s_i": [3, 4, 5, 7, 22], "s_j": [3, 4, 22], "s_q": 4, "s_r": 4, "s_t": [22, 24], "s_w": 13, "sa": [37, 38], "sablayrol": 1, "sacrif": 4, "sacrifac": 5, "sacrific": 4, "safe": [4, 20], "safeti": [20, 22, 37, 38], "sagemak": [25, 38], "sagemaker_embedding_endpoint": 38, "sagemaker_endpoint": 38, "sagemaker_endpoint_llm": 38, "saharan": [37, 38], "sai": [1, 3, 4, 5, 6, 7, 8, 12, 18, 20, 23, 24, 25], "said": 4, "saint": 4, "sake": 4, "saksham": 7, "sale": [4, 5, 38], "saleforc": 16, "salesforc": [16, 38], "salienc": 13, "salient": [4, 5], "saliman": [6, 8, 11], "salton": 4, "sam": 25, "sambanova": 38, "sambanovacloud": 38, "same": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 20, 21, 22, 23, 24, 30, 31, 33, 34, 36, 37, 38], "sampl": [3, 8, 10, 17, 18, 20, 22, 23, 24, 25], "samsum": 23, "samuel": [5, 22], "samyam": 21, "san": [6, 20], "sandhini": [16, 22], "sandipan": 22, "sanghai": 1, "sanh": 7, "sanita": [37, 38], "sanjeev": [9, 12], "sanjiv": 5, "sara": 13, "sarathchandra": [37, 38], "sastri": [1, 6, 8, 11, 16], "satisfact": [4, 37, 38], "satisfactori": [6, 7, 11], "satisfi": [1, 4, 5, 8, 22, 24, 37, 38], "satisifi": 22, "satoshi": 9, "satur": [4, 5, 11], "saudi": [37, 38], "saulnier": 1, "saurabh": [5, 7], "saurav": 22, "savares": 16, "save": [4, 5, 11, 12, 13, 21, 23, 30, 32, 35, 36], "save_load": 38, "savefig": 27, "saw": 4, "sbd": 21, "sbert": 38, "sbert_rerank": 38, "scaffold": 38, "scalabl": [2, 4, 5, 12, 13, 20], "scalar": [1, 4, 5, 14, 22], "scale": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 16, 19, 20, 21, 22, 25, 30, 31, 32, 33, 34, 35, 36, 38], "scan": [4, 25], "scann": [4, 5], "scao": 1, "scarciti": 20, "scarf": 38, "scatter": [20, 21], "scenario": [1, 4, 5, 7, 12, 20, 23, 37, 38], "scene": 16, "sch": [5, 8], "schedual": [], "schedul": 1, "scheinkman": 4, "schema": 38, "schemat": [4, 13], "scheme": [1, 6, 10, 11, 13, 24, 38], "school": 17, "schulman": 22, "schuster": 7, "schutzemr08": [4, 5], "schuurman": [17, 18, 23], "sci": [37, 38], "scienc": [0, 4, 12, 19, 20], "scientif": [4, 5, 6, 7, 20, 25, 37, 38], "scope": [3, 5], "score": [1, 2, 3, 5, 6, 8, 12, 13, 14, 16, 19, 20, 22, 23, 24, 37, 38], "scoreencod": 4, "scorer": [4, 20], "scott": 25, "scrape": 25, "scratch": [4, 5, 11, 25, 32, 35, 38], "screen": 3, "screener": 38, "screw": 3, "scribe": [37, 38], "script": [4, 19, 38], "scriptsiz": 4, "scrollfix": 38, "sdc": [4, 5], "sdcw19": 7, "sdk": 38, "seaborn": 27, "search": [0, 1, 3, 12, 13, 16, 19, 20, 22, 37, 38], "search_term": 38, "searchabl": 20, "searchain": 38, "searcher": 5, "season": 4, "seat": [18, 36], "seattl": [4, 5], "sebastian": [5, 7, 11], "sec": [4, 38], "sec_fil": 38, "sec_tabl": 38, "secgpt": 38, "secinsight": 38, "second": [1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 16, 21, 24, 30, 31, 33, 34, 36, 38], "secondari": 38, "secondli": [], "secret": 22, "secretli": 22, "sect": [37, 38], "section": [0, 1, 4, 5, 7, 8, 11, 12, 13, 19, 20, 21, 37, 38], "sector": [37, 38], "secur": [37, 38], "see": [1, 4, 5, 7, 12, 13, 16, 18, 20, 21, 22, 24, 25, 30, 36], "seed": [23, 32, 33, 34, 35], "seek": [2, 3, 4, 20, 24], "seem": [4, 19, 24], "seen": [4, 5, 7, 8, 11, 12, 20, 21, 23, 25, 37, 38], "seg": 7, "segmenet": 7, "segment": [2, 5, 7, 10, 11, 19], "select": [2, 5, 6, 7, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 38], "selectedmanu": 4, "selector": 38, "selectorprompttempl": [37, 38], "self": [4, 5, 7, 10, 11, 13, 16, 20, 22, 23, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "self_attn": [30, 31, 33, 34, 36], "self_attn_weight": [30, 36], "self_discov": 38, "self_discover_workflow": 38, "self_rag": 38, "sell": 4, "seltzer": 7, "selvaraju": 14, "semant": [1, 3, 6, 7, 8, 9, 10, 16, 19, 20, 25, 38], "semantic_chunk": 38, "semantic_double_merging_chunk": 38, "semantic_similar": 38, "semantic_similarity_ev": 38, "semantic_splitt": 38, "semanticscholar": 38, "sement": 20, "semi": [20, 38], "semin": 4, "semnat": 20, "sen": 5, "send": [20, 21], "senior": 4, "senji": 22, "sennrich": 1, "sens": [4, 5, 8, 38], "sensibl": 8, "sensit": [4, 5, 17, 20, 21, 23], "sensor": 4, "sent": [3, 4, 16, 20, 21], "sentenc": [4, 5, 6, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 38], "sentence_optim": 38, "sentence_splitt": 38, "sentence_window": 38, "sentence_window_retriev": 38, "sentencesplitt": [37, 38], "sentencetransformerrerank": 38, "sentiment": [4, 7, 12, 36], "sep": [4, 5, 7], "separ": [1, 4, 5, 6, 7, 11, 13, 16, 20, 22, 23, 27], "seq": [4, 5], "seq2seq": [11, 29], "seq_len": [30, 31, 33, 34, 36], "seq_length": 33, "seqlen": [30, 31, 33, 34, 36], "seqmask": 11, "seqmask_i": 11, "sequenc": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 18, 20, 21, 22, 23, 25, 30, 33, 36], "sequence_length": [30, 36], "sequencen": 9, "sequenti": [0, 1, 2, 7, 8, 11, 20, 21, 22, 23, 32, 35], "ser": [37, 38], "sergei": [1, 5], "seri": [1, 11, 29, 38], "seriou": [4, 5], "serp": [4, 38], "serv": [2, 3, 5, 7, 13, 16, 19, 20, 22, 24, 25, 38], "server": [4, 38], "servic": [4, 5, 19, 20, 37, 38], "service_context": [37, 38], "servicecontext": [37, 38], "session": [4, 5, 20, 37, 38], "set": [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36, 37, 38], "set_styl": 27, "set_xtick": 27, "set_xticklabel": 27, "setattribut": 38, "setitem": 38, "setup": [2, 4, 5, 38], "setwis": 3, "seven": [6, 11], "sever": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 16, 18, 20, 22, 23, 25], "severyn": 5, "sewon": 5, "sex": [4, 5], "sexual": 22, "sft": 20, "sgd": 25, "sh": 38, "sha": 2, "sha19": 1, "sha20": 1, "shachaf": 5, "shakeri": 5, "shallow": [1, 4, 5], "shan": 2, "shane": [18, 23], "shang": 7, "shanghao": 2, "shangyan": 2, "shanhuang": 2, "shansan": 1, "shao": 2, "shaohan": [1, 7], "shaoq": 2, "shape": [0, 1, 13, 14, 20, 30, 31, 32, 33, 34, 35, 36], "sharan": [5, 10, 17, 21, 23], "share": [1, 2, 4, 6, 7, 10, 11, 12, 13, 16, 19, 22, 25, 30, 31, 33, 34, 36, 37, 38], "sharepoint": 38, "sharma": [7, 11, 22], "sharp": 24, "sharpli": 22, "shayn": 23, "shazeer": [1, 2, 5, 10, 11], "shb15": 1, "she": 20, "shean": 23, "shed": 4, "sheer": [4, 5], "sheet": [37, 38], "sheetinpat": [37, 38], "sheetopd": [37, 38], "shelf": [4, 20, 23], "shen": [2, 5, 20, 22, 23], "shen2014lat": 4, "sheng": [5, 13, 17, 20], "shengfeng": [1, 2], "shep": 4, "sherman": 1, "shg": 5, "shi": [2, 19, 20, 22, 23], "shichao": 20, "shift": [0, 1, 10, 11, 13, 32, 34, 35], "shihan": 22, "shiji": 11, "ship": [4, 12], "shirish": 10, "shirong": 2, "shirt": 4, "shishir": 20, "shixiang": [18, 23], "shiyu": 2, "shop": [4, 5, 19, 38], "shopifi": 38, "short": [1, 4, 5, 11, 12, 16], "shortag": [4, 5], "shortcom": [4, 5, 11, 12], "shortcut": [32, 35], "shorten": [21, 32, 35], "shorter": [1, 4, 5, 13], "shortest": 19, "shorthand": [8, 14], "shot": [1, 3, 4, 6, 7, 8, 11, 16, 17, 20, 23], "should": [4, 5, 6, 7, 8, 10, 11, 13, 18, 20, 21, 22, 23, 24, 30, 36, 38], "shouldn": [4, 5], "shouyuan": 1, "show": [1, 4, 5, 6, 7, 8, 10, 12, 13, 16, 17, 19, 22, 23, 24, 25, 30, 31, 33, 34, 36], "showgraph": [37, 38], "shown": [1, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23], "showroom": 3, "shrink": 25, "shuaichen": 20, "shuang": 2, "shuffl": [8, 10, 32, 33, 34, 35], "shuguang": 5, "shuip": 2, "shume": [1, 7], "shunfeng": 2, "shusheng": 22, "shuster": 5, "shute": 2, "shutterstock": 4, "shuxin": [1, 11], "shyam": [1, 6, 8, 11], "si": 23, "siames": 4, "sick": 20, "siddartha": 22, "siddhant": 7, "siddhartha": 23, "side": [4, 5, 6, 7, 11, 20], "sidebar": 38, "sidebar__inn": 38, "sidebar__scrollwrap": 38, "sierra": [4, 5], "sift": 4, "sig": [37, 38], "sight": [4, 5], "sigir": [5, 20], "sigma": [1, 4, 5, 12, 22, 30, 31, 33, 34, 36], "sigma_": 4, "sigmoid": [1, 7, 9], "sign": [21, 37, 38], "signal": [4, 5, 8, 12, 19, 20, 22, 24], "signfic": [4, 5], "signficicantli": 20, "signific": [0, 1, 4, 5, 6, 7, 8, 11, 13, 17, 18, 20, 21, 30, 36, 37, 38], "significantli": [0, 2, 4, 5, 6, 7, 11, 12, 13, 14, 17, 18, 20, 22, 23, 25, 36, 37, 38], "sil": 19, "siliconflow": 38, "siliconflow_rerank": 38, "silu": [30, 31, 33, 34, 36], "silvio": 16, "sim": [4, 5, 8, 12, 13, 20, 22, 24], "simcha": 5, "simclr": [], "simen": 22, "simiarl": 17, "similar": [1, 6, 7, 8, 9, 10, 12, 16, 17, 20, 21, 22, 23, 25, 30, 31, 33, 34, 36, 37, 38], "similarli": [2, 4, 5, 8, 11, 24, 37, 38], "similiar": [20, 22], "simpl": [1, 2, 5, 6, 11, 12, 13, 16, 18, 19, 20, 21, 25, 36, 38], "simple_composable_memori": 38, "simple_directory_read": 38, "simple_directory_reader_parallel": 38, "simple_directory_reader_remote_f": 38, "simple_fus": 38, "simple_multi_mod": 38, "simple_summar": 38, "simplebm25f": 4, "simpledirectoryread": [37, 38], "simplegraphstor": [37, 38], "simpleindexdemo": 38, "simpleindexdemollama": 38, "simpleindexdemollama2": 38, "simpleindexdemommr": 38, "simpleindexons3": 38, "simpler": [2, 3, 4, 5, 8, 18, 20], "simplest": [4, 5, 14, 20], "simplewebpageread": 38, "simpli": [1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 20, 22, 25, 37, 38], "simplic": [1, 4, 5, 7, 11, 20, 24], "simplif": [1, 4, 18, 24], "simplifi": [1, 4, 5, 13, 20, 22, 30, 31, 32, 33, 34, 35, 36, 37, 38], "simplist": [4, 5], "simpo": 22, "simul": [4, 24, 37, 38], "simultan": [1, 2, 5, 7, 13, 22], "sin": [1, 11, 30, 31, 33, 34, 36], "sinatra": 4, "sinc": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 19, 21, 22, 23, 24, 25], "sine": [11, 30, 31, 33, 34, 36], "singer": 25, "singh": 1, "singhal": [4, 7], "singl": [1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 18, 20, 21, 22, 23, 36, 37, 38], "singlestor": 38, "singlestoredb": 38, "singular": [12, 19], "sinkhorn": [], "sinusoid": 1, "sir": 4, "sister": 12, "sit": 21, "site": [4, 5, 27, 34, 37, 38], "situat": [4, 19, 24], "sive": 4, "six": [7, 37, 38], "siyuan": 13, "sizabl": 1, "size": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 20, 22, 23, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "sizemedium": 4, "sk": [37, 38], "skew": 6, "skill": [0, 4, 6, 19], "skin": 4, "skip": [4, 38], "slack": 38, "slackdemo": 38, "slama": 22, "slate": 38, "slav": 23, "slice": [30, 36, 38], "slide": [3, 4, 20, 35, 38], "slightli": [4, 5, 10], "slim": 3, "slimpajama": 25, "slm": 20, "slope": 1, "slow": [4, 6, 7, 20, 21, 25, 37, 38], "slower": [1, 21], "slp": 1, "slug": 38, "slw": 11, "small": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 37, 38], "small_siz": 27, "smaller": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 19, 20, 22, 23, 25], "smallest": [4, 12, 13], "smart": [4, 5, 38], "smart_pdf_load": 38, "smartphon": [37, 38], "smaug": 22, "smdh13": 25, "smith": 1, "smooth": [1, 4, 5, 6, 9, 14, 37, 38], "smoother": [1, 4], "smoothin": 8, "smoothli": [6, 23], "smt": 4, "sn": 27, "snack": [4, 8], "sniffio": [37, 38], "snippet": [4, 18, 20], "snowflak": 38, "snowflake_query_engin": 38, "snrm": 5, "snscrape": 38, "snscrape_twitt": 38, "so": [2, 4, 5, 7, 8, 10, 11, 12, 13, 18, 22, 25, 27, 37, 38], "soap": [37, 38], "socher": [10, 12], "social": [4, 25], "socioeconom": [37, 38], "soft": [4, 5, 7, 14, 16, 23, 37, 38], "soften": [4, 5], "softer": [4, 5], "softli": 4, "softmax": [1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 21, 25, 30, 31, 32, 33, 34, 35, 36], "softwar": [13, 19, 20, 37, 38], "soh16": [4, 5], "soheil": 6, "sohn": 5, "solar": 38, "sold": 3, "sole": [4, 5, 18], "solid": [4, 12, 22], "solitari": 4, "solla": 13, "solut": [2, 4, 5, 7, 14, 17, 20, 22, 23, 38], "solv": [1, 2, 4, 7, 10, 12, 13, 16, 18, 19, 20, 21, 22, 24, 38], "some": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 34, 36, 37, 38], "someth": [4, 6, 18, 19, 20], "sometim": [1, 4, 5, 20, 22], "somewhat": [4, 6], "song": [2, 5, 7], "soon": 4, "sop": [7, 11], "sophist": [0, 4, 5, 19, 20], "sophositc": 20, "sordoni": 5, "soricut": [7, 11], "sort": [4, 5, 8, 11, 12, 14, 37, 38], "sota": 16, "sound": [1, 4, 6, 20], "soupsiev": [37, 38], "sourc": [1, 3, 4, 5, 7, 10, 19, 22, 37, 38], "source_1": 20, "source_2": 20, "source_3": 20, "sources_1": 20, "sources_2": 20, "sources_3": 20, "south": [4, 5, 37, 38], "sow": 22, "space": [2, 7, 9, 10, 11, 12, 13, 14, 16, 20, 21, 22, 24, 30, 31, 33, 34, 36], "spaghetti": 4, "spam": 5, "span": [4, 5, 7, 10, 38], "span_handl": 38, "span_typ": 38, "spanish": 4, "spanner": 4, "spark": 4, "spars": [0, 3, 12, 29, 38], "sparse_embed": 38, "sparsif": 4, "sparsifi": 4, "sparsiti": [2, 4, 9], "spdi": [37, 38], "speak": [4, 12], "speaker": 4, "spealiz": 5, "spec": 38, "specchia": [37, 38], "speci": [], "special": [0, 1, 2, 4, 5, 6, 7, 9, 10, 13, 14, 17, 18, 19, 20, 21, 25, 30, 36, 37, 38], "specialist": 17, "specif": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 30, 36, 37, 38], "specifi": [1, 4, 5, 6, 7, 8, 10, 11, 12, 14, 18, 20, 22, 24, 30, 31, 33, 34, 36, 37, 38], "specifici": 13, "specificlli": 22, "specimen": [37, 38], "speclial": 20, "specul": [0, 2, 8], "sped": 7, "speech": [4, 8, 38], "speed": [1, 2, 4, 5, 6, 7, 20, 21, 25, 30, 36], "speedup": [4, 5], "spell": [5, 7, 20], "spellnet": 4, "spend": [13, 20], "spent": [4, 5], "spink": 4, "spirit": 3, "spite": [37, 38], "split": [2, 4, 5, 11, 16, 27], "split_posit": [32, 35], "splitter": [37, 38], "sponsor": [4, 5], "spontan": [], "spoon": 4, "sport": 4, "spotifi": 38, "sprain": 4, "spread": 4, "spreadsheet": [37, 38], "spur": 0, "sp\u00e4rck": 4, "sql": [4, 38], "sql_join": 38, "sql_table_retriev": 38, "sqlalchemi": [37, 38], "sqlautovectorqueryengin": 38, "sqljoinqueryengin": 38, "sqlrouterqueryengin": 38, "sqrt": [1, 4, 5, 7, 11, 12, 25, 30, 31, 33, 34, 36], "squad": [4, 5, 10], "squar": [4, 5, 7, 12, 30, 31, 33, 34, 36], "squeez": 33, "src": 38, "sri": [37, 38], "srivastava": 4, "srnm": 4, "ssangyong": 8, "sst": 13, "st": [4, 13], "stabil": [1, 4, 30, 31, 33, 34, 36], "stabl": [1, 21, 22, 23, 38], "stablelm": 38, "stabli": 25, "stabliz": [1, 23, 30, 31, 33, 34, 36], "stack": [1, 7, 11, 37, 38], "stackoverflow": [25, 38], "staff": [37, 38], "stage": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 16, 20, 25], "stage1": 21, "stai": [1, 4, 5, 12, 20, 37, 38], "stakehold": [37, 38], "staliz": 1, "stamp": [37, 38], "stamptim": 20, "stan": [37, 38], "stand": [0, 4, 5, 7, 11, 12, 16, 21, 36, 37, 38], "standalon": 38, "standard": [1, 4, 5, 7, 12, 20, 21, 22, 37, 38], "stanford": 4, "stanford_alpaca": [32, 33, 34], "stanislaw": 23, "stanlei": 8, "starch": [4, 5], "start": [1, 4, 5, 6, 7, 8, 10, 11, 13, 14, 20, 22, 23, 24, 38], "start_char_idx": [37, 38], "starter": 38, "starter_exampl": 38, "starter_example_loc": 38, "starter_tool": 38, "startswith": 38, "stat": 27, "state": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 19, 20, 22, 23, 30, 31, 32, 33, 34, 35, 36, 37, 38], "state_dict": [31, 32, 33, 34, 35], "statement": [19, 20, 37, 38], "static": [1, 7, 12, 30, 36, 38], "staticmethod": [30, 36], "station": 4, "statist": [4, 5, 9, 12, 20, 37, 38], "statu": [20, 37, 38], "steam": 12, "steamship": 38, "steep": 6, "stefan": [5, 14], "stefano": 22, "stem": [4, 12, 20, 21], "step": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 32, 33, 34, 35, 36, 37, 38], "step_back_argilla": 38, "stephen": 5, "stepregard": 17, "stepwis": 22, "stern": 4, "steven": [16, 17, 19], "stiennon": 22, "still": [1, 2, 4, 5, 6, 9, 11, 13, 17, 20, 22, 25, 37, 38], "stimul": [37, 38], "stochast": [4, 14, 22, 24], "stock": [1, 4, 20, 38], "stock_market_data_query_engin": 38, "stockton": 12, "stoica": [13, 20], "stomach": [4, 5], "stool": 4, "stop": [4, 5, 7, 10, 13, 20, 25], "stopfilt": 4, "stopper": 4, "stopword": 19, "storag": [13, 20, 37, 38], "storage_context": [37, 38], "storage_context_vector": [37, 38], "storagecontext": [37, 38], "store": [4, 5, 7, 8, 9, 11, 13, 20, 21, 37, 38], "stori": [4, 14, 18], "stork": 13, "stoyanov": [7, 10, 11], "str": [36, 37, 38], "straight": [4, 7, 18, 20], "straightforward": [4, 16, 19, 20], "strand": [4, 5], "strang": [], "strateg": [4, 5], "strategi": [2, 8, 9, 10, 11, 13, 17, 19, 20, 21, 23, 24, 25, 38], "strawberri": 4, "stream": [7, 13, 38], "streamlit": 38, "streamlit_chatbot": 38, "street": [4, 8], "strength": [2, 4, 5, 7, 20, 22, 25, 36, 37, 38], "strengthen": 5, "stress": [37, 38], "stretch": [4, 5, 6], "strict": [31, 33, 34], "strictli": [4, 20, 37, 38], "stride": [4, 32, 33, 34, 35], "strike": 4, "string": [4, 5, 20, 23, 36, 38], "string_iter": 38, "stringifi": 38, "strip": [4, 8, 19, 36], "stripe": 38, "stripe_doc": 38, "striprtf": [37, 38], "strohman": 5, "strong": [4, 5, 6, 13, 22, 38], "stronger": [4, 5], "strongest": [4, 5], "strongli": 25, "struc": 4, "structr": 20, "structur": [0, 1, 2, 4, 5, 6, 7, 8, 11, 12, 16, 19, 20, 23, 25, 37, 38], "structured_data": 38, "structured_image_retriev": 38, "structured_llm": 38, "structured_output": 38, "structured_plann": 38, "structured_predict": 38, "structured_refin": 38, "struggl": [4, 6, 13, 19, 20, 22], "stud": [37, 38], "student": [0, 3, 4, 5, 7], "studi": [0, 1, 4, 5, 6, 7, 8, 11, 12, 16, 17, 22, 37, 38], "studio": 38, "stun": [18, 36], "style": [4, 5, 7, 10, 18, 20, 21, 38], "stylesheet": 38, "su": [1, 2], "sub": [4, 5, 6, 7, 11, 12, 13, 16, 22, 37, 38], "sub_quest": 38, "sub_question_query_engin": 38, "sub_question_weavi": 38, "subbiah": [1, 6, 8, 11], "subclass": 38, "subcompon": [4, 5], "subcutan": 4, "subdivis": [20, 37, 38], "subdoc": 38, "subdoc_summari": 38, "subfigur": 4, "subgradi": 25, "subgraph": 19, "subject": [4, 8, 19, 20, 37, 38], "sublay": [1, 30, 31, 33, 34, 36], "sublinear": 21, "submiss": 38, "submit": [4, 5, 38], "subordin": 20, "subplots_adjust": 27, "subquant": [4, 5], "subqueri": [3, 20], "subquest": 38, "subscrib": 38, "subscript": [4, 11], "subsequ": [0, 3, 4, 5, 6, 13, 14, 22, 37, 38], "subset": [2, 4, 5, 7, 11, 12, 13, 23], "subspac": [1, 4, 11, 13], "substack": 4, "substanti": [2, 4, 13, 21, 23], "substitut": [4, 5], "substr": 4, "subtask": [4, 5], "subtitl": 6, "subtl": [4, 11], "subtop": [4, 5], "subtract": [1, 22], "subunit": 12, "subvector": [4, 5], "subword": [1, 7], "succ": [1, 4, 5, 22], "success": [1, 2, 4, 5, 6, 7, 11, 16, 19, 20, 21, 22, 37, 38], "successfulli": [4, 23, 37, 38], "successor": 6, "succinct": [4, 37, 38], "sucess": 25, "suffer": [4, 5, 7, 8, 23], "suffic": [18, 23], "suffici": [2, 4, 5, 13, 20, 21, 24], "suffix": [4, 12, 16], "sugar": [4, 5], "suggest": [0, 5, 6, 7, 18, 23, 25, 36, 37, 38], "sui": 6, "suit": [2, 4, 7, 8, 11, 20, 25, 37, 38], "suitabl": [1, 4, 5, 10, 13, 20, 22], "sum": [4, 5, 6, 11, 12, 13, 14, 33], "sum_": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 22, 23, 24, 25, 30, 31, 33, 34, 36], "sum_i": [8, 13, 14, 22], "sum_j": [4, 14], "sum_t": 25, "sumit": 1, "summar": [1, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 18, 19, 20, 22, 23, 24, 25, 38], "summari": [1, 2, 4, 5, 13, 19, 20, 37, 38], "summat": [4, 5, 7, 12, 13, 14, 21], "summer": [12, 19], "sump": 4, "sun": [2, 4, 5, 7, 11, 14, 20], "sunshin": [4, 5], "supabas": 38, "supabasevectorindexdemo": 38, "super": [30, 31, 32, 33, 34, 35, 36], "superfici": [8, 20], "superglu": 11, "superior": [4, 20, 22], "superl": 12, "superscript": 24, "supervis": [1, 4, 5, 7, 11, 16, 20, 22, 23, 25], "supervisori": 4, "supplement": [4, 20], "supplementari": 7, "suppli": [4, 5, 19, 37, 38], "support": [1, 4, 19, 20, 21, 30, 31, 33, 34, 36, 37, 38], "supporting_modul": 38, "suppos": [1, 3, 4, 5, 6, 7, 8, 14, 20, 22, 24], "suprem": [37, 38], "suprisinli": 1, "sure": [4, 38], "surfac": [4, 5, 25], "surfer": 4, "surgeon": 13, "surgeri": [37, 38], "surgi": [37, 38], "surgic": [37, 38], "surpass": [37, 38], "surpris": [14, 19], "surprisingli": 7, "surreptiti": [], "surrog": [4, 37, 38], "surround": [4, 7, 12], "survei": [1, 3, 4, 5, 7, 11, 16, 20, 23, 25, 37, 38], "surviv": 19, "susan": 12, "susana": 7, "suscept": 4, "suspect": [37, 38], "sutskev": [5, 6, 8, 10, 11, 12, 25], "sutur": [37, 38], "suzgun": 23, "svg": 38, "svm": 4, "swallow": 4, "swallowl": 4, "swam": 12, "swap": [4, 7], "swape": 4, "swapo": 8, "swaroop": 17, "swd": 22, "swedish": 4, "sweep": 4, "swiglu": [1, 30, 31, 33, 34, 36], "swim": [3, 12], "swish": [1, 30, 31, 33, 34, 36], "swiss": 12, "switch": [4, 5, 7, 20, 37, 38], "switzerland": 12, "sy": [7, 36, 37, 38], "syfhpxcosnyi_6cmwd1w7u04myn1l3h7na5dsb0w7u0h6ntzz4bprgnuufga_saxlbcnrt": [37, 38], "sylvain": [11, 23], "symbol": [1, 4, 5, 6, 7, 8, 10, 11, 12], "symmetr": [4, 5, 16], "symmetri": 4, "symposium": 13, "symptom": [4, 37, 38], "symptom_1": [37, 38], "symptom_2": [37, 38], "synact": 8, "synnaev": 25, "synonym": [3, 4, 5, 16], "synonymi": 4, "syntact": [4, 5, 7, 20], "syntat": 8, "syntax": [4, 7, 20, 37, 38], "syntaxerror": [37, 38], "synthes": [4, 16, 19, 38], "synthesi": [5, 8, 19, 38], "synthet": [16, 20], "syrup": 4, "system": [0, 1, 6, 7, 8, 11, 12, 13, 16, 19, 20, 22, 24, 36, 37, 38], "systemat": [13, 17], "syw": 23, "szegedi": 1, "szu": 25, "t": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 24, 25, 27, 37, 38], "t0": [], "t3blbkfj_qu1cejyslo8ttahtnxwviczgguifyqhu191po4zofik3r8zik4ovn5ts_kzspcaevhkpqj": [37, 38], "t5": [5, 11, 21, 29], "t5layernorm": [30, 31, 33, 34, 36], "t_": [2, 4, 5, 7], "t_1": [4, 11], "t_2": [4, 11], "t_e": 16, "t_f": 16, "t_i": [2, 5, 7, 11, 14], "t_j": 11, "t_m": [4, 11], "t_n": 4, "t_p": 11, "t_q": [4, 5], "tab": [4, 5, 38], "tabindex": 38, "tabl": [1, 3, 4, 5, 8, 10, 11, 12, 13, 17, 19, 20, 21, 22, 23, 38], "tablestor": 38, "tablestoredemo": 38, "tablestorevectorstor": 38, "tablet": 4, "tabs__item": 38, "tabs__link": 38, "tabs__list": 38, "tabular": [3, 4, 12, 38], "tackl": [4, 7, 11, 18, 19, 23], "tag": [4, 7, 20, 36, 38], "tagger": 4, "tahami": [4, 5], "tai": 23, "tail": [3, 4, 5, 8, 14], "tailor": [4, 20], "tair": 38, "tairindexdemo": 38, "taj": 3, "tak": 17, "takao": 9, "take": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 20, 21, 22, 23, 24, 37, 38], "taken": [4, 7, 8, 11, 24, 37, 38], "takeshi": 18, "taliti": [37, 38], "talk": 4, "tan": 2, "tang": [1, 2, 5, 25], "tang2021improv": 4, "tangent": [1, 4], "tanh": [4, 9], "tant": 4, "tao": [2, 5, 23], "target": [2, 4, 5, 6, 7, 10, 11, 12, 16, 21, 22, 23, 24, 25, 30, 32, 33, 34, 36, 38], "target_batch": [32, 33, 34, 35], "target_chunk": 35, "target_id": 35, "target_length": [30, 36], "task": [0, 1, 2, 3, 8, 11, 12, 13, 14, 16, 19, 20, 22, 23, 24, 25, 32, 33, 34, 38], "tast": 4, "tat": 17, "tation": 4, "tatsu": [32, 33, 34], "tau": [5, 7, 16, 24], "tavili": 38, "tavily_research": 38, "tax": 20, "taylor": 13, "tcp": [4, 5], "tctcolbertv2": 4, "teach": [4, 5, 7, 16, 23, 25, 37, 38], "teacher": [7, 22], "teacherstudentdistillationschem": 4, "team": [20, 22], "teaspoon": 4, "tech": [1, 4], "techer": [4, 5], "technic": [1, 2, 4, 20, 21, 25, 37, 38], "techniqu": [0, 1, 2, 3, 5, 7, 10, 11, 12, 18, 20, 23, 25, 29, 30, 31, 33, 34, 36, 37, 38], "technol": [37, 38], "technologi": [0, 5, 8, 11, 12, 20, 37, 38], "tediou": 4, "tei": 38, "tei_rerank": 38, "telegram": 38, "telemedicin": [37, 38], "telephon": [3, 20, 37, 38], "tell": [4, 5, 20], "tem": 20, "temperament": 4, "temperatur": [3, 4, 5, 7, 16, 17, 36, 37, 38], "templat": [16, 37, 38], "template_var": [37, 38], "template_var_map": [37, 38], "tempor": [3, 19, 38], "temporari": 21, "tempt": 4, "ten": [4, 6, 7, 25], "tenac": [37, 38], "tenanc": 38, "tenant": 38, "tencent": 38, "tencentvectordb": 38, "tencentvectordbindexdemo": 38, "tend": [4, 5, 8, 10, 12, 14, 20, 25, 37, 38], "tendenc": [3, 4, 5, 17], "tengyu": 12, "tens": 12, "tensor": [30, 31, 32, 33, 34, 35, 36], "tensorfloat": 21, "tensorflow": 12, "tensorrt": 38, "term": [1, 2, 3, 7, 8, 11, 12, 13, 14, 16, 18, 20, 22, 25, 27, 37, 38], "termbas": 4, "termin": [20, 24], "terminologi": 20, "terms_definitions_tutori": 38, "terri": 22, "terribl": 18, "terribli": 19, "tesla": [20, 38], "tesla_10q_t": 38, "test": [1, 4, 5, 6, 7, 8, 12, 16, 17, 20, 38], "test_data_compon": [32, 33, 34, 35], "test_model": [32, 35], "teven": 1, "texa": 4, "text": [0, 1, 2, 3, 7, 8, 9, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], "text_data": [32, 33, 34, 35], "text_embedding_infer": 38, "text_embeddings_infer": 38, "text_encod": 16, "text_generation_infer": 38, "text_qa": [37, 38], "text_qa_templ": [37, 38], "text_templ": [37, 38], "text_to_imag": 38, "textbook": [4, 5], "textemb": 38, "textit": 12, "textual": [4, 5, 6, 10, 16], "textur": [37, 38], "textwidth": 4, "textwrap": 36, "textwrapp": 36, "tf": [4, 12], "tf32": 21, "tfidfsimilar": 4, "th": [1, 2, 4, 5, 7, 11, 13], "than": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 18, 20, 21, 22, 23, 24, 25, 36, 37, 38], "thang": 7, "thank": [1, 4, 8, 10], "theater": 6, "thedist": 4, "thei": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 36, 37, 38], "them": [1, 4, 5, 8, 10, 11, 12, 13, 16, 19, 20, 21, 23, 25, 30, 36, 37, 38], "themselv": 4, "theorecti": 22, "theorem": [4, 38], "theoret": [4, 9, 22], "theori": [1, 4, 5, 11, 22], "thereaft": 24, "therebi": [1, 4, 17], "therefor": [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 20, 21, 22, 24, 25], "thesi": [], "theta": [1, 3, 6, 7, 8, 12, 14, 22, 23, 25, 30, 31, 33, 34, 36], "theta_": [1, 7, 8, 25], "theta_1": [1, 7], "theta_2": [1, 7], "theta_i": 1, "theta_k": [1, 25], "theta_q": 1, "theta_x": 1, "thi": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 31, 33, 34, 36, 37, 38], "thibaut": [1, 22], "thin": [18, 36], "thing": [4, 5, 12, 19], "think": [4, 12, 17, 18], "thinnest": 19, "third": [3, 4, 5, 7, 24, 37, 38], "thirti": 7, "thoma": [1, 7, 11], "thorn": 22, "thorough": 4, "thorp": 1, "those": [1, 4, 5, 7, 8, 12, 13, 19, 20, 22, 37, 38], "though": [4, 5, 8, 37, 38], "thought": [0, 7, 8, 17, 19, 20, 23, 38], "thousand": [1, 4, 5, 6, 25], "thread": [4, 38], "threadlik": [4, 5], "threat": [37, 38], "three": [1, 4, 5, 6, 7, 11, 12, 16, 19, 20, 21, 22, 23, 25], "threshold": [4, 8, 12, 14], "through": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 16, 17, 19, 20, 22, 23, 24, 37, 38], "throughout": [4, 6, 7, 25], "throughput": 13, "thu": [1, 4, 5, 7, 8, 9, 11, 12, 13, 14, 17, 19, 21, 23], "ti": 1, "tian": [1, 2], "tianhang": 20, "tianjun": 20, "tianqi": 21, "tianyang": 5, "tianyi": [1, 25], "tianyu": 2, "tick": 27, "tick_label": 27, "tidb": 38, "tidbvector": 38, "tie": 5, "tie_word_embed": [31, 33, 34], "tieyan": [1, 11], "tifi": 4, "tific": [37, 38], "tificatedeath": [37, 38], "tight": 4, "tightli": 5, "tijmen": 13, "tiktoken": [32, 33, 34, 35, 37, 38], "tild": [4, 5, 11, 12, 24, 25], "tim": [6, 8, 11, 13], "time": [1, 2, 3, 5, 6, 7, 8, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 36, 37, 38], "time_weight": 38, "timelin": 1, "timeout": [37, 38], "timescal": 38, "timescale_vector_autoretriev": 38, "timescalevector": 38, "timestamp": 20, "timeweightedpostprocessordemo": 38, "timoth": 22, "timoth\u00e9": 1, "tini": 7, "tinybert": 11, "tissu": 4, "titl": [4, 5, 6, 18, 20, 27, 36, 37, 38], "titles": 27, "tiwari": [5, 7], "tli": 22, "tll": [4, 5], "tlm": 7, "tmp": 27, "toc": 38, "todai": [4, 6], "todo": 4, "togeth": [4, 5, 6, 9, 11, 12, 13, 19, 20, 22, 37, 38], "toggl": 38, "tok": [4, 7], "token": [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 30, 32, 33, 34, 35, 36, 38], "token_count": 38, "token_emb": [32, 35], "token_embed": [32, 35], "token_id": 35, "token_text_splitt": 38, "tokencountinghandl": 38, "tokenizer_nam": [32, 33, 34], "tokens_seen": [32, 33, 34, 35], "tokyo": 3, "tol": 24, "toler": [20, 24], "toll": [4, 5], "tom": [1, 5, 6, 8, 11, 20, 25], "toma": [5, 9, 12], "tomorrow": 8, "tong": 11, "tongzhou": 5, "tonic": 38, "tonic_valid": 38, "tonicvalidateevalu": 38, "too": [2, 4, 5, 7, 8, 13, 20, 22, 25], "took": [4, 5, 22], "tool": [0, 1, 4, 20, 37, 38], "tool_cal": 36, "tool_retriever_rout": 38, "tool_runn": 38, "tool_spec": 38, "toolbelt": [37, 38], "toolhous": 38, "toolhouse_llamaindex": 38, "top": [1, 2, 4, 5, 7, 8, 10, 11, 12, 16, 19, 20, 21, 22, 25, 27, 38], "topic": [7, 12, 14, 19, 20, 38], "topic_pars": 38, "topicnodepars": 38, "topk": 2, "topologi": 20, "tor": [4, 5], "torch": [30, 31, 32, 33, 34, 35, 36], "torch_dtyp": [31, 33, 34], "tori": 6, "toronto": [4, 5, 25], "total": [1, 2, 4, 5, 7, 8, 11, 12, 13, 16, 20, 24, 25], "totext": 16, "tough": 12, "tougher": 12, "toujour": 6, "tour": [4, 5], "toutanova": [5, 7, 11], "touvron": 22, "toward": [0, 2, 4, 5, 7, 10, 21, 22, 24, 25, 37, 38], "tower": [3, 4, 24], "tqdm": [37, 38], "tr": [4, 5, 24], "tra": 3, "tracabl": 20, "trace": [4, 19, 20, 38], "traceback": [27, 34], "tracer": 38, "tracing_and_debug": 38, "track": [14, 20], "track_token_seen": [32, 33, 34, 35], "tractabl": [4, 25], "trade": [2, 4, 5], "tradeoff": 4, "tradict": 20, "tradit": [1, 6, 9, 13, 19, 20, 22, 23, 36, 37, 38], "tradition": 11, "traditional_invertedlist": 4, "traditionalirengin": 4, "traffic": [4, 16], "train": [0, 1, 2, 3, 6, 8, 11, 12, 13, 14, 17, 18, 19, 20, 23, 30, 31, 36, 37, 38], "train_data": [32, 35], "train_dpo": 33, "train_load": [32, 33, 34, 35], "train_loss": [32, 33, 34, 35], "train_main": [32, 33, 34, 35], "train_model": [], "train_model_epoch": [32, 33, 34, 35], "train_ratio": [32, 35], "train_set": [32, 33, 34, 35], "trainabl": [3, 4, 5, 23], "trajectori": [22, 24], "tran": [37, 38], "trane": 1, "transact": [5, 12], "transcript": [4, 38], "transfer": [4, 5, 6, 7, 10, 16, 20, 23, 25, 37, 38], "transform": [0, 3, 6, 7, 10, 13, 16, 20, 21, 23, 25, 29, 30, 31, 33, 34, 36, 38], "transformer_backbon": [32, 35], "transformerlay": [6, 32, 35], "transformers_vers": [31, 33, 34], "transformsev": 38, "transfrom": 3, "transit": [4, 8, 22, 24, 37, 38], "translanguag": 7, "translat": [0, 1, 4, 7, 8, 10, 11, 14, 21, 22, 23, 25, 38], "transmiss": [37, 38], "transpar": [4, 18, 19, 20], "transpos": [1, 30, 31, 32, 33, 34, 35, 36], "transposit": 4, "trap": 38, "travers": [4, 19, 20], "tre": [37, 38], "treat": [1, 4, 5, 8, 12, 20, 37, 38], "treatment": [1, 4, 37, 38], "treatment_1": [37, 38], "treatment_2": [37, 38], "tree": [4, 5, 6, 8, 20, 38], "tree_summar": [37, 38], "treebank": [6, 8], "treival": 4, "trello": 38, "tremend": [4, 5], "trend": [4, 5, 6, 37, 38], "trevor": 5, "tri": [4, 5], "triangl": [4, 11], "triangleq": [4, 5, 24], "triangleright": 19, "triangular": [30, 36], "trick": [3, 4, 5, 8, 12, 22], "tricki": 4, "trier": 9, "trigger": [19, 20], "trigram": [4, 5, 8], "trillion": [0, 2, 21, 25], "trinh": 19, "trip": [20, 38], "tripl": [4, 5, 7, 20], "tripleloss": 7, "triplet": 19, "triton": 38, "triu": [30, 32, 35, 36], "trivial": [4, 14, 20], "triviaqa": 6, "trmd": 4, "trmdcolbert": 4, "troubl": 4, "troubleshoot": 20, "true": [3, 4, 5, 8, 14, 16, 22, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38], "trueli": 4, "truitt": 19, "trulen": 38, "trulens_eval_pack": 38, "truli": [19, 20], "truncat": [4, 5, 7, 8, 12, 20, 32, 33, 34], "trunk": 25, "trust": [19, 37, 38], "trustworthi": [4, 38], "truth": [2, 4, 5, 16, 17, 18, 20, 22, 36], "try": [4, 18, 20, 21, 36, 38], "tsai": 5, "tsj": [4, 5], "tsv": 27, "tt": [21, 37, 38], "tter": 5, "tu": [6, 11], "tulloch": 25, "tumor": 4, "tun": 23, "tunabl": 4, "tune": [0, 1, 2, 3, 4, 5, 11, 13, 14, 16, 17, 18, 22, 25, 38], "tupl": [4, 5, 18, 22, 24, 30, 31, 32, 33, 34, 35, 36], "turbo": [37, 38], "ture": 4, "turn": [4, 5, 12, 22, 24, 38], "turnov": [37, 38], "tutori": [19, 20, 38], "tv": 4, "tweet": [4, 5], "twice": [4, 5, 14], "twin": 5, "twinbert": [4, 5], "twitter": [25, 38], "twitterdemo": 38, "twizmer": 4, "two": [1, 2, 3, 6, 8, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "twoparadigm": 4, "tworek": 25, "txt": [32, 35], "txtai": 38, "txtaiindexdemo": 38, "ty": 12, "type": [1, 2, 3, 7, 10, 11, 13, 16, 17, 19, 20, 23, 25, 30, 31, 32, 33, 34, 35, 37, 38], "typeform": 38, "typeof": 38, "typescript": 38, "typesens": 38, "typesensedemo": 38, "typeset": 38, "typic": [1, 2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 36], "typing_extens": [37, 38], "typing_inspect": [37, 38], "typo": 4, "typograph": 4, "typolog": 7, "tze": [5, 8, 17], "u": [0, 1, 2, 4, 5, 6, 8, 9, 11, 12, 13, 14, 19, 20, 24, 37, 38], "u_": [4, 5], "u_1": 4, "u_2": 4, "u_i": 4, "u_k": 4, "u_q": 13, "u_t": 4, "ual": 4, "ubiquit": 4, "ubuntu": 27, "uhdarch": 4, "uk": [37, 38], "ukasz": [5, 11], "ukrainian": 19, "ul": 38, "ultim": [2, 4, 5, 6, 7, 24], "un": [4, 5, 6, 7, 11, 22], "unabl": 4, "unambigu": [4, 37, 38], "unattain": 0, "unavail": 24, "unbias": [8, 25], "unbound": [1, 38], "unbound_funct": 38, "uncertainti": 22, "unchang": [7, 17], "unclear": [4, 5, 20], "unclick": [4, 5], "uncommon": [12, 14], "unconvent": 1, "uncoordin": [37, 38], "uncorrupt": 11, "uncov": [3, 4], "undefin": [4, 38], "under": [2, 4, 5, 6, 7, 8, 22, 23, 24, 25, 30, 36, 37, 38], "underbrac": [1, 4, 5, 7, 12, 21, 22, 23, 30, 31, 33, 34, 36], "underflow": 21, "undergo": [4, 5, 11, 25], "undergon": [37, 38], "underli": [0, 4, 10, 20, 24], "underload": 2, "underneath": [37, 38], "underperform": 6, "underscor": [37, 38], "underset": 14, "understand": [0, 1, 2, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19, 22, 25, 37, 38], "understood": [4, 7, 8, 19], "undesir": [20, 22, 23], "undoubtedli": 13, "unembed": 25, "unequivoc": 3, "uneth": 12, "uneven": 2, "unevenli": 2, "unexpectedli": 22, "unexplain": 4, "unfairli": 6, "unforgiv": 4, "unfortun": [4, 5], "unhealthi": 4, "uni": [9, 10, 12], "unicod": [1, 4], "unicoil": 4, "unifi": [1, 5, 7, 10, 11, 12, 16, 38], "uniform": [2, 4, 5, 8, 12, 25, 37, 38], "uniformli": [1, 4, 5, 13, 14], "unimod": 16, "uninstal": [37, 38], "unintend": 22, "unintention": 7, "unintuit": 4, "union": [4, 30, 31, 32, 33, 34, 35, 36], "uniqu": [4, 5, 17, 24], "unit": [1, 3, 4, 5, 7, 11, 12, 13, 20, 21, 37, 38], "univari": 4, "univers": [5, 6, 7, 8, 10, 11, 14, 25, 37, 38], "unk": 8, "unknown": [4, 5, 8], "unlabel": [1, 6, 7], "unless": [20, 37, 38], "unlik": [0, 1, 4, 5, 20, 22, 23], "unlimit": [9, 22, 38], "unlock": [6, 23], "unnatur": 1, "unnecessari": [4, 5, 19], "unnecessarili": 13, "unnorm": [1, 7], "unobserv": 8, "unpack": [30, 36], "unparallel": [4, 5], "unpopular": [4, 5], "unpreced": 0, "unpredict": 22, "unrealist": 8, "unrecord": 20, "unrel": [4, 5], "unsaf": 22, "unsafeviewbackward0": [32, 35], "unseen": [1, 4, 8, 9, 18, 22, 23], "unselect": 20, "unsequeez": 33, "unsmooth": 8, "unsqueez": [30, 31, 32, 33, 34, 35, 36], "unsqueeze_dim": [30, 31, 33, 34, 36], "unstabl": [1, 23], "unstruct": 20, "unstructr": 20, "unstructur": [4, 5, 20, 25, 38], "unstructured_el": 38, "unsupervis": [4, 5, 7, 8, 10, 11], "unterthin": 11, "until": [4, 5, 14, 22, 24, 25, 27], "untrac": 20, "untrustworthi": 3, "unus": [13, 21], "unwant": 22, "up": [0, 1, 4, 5, 6, 7, 8, 10, 11, 12, 14, 16, 19, 20, 21, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "up_proj": [30, 31, 32, 33, 34, 35, 36], "upcast": [30, 31, 33, 34, 36], "updat": [1, 2, 4, 5, 6, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 32, 35, 37, 38], "updateth": 22, "upgrad": 38, "upload": [37, 38], "uploading_llama_dataset": 38, "upon": [1, 2, 4, 5, 20], "upper": [4, 11, 30, 36, 37, 38], "upset": [4, 5], "upstag": 38, "upstash": 38, "upstashvectordemo": 38, "uptrain": 38, "uptraincallback": 38, "upward": 6, "upweight": 22, "uri": [37, 38], "url": [1, 2, 5, 6, 7, 8, 9, 11, 13, 17, 21, 22, 23, 32, 33, 34, 35, 38], "urllib": [32, 33, 34, 35], "urllib3": [37, 38], "urlopen": [32, 33, 34, 35], "urvashi": 7, "us": [2, 3, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38], "usa": [4, 37, 38], "usag": [1, 4, 5, 7, 13, 16, 18, 19, 20, 21, 38], "usage_custom": 38, "usage_docu": 38, "usage_metadata_extractor": 38, "usage_nod": 38, "usage_pattern": 38, "usage_pattern_retriev": 38, "usage_standalon": 38, "use_cach": [30, 31, 33, 34, 36], "use_cas": 38, "use_mrop": [31, 33, 34], "usecas": 38, "user": [4, 5, 14, 18, 19, 20, 21, 23, 34, 36, 37, 38], "using_llm": 38, "usual": [1, 4, 5, 6, 7, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25], "uszkoreit": [5, 11], "utah": [4, 5], "utf": [1, 32, 33, 34, 35, 38], "util": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 16, 17, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38], "uv": 12, "uz": 5, "v": [1, 3, 4, 5, 7, 8, 9, 11, 13, 14, 17, 19, 21, 23, 37, 38], "v0": [27, 38], "v0_10_0_migrat": 38, "v1": [22, 38], "v2": [2, 38], "v4": 22, "v5": 22, "v_": [1, 4, 5, 12, 24, 25], "v_c": 12, "v_i": [1, 12], "v_j": 12, "v_k": 25, "v_proj": [30, 31, 33, 34, 36], "v_t": 12, "v_w": 12, "vacat": 19, "vagu": [4, 37, 38], "vakili": 5, "val_data": [32, 35], "val_load": [32, 35], "val_loss": [32, 33, 34, 35], "vald": 7, "valid": [0, 1, 4, 5, 8, 19, 20, 37, 38], "valium": 4, "vall": 22, "vallei": 25, "valter": 23, "valu": [1, 2, 3, 4, 5, 7, 8, 11, 12, 13, 14, 20, 21, 22, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "valuabl": [4, 5], "value_st": [30, 31, 33, 34, 36], "valueiterationalg": 24, "van": [11, 38], "vancouv": 4, "vanilla": [1, 20, 21, 23], "vanish": [1, 4, 5], "vanna": 38, "var": [32, 35, 38], "vari": [1, 2, 4, 5, 13, 18, 20, 25, 37, 38], "variabl": [1, 4, 8, 12, 18, 24, 34, 38], "varianc": [1, 4, 5, 21, 25, 30, 31, 33, 34, 36], "variance_epsilon": [30, 31, 33, 34, 36], "variant": [4, 5, 7, 8, 10, 11, 25, 38], "variat": [1, 8, 12, 20, 25, 30, 31, 33, 34, 36], "varieti": [3, 4, 5, 13, 20, 38], "variou": [0, 1, 2, 4, 5, 8, 11, 14, 16, 19, 20, 22, 23, 25, 37, 38], "vast": [0, 1, 4, 5, 7, 12, 37, 38], "vastli": [4, 5, 7, 14, 24], "vaswani": [5, 11], "vaue": 1, "vault": 4, "vc": 14, "vdot": [1, 11], "ve": [4, 7, 10, 19, 20], "vearch": 38, "vearchdemo": 38, "vec": [4, 5], "vechtomova": 5, "vecotr": 11, "vectara": 38, "vectara_auto_retriev": 38, "vectara_queri": 38, "vectara_rag": 38, "vectarademo": 38, "vector": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 16, 19, 20, 23, 38], "vector_databas": 38, "vector_db": 38, "vector_index": [37, 38], "vector_memori": 38, "vector_rag": [], "vector_rag_query_engin": [37, 38], "vector_stor": [37, 38], "vector_store_index": 38, "vectordb": 38, "vectorstor": 38, "vectorstoreindex": [37, 38], "vehicl": [4, 5, 23], "vein": 4, "veloc": 25, "venkatesh": 21, "verb": [4, 5, 8, 12], "verbos": [4, 5, 20, 37, 38], "verdict": [32, 35], "veri": [1, 4, 5, 6, 12, 14, 19, 20, 21, 25, 37, 38], "verif": [19, 20], "verifi": [19, 20, 37, 38], "verma": 5, "vers": 4, "versa": [4, 5, 14], "versatil": [0, 1, 23], "versicherung": 4, "version": [4, 5, 7, 8, 11, 12, 22, 34, 37, 38], "vertex": 38, "vertex_ai_search_retriev": 38, "vertex_embedding_endpoint": 38, "vertex_endpoint": 38, "vertexai": 38, "vertexai_search": 38, "vertexaidemo": 38, "vertexaivectorsearch": 38, "vertexaivectorsearchdemo": 38, "vertic": [4, 5, 23], "veselin": [7, 11], "vespa": 38, "vespaindexdemo": 38, "vestig": [37, 38], "via": [2, 3, 6, 7, 8, 9, 10, 11, 12, 16, 17, 20, 22, 23, 24, 25], "viabl": 24, "vice": [4, 5, 14, 37, 38], "vicin": 4, "victor": 7, "vicuna": 38, "video": [4, 5, 16, 23, 37, 38], "videodb": 38, "videodb_retriev": 38, "view": [4, 5, 6, 7, 12, 22, 24, 30, 31, 32, 33, 34, 35, 36], "viewbox": 38, "viewport": 38, "vigor": 4, "vijayakumar": 14, "vincent": [9, 20, 23], "vinci": 19, "vinyal": [5, 7], "violat": 4, "viral": 4, "virginia": [4, 5], "virtu": 4, "virtuou": 38, "visdial": 16, "vishrav": 7, "vision": 11, "visit": 22, "visitor": [37, 38], "visual": [4, 5, 16, 18, 22, 36], "visuallanguag": 16, "vit": 16, "vital": [37, 38], "vitamin": 4, "viterbi": 4, "vl": 38, "vladimir": 5, "vllm": 38, "vocab": 7, "vocab_s": [30, 31, 32, 33, 34, 35, 36], "vocabulari": [4, 6, 7, 9, 10, 11, 12, 14, 20, 22, 25, 30, 31, 32, 33, 34, 35, 36], "void": 38, "volum": [4, 5, 17, 20, 21, 37, 38], "voorhe": [4, 5], "voronoi": [4, 5], "voss": 22, "vote": [4, 5, 17], "vowel": 4, "voyag": 38, "voyage_query_engin": 38, "voyageai": 38, "voyageai_rerank": 38, "voyageairerank": 38, "vp": 4, "vpn": 4, "vqa": 16, "vqg": 16, "vr": 7, "vscodecontentref": [30, 36], "vsp": [4, 5, 11], "vtgs20": [4, 5], "vulner": [4, 5], "vulnerbl": 22, "vw": [1, 11], "vw_i": 11, "w": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 22, 23, 32, 33, 34, 35, 37, 38], "w3": 38, "w32a8": 13, "w8a32": 13, "w8a8": 13, "w_": [4, 6, 7, 8, 9, 11, 12, 13], "w_0": [8, 11], "w_1": [1, 4, 7, 8, 11, 12], "w_2": [1, 4, 7, 8, 11, 12, 30, 31, 33, 34, 36], "w_c": 12, "w_g": 2, "w_i": [4, 5, 8, 12, 13, 14, 16], "w_j": [1, 4, 5, 8, 12, 13], "w_k": [12, 23, 32, 35], "w_l": 22, "w_m": 12, "w_n": [4, 8], "w_o": [1, 13, 21, 32, 35], "w_q": [4, 13, 23, 32, 35], "w_quant": 13, "w_t": [9, 12, 16], "w_v": [23, 32, 35], "w_xx_t": 9, "w_y": 9, "wa": [1, 3, 4, 5, 6, 7, 8, 11, 16, 18, 19, 20, 21, 22, 23, 25, 36, 37, 38], "wachter": 8, "wai": [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 16, 17, 19, 20, 22, 23, 24, 25, 37, 38], "waii": 38, "wainwright": 22, "walk": [3, 4, 9, 12, 38], "walker": 38, "wall": [8, 19], "walli": 23, "wandb": 38, "wandbcallbackhandl": 38, "wang": [1, 2, 4, 5, 7, 11, 17, 18, 19, 20, 22, 23, 25, 37, 38], "wang2018lambda": 4, "wang2020understand": 4, "wang2021bert": 4, "wangd": 2, "wanjia": 2, "want": [4, 5, 11, 13, 14, 18, 19, 22], "war": [3, 19], "ward": [37, 38], "warm": 1, "warranti": 6, "wash": [37, 38], "washington": [4, 5], "wasn": [], "wasser": 11, "wast": [4, 13, 21], "watch": [4, 7], "water": [4, 11, 12], "watsonx": 38, "watt": 4, "wave": [1, 11], "wavebreakmedia": 4, "wavelength": [1, 11], "wayn": [1, 5, 25], "wbz": 23, "we": [0, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38], "weak": [4, 5, 22], "weaker": 4, "weakest": [4, 5], "weakli": [4, 5], "wealth": [37, 38], "weather": [4, 5, 20, 38], "weaviat": 38, "weaviate_existing_data": 38, "weaviatedemo": 38, "weaviateindex_auto_retriev": 38, "weaviateindex_metadata_filt": 38, "weaviateindexdemo": 38, "web": [4, 5, 6, 16, 19, 20, 25, 37, 38], "webimagetext": 16, "webpag": 20, "webpagedemo": 38, "webquest": 6, "websit": [4, 6, 11], "webson": 23, "webtext": [6, 11, 16, 25], "webtext2": 6, "wednesdai": 4, "week": 10, "weekli": 4, "wei": [1, 2, 4, 5, 7, 10, 11, 17, 18, 20, 22, 23], "weigh": [4, 5], "weight": [2, 4, 6, 7, 8, 9, 12, 13, 20, 21, 23, 30, 31, 33, 34, 36, 38], "weight_decai": [32, 33, 34, 35], "weiglit": 13, "weilin": 22, "weishung": 17, "weissenborn": 11, "weizhu": 23, "welcom": [37, 38], "welind": 22, "well": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 20, 21, 22, 23, 37, 38], "wen": [1, 2, 5, 25], "wenfeng": 2, "wenhao": 5, "wenhui": 7, "wenji": 22, "wenjun": 2, "wenpeng": [16, 23], "wenqin": 2, "went": [4, 7, 12], "wentao": 2, "wenwu": 11, "wenzek": 7, "were": [0, 1, 4, 5, 8, 11, 16, 18, 19, 21, 22, 23, 25, 36, 37, 38], "weslei": 5, "wesolowski": 25, "west": [6, 8, 11], "weston": [5, 12], "wettest": [4, 5], "wh": [4, 5, 12], "what": [0, 3, 4, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 27, 36, 37, 38], "whatsapp": 38, "whe": 12, "when": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 22, 23, 25, 30, 36, 37, 38], "whenev": [22, 25], "where": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "wherea": [1, 4, 5, 6, 13], "whether": [0, 4, 5, 7, 10, 16, 19, 20, 22, 30, 36, 37, 38], "which": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 33, 34, 36, 37, 38], "while": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 25, 36, 37, 38], "white": [4, 22, 38], "whitegrid": 27, "whitespac": 4, "whl": [37, 38], "who": [3, 4, 20, 37, 38], "whole": [2, 3, 4, 7, 11, 21, 22, 23, 24, 25, 37, 38], "whom": [37, 38], "whose": [1, 4, 5, 8, 11, 12, 16, 23], "why": [7, 18, 20, 22, 23, 37, 38], "wi20": [4, 5], "wide": [0, 1, 4, 5, 6, 7, 8, 11, 16, 17, 18, 21, 23, 36, 37, 38], "wider": [3, 4, 7, 13], "widespread": [1, 4, 5, 37, 38], "widetild": 4, "widget": [37, 38], "width": [1, 13, 14, 36, 38], "wiki": [4, 38], "wikipedia": [4, 5, 6, 7, 8, 11, 16, 20, 25, 38], "wikipediaread": 38, "wikipidia": 7, "wikitext": [1, 8], "wilcox": [37, 38], "wild": 4, "william": [1, 2, 23], "willing": 4, "win": [4, 22], "win_amd64": [37, 38], "window": [3, 4, 5, 6, 9, 12, 20, 21, 25, 35, 38], "wine": 12, "wing": 4, "winner": [4, 6], "wip": [29, 38], "wisconsin": [37, 38], "wise": [6, 7, 11, 13, 22, 23, 38], "wish": 4, "wit": [0, 16], "within": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 19, 20, 22, 37, 38], "without": [1, 2, 3, 4, 5, 6, 7, 9, 11, 13, 14, 16, 18, 19, 20, 23, 24, 25], "wmd": 1, "wolf": [7, 12], "wolff": 13, "wolfgang": 7, "wolfram": 38, "wolfram_alpha": 38, "wolski": 22, "woman": 12, "won": [4, 20, 23], "wonder": 4, "wong": 1, "wook": 16, "woosuk": 13, "word": [1, 7, 9, 10, 11, 13, 14, 16, 18, 20, 22, 23, 25, 29, 37, 38], "word2vec": [4, 5, 7], "wordcloud": 27, "wordlift": 38, "wordliftdemo": 38, "wordnet": [4, 16, 20], "wordpiec": [4, 5, 7], "wordpress": 38, "work": [1, 4, 5, 6, 10, 12, 13, 19, 20, 21, 23, 25], "workaround": 38, "worker": 38, "workersai": 38, "workflow": [20, 38], "workflows_cookbook": 38, "workshop": 5, "world": [0, 1, 3, 4, 5, 6, 8, 18, 20, 23, 24, 25, 36, 37, 38], "worldwid": [37, 38], "worri": 38, "wors": [4, 5, 21], "worst": [4, 5], "worth": [4, 11, 37, 38], "worthi": 19, "would": [0, 1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 24, 37, 38], "wouldn": 19, "wrap": 36, "wrapped_text": 36, "wrapper": 36, "wrapt": [37, 38], "wright": [37, 38], "wrist": 4, "write": [0, 1, 4, 5, 8, 12, 13, 14, 16, 17, 18, 19, 22, 24, 32, 33, 34, 35, 36, 38], "writer": [4, 8], "written": [4, 7, 8, 12, 13, 37, 38], "wrong": [4, 22], "wrote": [4, 6, 22], "wsc": 7, "wspace": 27, "wta": 4, "wu": [2, 5, 6, 7, 8, 10, 11, 13, 16, 19, 22, 23, 25], "ww": [17, 18, 23], "wwd": 7, "www": [4, 22, 38], "wyq": 20, "wzc": 22, "x": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 38], "x1": [30, 31, 33, 34, 36], "x2": [30, 31, 33, 34, 36], "x_": [4, 5, 6, 7, 12, 13, 25], "x_0": 22, "x_1": [4, 6, 7, 11, 23, 25], "x_2": [11, 23], "x_i": [1, 11, 23, 30, 31, 33, 34, 36], "x_j": 4, "x_m": [4, 22, 23], "x_n": 11, "x_p": 11, "x_t": [4, 6, 7, 9, 25], "xa0": [37, 38], "xa045": [37, 38], "xa0a": [37, 38], "xa0administr": [37, 38], "xa0adopt": [37, 38], "xa0audit": [37, 38], "xa0bush": [37, 38], "xa0challeng": [37, 38], "xa0clin": [37, 38], "xa0compli": [37, 38], "xa0data": [37, 38], "xa0depart": [37, 38], "xa0develop": [37, 38], "xa0do": [37, 38], "xa0emr": [37, 38], "xa0futur": [37, 38], "xa0implement": [37, 38], "xa0improv": [37, 38], "xa0leg": [37, 38], "xa0med": [37, 38], "xa0pap": [37, 38], "xa0perceiv": [37, 38], "xa0proc": [37, 38], "xa0south": [37, 38], "xa0technolog": [37, 38], "xa0ther": [37, 38], "xa0typ": [37, 38], "xa0year": [37, 38], "xavier": 22, "xfg": 22, "xi": 4, "xia": [2, 5, 7, 11, 22], "xiang": 23, "xiangkun": 20, "xiangyang": 5, "xiangyu": 2, "xianzu": 2, "xiao": [2, 7, 11, 20], "xiaodan": 7, "xiaodong": [2, 5], "xiaohan": 2, "xiaohua": 11, "xiaohui": 23, "xiaojin": 2, "xiaokang": 2, "xiaolei": [1, 25], "xiaoqi": 7, "xiaosha": 2, "xiaotao": 2, "xiaowen": 2, "xiaoxiang": 2, "xie": [2, 23], "xin": [1, 2, 5, 7, 25], "xinfer": 38, "xinference_local_deploy": 38, "xinference_rerank": 38, "xing": [1, 11], "xingchao": 2, "xingkai": 2, "xingwu": 5, "xinlei": 5, "xinnan": 2, "xintao": 20, "xinxia": 2, "xinyi": 2, "xinyu": [1, 2, 20, 25], "xinyuan": 2, "xinyun": [17, 23], "xiong": [1, 2, 5, 10, 11, 16, 20], "xiong2017end": 4, "xiong2020approxim": 4, "xipeng": [1, 5], "xiubo": 5, "xlabel": 27, "xlm": 6, "xml": 4, "xmln": 38, "xorbit": 38, "xsum": 10, "xtick": 27, "xtreme": 7, "xu": [2, 4, 21, 22, 23], "xuanhui": 5, "xue": 2, "xuecheng": 2, "xueqi": 5, "xuezhi": [17, 18, 23], "xuheng": 2, "xv": [1, 30, 31, 33, 34, 36], "xw": [1, 23], "xw_1": [1, 30, 31, 33, 34, 36], "xwvd20": 11, "xxl": [4, 5], "xxq": 23, "xyh": [1, 11], "y": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 19, 20, 22, 23, 25, 27, 37, 38], "y_": [4, 5, 9, 14, 19, 22, 23], "y_1": [4, 5, 11, 14, 22, 23], "y_2": [4, 5, 11, 22, 23], "y_3": [4, 5], "y_4": [4, 5], "y_5": [4, 5], "y_i": [4, 5, 11, 22, 23], "y_j": 23, "y_l": 22, "y_m": 11, "y_n": [14, 23], "y_p": 11, "y_t": [7, 14, 19, 22, 23], "y_w": 22, "yafu": 23, "yahoo": [4, 38], "yahoo_fin": 38, "yamada": 4, "yan": [2, 5, 19, 22], "yandexgpt": 38, "yanen": 4, "yang": [1, 2, 4, 5, 7, 11, 13, 20, 21, 23, 25], "yang2018anserini": 4, "yanghua": 20, "yangi": [34, 37, 38], "yangq": 25, "yanhong": 2, "yann": 13, "yanp": [2, 23], "yanqi": [5, 10], "yanyan": [1, 11], "yao": [2, 5], "yaofeng": 2, "yaohui": 2, "yarl": [37, 38], "yashunin": 5, "yate": 5, "ye": [2, 5, 19, 22], "year": [0, 1, 3, 4, 5, 8, 11, 19, 20, 37, 38], "yeast": 4, "yellow": [1, 3, 4], "yelong": [5, 23], "yelp": 38, "yelysei": 13, "yet": [4, 5, 14, 30, 36], "yew": 13, "yexpect": [37, 38], "yfl18": 5, "ygzl24": 19, "yi": [2, 5, 20, 22, 23, 37, 38], "yichao": 2, "yichun": 7, "yield": [0, 1, 4, 5, 11, 13, 18, 25, 37, 38], "yifan": [1, 2, 5, 25], "yih": 5, "yiliang": 2, "yilmaz": [5, 23], "yime": 7, "yin": [7, 16, 17, 23], "ying": [2, 13], "yingqi": 5, "yingqian": [1, 25], "yingyu": 12, "yinhan": [7, 10, 11], "yishi": 2, "yisong": 2, "yix": 5, "yixuan": 2, "yiyang": 2, "yiyuan": 2, "yizhi": 5, "yizhong": 19, "ylabel": 27, "ymainten": [37, 38], "yoav": [8, 12], "yolk": 4, "yong": 16, "yonghui": 7, "yongqiang": 2, "yongt": 20, "yoram": 25, "york": [3, 7], "yoshua": [5, 9], "you": [0, 1, 2, 4, 5, 6, 7, 10, 11, 13, 16, 18, 19, 20, 21, 23, 30, 31, 33, 34, 36, 37, 38], "you_retriev": 38, "youbi": 25, "youn": 13, "your": [4, 10, 16, 19, 20, 22, 23, 37, 38], "yourself": [4, 20], "youtub": 38, "youtube_metadata": 38, "youtube_transcript": 38, "ystem": [1, 6, 8, 11], "ytick": 27, "yu": [1, 2, 5, 7, 13, 22, 23], "yuan": [2, 7, 25], "yuandong": 1, "yuanzhi": [12, 17, 23], "yuchen": [2, 5], "yuduan": 2, "yue": [2, 23], "yuheng": 2, "yujia": 2, "yukun": 2, "yun": [1, 2, 5, 19, 20, 23, 25], "yunchang": [1, 11], "yunfan": [2, 20], "yunfeng": 1, "yuntao": 22, "yunxian": 2, "yunxuan": 23, "yupeng": [1, 25], "yuqe": 13, "yuri": [1, 25], "yushuo": [1, 25], "yusuk": 18, "yutaka": 18, "yute": 2, "yuxi": 20, "yuxiang": 2, "yuxin": 5, "yuxiong": 21, "yuxuan": 2, "yuyang": 2, "yuyu": 5, "yyhbz24": [1, 21], "z": [2, 4, 5, 6, 7, 10, 12, 13, 22, 23, 37, 38], "z_": [4, 5, 14, 25], "z_g": 12, "z_i": [4, 7, 14], "z_j": [4, 7, 14], "zaharia": [4, 5, 20], "zamani": [4, 5], "zamani2018neur": 4, "zapier": 38, "zaragoza": 5, "zcpdemo": 38, "zehui": 2, "zemlyanskii": 1, "zendesk": [4, 38], "zeng": 2, "zenguard": 38, "zep": 38, "zephyr": 38, "zephyr_query_engin": 38, "zepindexdemo": 38, "zeqiu": 19, "zero": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 20, 23, 25, 27, 30, 32, 35, 36], "zero_grad": [32, 33, 34, 35], "zero_point": 13, "zeropoint": 13, "zeroshot": 13, "zettlemoy": [7, 10, 11, 13], "zewen": 7, "zeyuan": 23, "zha": 2, "zhai": [4, 11], "zhang": [1, 2, 5, 11, 13, 16, 17, 20, 21, 22, 23, 25], "zhangli": 2, "zhao": [1, 2, 5, 20, 23, 25], "zhaopeng": 11, "zhe": [2, 5], "zhean": 2, "zhen": [2, 5, 19, 23], "zhenda": 2, "zheng": [1, 2, 11, 13, 17, 21, 22], "zhenghao": 5, "zhengyan": [2, 23], "zhenzhong": [7, 11], "zhewen": 2, "zhibin": 2, "zhicheng": 2, "zhifeng": 7, "zhigang": 2, "zhihong": 2, "zhipeng": [1, 2, 25], "zhipuai": 38, "zhiqe": 7, "zhiyu": [2, 22], "zhiyuan": 5, "zhongtao": 23, "zhongyu": 2, "zhou": [1, 2, 5, 7, 10, 17, 18, 22, 23, 25], "zhouhong": 20, "zhu": [2, 4, 19, 23], "zhuang": [5, 13], "zhuohan": 13, "zhuoshu": 2, "zhuyun": [5, 20, 23], "zican": [1, 25], "ziegler": 22, "zihui": 2, "zijia": 2, "zijun": 2, "zikang": [1, 25], "zilin": 2, "zilliz": 38, "zimbabw": 12, "zip": [32, 33, 34], "ziwei": 2, "ziyang": 2, "ziyi": 2, "zizheng": 2, "zlcf24": 23, "zmc": 17, "zoph": [1, 2, 23], "zou": 2, "zpj": 20, "zqh": [4, 5], "zs19": 1, "zulip": 38, "zyte": 38, "zyte_serp": 38, "zyteserpdemo": 38, "zzl": [1, 25], "\u00e1": [7, 25], "\u00e4": 5, "\u00e8": [22, 25], "\u00e9": [5, 7, 9, 22], "\u00ed": 7, "\u00fc": [5, 8], "\u011f": 5, "\u0142": [5, 11], "\u4f7f\u5176\u80fd\u591f\u6839\u636e\u4e0d\u540c\u4efb\u52a1\u9700\u6c42\u8c03\u6574\u751f\u6210\u884c\u4e3a": [], "\u5177\u4f53\u800c\u8a00": [], "\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u68c0\u7d22\u64cd\u4f5c": [], "\u5219\u66f4\u8fdb\u4e00\u6b65": [], "\u521b\u65b0": [], "\u53cd\u601dtoken\u751f\u6210": [], "\u5728\u751f\u6210\u7b54\u6848\u540e": [], "\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d": [], "\u5927\u6a21\u578brag": [], "\u5982retriev": [], "\u5e76\u5e76\u884c\u5904\u7406\u591a\u4e2a\u68c0\u7d22\u5230\u7684\u6bb5\u843d": [], "\u5e76\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u63d0\u9ad8\u751f\u6210\u7b54\u6848\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6574\u4f53\u8d28\u91cf": [], "\u6309\u9700\u68c0\u7d22": [], "\u652f\u6301\u5ea6\u548c\u6574\u4f53\u6548\u7528": [], "\u6839\u636e\u53cd\u601dtoken\u7684\u6307\u793a": [], "\u68c0\u7d22\u589e\u5f3a": [], "\u6a21\u578b\u4f1a\u751f\u6210\u7279\u6b8a\u7684\u53cd\u601dtoken": [], "\u6a21\u578b\u51b3\u5b9a\u662f\u5426\u9700\u8981\u8fdb\u4e00\u6b65\u68c0\u7d22\u76f8\u5173\u6587\u6863": [], "\u6a21\u578b\u5229\u7528\u53cd\u601dtoken\u8fdb\u884c\u81ea\u6211\u8bc4\u4f30": [], "\u6b64\u5916": [], "\u751f\u6210\u4e0e\u8bc4\u4f30": [], "\u8bc4\u4f30\u68c0\u7d22\u6587\u6863\u7684\u76f8\u5173\u6027": [], "\u8fd8\u5173\u6ce8\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u63a7\u6027\u548c\u53cd\u601d\u80fd\u529b": [], "\u8fd9\u4e9btoken\u5206\u522b\u7528\u4e8e\u6307\u793a\u662f\u5426\u9700\u8981\u68c0\u7d22": [], "\u9009\u62e9\u6700\u4f73\u8f93\u51fa": [], "\u901a\u8fc7\u5f15\u5165\u81ea\u6211\u53cd\u601d\u673a\u5236\u6765\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf": []}, "titles": ["<span class=\"section-number\">1. </span>Introduction: LLM in the Age of AI", "<span class=\"section-number\">9. </span>LLM Architectures Fundamentals", "<span class=\"section-number\">10. </span>MoE Sparse Architectures (WIP)", "<span class=\"section-number\">27. </span>Application of LLM in IR (WIP)", "Neural text ranking and information retrieval", "<span class=\"section-number\">26. </span>Information Retrieval and Text Ranking", "<span class=\"section-number\">8. </span>GPT Series", "<span class=\"section-number\">6. </span>BERT", "<span class=\"section-number\">2. </span>Language Models", "<span class=\"section-number\">3. </span>Early Neural Language Models", "<span class=\"section-number\">7. </span>Seq2Seq: T5 and BART", "<span class=\"section-number\">5. </span>Transformers", "<span class=\"section-number\">4. </span>Word Embeddings", "<span class=\"section-number\">21. </span>Inference Acceleration (WIP)", "<span class=\"section-number\">20. </span>Decoding", "Multimodality fundamentals", "Vision Language Pretraining", "<span class=\"section-number\">23. </span>Advanced Prompting Techniques", "<span class=\"section-number\">22. </span>Basic Prompting", "<span class=\"section-number\">25. </span>Advanced RAG (WIP)", "<span class=\"section-number\">24. </span>RAG", "<span class=\"section-number\">16. </span>LLM Training Acceleration (WIP)", "<span class=\"section-number\">14. </span>LLM Alignement and Preference Learning", "<span class=\"section-number\">13. </span>LLM Finetuning", "<span class=\"section-number\">15. </span>*Reinforcement Learning Essentials", "<span class=\"section-number\">12. </span>LLM Training Fundamentals", "&lt;no title&gt;", "Analysis of Queries", "markmap", "Table of Contents", "<span class=\"section-number\">10. </span>*Annotated LLama", "<span class=\"section-number\">11. </span>*Lab: Minimal LLama", "*Lab: Instruction Finetuning", "<span class=\"section-number\">19. </span>*Annotated DPO Training", "<span class=\"section-number\">18. </span>*Lab: Annotated Finetuning", "<span class=\"section-number\">17. </span>*Lab: LLM Pretraining", "Prompting Lab", "&lt;no title&gt;", "&lt;no title&gt;"], "titleterms": {"": 8, "0": 4, "1": [4, 6], "175b": 23, "1982": [], "2": [4, 6, 16, 22], "200": 6, "3": [4, 6, 23], "4": 4, "5": 4, "A": [4, 20, 23], "And": [5, 7], "As": 5, "For": [5, 21], "In": [5, 17], "It": 7, "Of": [8, 11], "On": [5, 8], "One": 21, "The": [0, 1, 4, 7, 8, 11, 12, 13, 14, 21, 22, 23, 24], "To": 5, "about": 0, "absolut": 1, "acceler": [13, 21], "accur": 22, "accuraci": [6, 23], "across": 10, "action": 24, "activ": 21, "ad": [4, 5], "adagrad": 25, "adam": [21, 25], "adamw": 25, "adapt": [23, 25], "add": 8, "advanc": [5, 13, 17, 19, 20], "ag": 0, "agent": [19, 29], "ai": 0, "albert": 7, "algorithm": [13, 22, 24, 25], "alibi": 1, "alic": [], "align": [4, 22], "alloc": 21, "alpha": 8, "among": [6, 20], "an": 4, "analysi": [10, 11, 27], "anatomi": [7, 11], "annot": [30, 33, 34], "answer": [4, 5, 6], "ap": 4, "appear": 6, "appendix": 21, "applic": [3, 16, 29], "approach": [4, 20, 23], "approxim": [4, 5], "ar": [4, 6, 7], "architectur": [1, 2, 4, 5, 7, 11, 16, 29, 32, 35], "arithmet": 6, "around": 6, "articl": 6, "aspect": 22, "assum": 4, "assumpt": 13, "attent": [1, 11, 13, 30, 31, 32, 33, 34, 35, 36], "attribut": 5, "augment": 20, "averag": 4, "avoid": [], "awar": [1, 4, 5], "awq": 13, "b": 23, "back": [8, 17], "balanac": 2, "balanc": 2, "bart": 10, "base": [4, 5, 12, 18, 19, 23, 24], "basic": [1, 4, 13, 14, 18, 20, 23], "batch": [4, 5], "bay": 4, "bbpe": 1, "beam": 14, "begin": 4, "behavior": 14, "below": [], "benchmark": [4, 5, 7, 8, 23], "berkelei": [], "bert": [4, 5, 7], "bertbas": 7, "bertlarg": 7, "beta": 1, "between": 5, "bi": [4, 5], "bia": 8, "bibliographi": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25], "bipartit": 4, "blender": 4, "blip": 16, "block": 13, "bm25": [4, 5], "bm25f": 4, "bob": [], "book": [0, 6], "bootstrap": 23, "bpe": 1, "branch": 11, "breadown": 1, "breakdown": [1, 11, 13], "build": 4, "byte": 1, "cach": 13, "can": [6, 22], "candid": 4, "car": [4, 5], "case": [8, 13], "categor": [3, 20], "caveat": 8, "cbow": 12, "chain": 18, "challeng": [4, 5, 13, 20], "channel": 13, "char": 4, "checkpoint": 21, "choic": [1, 8, 17, 25], "choos": 20, "chunk": [1, 20], "classic": [4, 5], "classif": 18, "clean": 25, "clear": 4, "clip": 16, "close": 6, "cluster": [4, 5], "cnn": [4, 5], "code": [4, 5], "coffe": [], "coil": 4, "colbert": [4, 5], "collect": [3, 22], "collis": 5, "combin": [13, 17, 25], "common": 6, "commonli": 7, "commun": 21, "compar": 7, "comparis": 23, "comparison": [4, 6, 10, 11, 23], "complex": [14, 20], "compon": 21, "componen": [2, 7], "composit": 1, "compress": 13, "comput": [1, 4, 5, 7, 11, 13, 14], "concept": [13, 20], "configur": [1, 7], "connect": 5, "consid": [4, 20], "consider": [2, 10, 16], "consist": [10, 17], "construct": 4, "content": 29, "context": [1, 4, 5, 17, 18, 20], "contextu": [4, 5], "continu": 25, "contrast": 12, "control": [14, 20], "convent": 11, "converg": 24, "convers": 20, "corpu": 6, "correct": [4, 19], "correspond": 4, "cort": 4, "cost": 13, "cot": [17, 18], "covid": 4, "crag": 19, "criterion": 24, "critic": 22, "cross": [4, 5, 8], "ct": [4, 5], "cumul": [4, 5], "d_": 4, "data": [4, 5, 20, 21, 22, 25, 32, 33, 34, 35], "dataset": [4, 5, 8], "dc": [4, 5], "decai": 25, "decis": [22, 24], "decod": [11, 14, 30, 31, 33, 34, 36], "deep": [4, 5], "deepseek": 2, "deepspe": 21, "demonstr": 10, "denois": [4, 5], "dens": [1, 2, 4, 5, 20], "depend": 4, "dequant": 13, "deriv": 8, "descent": 25, "design": [16, 19], "detail": 16, "develop": 11, "devic": 21, "diagon": 13, "differ": [11, 20, 21, 23], "dimension": 4, "discount": [4, 5, 8], "discuss": [4, 20, 22], "distanc": [4, 5], "distil": [3, 4, 5, 7], "distillbert": 7, "distribut": 21, "divers": 20, "doc": [3, 5], "document": [4, 5, 20, 27], "doe": 1, "domain": [4, 5], "down": 12, "downstream": 16, "dpo": [22, 33], "drive": 22, "drmm": 4, "dropout": 11, "dssm": [4, 5], "dual": [1, 4, 5], "duet": 4, "duo": [4, 5], "dure": 21, "dynam": [4, 5, 17], "e": 7, "earli": 9, "effect": 22, "effici": [4, 5, 7, 23], "electra": 7, "elmo": 7, "emb": 3, "embed": [1, 3, 4, 5, 7, 12, 30, 31, 33, 34, 36], "encod": [1, 4, 5, 7, 11], "end": 4, "engin": 4, "enhanc": [4, 20], "enrich": 4, "ensembl": [4, 5, 17], "entri": [32, 35], "entropi": 8, "error": [4, 13, 24], "essenti": 24, "estim": [1, 8, 12, 24], "evalu": [4, 5, 7, 8, 20, 22, 24], "exact": [4, 5], "exampl": [1, 4, 5, 12, 17, 20, 24], "exhaust": [4, 5], "expans": [4, 5, 25], "exploit": 22, "explor": 22, "extend": 1, "extract": [18, 19], "extrem": 7, "factor": 20, "fals": [4, 5], "featur": 4, "feed": 9, "feedback": [3, 4], "feedforward": 11, "few": 18, "ffn": [1, 30, 31, 32, 33, 34, 35, 36], "file": [4, 5], "fill": 13, "fine": [6, 7, 10, 20, 23], "finetun": [20, 23, 32, 34], "finit": 24, "five": 12, "float": 21, "flop": 1, "form": [], "forward": [1, 9], "found": [], "foundat": 29, "fp8": 13, "frac": 4, "framework": [4, 5, 13, 20, 24], "free": [2, 24], "frequent": 12, "from": [1, 4, 5, 22], "function": [4, 5, 23, 24], "fundament": [1, 2, 4, 5, 13, 14, 15, 20, 25], "further": 20, "fuse": 16, "fusion": 4, "g_k": 25, "gain": [4, 5], "gamma": [1, 22], "gefe": 3, "gener": [3, 4, 6, 10, 13, 17, 20, 22], "given": 4, "glove": 12, "glue": 23, "gpt": [6, 23], "gptq": 13, "gpu": 21, "gqa": [1, 13], "gradient": 25, "gram": [4, 8, 12], "granular": [13, 20], "graph": [4, 19, 20], "graphrag": 19, "greedi": 14, "group": 1, "groupwis": 13, "happen": 13, "hard": [4, 5], "hash": 5, "have": 4, "head": 1, "hessian": 13, "heurist": [4, 5], "hierarch": [4, 5], "high": 4, "hoc": [4, 5], "how": 22, "human": 6, "hybrid": 4, "hyperparamet": 7, "hypothesi": 23, "i": [1, 4, 5, 11, 12, 13, 22], "identifi": 6, "idf": 5, "ii": [4, 5, 12], "imag": 16, "impact": 4, "imperfect": 7, "implement": [5, 16, 22], "implicit": 22, "import": [4, 5, 22, 25], "improv": [22, 24], "increas": 4, "index": [4, 5, 20], "infer": [13, 19, 23, 29], "infil": 10, "inform": [4, 5, 29], "initi": 23, "input": [7, 11], "instruct": [16, 18, 23, 32], "insturct": 23, "int8": 13, "interact": 4, "interpol": [1, 4], "introduct": [0, 4, 5, 6, 7, 16, 29], "invert": [4, 5], "ir": [3, 4, 5], "iter": [22, 24], "k": 14, "katz": 8, "kei": [2, 19], "kl": 5, "knowledg": [4, 5, 19, 20], "knrm": 4, "kv": [1, 13], "l_2": 25, "lab": [31, 32, 34, 35, 36], "label": [4, 5, 22], "lambdanet": 4, "languag": [0, 3, 4, 6, 7, 8, 9, 10, 11, 13, 16, 23, 30, 31, 33, 34, 36], "larg": [0, 5], "law": 23, "layer": [1, 7, 11, 30, 31, 32, 33, 34, 35, 36], "lead": 22, "learn": [4, 5, 17, 18, 22, 24, 25, 33], "learnabl": 4, "left": 4, "legal": 20, "let": 21, "letter": 5, "level": [1, 4, 5], "lingual": 6, "link": 28, "list": [3, 4], "llama": [22, 30, 31, 33, 34, 36], "llm": [0, 1, 3, 13, 18, 20, 21, 22, 23, 25, 29, 32, 35], "lm": 7, "load": 2, "logist": 22, "long": [1, 5, 20], "lora": 23, "loss": [2, 4, 5, 22, 23], "low": 23, "m": [4, 5], "machin": 6, "marco": [4, 5], "markmap": 28, "markov": [22, 24], "mask": [7, 11], "match": [4, 5], "mathrm": 4, "matrix": 13, "mbert": 7, "mdp": [22, 24], "me": 4, "mean": [1, 4], "mechan": 1, "med": 17, "memori": [13, 21], "method": [4, 5, 23, 25], "methodologi": 22, "metric": [4, 5, 8], "mha": 1, "minibatch": 25, "minilm": 7, "minim": [13, 20, 31], "mismatch": 20, "mistral": 1, "mix": 21, "mixtral": [], "mixtur": 25, "mle": 8, "mmlu": 17, "mobilebert": 7, "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 20, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35, 36], "modern": [4, 5], "modul": [7, 11], "moe": 2, "momentum": 25, "monitor": 22, "mono": [4, 5], "more": 8, "most": [7, 10], "mother": [], "motiv": [1, 2, 4, 5, 8, 9, 19, 20, 22, 23], "movi": 18, "mqa": 1, "mrr": 4, "mse": 5, "mtp": 2, "multi": [1, 4, 5, 6, 20], "multihead": 11, "multilingu": 7, "multimod": 15, "multinli": 23, "multipl": [4, 13, 25], "multistag": [4, 5], "n": [4, 5, 8, 21], "naiv": 4, "natur": [3, 4, 5, 6], "ndcg": [4, 5], "nearest": [4, 5], "necessari": 11, "need": [1, 5], "neg": [4, 5, 12], "neighbor": [4, 5], "network": 13, "neural": [4, 6, 9, 13], "new": 6, "next": 7, "ngram": 5, "nine": 12, "nois": 12, "non": [4, 5], "nonlinear": 1, "norm": [1, 30, 31, 33, 34, 36], "normal": [1, 4, 5], "notat": 24, "note": [4, 5], "nprf": 4, "nq": [4, 5], "nsp": 7, "ntk": 1, "number": [1, 5, 21], "nv": 3, "ob": 13, "object": [4, 5, 10, 20], "off": [8, 13], "offlin": 4, "one": 21, "onli": [4, 22], "onlin": [4, 5], "oov": 8, "open": [4, 5], "oper": 21, "opportun": [4, 5], "optim": [3, 12, 20, 21, 25], "other": 23, "out": 8, "output": 11, "over": 22, "overal": [4, 11, 22], "overview": [1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 16, 21, 22, 23, 24, 25], "p": 14, "page": 13, "pair": [4, 5, 6], "pairwis": [4, 5], "paper": 4, "paradigm": [4, 5], "parallel": 21, "paramet": [1, 7, 8, 23], "pars": 20, "part": 1, "pass": 1, "passag": [4, 5], "peft": 23, "per": 13, "perform": [6, 10, 12, 13, 17], "perplex": 8, "person": 4, "perspect": 4, "phi": 21, "philz": [], "phrase": 4, "pipelin": [4, 5], "point": [4, 5], "pointwis": [4, 5, 11], "polici": [22, 24], "polyencod": 4, "popular": [4, 5], "posit": [1, 4, 5, 11, 22], "postion": 1, "ppo": 22, "practic": [4, 8, 20, 22], "pre": [4, 7, 10, 13], "precis": [4, 5, 21], "predic": [], "predict": [4, 5, 7, 25], "prefer": [22, 33], "prefix": 23, "preliminari": 22, "preprocess": 4, "pretrain": [6, 7, 10, 11, 16, 25, 35], "principl": [4, 5], "probabilist": 4, "problem": [4, 12], "process": [4, 21, 22, 24], "product": [4, 5], "program": 18, "prompt": [13, 17, 18, 20, 23, 29, 36], "properti": [1, 24], "provid": [], "prune": 13, "pseudo": [4, 5], "put": 7, "q": 24, "q_": 4, "qualiti": [20, 22], "quant": 13, "quantiz": [4, 5, 13], "queri": [1, 3, 4, 5, 20, 27], "question": [4, 5, 6], "qw": 4, "qwen2": 1, "r": [7, 23], "raft": 20, "rag": [3, 19, 20, 29], "random": [4, 5], "rank": [3, 4, 5, 23], "ranker": [3, 4, 5], "ranknet": 4, "rare": 8, "rate": 25, "re": 4, "reason": [6, 20], "recal": [4, 5], "reciproc": 4, "recommend": 4, "recurr": [9, 11], "recurs": 24, "reflect": 19, "regress": [4, 5, 22], "reinforc": [22, 24], "relat": 24, "relationship": [8, 12, 20, 22, 24], "relax": 4, "relev": 4, "represent": [4, 5], "requir": [13, 21], "rerank": 20, "residu": 5, "respons": [22, 23], "result": [5, 20, 23], "retriev": [3, 4, 5, 19, 20, 29], "review": 18, "reward": [22, 24], "rewrit": [4, 5, 20], "right": 4, "rightarrow": 4, "rise": 0, "rl": 22, "rlhf": 22, "rm": [1, 30, 31, 33, 34, 36], "rm3": 4, "rmsprop": 25, "robert": 23, "robust": [4, 5], "root": 1, "rope": 1, "rotari": 1, "rotori": [30, 31, 33, 34, 36], "sampl": [4, 5, 7, 12, 14], "scale": [5, 23], "schedul": 25, "scheme": [4, 5], "scope": 4, "score": 4, "search": [4, 5, 14], "searcher": 4, "segment": 4, "select": 4, "self": [1, 17, 19], "semant": [4, 5, 12], "sens": 6, "sentenc": 7, "sentiment": 18, "seq2seq": 10, "sequenc": [4, 11], "seri": 6, "serp": 3, "serv": 4, "set": 7, "sft": 22, "share": 5, "shop": [], "short": 6, "shot": 18, "shuffl": 17, "signal": 16, "similar": [4, 5], "simpl": [4, 8, 22], "singl": 4, "site": 28, "size": [5, 21, 25], "skip": 12, "slide": 1, "smooth": [8, 13, 22], "snrm": 4, "softwar": [4, 5], "some": [], "sota": 6, "sourc": [20, 25], "space": [4, 5], "spars": [2, 4, 5, 20], "sparterm": 4, "special": 8, "specif": 4, "speed": 13, "speical": 13, "spell": 4, "speller": 4, "split": 20, "squar": 1, "stack": [30, 31, 33, 34, 36], "stage": 21, "standard": 13, "star": 8, "state": [21, 24], "statement": 4, "static": [4, 5], "statist": 8, "step": 17, "stochast": 25, "stop": 24, "stopword": [], "storag": [4, 5, 21], "strategi": [4, 5, 7, 16], "stream": 4, "strong": 10, "studi": 23, "subject": [], "subword": 12, "suggest": 4, "summari": [11, 21], "superglu": 6, "supervis": 6, "svd": 12, "switch": 2, "syntact": 12, "system": [4, 5], "t5": [4, 10], "tabl": 29, "task": [4, 5, 6, 7, 10, 17, 18], "teacher": [4, 5], "techniqu": [4, 8, 13, 17, 21], "temperatur": 14, "tensor": [13, 21], "terc": [4, 5], "term": [4, 5], "test": [31, 32, 33, 34, 35], "text": [4, 5, 6, 10, 18], "tf": 5, "theorem": 24, "thi": 0, "thought": 18, "time": 4, "tinybert": 7, "todai": 7, "togeth": [7, 17, 25], "token": [1, 4, 5, 25], "tokenzi": 1, "top": 14, "topic": [4, 5], "total": 21, "track": [4, 5], "trade": [8, 13], "tradit": [4, 5], "train": [4, 5, 7, 10, 16, 21, 22, 25, 29, 32, 33, 34, 35], "transform": [1, 2, 4, 5, 11, 32, 35], "translat": 6, "trec": [4, 5], "triplet": [4, 5], "tune": [6, 7, 10, 20, 23], "turn": 20, "tutori": 4, "two": [4, 5, 7], "ty": 1, "type": [4, 5, 12, 21], "uhd": 4, "ultra": 4, "understand": [3, 4, 5, 10, 16, 20, 23], "uni": 4, "unifi": 4, "unigram": [4, 8], "unsupervis": 6, "up": 13, "url": 4, "us": [1, 4, 5, 7, 21, 22], "util": 20, "v": [2, 12, 18, 20, 22, 24], "v3": 2, "valid": 23, "valu": 24, "vari": 10, "varianc": 8, "variant": [1, 22], "variat": [4, 5], "variou": 7, "vector": [4, 5], "via": [1, 4, 5, 13, 21], "vision": [16, 29], "visual": 12, "vocabulari": [1, 5, 8], "vocalbulari": 20, "volumn": 21, "we": [1, 4, 5], "weight": [1, 5, 11, 25], "what": [1, 13], "when": 20, "where": 13, "whether": 6, "which": 1, "why": [1, 4, 5], "wikisql": 23, "window": 1, "wip": [2, 3, 13, 19, 21], "wise": [4, 5], "word": [4, 5, 6, 8, 12], "word2vec": 12, "work": 22, "xlm": 7, "yarn": 1, "zero": [18, 21]}})